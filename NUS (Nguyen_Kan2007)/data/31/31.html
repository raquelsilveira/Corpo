<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
<HEAD>
<TITLE>Conference in Research and Practice in Information Technology - Style Guide</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<META name="generator" content="pdftohtml 0.35beta">
<META name="author" content="John Roddick">
<META name="date" content="2002-11-14T15:26:02+00:00">
</HEAD>
<BODY bgcolor="#A0A0A0" vlink="blue" link="blue">
<!-- Page 1 -->
<a name="1"></a>
<DIV style="position:relative;width:892;height:1263;">
<STYLE type="text/css">
<!--
	.ft0{font-size:22px;font-family:Times;color:#000000;}
	.ft1{font-size:16px;font-family:Times;color:#000000;}
	.ft2{font-size:13px;font-family:Times;color:#000000;}
	.ft3{font-size:13px;font-family:Courier;color:#000000;}
	.ft4{font-size:11px;font-family:Courier;color:#000000;}
	.ft5{font-size:11px;font-family:Times;color:#000000;}
	.ft6{font-size:14px;font-family:Times;color:#000000;}
	.ft7{font-size:7px;font-family:Times;color:#000000;}
	.ft8{font-size:12px;font-family:Times;color:#000000;}
	.ft9{font-size:6px;font-family:Times;color:#000000;}
	.ft10{font-size:11px;line-height:15px;font-family:Times;color:#000000;}
	.ft11{font-size:13px;line-height:17px;font-family:Times;color:#000000;}
	.ft12{font-size:13px;line-height:18px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="892" height="1263" src="31001.png" alt="background image">
<DIV style="position:absolute;top:92;left:86"><nobr><span class="ft0"><b>An empirical comparison of supervised machine learning techniques in </b></span></nobr></DIV>
<DIV style="position:absolute;top:119;left:372"><nobr><span class="ft0"><b>bioinformatics </b></span></nobr></DIV>
<DIV style="position:absolute;top:169;left:298"><nobr><span class="ft1"><b>Aik Choon TAN and David GILBERT </b></span></nobr></DIV>
<DIV style="position:absolute;top:194;left:242"><nobr><span class="ft2">Bioinformatics Research Centre, Department of Computing Science </span></nobr></DIV>
<DIV style="position:absolute;top:211;left:233"><nobr><span class="ft2">12 Lilybank Gardens, University of Glasgow, Glasgow G12 8QQ, UK. </span></nobr></DIV>
<DIV style="position:absolute;top:240;left:311"><nobr><span class="ft3">{actan, drg}@brc.dcs.gla.ac.uk</span></nobr></DIV>
<DIV style="position:absolute;top:241;left:581"><nobr><span class="ft4">  </span></nobr></DIV>
<DIV style="position:absolute;top:264;left:446"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:280;left:86"><nobr><span class="ft6"><b>Abstract </b></span></nobr></DIV>
<DIV style="position:absolute;top:309;left:86"><nobr><span class="ft10">Research in bioinformatics is driven by the experimental data. <br>Current biological databases are populated by vast amounts of <br>experimental data. Machine learning has been widely applied to <br>bioinformatics and has gained a lot of success in this research <br>area.  At present, with various learning algorithms available in the <br>literature, researchers are facing difficulties in choosing the best <br>method that can apply to their data. We performed an empirical <br>study on 7 individual learning systems and 9 different combined <br>methods on 4 different biological data sets, and provide some <br>suggested issues to be considered when answering the following <br>questions: (i) How does one choose which algorithm is best <br>suitable for their data set? (ii) Are combined methods better than <br>a single approach? (iii) How does one compare the effectiveness <br>of a particular algorithm to <A href="31.html#1">the others? </a></span></nobr></DIV>
<DIV style="position:absolute;top:537;left:86"><nobr><span class="ft5">Keywords:  </span></nobr></DIV>
<DIV style="position:absolute;top:536;left:156"><nobr><span class="ft2">Supervised machine learning, bioinformatics, </span></nobr></DIV>
<DIV style="position:absolute;top:553;left:86"><nobr><span class="ft2">ensemble methods, performance evaluation. </span></nobr></DIV>
<DIV style="position:absolute;top:588;left:86"><nobr><span class="ft6"><b>1 Introduction </b></span></nobr></DIV>
<DIV style="position:absolute;top:616;left:86"><nobr><span class="ft11">In the post-genome era, research in bioinformatics has <br>been overwhelmed by the experimental data. The <br>complexity of biological data ranges from simple strings <br>(nucleotides and amino acids sequences) to complex <br>graphs (biochemical networks); from 1D (sequence data) <br>to 3D (protein and RNA structures). Considering the <br>amount and complexity of the data, it is becoming <br>impossible for an expert to compute and compare the <br>entries within the current databases. Thus, machine <br>learning and artificial intelligence techniques have been <br>widely applied in this domain to discover and mine the <br>knowledge in the databases. Quoting from Baldi and <br>Brunak (Baldi and Brunak, 2001) "As a result, the need for <br>computer / statistical / machine learning techniques is <br>today stronger rather than weaker." </span></nobr></DIV>
<DIV style="position:absolute;top:884;left:86"><nobr><span class="ft11">Shavlik et al. (Shavlik et al., 1995) described the field of <br>molecular biology as tailor-made for machine learning <br>approaches. This is due to the nature of machine learning <br>approaches that performs well in domains where there is a <br>vast amount of data but little theory ­ this is exactly the <br>situation in bioinformatics.  Since the introduction of <br>machine learning to this field, various algorithms and <br>methods have been produced and applied to study different <br>data sets. Most of these studies compare a `new' algorithm </span></nobr></DIV>
<DIV style="position:absolute;top:275;left:457"><nobr><span class="ft11">with the conventional ones, asserting the effectiveness and <br>efficiencies of their methods in particular data sets. The <br>variety of learning algorithms currently available for the <br>researchers are enormous and the main problems faced by <br>researchers are: (i) How does one choose which algorithm <br>is best suitable for their data set? (ii) Are combined <br>methods better than a single approach? (iii) How does one <br>compare the effectiveness of a particular algorithm to the <br>others?  </span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:86"><nobr><span class="ft2">                                                           </span></nobr></DIV>
<DIV style="position:absolute;top:1079;left:86"><nobr><span class="ft10">Copyright © 2003, Australian Computer Society, Inc.  This paper <br>appeared at First Asia-Pacific Bioinformatics Conference, <br>Adelaide, Australia.  Conferences in Research and Practice in <br>Information Technology, Vol. 19. Yi-Ping Phoebe Chen, Ed. <br>Reproduction for academic, not-for profit purposes permitted <br>provided this text is included.</span></nobr></DIV>
<DIV style="position:absolute;top:1155;left:247"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:439;left:457"><nobr><span class="ft11">The objective of this study is to provide some suggestions <br>for the community by answering the above questions. This <br>paper is organised as follows. Section 2 presents a brief <br>summary of machine learning. Section 3 outlines the <br>materials and methods used in this study. Section 4 <br>presents the results and discussion, and the final section <br>summarises this work. </span></nobr></DIV>
<DIV style="position:absolute;top:578;left:457"><nobr><span class="ft6"><b>2 </b></span></nobr></DIV>
<DIV style="position:absolute;top:578;left:490"><nobr><span class="ft6"><b>Machine Learning Background </b></span></nobr></DIV>
<DIV style="position:absolute;top:606;left:457"><nobr><span class="ft11">A machine learning algorithm is one that can learn from <br>experience (observed examples) with respect to some class <br>of tasks and a performance measure. (Mitchell, 1997). <br>Machine learning methods are suitable for molecular <br>biology data due to the learning algorithm's ability to <br>construct classifiers/hypotheses that can explain complex <br>relationships in the data. The classifiers or hypotheses can <br>then be interpreted by a domain expert who suggests some <br>wet-lab experiments to validate or refute the hypotheses. <br>This feedback loop between in silico and in vivo / in vitro <br>experiments accelerates the knowledge discovery process <br>over the biological data.  This feedback is an important <br>characteristic of machine learning in bioinformatics. </span></nobr></DIV>
<DIV style="position:absolute;top:839;left:457"><nobr><span class="ft12">Generally, there are two types of learning schemes in <br>machine learning: supervised learning where the output <br>has been given a priori labelled or the learner has some <br>prior knowledge of the data; and unsupervised learning <br>where no prior information is given to the learner <br>regarding the data or the output. The overall tasks for the <br>learner are to classify, characterise, and cluster the input <br>data. Classification is the most common task in biological <br>problem where given two different sets of examples, <br>namely positive E</span></nobr></DIV>
<DIV style="position:absolute;top:994;left:565"><nobr><span class="ft7"><i>+</i></span></nobr></DIV>
<DIV style="position:absolute;top:996;left:571"><nobr><span class="ft2"> and negative E</span></nobr></DIV>
<DIV style="position:absolute;top:994;left:663"><nobr><span class="ft7"><i>-</i></span></nobr></DIV>
<DIV style="position:absolute;top:996;left:666"><nobr><span class="ft2"> examples (E</span></nobr></DIV>
<DIV style="position:absolute;top:994;left:743"><nobr><span class="ft7"><i>+</i></span></nobr></DIV>
<DIV style="position:absolute;top:994;left:750"><nobr><span class="ft2">E</span></nobr></DIV>
<DIV style="position:absolute;top:994;left:770"><nobr><span class="ft7"><i>-</i></span></nobr></DIV>
<DIV style="position:absolute;top:996;left:774"><nobr><span class="ft2"> =</span></nobr></DIV>
<DIV style="position:absolute;top:994;left:785"><nobr><span class="ft2">), </span></nobr></DIV>
<DIV style="position:absolute;top:1013;left:457"><nobr><span class="ft11">the learner needs to construct a classifier to distinguish <br>between the positive examples and the negative set. This <br>classifier can then be used as the basis for classifying as <br>yet unseen data in the future. Usually, for a supervised <br>classification problem, the training examples are in the <br>form of a set of tuples </span></nobr></DIV>
<DIV style="position:absolute;top:1102;left:604"><nobr><span class="ft8">{(</span></nobr></DIV>
<DIV style="position:absolute;top:1099;left:734"><nobr><span class="ft2"> where  x</span></nobr></DIV>
<DIV style="position:absolute;top:1102;left:721"><nobr><span class="ft8">)}</span></nobr></DIV>
<DIV style="position:absolute;top:1102;left:695"><nobr><span class="ft8">,</span></nobr></DIV>
<DIV style="position:absolute;top:1102;left:676"><nobr><span class="ft8">(</span></nobr></DIV>
<DIV style="position:absolute;top:1102;left:652"><nobr><span class="ft8">),...,</span></nobr></DIV>
<DIV style="position:absolute;top:1102;left:628"><nobr><span class="ft8">,</span></nobr></DIV>
<DIV style="position:absolute;top:1111;left:641"><nobr><span class="ft9">1</span></nobr></DIV>
<DIV style="position:absolute;top:1111;left:623"><nobr><span class="ft9">1</span></nobr></DIV>
<DIV style="position:absolute;top:1112;left:716"><nobr><span class="ft9">j</span></nobr></DIV>
<DIV style="position:absolute;top:1111;left:709"><nobr><span class="ft9">n</span></nobr></DIV>
<DIV style="position:absolute;top:1111;left:689"><nobr><span class="ft9">n</span></nobr></DIV>
<DIV style="position:absolute;top:1111;left:647"><nobr><span class="ft9">j</span></nobr></DIV>
<DIV style="position:absolute;top:1102;left:702"><nobr><span class="ft8">y</span></nobr></DIV>
<DIV style="position:absolute;top:1102;left:682"><nobr><span class="ft8">x</span></nobr></DIV>
<DIV style="position:absolute;top:1102;left:635"><nobr><span class="ft8">y</span></nobr></DIV>
<DIV style="position:absolute;top:1102;left:617"><nobr><span class="ft8">x</span></nobr></DIV>
<DIV style="position:absolute;top:1106;left:788"><nobr><span class="ft7"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:1099;left:791"><nobr><span class="ft2"> is </span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:457"><nobr><span class="ft2">the class label and y</span></nobr></DIV>
<DIV style="position:absolute;top:1132;left:595"><nobr><span class="ft7"><i>ij</i></span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:601"><nobr><span class="ft2"> is the set of attributes for the </span></nobr></DIV>
<DIV style="position:absolute;top:1142;left:457"><nobr><span class="ft2">instances. The task of the learning algorithm is to produce </span></nobr></DIV>
</DIV>
<!-- Page 2 -->
<a name="2"></a>
<DIV style="position:relative;width:892;height:1263;">
<STYLE type="text/css">
<!--
	.ft13{font-size:9px;font-family:Times;color:#000000;}
	.ft14{font-size:10px;font-family:Times;color:#000000;}
	.ft15{font-size:5px;font-family:Times;color:#000000;}
	.ft16{font-size:4px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="892" height="1263" src="31002.png" alt="background image">
<DIV style="position:absolute;top:87;left:86"><nobr><span class="ft11">a classifier (hypothesis, function) to classify the instances <br>into the correct class.  In this study, we only consider <br>supervised machine learning applied to classification. </span></nobr></DIV>
<DIV style="position:absolute;top:157;left:86"><nobr><span class="ft6"><b>3 </b></span></nobr></DIV>
<DIV style="position:absolute;top:157;left:119"><nobr><span class="ft6"><b>Materials and Methodologies  </b></span></nobr></DIV>
<DIV style="position:absolute;top:194;left:86"><nobr><span class="ft6"><b>3.1  Machine learning algorithms </b></span></nobr></DIV>
<DIV style="position:absolute;top:222;left:86"><nobr><span class="ft11">We performed an empirical comparison of rule-based <br>learning systems (Decision trees, One Rule, Decision <br>rules), statistical learning system (Naïve Bayes, Instance <br>Based, SVM and neural networks) and ensemble methods <br>(Stacking, Bagging and Boosting) on the data listed in <br>Table 1 based on the accuracy, positive predicted value, <br>specificity and sensitivity of the learning algorithms. All <br>the learning methods used in this study were obtained from <br>the WEKA machine learning package <br>(http://www.cs.waikato.ac.nz/~ml/weka/).   </span></nobr></DIV>
<DIV style="position:absolute;top:412;left:86"><nobr><span class="ft6"><b>3.2 Data </b></span></nobr></DIV>
<DIV style="position:absolute;top:412;left:165"><nobr><span class="ft6"><b>set </b></span></nobr></DIV>
<DIV style="position:absolute;top:440;left:86"><nobr><span class="ft11">In this study we used the following data sets obtained from <br>UCI machine learning repository (Blake and Merz, 1998). <br>We briefly describe the biological motivation for the data <br>sets; interested readers should refer to the cited papers for <br>details. </span></nobr></DIV>
<DIV style="position:absolute;top:535;left:86"><nobr><span class="ft11">E.coli data set ­ The objective of this data set is to predict <br>the cellular localisation sites of E.coli proteins (Horton and <br>Nakai, 1996).  There are 8 different cellular sites, which <br>are cytoplasm (cp), inner membrane without signal <br>sequence (im), periplasm (pp), inner membrane with <br>uncleavable signal sequence (imU), outer membrane (om), <br>outer membrane lipoprotein (omL), inner membrane <br>lipoprotein (imL) and inner membrane with cleavable <br>signal sequence (imS).  The attributes are signal sequence <br>recognition methods (specifically those of McGeoch and <br>von Heijne), the presence of charge on N-terminus of <br>predicted lipoproteins and 3 different scoring functions on <br>the amino acid contents whether predicted as a outer <br>membrane or inner membrane, cleavable or uncleavable <br>sequence signal. </span></nobr></DIV>
<DIV style="position:absolute;top:803;left:86"><nobr><span class="ft11">Yeast data set ­ The objective is similar to the E.coli data, <br>which is to determine the cellular localisation of the yeast <br>proteins (Horton and Nakai, 1996).  There are 10 different <br>sites, which include: CYT (cytosolic or cytoskeletal); <br>NUC (nuclear); MIT (mitochondrial); ME3 (membrane <br>protein, no N-terminal signal); ME2 (membrane protein, <br>uncleaved signal); ME1 (membrane protein, cleaved <br>signal); EXC (extracellular); VAC (vacuolar); POX <br>(peroxisomal) and ERL (endoplasmic reticulum lumen). <br>The attributes are similar to the E.coli data set with the <br>addition of nuclear localisation information. </span></nobr></DIV>
<DIV style="position:absolute;top:1002;left:86"><nobr><span class="ft11">Promoter data set. The task of the classifier is to predict <br>whether a DNA sequence from E.coli is either a promoter <br>or not (Towell et al., 1990). The input data is a <br>57-nucleotide sequence (A, C, T or G). </span></nobr></DIV>
<DIV style="position:absolute;top:1080;left:86"><nobr><span class="ft11">HIV data set ­ The data set contains 362 octamer protein <br>sequences each of which needs to be classified as an HIV <br>protease cleavable site or uncleavable site (Cai and Chou, <br>1998).  </span></nobr></DIV>
<DIV style="position:absolute;top:92;left:457"><nobr><span class="ft13"><b>Data set </b></span></nobr></DIV>
<DIV style="position:absolute;top:92;left:593"><nobr><span class="ft13"><b>E.coli </b></span></nobr></DIV>
<DIV style="position:absolute;top:92;left:646"><nobr><span class="ft13"><b>Yeast </b></span></nobr></DIV>
<DIV style="position:absolute;top:92;left:699"><nobr><span class="ft13"><b>Promoters </b></span></nobr></DIV>
<DIV style="position:absolute;top:92;left:774"><nobr><span class="ft13"><b>HIV </b></span></nobr></DIV>
<DIV style="position:absolute;top:116;left:457"><nobr><span class="ft13"><b>Continuous Attribute </b></span></nobr></DIV>
<DIV style="position:absolute;top:115;left:593"><nobr><span class="ft13"><b>2 0 57 </b></span></nobr></DIV>
<DIV style="position:absolute;top:115;left:774"><nobr><span class="ft13"><b>8 </b></span></nobr></DIV>
<DIV style="position:absolute;top:139;left:457"><nobr><span class="ft13"><b>Discrete Attribute </b></span></nobr></DIV>
<DIV style="position:absolute;top:139;left:593"><nobr><span class="ft13"><b>5 8 0 </b></span></nobr></DIV>
<DIV style="position:absolute;top:139;left:774"><nobr><span class="ft13"><b>0 </b></span></nobr></DIV>
<DIV style="position:absolute;top:163;left:457"><nobr><span class="ft13"><b>Classes </b></span></nobr></DIV>
<DIV style="position:absolute;top:162;left:593"><nobr><span class="ft13"><b>8 10 2 </b></span></nobr></DIV>
<DIV style="position:absolute;top:162;left:774"><nobr><span class="ft13"><b>2 </b></span></nobr></DIV>
<DIV style="position:absolute;top:186;left:457"><nobr><span class="ft13"><b>Data Size </b></span></nobr></DIV>
<DIV style="position:absolute;top:186;left:593"><nobr><span class="ft13"><b>336 1484 106 </b></span></nobr></DIV>
<DIV style="position:absolute;top:186;left:774"><nobr><span class="ft13"><b>362 </b></span></nobr></DIV>
<DIV style="position:absolute;top:210;left:515"><nobr><span class="ft2">Table 1: Data sets used in this study. </span></nobr></DIV>
<DIV style="position:absolute;top:245;left:457"><nobr><span class="ft6"><b>3.3 Evaluation </b></span></nobr></DIV>
<DIV style="position:absolute;top:273;left:457"><nobr><span class="ft11">We constructed a confusion matrix (contingency table) to <br>evaluate the classifier's performance. Table 2 shows a <br>generic contingency table for a binary class problem. True <br>positives (TP) denote the correct classifications of positive <br>examples. True negatives (TN) are the correct <br>classifications of negative examples. False positives (FP) <br>represent the incorrect classifications of negative <br>examples into class positive and False negatives (FN) are <br>the positive examples incorrectly classified into class <br>negative.  </span></nobr></DIV>
<DIV style="position:absolute;top:455;left:678"><nobr><span class="ft13"><b>Predicted </b></span></nobr></DIV>
<DIV style="position:absolute;top:455;left:544"><nobr><span class="ft13"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:479;left:642"><nobr><span class="ft13"><b>Positive Negative </b></span></nobr></DIV>
<DIV style="position:absolute;top:502;left:554"><nobr><span class="ft13"><b>Positive </b></span></nobr></DIV>
<DIV style="position:absolute;top:502;left:655"><nobr><span class="ft13"><b>TP FN </b></span></nobr></DIV>
<DIV style="position:absolute;top:502;left:487"><nobr><span class="ft13"><b>Actual </b></span></nobr></DIV>
<DIV style="position:absolute;top:526;left:552"><nobr><span class="ft13"><b>Negative </b></span></nobr></DIV>
<DIV style="position:absolute;top:526;left:656"><nobr><span class="ft13"><b>FP TN </b></span></nobr></DIV>
<DIV style="position:absolute;top:550;left:457"><nobr><span class="ft11">Table 2: A contingency table for a binary class <br>problem. </span></nobr></DIV>
<DIV style="position:absolute;top:593;left:457"><nobr><span class="ft11">Based on the contingency table, several measurements can <br>be carried out to evaluate the performance of the induced <br>classifier. The most popular performance evaluation <br>measure used in prediction or classification learning is <br>classifier accuracy which measures the proportion of <br>correctly classified instances; </span></nobr></DIV>
<DIV style="position:absolute;top:697;left:777"><nobr><span class="ft14"><i>FN</i></span></nobr></DIV>
<DIV style="position:absolute;top:697;left:749"><nobr><span class="ft14"><i>FP</i></span></nobr></DIV>
<DIV style="position:absolute;top:697;left:719"><nobr><span class="ft14"><i>TN</i></span></nobr></DIV>
<DIV style="position:absolute;top:697;left:693"><nobr><span class="ft14"><i>TP</i></span></nobr></DIV>
<DIV style="position:absolute;top:680;left:749"><nobr><span class="ft14"><i>TN</i></span></nobr></DIV>
<DIV style="position:absolute;top:680;left:722"><nobr><span class="ft14"><i>TP</i></span></nobr></DIV>
<DIV style="position:absolute;top:696;left:767"><nobr><span class="ft14"><i>+</i></span></nobr></DIV>
<DIV style="position:absolute;top:696;left:739"><nobr><span class="ft14"><i>+</i></span></nobr></DIV>
<DIV style="position:absolute;top:696;left:711"><nobr><span class="ft14"><i>+</i></span></nobr></DIV>
<DIV style="position:absolute;top:687;left:660"><nobr><span class="ft14"><i>Acc</i></span></nobr></DIV>
<DIV style="position:absolute;top:678;left:740"><nobr><span class="ft14"><i>+</i></span></nobr></DIV>
<DIV style="position:absolute;top:686;left:682"><nobr><span class="ft14"><i>=</i></span></nobr></DIV>
<DIV style="position:absolute;top:679;left:803"><nobr><span class="ft2">. </span></nobr></DIV>
<DIV style="position:absolute;top:711;left:457"><nobr><span class="ft11">Positive Predictive Accuracy (PPV, or the reliability of <br>positive predictions of the induced classifier) is computed <br>by</span></nobr></DIV>
<DIV style="position:absolute;top:764;left:540"><nobr><span class="ft14"><i>FP</i></span></nobr></DIV>
<DIV style="position:absolute;top:764;left:515"><nobr><span class="ft14"><i>TP</i></span></nobr></DIV>
<DIV style="position:absolute;top:746;left:528"><nobr><span class="ft14"><i>TP</i></span></nobr></DIV>
<DIV style="position:absolute;top:754;left:475"><nobr><span class="ft14"><i>PPV</i></span></nobr></DIV>
<DIV style="position:absolute;top:763;left:530"><nobr><span class="ft14"><i>+</i></span></nobr></DIV>
<DIV style="position:absolute;top:753;left:504"><nobr><span class="ft14"><i>=</i></span></nobr></DIV>
<DIV style="position:absolute;top:746;left:559"><nobr><span class="ft2">. Sensitivity (S</span></nobr></DIV>
<DIV style="position:absolute;top:753;left:648"><nobr><span class="ft7"><i>n</i></span></nobr></DIV>
<DIV style="position:absolute;top:746;left:653"><nobr><span class="ft2">) measures the fraction of </span></nobr></DIV>
<DIV style="position:absolute;top:782;left:457"><nobr><span class="ft2">actual positive examples that are correctly classified </span></nobr></DIV>
<DIV style="position:absolute;top:817;left:512"><nobr><span class="ft14"><i>FN</i></span></nobr></DIV>
<DIV style="position:absolute;top:817;left:485"><nobr><span class="ft14"><i>TP</i></span></nobr></DIV>
<DIV style="position:absolute;top:800;left:500"><nobr><span class="ft14"><i>TP</i></span></nobr></DIV>
<DIV style="position:absolute;top:816;left:502"><nobr><span class="ft14"><i>+</i></span></nobr></DIV>
<DIV style="position:absolute;top:806;left:475"><nobr><span class="ft14"><i>=</i></span></nobr></DIV>
<DIV style="position:absolute;top:808;left:459"><nobr><span class="ft14"><i>S</i></span></nobr></DIV>
<DIV style="position:absolute;top:815;left:466"><nobr><span class="ft15"><i>n</i></span></nobr></DIV>
<DIV style="position:absolute;top:800;left:532"><nobr><span class="ft2">; while specificity (S</span></nobr></DIV>
<DIV style="position:absolute;top:807;left:661"><nobr><span class="ft7"><i>p</i></span></nobr></DIV>
<DIV style="position:absolute;top:800;left:666"><nobr><span class="ft2">) measures the fraction </span></nobr></DIV>
<DIV style="position:absolute;top:831;left:457"><nobr><span class="ft11">of actual negative examples that are correctly <br>classified</span></nobr></DIV>
<DIV style="position:absolute;top:868;left:568"><nobr><span class="ft13"><b>FP</b></span></nobr></DIV>
<DIV style="position:absolute;top:868;left:541"><nobr><span class="ft13"><b>TN</b></span></nobr></DIV>
<DIV style="position:absolute;top:851;left:554"><nobr><span class="ft13"><b>TN</b></span></nobr></DIV>
<DIV style="position:absolute;top:866;left:559"><nobr><span class="ft13"><b>+</b></span></nobr></DIV>
<DIV style="position:absolute;top:859;left:516"><nobr><span class="ft13"><b>S</b></span></nobr></DIV>
<DIV style="position:absolute;top:849;left:586"><nobr><span class="ft2">.  </span></nobr></DIV>
<DIV style="position:absolute;top:866;left:523"><nobr><span class="ft16"><i>p</i></span></nobr></DIV>
<DIV style="position:absolute;top:857;left:532"><nobr><span class="ft13"><b>=</b></span></nobr></DIV>
<DIV style="position:absolute;top:899;left:457"><nobr><span class="ft6"><b>3.4 Cross-validation </b></span></nobr></DIV>
<DIV style="position:absolute;top:927;left:457"><nobr><span class="ft11">To evaluate the robustness of the classifier, the normal <br>methodology is to perform cross validation on the <br>classifier. Ten fold cross validation has been proved to be <br>statistically good enough in evaluating the performance of <br>the classifier (Witten and Frank, 2000). In ten fold cross <br>validation, the training set is equally divided into 10 <br>different subsets.  Nine out of ten of the training subsets <br>are used to train the learner and the tenth subset is used as <br>the test set. The procedure is repeated ten times, with a <br>different subset being used as the test set. </span></nobr></DIV>
</DIV>
<!-- Page 3 -->
<a name="3"></a>
<DIV style="position:relative;width:892;height:1263;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="892" height="1263" src="31003.png" alt="background image">
<DIV style="position:absolute;top:87;left:86"><nobr><span class="ft6"><b>4 Results </b></span></nobr></DIV>
<DIV style="position:absolute;top:87;left:174"><nobr><span class="ft6"><b>and </b></span></nobr></DIV>
<DIV style="position:absolute;top:87;left:205"><nobr><span class="ft6"><b>Discussion </b></span></nobr></DIV>
<DIV style="position:absolute;top:115;left:86"><nobr><span class="ft11">We summarise our experimental results in Figure 1 and 2. <br>The full analysis of this study is available in <br>http://www.brc.dcs.gla.ac.uk/~actan/APBC2003. </span></nobr></DIV>
<DIV style="position:absolute;top:425;left:437"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:448;left:109"><nobr><span class="ft2">Figure 1. Accuracy vs Positive Predictive Value </span></nobr></DIV>
<DIV style="position:absolute;top:723;left:437"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:746;left:153"><nobr><span class="ft2">Figure 2. Specificity vs Sensitivity </span></nobr></DIV>
<DIV style="position:absolute;top:772;left:86"><nobr><span class="ft11">From the results, we observed that most of the individual <br>learners tend to perform well either in accuracy or <br>specificity. Probably this is due to the induced classifier <br>being able to characterise the negative examples (most of <br>the training sets have large ratio of negative examples <br>compared to positive examples).  Furthermore, the results <br>suggest that combination approaches are in general better <br>at minimising overfitting of the training data. We also <br>observed from this experiment that boosting performs <br>better than bagging.  This is because attributes which are <br>highly important in discriminating between classes are <br>randomly removed by bagging; however they are <br>preserved in boosting and thus contribute to the final <br>voting scheme. The only individual learning system that <br>perform better than the combined methods is Naïve Bayes <br>learning. This may suggest that Naïve Bayes is capable of <br>classifying instances based on simple prior probabilistic <br>knowledge.  In this study SVM does not perform well <br>compared to other methods, probably due to the fact that <br>training data are not separable in the vector space. </span></nobr></DIV>
<DIV style="position:absolute;top:87;left:457"><nobr><span class="ft6"><b>4.1 Rules-of-thumb </b></span></nobr></DIV>
<DIV style="position:absolute;top:115;left:457"><nobr><span class="ft11">In this section, we address the following questions by <br>providing some suggested issues (rules-of-thumb) to be <br>considered when answering them.  </span></nobr></DIV>
<DIV style="position:absolute;top:176;left:457"><nobr><span class="ft11">(i) How does one choose which algorithm is best suitable <br>for their data set?  </span></nobr></DIV>
<DIV style="position:absolute;top:219;left:457"><nobr><span class="ft11">Ratio of the training data ­ From these experiments, we <br>observed that the division of the training data plays a <br>crucial role in determining the performance of the <br>algorithms. If the training TPs and TNs are almost equal in <br>size, the algorithms tend to construct much better <br>classifiers. This observation suggested that the classifier <br>induced from equal size of TP and TN tend to be more <br>robust in classifying the instances. Furthermore, the <br>classifiers generated consider all the discriminative <br>attributes that distinguish between two different classes. If <br>the size of the TP set is small compared to that of TN, most <br>probably the classifier will overfit the positive examples <br>and thus perform poorly in the cross validation stages. </span></nobr></DIV>
<DIV style="position:absolute;top:452;left:457"><nobr><span class="ft11">Attributes ­ Another factor that must be taken into <br>consideration when choosing a learning method is the <br>nature of the attributes. Generally, statistical methods (e.g. <br>SVM, neural networks) tend to perform much better over <br>multi-dimensions and continuous attributes. This is <br>because the learning strategy embedded in these <br>algorithms enables the learners to find a maximal margin <br>that can distinguish different classes in the vector space. <br>By contrast, rule-based systems (e.g. Decision trees, <br>PART) tend to perform better in discrete / categorical <br>attributes. The algorithms of these methods operate in a  <br>top-down manner where the first step is to find the most <br>discriminative attribute that classifies different classes. <br>The process is iterated until most of the instances are <br>classified into their class. </span></nobr></DIV>
<DIV style="position:absolute;top:720;left:457"><nobr><span class="ft11">Credibility vs. Comprehensibility ­ When choosing a <br>machine learning technique, users need to ask themselves <br>what they really want to "discover" from the data. If they <br>are interested in generating understandable hypotheses, <br>then a rule-base learning algorithm should be used instead <br>of statistical ones. Most machine learning algorithms <br>follow Occam's principle when constructing the final <br>hypothesis. According to this principle, the algorithm <br>tends to find the simplest hypotheses by avoiding <br>overfitting the training data. But does this principle still <br>hold in bioinformatics?   In bioinformatics we often wish <br>to explore data and explain results, and hence we are <br>interested in applying intelligent systems to provide an <br>insight to understand the relations between complex data.  <br>The question then arises as to whether we prefer a simple <br>classifier or a highly comprehensible model.  In general, <br>there is a trade off between the credibility and <br>comprehensibility of a model.  Domingos (1999) <br>suggested applying domain constraints as an alternative <br>for avoiding overfitting the data. We agree with <br>Muggleton et al. (1998) that when comparing the <br>performance of learning systems in a bioinformatics <br>context, the hypothesis with better explanatory power is <br>preferable when there exist more than one hypotheses with <br>statistical equivalent predictive accuracy. </span></nobr></DIV>
</DIV>
<!-- Page 4 -->
<a name="4"></a>
<DIV style="position:relative;width:892;height:1263;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="892" height="1263" src="31004.png" alt="background image">
<DIV style="position:absolute;top:87;left:86"><nobr><span class="ft2">(ii) Are combined methods better than a single approach?  </span></nobr></DIV>
<DIV style="position:absolute;top:113;left:86"><nobr><span class="ft11">From the experiments most of the combined methods <br>perform better than the individual learner. This is because <br>none of the individual methods can claim that they are <br>superior to the others due to statistical, computational and <br>representational reasons (Dietterich, 2000).  Every <br>learning algorithm uses a different search strategy.  If the <br>training data is too small, the individual learner can induce <br>different hypotheses with similar performances from the <br>search space. Thus, by averaging the different hypotheses, <br>the combined classifier may produce a good <br>approximation to the true hypotheses. The computational <br>reason is to avoid local optima of individual search <br>strategy. By performing different initial searches and <br>combining the outputs, the final classifier may provide a <br>better approximation to the true hypotheses. Lastly, due to <br>the limited amount of training data, the individual <br>classifier may not represent the true hypotheses. Thus, <br>through considering different classifiers, it may be <br>possible to expand the final classifier to an approximate <br>representation of the true hypotheses. Ensemble learning <br>has been an active research topic in machine learning but <br>not in the bioinformatics community. Since most of the <br>hypotheses induced are from incomplete biological data, it <br>is essential to generate a good approximation by <br>combining individual learners. </span></nobr></DIV>
<DIV style="position:absolute;top:553;left:86"><nobr><span class="ft11"> (iii) How does one compare the effectiveness of a <br>particular algorithm to the others?  </span></nobr></DIV>
<DIV style="position:absolute;top:597;left:86"><nobr><span class="ft11">Predictive accuracy ­ Most of the time, we can find in the <br>literature reports that a learning scheme performs better <br>than another in term of one model's accuracy when <br>applied to a particular data set. From this study, we found <br>that accuracy is not the ultimate measurement when <br>comparing the learner's credibility. Accuracy is just the <br>measurement of the total correctly classified instances. <br>This measurement is the overall error rate, but there can be <br>other measures of the accuracy of a classifier rule. If the <br>training data set has 95 TNs and 5 TPs, by classifying all <br>the instances into a negative class, the classifier still can <br>achieve a 95% accuracy. But the sensitivity and the <br>positive predicted value is 0% (both measurements <br>evaluate the performance in classifying TPs). This means <br>that although the accuracy of the classifier is 95% it still <br>cannot discriminate between the positive examples and the <br>negatives. Thus, when comparing the performance of <br>different classifiers, accuracy as a measure is not enough. <br>Different measures should be evaluated depending on <br>what type of question that the user seeks to answer. See <br>Salzberg (Salzberg, 1999) for a tutorial on comparing <br>classifiers. </span></nobr></DIV>
<DIV style="position:absolute;top:994;left:86"><nobr><span class="ft6"><b>5 Conclusions </b></span></nobr></DIV>
<DIV style="position:absolute;top:1022;left:86"><nobr><span class="ft11">Machine learning has increasingly gained attention in <br>bioinformatics research. With the availability of different <br>types of learning methods, it has become common for the <br>researchers to apply the off-shelf systems to classify and <br>mine their databases. In the research reported in this paper, <br>we have performed a comparison of different supervised <br>machine learning techniques in classifying biological data. <br>We have shown that none of the single methods could </span></nobr></DIV>
<DIV style="position:absolute;top:87;left:457"><nobr><span class="ft11">consistently perform well over all the data sets.  The <br>performance of the learning techniques is highly <br>dependant on the nature of the training data. This study <br>also shows that combined methods perform better than the <br>individual ones in terms of their specificity, sensitivity, <br>positive predicted value and accuracy. We have suggested <br>some rules-of-thumb for the reader on choosing the best <br>suitable learning method for their dataset. </span></nobr></DIV>
<DIV style="position:absolute;top:243;left:457"><nobr><span class="ft6"><b>6 Acknowledgements </b></span></nobr></DIV>
<DIV style="position:absolute;top:271;left:457"><nobr><span class="ft11">We would like to thank colleagues in the Bioinformatics <br>Research Centre for constructive discussions. We would <br>also like to thank the anonymous reviewers for their useful <br>comments. The University of Glasgow funded AC Tan's <br>studentship. </span></nobr></DIV>
<DIV style="position:absolute;top:375;left:457"><nobr><span class="ft6"><b>7 References </b></span></nobr></DIV>
<DIV style="position:absolute;top:403;left:457"><nobr><span class="ft2">BALDI, P. AND BRUNAK, S. (2001) Bioinformatics: </span></nobr></DIV>
<DIV style="position:absolute;top:420;left:471"><nobr><span class="ft2">The Machine Learning Approach, 2</span></nobr></DIV>
<DIV style="position:absolute;top:418;left:687"><nobr><span class="ft7"><i>nd</i></span></nobr></DIV>
<DIV style="position:absolute;top:420;left:696"><nobr><span class="ft2"> Ed., MIT Press. </span></nobr></DIV>
<DIV style="position:absolute;top:446;left:457"><nobr><span class="ft2">Blake, C.L. AND Merz, C.J. (1998) UCI Repository of </span></nobr></DIV>
<DIV style="position:absolute;top:464;left:471"><nobr><span class="ft11">machine learning databases <br>[http://www.ics.uci.edu/~mlearn/MLRepository.html] </span></nobr></DIV>
<DIV style="position:absolute;top:507;left:457"><nobr><span class="ft2">CAI, Y.-D. AND CHOU, K.-C. (1998) Artificial neural </span></nobr></DIV>
<DIV style="position:absolute;top:524;left:471"><nobr><span class="ft11">network model for predicting HIV protease cleavage <br>sites in protein. Advances in Engineering Software, 29: <br>119-128. </span></nobr></DIV>
<DIV style="position:absolute;top:585;left:457"><nobr><span class="ft2">DIETTERICH, T.G. (2000) Ensemble methods in </span></nobr></DIV>
<DIV style="position:absolute;top:602;left:471"><nobr><span class="ft11">machine learning. In Proceedings of the First <br>International Workshop on MCS, LNCS 1857: 1-15. </span></nobr></DIV>
<DIV style="position:absolute;top:646;left:457"><nobr><span class="ft2">DOMINGOS, P. (1999) The role of Occam's razor in </span></nobr></DIV>
<DIV style="position:absolute;top:663;left:471"><nobr><span class="ft11">knowledge discovery. Data Mining and Knowledge <br>Discovery, 3: 409-425. </span></nobr></DIV>
<DIV style="position:absolute;top:707;left:457"><nobr><span class="ft2">HORTON, P. AND NAKAI, K. (1996) A probabilistic </span></nobr></DIV>
<DIV style="position:absolute;top:724;left:471"><nobr><span class="ft11">classification system for predicting the cellular <br>localization sites of proteins. In Proceedings of Fourth <br>International Conference on ISMB, p.109-115. AAAI / <br>MIT Press. </span></nobr></DIV>
<DIV style="position:absolute;top:802;left:457"><nobr><span class="ft2">MITCHELL, T. (1997) Machine Learning. McGraw-Hill. </span></nobr></DIV>
<DIV style="position:absolute;top:828;left:457"><nobr><span class="ft2">MUGGLETON, S., SRINIVASAN, A., KING, R.D. AND </span></nobr></DIV>
<DIV style="position:absolute;top:845;left:471"><nobr><span class="ft11">STERNBERG, M.J.E. (1998) Biochemical knowledge <br>discovery using inductive logic programming.  In H. <br>Motoda (Ed.) Proceedings of the First Conference on <br>Discovery Science, Springer-Verlag. </span></nobr></DIV>
<DIV style="position:absolute;top:923;left:457"><nobr><span class="ft2">SALZBERG, S. (1999). On comparing classifiers: a </span></nobr></DIV>
<DIV style="position:absolute;top:941;left:471"><nobr><span class="ft11">critique of current research and methods. Data mining <br>and knowledge discovery, 1: 1-12. </span></nobr></DIV>
<DIV style="position:absolute;top:984;left:457"><nobr><span class="ft2">SHAVLIK, J., HUNTER, L. &amp; SEARLS, D. (1995). </span></nobr></DIV>
<DIV style="position:absolute;top:1001;left:471"><nobr><span class="ft2">Introduction. Machine Learning, 21: 5-10. </span></nobr></DIV>
<DIV style="position:absolute;top:1028;left:457"><nobr><span class="ft2">TOWELL, G.G., SHAVLIK, J.W. AND NOORDEWIER, </span></nobr></DIV>
<DIV style="position:absolute;top:1045;left:471"><nobr><span class="ft11">M.O. (1990) Refinement of approximate domain <br>theories by knowledge-based neural networks. In <br>Proceedings of the Eighth National Conference on <br>Artificial Intelligence, p. 861-866. AAAI Press. </span></nobr></DIV>
<DIV style="position:absolute;top:1123;left:457"><nobr><span class="ft2">WITTEN, I.H. AND FRANK, E. (2000) Data Mining: </span></nobr></DIV>
<DIV style="position:absolute;top:1140;left:471"><nobr><span class="ft11">Practical machine learning tools and techniques with <br>java implementations. Morgan Kaufmann. </span></nobr></DIV>
</DIV>
</BODY>
</HTML>
