<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
<HEAD>
<TITLE>Microsoft Word - fe16-kim.doc</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<META name="generator" content="pdftohtml 0.35beta">
<META name="author" content="<B1E8B9CEBCBA>">
<META name="date" content="2006-05-14T08:58:31+00:00">
</HEAD>
<BODY bgcolor="#A0A0A0" vlink="blue" link="blue">
<!-- Page 1 -->
<a name="1"></a>
<DIV style="position:relative;width:918;height:1263;">
<STYLE type="text/css">
<!--
	.ft0{font-size:24px;font-family:Helvetica;color:#000000;}
	.ft1{font-size:15px;font-family:Helvetica;color:#000000;}
	.ft2{font-size:12px;font-family:Helvetica;color:#000000;}
	.ft3{font-size:15px;font-family:Times;color:#000000;}
	.ft4{font-size:15px;font-family:Times;color:#000000;}
	.ft5{font-size:11px;font-family:Times;color:#000000;}
	.ft6{font-size:11px;font-family:Times;color:#ff0000;}
	.ft7{font-size:11px;font-family:Times;color:#000000;}
	.ft8{font-size:11px;font-family:Times;color:#000000;}
	.ft9{font-size:15px;font-family:Helvetica;color:#000000;}
	.ft10{font-size:11px;font-family:Times;color:#000000;}
	.ft11{font-size:11px;font-family:Helvetica;color:#000000;}
	.ft12{font-size:8px;font-family:Times;color:#000000;}
	.ft13{font-size:9px;font-family:Times;color:#000000;}
	.ft14{font-size:9px;font-family:Times;color:#000000;}
	.ft15{font-size:16px;font-family:Courier;color:#000000;}
	.ft16{font-size:11px;line-height:15px;font-family:Times;color:#000000;}
	.ft17{font-size:9px;line-height:13px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1263" src="203001.png" alt="background image">
<DIV style="position:absolute;top:159;left:145"><nobr><span class="ft0"><b>UML-Based Service Robot Software Development:  </b></span></nobr></DIV>
<DIV style="position:absolute;top:190;left:374"><nobr><span class="ft0"><b>A Case Study </b></span></nobr></DIV>
<DIV style="position:absolute;top:224;left:106"><nobr><span class="ft1">Minseong Kim, Suntae Kim, </span></nobr></DIV>
<DIV style="position:absolute;top:244;left:159"><nobr><span class="ft1">Sooyong Park </span></nobr></DIV>
<DIV style="position:absolute;top:264;left:108"><nobr><span class="ft2">Department of Computer Science </span></nobr></DIV>
<DIV style="position:absolute;top:281;left:156"><nobr><span class="ft2">Sogang University </span></nobr></DIV>
<DIV style="position:absolute;top:298;left:140"><nobr><span class="ft2">Seoul, REP. of KOREA </span></nobr></DIV>
<DIV style="position:absolute;top:320;left:118"><nobr><span class="ft1">{minskim,jipsin08,sypark} </span></nobr></DIV>
<DIV style="position:absolute;top:345;left:156"><nobr><span class="ft1">@sogang.ac.kr </span></nobr></DIV>
<DIV style="position:absolute;top:224;left:341"><nobr><span class="ft1">Mun-Taek Choi, Munsang Kim </span></nobr></DIV>
<DIV style="position:absolute;top:244;left:365"><nobr><span class="ft2">Center for Intelligent Robotics   </span></nobr></DIV>
<DIV style="position:absolute;top:261;left:340"><nobr><span class="ft2">Frontier 21 Program at Korea Institute </span></nobr></DIV>
<DIV style="position:absolute;top:278;left:373"><nobr><span class="ft2">of Science and Technology </span></nobr></DIV>
<DIV style="position:absolute;top:294;left:385"><nobr><span class="ft2">Seoul, REP. of KOREA </span></nobr></DIV>
<DIV style="position:absolute;top:317;left:388"><nobr><span class="ft1"> {mtchoi,munsang} </span></nobr></DIV>
<DIV style="position:absolute;top:342;left:418"><nobr><span class="ft1">@kist.re.kr </span></nobr></DIV>
<DIV style="position:absolute;top:224;left:643"><nobr><span class="ft1">Hassan Gomaa</span></nobr></DIV>
<DIV style="position:absolute;top:224;left:765"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:244;left:598"><nobr><span class="ft2">Dept. of Information and Software </span></nobr></DIV>
<DIV style="position:absolute;top:261;left:666"><nobr><span class="ft2">Engineering </span></nobr></DIV>
<DIV style="position:absolute;top:278;left:624"><nobr><span class="ft2">George Mason University </span></nobr></DIV>
<DIV style="position:absolute;top:294;left:629"><nobr><span class="ft2">Fairfax, VA 22030, USA </span></nobr></DIV>
<DIV style="position:absolute;top:317;left:631"><nobr><span class="ft1">hgomaa@gmu.edu </span></nobr></DIV>
<DIV style="position:absolute;top:342;left:704"><nobr><span class="ft1"> </span></nobr></DIV>
<DIV style="position:absolute;top:370;left:91"><nobr><span class="ft4"><b>ABSTRACT</b></span></nobr></DIV>
<DIV style="position:absolute;top:374;left:186"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:390;left:91"><nobr><span class="ft16">The research field of Intelligent Service Robots, which has <br>become more and more popular over the last years, covers a wide <br>range of applications from climbing machines for cleaning large <br>storefronts to robotic assistance for disabled or elderly people. <br>When developing service robot software, it is a challenging <br>problem to design the robot architecture by carefully considering <br>user needs and requirements, implement robot application <br>components based on the architecture, and integrate these <br>components in a systematic and comprehensive way for <br>maintainability and reusability. Furthermore, it becomes more <br>difficult to communicate among development teams and with <br>others when many engineers from different teams participate in <br>developing the service robot.</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:245"><nobr><span class="ft6"> </span></nobr></DIV>
<DIV style="position:absolute;top:575;left:248"><nobr><span class="ft5">To solve these problems, we applied </span></nobr></DIV>
<DIV style="position:absolute;top:590;left:91"><nobr><span class="ft16">the COMET design method, which uses the industry-standard <br>UML notation, to developing the software of an intelligent service <br>robot for the elderly, called T-Rot, under development at Center <br>for Intelligent Robotics (CIR). In this paper, we discuss our <br>experiences with the project in which we successfully addressed <br>these problems and developed the autonomous navigation system <br>of the robot with the COMET/UML method. </span></nobr></DIV>
<DIV style="position:absolute;top:716;left:91"><nobr><span class="ft4"><b>Categories and Subject Descriptors</b></span></nobr></DIV>
<DIV style="position:absolute;top:720;left:356"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:737;left:91"><nobr><span class="ft16">D.2.2 [<b>Software Engineering</b>]: Design Tools and Techniques ­ <br><i>object-oriented design methods </i></span></nobr></DIV>
<DIV style="position:absolute;top:785;left:91"><nobr><span class="ft4"><b>General Terms</b></span></nobr></DIV>
<DIV style="position:absolute;top:789;left:205"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:805;left:91"><nobr><span class="ft5">Design </span></nobr></DIV>
<DIV style="position:absolute;top:839;left:91"><nobr><span class="ft4"><b>Keywords</b></span></nobr></DIV>
<DIV style="position:absolute;top:859;left:91"><nobr><span class="ft16">Software engineering, object-oriented analysis and design <br>methods, service robot development, UML </span></nobr></DIV>
<DIV style="position:absolute;top:908;left:91"><nobr><span class="ft4"><b>1.</b></span></nobr></DIV>
<DIV style="position:absolute;top:907;left:104"><nobr><span class="ft9"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:908;left:115"><nobr><span class="ft4"><b>INTRODUCTION </b></span></nobr></DIV>
<DIV style="position:absolute;top:928;left:91"><nobr><span class="ft16">Robots have been used in several new applications. In recent <br>years, both academic and commercial research has been focusing </span></nobr></DIV>
<DIV style="position:absolute;top:370;left:476"><nobr><span class="ft16">on the development of a new generation of robots in the emerging <br>field of service robots. Service robots are individually designed to <br>perform tasks in a specific environment for working with or <br>assisting humans and must be able to perform services semi- or <br>fully automatically [1]. Examples of service robots are those used <br>for inspection, maintenance, housekeeping, office automation and <br>aiding senior citizens or physically challenged individuals [2]. A <br>number of commercialized service robots have recently been <br>introduced such as vacuum cleaning robots, home security robots, <br>robots for lawn mowing, entertainment robots, and guide robots <br>[3, 4]. </span></nobr></DIV>
<DIV style="position:absolute;top:548;left:476"><nobr><span class="ft16">In this context, Public Service Robot (PSR) systems have been <br>developed for indoor service tasks at Korea Institute of Science <br>and Technology (KIST) [5, 6]. The PSR is an intelligent service <br>robot, which has various capabilities such as navigation, <br>manipulation, etc. Up to now, three versions of the PSR systems, <br>that is, <i>PSR-1</i>, <i>PSR-2</i>, and a guide robot <i>Jinny</i> have been built.  </span></nobr></DIV>
<DIV style="position:absolute;top:649;left:476"><nobr><span class="ft16">The worldwide aging population and health care costs of aged <br>people are rapidly growing and are set to become a major problem <br>in the coming decades. This phenomenon could lead to a huge <br>market for service robots assisting with the care and support of <br>the disabled and elderly in the future [8]. As a result, a new <br>project is under development at Center for Intelligent Robotics <br>(CIR) at KIST, i.e. the intelligent service robot for the elderly, <br>called T-Rot.  </span></nobr></DIV>
<DIV style="position:absolute;top:781;left:476"><nobr><span class="ft16">In our service robot applications, it is essential to not only <br>consider and develop a well-defined robot software architecture, <br>but also to develop and integrate robot application components in <br>a systematic and comprehensive manner. There are several <br>reasons for this:  </span></nobr></DIV>
<DIV style="position:absolute;top:867;left:486"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:867;left:505"><nobr><span class="ft16">First, service robots interact closely with humans in a wide <br>range of situations for providing services through robot <br>application components such as vision recognition, speech <br>recognition, navigation, etc. Thus, a well-defined robot <br>control architecture is required for coherently and <br>systematically combining these services into an integrated <br>system.  </span></nobr></DIV>
<DIV style="position:absolute;top:983;left:486"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:983;left:505"><nobr><span class="ft16">Second, in robot systems, there are many-to-many relations <br>among software components as well as hardware <br>components. For instance, a local map module requires <br>range data from a laser scanner, ultrasonic sensors, and <br>infrared sensors, as well as prior geometrical descriptions of <br>the environment. On the other hand, the laser scanner should <br>provide its data to a path planner, localizer, and a local map </span></nobr></DIV>
<DIV style="position:absolute;top:973;left:97"><nobr><span class="ft12"> </span></nobr></DIV>
<DIV style="position:absolute;top:994;left:97"><nobr><span class="ft17">Permission to make digital or hard copies of all or part of this work for <br>personal or classroom use is granted without fee provided that copies are <br>not made or distributed for profit or commercial advantage and that <br>copies bear this notice and the full citation on the first page. To copy <br>otherwise, or republish, to post on servers or to redistribute to lists, <br>requires prior specific permission and/or a fee. <br><i>ICSE'06</i>, May 20-28, 2006, Shanghai, China. <br>Copyright 2006 ACM 1-59593-085-X/06/0005...$5.00. </span></nobr></DIV>
<DIV style="position:absolute;top:1104;left:97"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:1165;left:449"><nobr><span class="ft5">534</span></nobr></DIV>
</DIV>
<!-- Page 2 -->
<a name="2"></a>
<DIV style="position:relative;width:918;height:1263;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1263" src="203002.png" alt="background image">
<DIV style="position:absolute;top:159;left:120"><nobr><span class="ft16">building module. These relationships, as well as interactions <br>among software or hardware modules, must be carefully <br>analyzed and systematically managed from an early stage of <br>development in order to understand the big picture.  </span></nobr></DIV>
<DIV style="position:absolute;top:229;left:101"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:230;left:120"><nobr><span class="ft16">Third, the functional performance of each software and <br>hardware module becomes highly dependent on the <br>architecture, as the number of robot platforms increases [6], <br>and new services are added, or existing services are removed <br>or updated to address changes in user needs. </span></nobr></DIV>
<DIV style="position:absolute;top:315;left:101"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:315;left:120"><nobr><span class="ft16">Fourth, previously developed software modules like maps, <br>localization, and path planners can be directly reused for <br>new tasks or services by service robot developers. Thus, a <br>robot architecture, as well as systematic processes or <br>methods, are required to support the implementation of the <br>system, to ensure modularity and reusability. </span></nobr></DIV>
<DIV style="position:absolute;top:416;left:91"><nobr><span class="ft16">As a consequence, in the previous work [5,6], the Tripodal <br>schematic control architecture was proposed to tackle the <br>problems. Many related research activities have been done. <br>However, it is still a challenging problem to develop the robot <br>architecture by carefully taking into account user needs and <br>requirements, implement robot application components based on <br>the architecture, and integrate these components in a systematic <br>and comprehensive way. The reason is that the developers of <br>service robots generally tend to be immersed in technology <br>specific components, e.g. vision recognizer, localizer and path <br>planner, at an early stage of product development without <br>carefully considering architecture to integrate those components <br>for various services [9]. Moreover, engineers and developers are <br>often grouped into separate teams in accordance with the specific <br>technologies (e.g., speech processing, vision processing), which <br>makes integration of these components more difficult [7, 9]. In <br>such a project like T-Rot, particularly, several engineers and <br>developers (i.e., approximately, more than 150 engineers) from <br>different organizations and teams participate in the <br>implementation of the service robot. Each separate team tends to <br>address the specific technologies such as object recognition, <br>manipulation, and navigation and so on. Engineers who come <br>from different teams are concerned with different characteristics <br>of the system. Thus, a common medium is required to create <br>mutual understanding, form consensus, and communicate with <br>each other for successfully constructing the service robot. Without <br>such a medium or language, it is difficult to sufficiently <br>understand the service robot system and interact between teams to <br>integrate components for services.  </span></nobr></DIV>
<DIV style="position:absolute;top:872;left:91"><nobr><span class="ft16">Within the domain of software engineering, many approaches <br>have been suggested for a systematic and complete system <br>analysis and design, and for the capture of specifications. The <br>object-oriented paradigm [10,11] is a widely-accepted approach <br>to not only cover the external and declarative view of a system, <br>but also at the same time bridge seamlessly with the internal <br>implementation view of a system [13]. Object-oriented concepts <br>are crucial in software analysis and design because they focus on <br>fundamental issues of adaptation and evolution [14]. Therefore, <br>compared with the traditional structured software development <br>methods, object-oriented methods are a more modular approach <br>for analysis, design, and implementation of complex software <br>systems, which leads to more self-contained and hence modifiable <br>and maintainable systems. More recently, the Unified Modeling <br>Language (UML) [15,16] has captured industry-wide attention for </span></nobr></DIV>
<DIV style="position:absolute;top:159;left:476"><nobr><span class="ft16">its role as a general-purpose language for modeling software <br>systems, especially for describing object-oriented models. The <br>UML notation is useful to specify the requirements, document the <br>structure, decompose into objects, and define relationships <br>between objects in a software system. Certain notations in the <br>UML have particular importance for modeling embedded systems <br>[17,18], like robot systems. By adopting the UML notation, <br>development teams thus can communicate among themselves and <br>with others using a defined standard [14,17,18]. More importantly, <br>it is essential for the UML notation to be used with a systematic <br>object-oriented analysis and design method in order to be <br>effectively applied [14].  </span></nobr></DIV>
<DIV style="position:absolute;top:353;left:476"><nobr><span class="ft16">As a result, our aim is to develop the intelligent service robot <br>based on the systematic software engineering method, especially <br>for real-time, embedded and distributed systems with UML. To <br>do so, we applied the COMET method, which is a UML based <br>method for the development of concurrent applications, <br>specifically distributed and real-time applications [14]. By using <br>the COMET method, it is possible to reconcile specific <br>engineering techniques with the industry-standard UML and <br>furthermore to fit such techniques into a fully defined <br>development process towards developing the service robot <br>systems. </span></nobr></DIV>
<DIV style="position:absolute;top:531;left:476"><nobr><span class="ft16">In this paper, we describe our experience of applying the COMET <br>/UML method into developing the intelligent service robot for the <br>elderly, called T-Rot, developed at CIR. In particular, we focused <br>on designing an autonomous navigation system for the service <br>robot, which is one of the most challenging issues for the <br>development of service robots. </span></nobr></DIV>
<DIV style="position:absolute;top:632;left:476"><nobr><span class="ft16">Section 2 describes the hardware configuration and services of the <br>T-Rot, and discusses the related work. Section 3 illustrates how to <br>apply the COMET method into designing and developing the <br>autonomous navigation system for the service robot, and <br>discusses the results of experiments. The lessons learned from the <br>project are summarized in section 4, and section 5 concludes the <br>paper with some words on further work. </span></nobr></DIV>
<DIV style="position:absolute;top:758;left:476"><nobr><span class="ft4"><b>2.</b></span></nobr></DIV>
<DIV style="position:absolute;top:758;left:489"><nobr><span class="ft9"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:758;left:500"><nobr><span class="ft4"><b>BACKGROUD ON T-Rot </b></span></nobr></DIV>
<DIV style="position:absolute;top:781;left:476"><nobr><span class="ft4"><b>2.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:781;left:498"><nobr><span class="ft9"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:781;left:509"><nobr><span class="ft4"><b>PSR and T-Rot </b></span></nobr></DIV>
<DIV style="position:absolute;top:914;left:809"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:932;left:576"><nobr><span class="ft7"><b>Fig. 1. KIST service robots </b></span></nobr></DIV>
<DIV style="position:absolute;top:953;left:476"><nobr><span class="ft16">At KIST, intelligent service robots have been developed in large-<br>scale indoor environments since 1998. So far, <i>PSR-1</i> and <i>PSR-2</i>, <br>which performs delivery, patrol, and floor cleaning jobs, and a <br>guide robot <i>Jinny</i>, which provides services like exhibition guide <br>and guidance of the road at a museum, have been built [5,6] (see <br>Fig. 1). The service robot T-Rot is the next model of the PSR <br>system under development for assisting aged persons. <br>Development of T-Rot, in which our role is developing and <br>integrating robot software, started in 2003 by mainly CIR with </span></nobr></DIV>
<DIV style="position:absolute;top:1165;left:449"><nobr><span class="ft5">535</span></nobr></DIV>
</DIV>
<!-- Page 3 -->
<a name="3"></a>
<DIV style="position:relative;width:918;height:1263;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1263" src="203003.png" alt="background image">
<DIV style="position:absolute;top:159;left:91"><nobr><span class="ft16">more than 10 groups consisting of more than 150 researchers and <br>engineers from academia and industry. This project is based on <br>the needs and requirements of elderly people through the studies <br>and analysis of the commercial health-care market for providing <br>useful services to them. Thus, the aim of this project is to develop <br>the intelligent service robot for the elderly by cooperating and <br>integrating the results of different research groups. This project <br>that is divided into three stages will continue until 2013 and we <br>are now in the first stage for developing the service robot <br>incrementally to provide various services. </span></nobr></DIV>
<DIV style="position:absolute;top:323;left:91"><nobr><span class="ft4"><b>2.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:322;left:113"><nobr><span class="ft9"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:323;left:124"><nobr><span class="ft4"><b>Hardware of T-Rot </b></span></nobr></DIV>
<DIV style="position:absolute;top:342;left:91"><nobr><span class="ft16">The initial version of T-Rot, as shown in Fig. 2, has three single <br>board computer (SBC), that is, mobile Pentium 4 (2.2GHz) and <br>1GB SDRAM on each SBC. In terms of software environment, <br>Linux Red hat 9.0 and RTAI (Real-Time Application Interface) <br>[12] are used as operating system. Fig. 3 shows hardware <br>configuration as a whole. As mentioned earlier, development of <br>T-Rot is conducted incrementally for various services and thus the <br>platform will be extended with manipulators and robot hands later. <br>In our project, we developed the robot software based on the <br>initial version of the platform. The details of the hardware <br>platform are described in Table 1. </span></nobr></DIV>
<DIV style="position:absolute;top:642;left:307"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:661;left:158"><nobr><span class="ft7"><b>Fig. 2. T-Rot robot hardware platform </b></span></nobr></DIV>
<DIV style="position:absolute;top:882;left:433"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:900;left:119"><nobr><span class="ft7"><b>Fig. 3. T-Rot robot hardware platform configuration </b></span></nobr></DIV>
<DIV style="position:absolute;top:921;left:148"><nobr><span class="ft7"><b>Table 1. T-Rot hardware platform devices </b></span></nobr></DIV>
<DIV style="position:absolute;top:943;left:170"><nobr><span class="ft13">Intel Mobile Pentium 4 (2.2 GHz) </span></nobr></DIV>
<DIV style="position:absolute;top:963;left:170"><nobr><span class="ft13">1GB SDRAM </span></nobr></DIV>
<DIV style="position:absolute;top:943;left:100"><nobr><span class="ft13">SBC  </span></nobr></DIV>
<DIV style="position:absolute;top:984;left:170"><nobr><span class="ft13">30GB Hard Disk </span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:170"><nobr><span class="ft13">16 microphones for speaker localization </span></nobr></DIV>
<DIV style="position:absolute;top:1024;left:170"><nobr><span class="ft13">1 microphone for speech recognition </span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:100"><nobr><span class="ft13">Voice </span></nobr></DIV>
<DIV style="position:absolute;top:1044;left:170"><nobr><span class="ft13">1 speaker for speech generation </span></nobr></DIV>
<DIV style="position:absolute;top:1065;left:100"><nobr><span class="ft13">Vision </span></nobr></DIV>
<DIV style="position:absolute;top:1065;left:170"><nobr><span class="ft17">2 stereo vision cameras for recognizing users and object<br>s (1288 H x 1032 V maximum resolution and 7Hz fram</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:555"><nobr><span class="ft13">e rates) </span></nobr></DIV>
<DIV style="position:absolute;top:180;left:555"><nobr><span class="ft13">Pan/Tilt for controlling the vision part </span></nobr></DIV>
<DIV style="position:absolute;top:200;left:555"><nobr><span class="ft13">2 laser scanners (front and back) </span></nobr></DIV>
<DIV style="position:absolute;top:221;left:555"><nobr><span class="ft13">2 IR scanners (front and back) </span></nobr></DIV>
<DIV style="position:absolute;top:241;left:555"><nobr><span class="ft13">12 Ultrasonic sensors </span></nobr></DIV>
<DIV style="position:absolute;top:200;left:485"><nobr><span class="ft13">Sensor  </span></nobr></DIV>
<DIV style="position:absolute;top:261;left:555"><nobr><span class="ft13">1 Gyroscope sensor for measuring balance </span></nobr></DIV>
<DIV style="position:absolute;top:282;left:555"><nobr><span class="ft13">2 actuators for two drive wheels (right and left) </span></nobr></DIV>
<DIV style="position:absolute;top:302;left:555"><nobr><span class="ft13">2 free wheels (the support wheels) </span></nobr></DIV>
<DIV style="position:absolute;top:322;left:555"><nobr><span class="ft13">2 Servo Motors (100 [w]) </span></nobr></DIV>
<DIV style="position:absolute;top:343;left:555"><nobr><span class="ft13">2 encoders (2048 ppr) </span></nobr></DIV>
<DIV style="position:absolute;top:282;left:485"><nobr><span class="ft13">Actuator </span></nobr></DIV>
<DIV style="position:absolute;top:363;left:555"><nobr><span class="ft13">2 bumpers  </span></nobr></DIV>
<DIV style="position:absolute;top:383;left:555"><nobr><span class="ft13">1 TFT LCD &amp; Touch (10.4" 1024x768, 26000 colors) </span></nobr></DIV>
<DIV style="position:absolute;top:404;left:555"><nobr><span class="ft13">KVM (Keyboard/Mouse) </span></nobr></DIV>
<DIV style="position:absolute;top:383;left:485"><nobr><span class="ft13">Interface </span></nobr></DIV>
<DIV style="position:absolute;top:424;left:555"><nobr><span class="ft13">Wireless LAN for communications </span></nobr></DIV>
<DIV style="position:absolute;top:448;left:476"><nobr><span class="ft4"><b>2.3</b></span></nobr></DIV>
<DIV style="position:absolute;top:447;left:498"><nobr><span class="ft9"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:448;left:509"><nobr><span class="ft4"><b>Robot Services </b></span></nobr></DIV>
<DIV style="position:absolute;top:467;left:476"><nobr><span class="ft16">Some of the primary services under-developed that the initial <br>version for T-Rot provides for the elderly are described as below. </span></nobr></DIV>
<DIV style="position:absolute;top:504;left:486"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:504;left:505"><nobr><span class="ft16">Voice-based Information Services: The robot T-Rot can <br>recognize voice commands from a user (i.e., an aged person) <br>via microphones equipped with the robot and can synthesize <br>voices for services. While a user is watching TV, the user <br>can ask some questions about the specific TV program or <br>request a task to open an Internet homepage by speaking the <br>TV program name.  </span></nobr></DIV>
<DIV style="position:absolute;top:621;left:486"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:621;left:505"><nobr><span class="ft16">Sound Localization and Voice Recognition: A user can call <br>a robot's predefined name, to let the robot recognize the call <br>while the robot knows the direction to move to the user. This <br>service analyzes audio data from 3 microphones on the <br>shoulder for sound localization and 16 mic array on the head <br>for speech recognition to recognize the command from the <br>user. </span></nobr></DIV>
<DIV style="position:absolute;top:737;left:486"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:737;left:505"><nobr><span class="ft16">Autonomous navigation: A user can command the robot to <br>move to a specific position in the map to perform some task. <br>For instance, the robot can navigate to its destination in the <br>home environment via its sensors, which include laser <br>scanners and ultrasonic sensors. The robot plans a path to <br>the specified position, executes this plan, and modifies it as <br>necessary for avoiding unexpected obstacles. While the <br>robot is moving, it constantly checks sensor data from its <br>sensors every 200 ms. </span></nobr></DIV>
<DIV style="position:absolute;top:885;left:486"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:885;left:505"><nobr><span class="ft16">An errand service: The robot can carry objects that a user <br>(i.e., an aged person) usually uses, like a plate, books, a cane <br>a cup of tea, beverages, etc according to the user's <br>instructions. For instance, the user can order the robot to <br>bring a cup of tea or beverage by speaking the name of the <br>drink. </span></nobr></DIV>
<DIV style="position:absolute;top:986;left:476"><nobr><span class="ft16">Of these T-Rot services, our emphasis was on the autonomous <br>navigation service, which is one of the most challenging issues <br>and is essential in developing service robots, particularly mobile <br>service robots to assist elderly people. It includes hardware <br>integration for various sensors and actuators, and the development <br>of crucial navigation algorithms like maps, path planners, and </span></nobr></DIV>
<DIV style="position:absolute;top:1165;left:449"><nobr><span class="ft5">536</span></nobr></DIV>
</DIV>
<!-- Page 4 -->
<a name="4"></a>
<DIV style="position:relative;width:918;height:1263;">
<STYLE type="text/css">
<!--
	.ft18{font-size:5px;font-family:Helvetica;color:#000000;}
	.ft19{font-size:3px;font-family:Helvetica;color:#000000;}
	.ft20{font-size:5px;font-family:Helvetica;color:#000000;}
	.ft21{font-size:11px;line-height:21px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1263" src="203004.png" alt="background image">
<DIV style="position:absolute;top:159;left:91"><nobr><span class="ft16">localizers as well as software integration of software modules like <br>a path planner, a localizer, and a map building module. </span></nobr></DIV>
<DIV style="position:absolute;top:199;left:91"><nobr><span class="ft4"><b>2.4</b></span></nobr></DIV>
<DIV style="position:absolute;top:199;left:113"><nobr><span class="ft9"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:199;left:124"><nobr><span class="ft4"><b>Control Architecture of PSR </b></span></nobr></DIV>
<DIV style="position:absolute;top:219;left:91"><nobr><span class="ft16">Up to now, there have been many related research activities to <br>develop efficient and well-defined control architectures and <br>system integration strategies for constructing service robots. A <br>recent trend is that many control architectures are converging to a <br>similar structure based on a hybrid approach that integrates <br>reactive control and deliberation [6]. At KIST, for developing <br>service robots, that is <i>PSR-1</i>,  <i>PSR-2</i>, and <i>Jinny  </i>in the previous <br>work [5,6], the Tripodal schematic control architecture was <br>proposed as the solution to the problem.  <br>One important point of Tripodal schematic design is to integrate <br>robot systems by using a layered functionality diagram. The <br>layered functionality diagram is a conceptual diagram of three <br>layers for arrangement of various hardware and software modules <br>and functions. It also shows the connectivity and the information <br>flow between components. Those layers are composed of <br>deliberate, sequencing, and reactive layers based on the hybrid <br>approach. The purposes of the deliberate layer are to interface <br>with a user and to execute a planning process. The sequencing <br>layer is classified into two groups, that is, the controlling part that <br>executes the process by managing the components in the reactive <br>layer and the information part that extracts highly advanced <br>information from sensor data. The reactive layer controls the real-<br>time command and hardware-related modules for sensors and <br>actuators. The detailed description of whole control architecture <br>of the PSR is introduced in [5]. <br>However, as described earlier, in order to effectively apply this <br>approach and the UML notation to developing service robots, it is <br>essential to use a systematic software engineering process or <br>methods like object-oriented analysis and design methods, <br>especially for real-time and embedded systems. We believe that <br>only a systematic and comprehensive software development <br>process and method will be able to resolve the issues discussed <br>before and will be vital for success in developing service robots. </span></nobr></DIV>
<DIV style="position:absolute;top:749;left:91"><nobr><span class="ft4"><b>2.5</b></span></nobr></DIV>
<DIV style="position:absolute;top:748;left:113"><nobr><span class="ft9"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:749;left:124"><nobr><span class="ft4"><b>The COMET method </b></span></nobr></DIV>
<DIV style="position:absolute;top:769;left:91"><nobr><span class="ft16">COMET [14] is a method for designing real-time and distributed <br>applications, which integrates object-oriented and concurrent <br>processing concepts and uses the UML notation [15,16]. The <br>COMET object- oriented software life cycle model is a highly <br>iterative software development process based around the use case <br>concept. Therefore, in this project, the COMET method with <br>UML was used to develop a system for autonomous navigation by <br>the intelligent service robot, T-Rot. The method separates <br>requirements activities, analysis activities and design activities, <br>and these activities are briefly described as below. The details are <br>described in section 3 with the case study. </span></nobr></DIV>
<DIV style="position:absolute;top:944;left:101"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:944;left:120"><nobr><span class="ft16">Requirements modeling - A use case model is developed in <br>which the functional requirements of the system are defined <br>in terms of actors and use cases.  </span></nobr></DIV>
<DIV style="position:absolute;top:996;left:101"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:996;left:120"><nobr><span class="ft16">Analysis modeling - Static and dynamic models of the <br>system are developed. The static model defines the <br>structural relationships among problem domain classes. A <br>dynamic model is then developed in which the use cases <br>from the requirements model are refined to show the objects <br>that participate in each use case and how they interact with <br>each other.  </span></nobr></DIV>
<DIV style="position:absolute;top:159;left:486"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:159;left:505"><nobr><span class="ft16">Design modeling ­ The software architecture of the system <br>is designed, in which the analysis model is mapped to an <br>operational environment. For distributed applications, a <br>component based development approach is taken, in which <br>each subsystem is designed as a distributed self-contained <br>component. </span></nobr></DIV>
<DIV style="position:absolute;top:267;left:476"><nobr><span class="ft4"><b>3.</b></span></nobr></DIV>
<DIV style="position:absolute;top:266;left:489"><nobr><span class="ft9"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:267;left:500"><nobr><span class="ft4"><b>APPLYING THE COMET/UML </b></span></nobr></DIV>
<DIV style="position:absolute;top:287;left:476"><nobr><span class="ft4"><b>METHOD TO T-ROT </b></span></nobr></DIV>
<DIV style="position:absolute;top:307;left:476"><nobr><span class="ft16">In this section, we explain how to develop robot software for the <br>autonomous navigation system with the COMET/UML method. <br>In our project, the UML notation conforms to UML 1.3 and the <br>Rational Rose tool is used. </span></nobr></DIV>
<DIV style="position:absolute;top:375;left:476"><nobr><span class="ft4"><b>3.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:375;left:498"><nobr><span class="ft9"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:375;left:509"><nobr><span class="ft4"><b>Requirements Modeling  </b></span></nobr></DIV>
<DIV style="position:absolute;top:395;left:476"><nobr><span class="ft16">Capturing the functional requirements of the system is the first <br>phase in software development, which defines what the system <br>should do or provide for the user. In our approach, developers can <br>catch the functional requirements or services by using the use <br>case model in terms of use cases and actors (see Fig. 4). To <br>identify and define the requirements of the system more clearly, <br>the system has to be considered like a black box. In the service <br>robot, the actor can be usually a human user as well as external <br>I/O devices and external timer.  </span></nobr></DIV>
<DIV style="position:absolute;top:564;left:633"><nobr><span class="ft18"><b>Navigation</b></span></nobr></DIV>
<DIV style="position:absolute;top:573;left:535"><nobr><span class="ft18"><b>Commander</b></span></nobr></DIV>
<DIV style="position:absolute;top:581;left:533"><nobr><span class="ft19"><b>(from 1.0 Actors)</b></span></nobr></DIV>
<DIV style="position:absolute;top:632;left:737"><nobr><span class="ft18"><b>Clock</b></span></nobr></DIV>
<DIV style="position:absolute;top:641;left:724"><nobr><span class="ft19"><b>(from 1.0 Actors)</b></span></nobr></DIV>
<DIV style="position:absolute;top:624;left:617"><nobr><span class="ft18"><b>Obstacle Avoidance</b></span></nobr></DIV>
<DIV style="position:absolute;top:586;left:631"><nobr><span class="ft20">&lt;&lt;extend&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:636;left:772"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:655;left:541"><nobr><span class="ft7"><b>Fig. 4. Use case diagram for Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:676;left:476"><nobr><span class="ft16">Table 2 shows a specification for <i>Navigation  </i>use case. In our <br>navigation system, we identified a <i>Commander </i>and a <i>Clock</i> as an <br>actor. While the robot is moving, if the robot recognizes obstacles, <br>it should avoid them for continuing to go to the destination. Even <br>when humans or objects suddenly appear, the robot must be able <br>to stop to avoid crashing into those. However, in order to do this, <br>the robot has to check that there are obstacles by using sensor data <br>more often (e.g., every 50 ms) than the normal navigation system <br>does (e.g., every 200 ms). As a result, the <i>Obstacle Avoidance</i> use <br>case is extended from the <i>Navigation</i> use case. During the <br><i>Navigation</i> use case is executing, if the obstacles are recognized, <br>then the <i>Obstacle Avoidance</i> use case is triggered to perform the <br>emergency stop of the robot. If the obstacles disappear, the robot <br>moves again to the destination. </span></nobr></DIV>
<DIV style="position:absolute;top:897;left:572"><nobr><span class="ft7"><b>Table 2. Navigation use case </b></span></nobr></DIV>
<DIV style="position:absolute;top:919;left:477"><nobr><span class="ft13">Summary  </span></nobr></DIV>
<DIV style="position:absolute;top:919;left:557"><nobr><span class="ft17">The Commander enters a destination and the robot <br>system moves to the destination. </span></nobr></DIV>
<DIV style="position:absolute;top:953;left:477"><nobr><span class="ft13">Actor Commander </span></nobr></DIV>
<DIV style="position:absolute;top:974;left:477"><nobr><span class="ft13">Precondition </span></nobr></DIV>
<DIV style="position:absolute;top:974;left:557"><nobr><span class="ft17">The robot system has the grid map and the current <br>position is known </span></nobr></DIV>
<DIV style="position:absolute;top:1008;left:477"><nobr><span class="ft13">Description </span></nobr></DIV>
<DIV style="position:absolute;top:1008;left:557"><nobr><span class="ft17">1. The use case begins when the commander enters a <br>destination. </span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:557"><nobr><span class="ft17">2. The system calculates an optimal path to the <br>destination. </span></nobr></DIV>
<DIV style="position:absolute;top:1074;left:557"><nobr><span class="ft13">3. The system commands the wheel actuator to start </span></nobr></DIV>
<DIV style="position:absolute;top:1165;left:449"><nobr><span class="ft5">537</span></nobr></DIV>
</DIV>
<!-- Page 5 -->
<a name="5"></a>
<DIV style="position:relative;width:918;height:1263;">
<STYLE type="text/css">
<!--
	.ft22{font-size:14px;font-family:Times;color:#000000;}
	.ft23{font-size:14px;font-family:Helvetica;color:#000000;}
	.ft24{font-size:2px;font-family:Helvetica;color:#000000;}
	.ft25{font-size:3px;font-family:Helvetica;color:#000000;}
	.ft26{font-size:3px;font-family:Helvetica;color:#000000;}
	.ft27{font-size:4px;font-family:Times;color:#000000;}
	.ft28{font-size:4px;font-family:Helvetica;color:#000000;}
	.ft29{font-size:1px;font-family:Helvetica;color:#000000;}
	.ft30{font-size:4px;font-family:Helvetica;color:#000000;}
	.ft31{font-size:3px;font-family:Helvetica;color:#000000;}
	.ft32{font-size:11px;line-height:15px;font-family:Times;color:#000000;}
	.ft33{font-size:3px;line-height:6px;font-family:Helvetica;color:#000000;}
	.ft34{font-size:3px;line-height:5px;font-family:Helvetica;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1263" src="203005.png" alt="background image">
<DIV style="position:absolute;top:160;left:172"><nobr><span class="ft13">moving to the destination. </span></nobr></DIV>
<DIV style="position:absolute;top:179;left:172"><nobr><span class="ft17">4. The wheel actuator notifies the system that it has <br>started moving </span></nobr></DIV>
<DIV style="position:absolute;top:213;left:172"><nobr><span class="ft17">5. The system periodically reads sensor data and <br>calculates the current position. </span></nobr></DIV>
<DIV style="position:absolute;top:246;left:172"><nobr><span class="ft17">6. The system determines that it arrives at the destination <br>and commands the wheel actuator to stop. </span></nobr></DIV>
<DIV style="position:absolute;top:280;left:172"><nobr><span class="ft17">7. The wheel actuator notifies the system that it has <br>stopped moving and the use case is finished. </span></nobr></DIV>
<DIV style="position:absolute;top:314;left:92"><nobr><span class="ft13">Alternative </span></nobr></DIV>
<DIV style="position:absolute;top:314;left:172"><nobr><span class="ft17">6.1. If the system doesn't arrive at the destination, it <br>keeps moving. </span></nobr></DIV>
<DIV style="position:absolute;top:348;left:92"><nobr><span class="ft13">Postcondition  The robot system is at the destination and waiting for the </span></nobr></DIV>
<DIV style="position:absolute;top:361;left:172"><nobr><span class="ft13">next destination. </span></nobr></DIV>
<DIV style="position:absolute;top:382;left:91"><nobr><span class="ft4"><b>3.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:382;left:113"><nobr><span class="ft9"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:382;left:124"><nobr><span class="ft4"><b>Analysis Modeling </b></span></nobr></DIV>
<DIV style="position:absolute;top:411;left:91"><nobr><span class="ft22"><i>3.2.1</i></span></nobr></DIV>
<DIV style="position:absolute;top:411;left:124"><nobr><span class="ft23"><i> </i></span></nobr></DIV>
<DIV style="position:absolute;top:411;left:134"><nobr><span class="ft22"><i>Static Modeling </i></span></nobr></DIV>
<DIV style="position:absolute;top:429;left:91"><nobr><span class="ft16">The objective of static modeling is to understand the interface <br>between the system and the external environment and to describe <br>the static structure of the system under development by <br>developing a system context class diagram. It is specifically <br>important for real-time and embedded systems like robot systems <br>[14]. The system context class diagram can be determined by <br>static modeling of the external classes that connect to the system. </span></nobr></DIV>
<DIV style="position:absolute;top:583;left:102"><nobr><span class="ft19"><b>Commander</b></span></nobr></DIV>
<DIV style="position:absolute;top:591;left:102"><nobr><span class="ft24"><b>(from 1.0 Actors)</b></span></nobr></DIV>
<DIV style="position:absolute;top:621;left:175"><nobr><span class="ft19"><b>Sensor</b></span></nobr></DIV>
<DIV style="position:absolute;top:613;left:151"><nobr><span class="ft25">&lt;&lt;external input device&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:560;left:366"><nobr><span class="ft19"><b>WheelActuator</b></span></nobr></DIV>
<DIV style="position:absolute;top:553;left:352"><nobr><span class="ft25">&lt;&lt;external output device&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:560;left:164"><nobr><span class="ft19"><b>CommandLine</b></span></nobr></DIV>
<DIV style="position:absolute;top:553;left:161"><nobr><span class="ft25">&lt;&lt;external user&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:566;left:152"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:566;left:129"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:566;left:152"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:566;left:129"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:560;left:242"><nobr><span class="ft19"><b>Robot Navigation System</b></span></nobr></DIV>
<DIV style="position:absolute;top:553;left:261"><nobr><span class="ft25">&lt;&lt;System&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:605;left:215"><nobr><span class="ft25">1..*</span></nobr></DIV>
<DIV style="position:absolute;top:576;left:258"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:605;left:215"><nobr><span class="ft25">1..*</span></nobr></DIV>
<DIV style="position:absolute;top:576;left:258"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:587;left:208"><nobr><span class="ft26"><i>Inputs To </i></span></nobr></DIV>
<DIV style="position:absolute;top:587;left:235"><nobr><span class="ft27"></span></nobr></DIV>
<DIV style="position:absolute;top:564;left:328"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:340"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:328"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:340"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:544;left:315"><nobr><span class="ft26"><i>Outputs to </i></span></nobr></DIV>
<DIV style="position:absolute;top:544;left:345"><nobr><span class="ft27"></span></nobr></DIV>
<DIV style="position:absolute;top:564;left:225"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:217"><nobr><span class="ft25">1 1</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:217"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:544;left:196"><nobr><span class="ft26"><i>interacts with </i></span></nobr></DIV>
<DIV style="position:absolute;top:544;left:233"><nobr><span class="ft27"></span></nobr></DIV>
<DIV style="position:absolute;top:641;left:363"><nobr><span class="ft19"><b>Clock</b></span></nobr></DIV>
<DIV style="position:absolute;top:648;left:353"><nobr><span class="ft24"><b>(from 1.0 Actors)</b></span></nobr></DIV>
<DIV style="position:absolute;top:618;left:270"><nobr><span class="ft19"><b>Clock</b></span></nobr></DIV>
<DIV style="position:absolute;top:611;left:253"><nobr><span class="ft25">&lt;&lt;external timer&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:605;left:280"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:574;left:274"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:605;left:280"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:574;left:274"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:588;left:287"><nobr><span class="ft26"><i> Awakens</i></span></nobr></DIV>
<DIV style="position:absolute;top:588;left:281"><nobr><span class="ft27"></span></nobr></DIV>
<DIV style="position:absolute;top:642;left:431"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:661;left:114"><nobr><span class="ft7"><b>Fig. 5. Robot Navigation System context class diagram </b></span></nobr></DIV>
<DIV style="position:absolute;top:682;left:91"><nobr><span class="ft16">The system context class diagram of the <i>Robot Navigation System</i> <br>is shown in Fig. 5, which illustrates the external classes to which <br>the system has to interface. In our navigation system, a <br>commander enters a destination via a command line, to which the <br>robot should move. The system uses sensor data via various <br>sensors such as laser scanners, IR scanners, ultrasonic sensors, etc <br>and it controls the wheels of the robot via the wheel actuator. <br>Therefore, the external classes correspond to the users (i.e., a <br><i>Commander </i>who interacts with the system via a <i>Command Line</i>), <br>and I/O devices (i.e., a <i>Sensor</i> and <i>Wheel Actuator</i>). A <i>Clock</i> actor <br>needs an external timer class called <i>Clock</i> to provide timer events <br>to the system. This external timer class is needed to periodically <br>check sensor data via those sensors for avoiding obstacles (i.e., <br>doing the emergency stop) while the robot is moving. <br>Next, to structure the <i>Robot Navigation System</i> into objects, <br>object structuring needs to be considered in preparation for <br>dynamic modeling. The objective of the object structuring is to <br>decompose the problem into objects within the system. We <br>identified the internal objects according to the object structuring <br>criteria in COMET (see Fig. 6). In our system, interface objects, <br>i.e. a <i>Command Line Interface</i>,  <i>Sensor Interface</i> and <i>Wheel <br>Actuator Interface </i>are identified by identifying the external <br>classes that interface to the system, i.e. the <i>Command Line</i>, <br><i>Sensor</i>, and <i>Wheel Actuator</i>, respectively. There are four entity <br>objects identified, that is, a <i>Current Position</i>,  <i>Destination</i>, <br><i>Navigation Path</i> and <i>Navigation Map</i>, which are usually long-<br>living object that stores information. In addition to those objects, </span></nobr></DIV>
<DIV style="position:absolute;top:159;left:476"><nobr><span class="ft16">there is a need for control objects, which provide the overall <br>coordination for objects in a use case and may be coordinator, <br>state-dependent control, or timer objects. The <i>Navigation System</i> <br>has a state-dependent control object called <i>Navigation Control</i> <br>that controls the wheel actuator and sensors. The states of the <br><i>Navigation Control</i> object are shown on a <i>Navigation Control</i> <br>statechart (this will be discussed in the dynamic modeling). There <br>are two timer objects, i.e. a <i>Navigation Timer</i> and an <i>Obstacle <br>Avoidance Timer</i>. The <i>Obstacle Avoidance Timer</i> is activated by a <br>timer event from an external timer to periodically check that there <br>is any obstacle around the robot. On the other hand, the <br><i>Navigation Timer</i> is started by the <i>Navigation Control</i> object and <br>generates a timer event for navigation. Also, a <i>Localizer <br></i>algorithm object and <i>Path Planner</i> algorithm object are identified, <br>which encapsulate an algorithm used in the problem domain, <br>namely the autonomous navigation. </span></nobr></DIV>
<DIV style="position:absolute;top:412;left:628"><nobr><span class="ft28"><i><b>                                         &lt;&lt; Robot Navigation System &gt;&gt;</b></i></span></nobr></DIV>
<DIV style="position:absolute;top:451;left:482"><nobr><span class="ft25">Commander</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:481"><nobr><span class="ft29">(from 1.0 Actors)</span></nobr></DIV>
<DIV style="position:absolute;top:433;left:647"><nobr><span class="ft30">CommandLineInterface</span></nobr></DIV>
<DIV style="position:absolute;top:426;left:657"><nobr><span class="ft25">&lt;&lt;user interface&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:433;left:552"><nobr><span class="ft30">CommandLine</span></nobr></DIV>
<DIV style="position:absolute;top:427;left:551"><nobr><span class="ft25">&lt;&lt;external user&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:440;left:503"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:440;left:540"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:440;left:503"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:440;left:540"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:430;left:634"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:430;left:601"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:430;left:634"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:430;left:601"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:660"><nobr><span class="ft30">SensorInterface</span></nobr></DIV>
<DIV style="position:absolute;top:458;left:651"><nobr><span class="ft25">&lt;&lt;input device interface&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:552"><nobr><span class="ft30">Sensor</span></nobr></DIV>
<DIV style="position:absolute;top:458;left:533"><nobr><span class="ft25">&lt;&lt;external input device&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:634"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:602"><nobr><span class="ft25">1..*</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:634"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:602"><nobr><span class="ft25">1..*</span></nobr></DIV>
<DIV style="position:absolute;top:497;left:540"><nobr><span class="ft30">WheelActuator</span></nobr></DIV>
<DIV style="position:absolute;top:491;left:529"><nobr><span class="ft25">&lt;&lt;external output device&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:496;left:651"><nobr><span class="ft30">WheelActuatorInterface</span></nobr></DIV>
<DIV style="position:absolute;top:490;left:651"><nobr><span class="ft25">&lt;&lt;output device interface&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:503;left:601"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:501;left:634"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:503;left:601"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:501;left:634"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:528;left:752"><nobr><span class="ft30">Destination</span></nobr></DIV>
<DIV style="position:absolute;top:522;left:755"><nobr><span class="ft25">&lt;&lt;entity&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:559;left:645"><nobr><span class="ft30">Navigation Path</span></nobr></DIV>
<DIV style="position:absolute;top:553;left:655"><nobr><span class="ft25">&lt;&lt;entity&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:557;left:752"><nobr><span class="ft30">Navigation Map</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:761"><nobr><span class="ft25">&lt;&lt;entity&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:497;left:754"><nobr><span class="ft30">Current Position</span></nobr></DIV>
<DIV style="position:absolute;top:491;left:763"><nobr><span class="ft25">&lt;&lt;entity&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:433;left:754"><nobr><span class="ft30">Navigation Control</span></nobr></DIV>
<DIV style="position:absolute;top:426;left:755"><nobr><span class="ft25">&lt;&lt;state dependent&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:752"><nobr><span class="ft30">Navigation Timer</span></nobr></DIV>
<DIV style="position:absolute;top:457;left:763"><nobr><span class="ft25">&lt;&lt;timer&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:527;left:648"><nobr><span class="ft30">ObstacleAvoidanceTimer</span></nobr></DIV>
<DIV style="position:absolute;top:521;left:670"><nobr><span class="ft25">&lt;&lt;timer&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:528;left:564"><nobr><span class="ft30">Clock</span></nobr></DIV>
<DIV style="position:absolute;top:522;left:550"><nobr><span class="ft25">&lt;&lt;external timer&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:632"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:600"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:632"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:600"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:587;left:651"><nobr><span class="ft25">Localizer</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:644"><nobr><span class="ft25">&lt;&lt;algorithm&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:585;left:754"><nobr><span class="ft25">PathPlanner</span></nobr></DIV>
<DIV style="position:absolute;top:578;left:751"><nobr><span class="ft25">&lt;&lt;algorithm&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:595;left:823"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:613;left:497"><nobr><span class="ft7"><b>Fig. 6. Object structuring class diagram for Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:628;left:631"><nobr><span class="ft7"><b>System</b> </span></nobr></DIV>
<DIV style="position:absolute;top:658;left:476"><nobr><span class="ft22"><i>3.2.2</i></span></nobr></DIV>
<DIV style="position:absolute;top:658;left:508"><nobr><span class="ft23"><i> </i></span></nobr></DIV>
<DIV style="position:absolute;top:658;left:519"><nobr><span class="ft22"><i>Dynamic Modeling </i></span></nobr></DIV>
<DIV style="position:absolute;top:677;left:476"><nobr><span class="ft16">Dynamic modeling emphasizes the dynamic behavior of the <br>system and plays an important role for distributed, concurrent and <br>real-time system analysis. The dynamic model defines the object <br>interactions that correspond to each use case and thus is based on <br>the use cases and the objects identified during object structuring. <br>In our case, collaboration diagrams are developed to show the <br>sequence of object interactions for each use case. Additionally, if <br>the collaboration involves the state-dependent object, which <br>executes a statechart, the event sequence is shown on a statechart.  </span></nobr></DIV>
<DIV style="position:absolute;top:921;left:635"><nobr><span class="ft19"><b> : Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:927;left:642"><nobr><span class="ft19"><b>Control</b></span></nobr></DIV>
<DIV style="position:absolute;top:838;left:528"><nobr><span class="ft19"><b> : CommandLine</b></span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:510"><nobr><span class="ft19"><b> : Sensor</b></span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:784"><nobr><span class="ft19"><b> : WheelActuator</b></span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:674"><nobr><span class="ft19"><b> : WheelActuatorInterface</b></span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:594"><nobr><span class="ft19"><b> : SensorInterface</b></span></nobr></DIV>
<DIV style="position:absolute;top:964;left:526"><nobr><span class="ft19"><b> : Destination</b></span></nobr></DIV>
<DIV style="position:absolute;top:969;left:716"><nobr><span class="ft19"><b> : Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:975;left:727"><nobr><span class="ft19"><b>Path</b></span></nobr></DIV>
<DIV style="position:absolute;top:921;left:782"><nobr><span class="ft19"><b> : Navigation Map</b></span></nobr></DIV>
<DIV style="position:absolute;top:880;left:715"><nobr><span class="ft19"><b> : Current </b></span></nobr></DIV>
<DIV style="position:absolute;top:886;left:718"><nobr><span class="ft19"><b>Position</b></span></nobr></DIV>
<DIV style="position:absolute;top:838;left:620"><nobr><span class="ft19"><b> : CommandLineInterface</b></span></nobr></DIV>
<DIV style="position:absolute;top:884;left:529"><nobr><span class="ft19"><b> : Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:890;left:538"><nobr><span class="ft19"><b>Timer</b></span></nobr></DIV>
<DIV style="position:absolute;top:969;left:799"><nobr><span class="ft19"><b>Path </b></span></nobr></DIV>
<DIV style="position:absolute;top:975;left:796"><nobr><span class="ft19"><b>Planner</b></span></nobr></DIV>
<DIV style="position:absolute;top:880;left:796"><nobr><span class="ft19"><b>Localizer</b></span></nobr></DIV>
<DIV style="position:absolute;top:859;left:481"><nobr><span class="ft33"><i><b>Sequencing<br>Layer</b></i></span></nobr></DIV>
<DIV style="position:absolute;top:831;left:529"><nobr><span class="ft25">&lt;&lt;external user&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:830;left:630"><nobr><span class="ft25">&lt;&lt;user interface&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:914;left:623"><nobr><span class="ft25">&lt;&lt;state dependent control&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:877;left:535"><nobr><span class="ft25">&lt;&lt;timer&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:873;left:716"><nobr><span class="ft25">&lt;&lt;entity&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:873;left:791"><nobr><span class="ft25">&lt;&lt;algorithm&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:914;left:792"><nobr><span class="ft25">&lt;&lt;entity&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:957;left:532"><nobr><span class="ft25">&lt;&lt;entity&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:962;left:720"><nobr><span class="ft25">&lt;&lt;entity&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:960;left:789"><nobr><span class="ft25">&lt;&lt;algorithm&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:1023;left:498"><nobr><span class="ft25">&lt;&lt;external input device&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:1024;left:590"><nobr><span class="ft25">&lt;&lt;input device interface&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:1025;left:679"><nobr><span class="ft25">&lt;&lt;output device interface&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:1024;left:774"><nobr><span class="ft25">&lt;&lt;external output device&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:823;left:481"><nobr><span class="ft33"><i><b>Deliberate <br>Layer</b></i></span></nobr></DIV>
<DIV style="position:absolute;top:997;left:481"><nobr><span class="ft33"><i><b>Reactive <br>Layer</b></i></span></nobr></DIV>
<DIV style="position:absolute;top:954;left:582"><nobr><span class="ft25">1.2a: Store Destination</span></nobr></DIV>
<DIV style="position:absolute;top:960;left:574"><nobr><span class="ft25">2.11, 3.11 : Check Destination</span></nobr></DIV>
<DIV style="position:absolute;top:938;left:570"><nobr><span class="ft25">2.12 : No , 3.12: Yes</span></nobr></DIV>
<DIV style="position:absolute;top:960;left:668"><nobr><span class="ft25">1.13, 2.18: Planned Path</span></nobr></DIV>
<DIV style="position:absolute;top:945;left:684"><nobr><span class="ft25">1.10, 2.15: Read a Path</span></nobr></DIV>
<DIV style="position:absolute;top:993;left:696"><nobr><span class="ft25">1.14: Start</span></nobr></DIV>
<DIV style="position:absolute;top:998;left:695"><nobr><span class="ft25">2.19: Move</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:696"><nobr><span class="ft25">3.13: Stop</span></nobr></DIV>
<DIV style="position:absolute;top:1002;left:652"><nobr><span class="ft25">1.17: Started</span></nobr></DIV>
<DIV style="position:absolute;top:1007;left:650"><nobr><span class="ft25">3.16: Stopped</span></nobr></DIV>
<DIV style="position:absolute;top:892;left:639"><nobr><span class="ft25">1.4, 2.7, 3.7: Read Current Position</span></nobr></DIV>
<DIV style="position:absolute;top:901;left:701"><nobr><span class="ft25">1.7, 2.10, 3.10: Current Position</span></nobr></DIV>
<DIV style="position:absolute;top:912;left:725"><nobr><span class="ft25">1.2, 2.5, 3.5: Read Map</span></nobr></DIV>
<DIV style="position:absolute;top:918;left:726"><nobr><span class="ft25">1.8, 2.13: Update Map</span></nobr></DIV>
<DIV style="position:absolute;top:931;left:730"><nobr><span class="ft25">1.3, 2.6, 3.6 : Map</span></nobr></DIV>
<DIV style="position:absolute;top:936;left:724"><nobr><span class="ft25">1.9, 2.14: Updated Map</span></nobr></DIV>
<DIV style="position:absolute;top:834;left:572"><nobr><span class="ft25">1: Enter Destination</span></nobr></DIV>
<DIV style="position:absolute;top:868;left:594"><nobr><span class="ft25">1.1: Destination Entered</span></nobr></DIV>
<DIV style="position:absolute;top:1000;left:594"><nobr><span class="ft25">2.1, 3.1: Read Sensors</span></nobr></DIV>
<DIV style="position:absolute;top:1017;left:610"><nobr><span class="ft25">2.4, 3.4: Sensor Data</span></nobr></DIV>
<DIV style="position:absolute;top:1019;left:551"><nobr><span class="ft25">2.2, 3.2: Read</span></nobr></DIV>
<DIV style="position:absolute;top:1045;left:549"><nobr><span class="ft25">2.3, 3.3: Data</span></nobr></DIV>
<DIV style="position:absolute;top:1007;left:726"><nobr><span class="ft34">1.15: Start WheelActuator Output<br>2.20:Move WheelActuator Output</span></nobr></DIV>
<DIV style="position:absolute;top:1019;left:726"><nobr><span class="ft25">3.14: Stop WheelActuator Output</span></nobr></DIV>
<DIV style="position:absolute;top:1046;left:737"><nobr><span class="ft25">1.16, 5.8: Started Ack</span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:740"><nobr><span class="ft25">3.15: Stopped Ack</span></nobr></DIV>
<DIV style="position:absolute;top:868;left:746"><nobr><span class="ft25">1.5, 2.8, 3.8: Localize</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:737"><nobr><span class="ft25">1.6, 2.9, 3.9: Current Position</span></nobr></DIV>
<DIV style="position:absolute;top:895;left:574"><nobr><span class="ft25">2, 3: After(Elapsed Time)</span></nobr></DIV>
<DIV style="position:absolute;top:915;left:554"><nobr><span class="ft25">1.18, 5.10: Start Timer</span></nobr></DIV>
<DIV style="position:absolute;top:921;left:554"><nobr><span class="ft25">3.17, 4.10: Stop Timer</span></nobr></DIV>
<DIV style="position:absolute;top:981;left:755"><nobr><span class="ft25">1.12, 2.17: Path</span></nobr></DIV>
<DIV style="position:absolute;top:956;left:746"><nobr><span class="ft25">1.11, 2.16: Plan a path</span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:835"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:1070;left:501"><nobr><span class="ft7"><b>Fig. 7. Collaboration diagram for Navigation use case </b></span></nobr></DIV>
<DIV style="position:absolute;top:1165;left:449"><nobr><span class="ft5">538</span></nobr></DIV>
</DIV>
<!-- Page 6 -->
<a name="6"></a>
<DIV style="position:relative;width:918;height:1263;">
<STYLE type="text/css">
<!--
	.ft35{font-size:4px;font-family:Helvetica;color:#000000;}
	.ft36{font-size:2px;font-family:Helvetica;color:#000000;}
	.ft37{font-size:4px;line-height:7px;font-family:Helvetica;color:#000000;}
	.ft38{font-size:4px;line-height:7px;font-family:Helvetica;color:#000000;}
	.ft39{font-size:11px;line-height:20px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1263" src="203006.png" alt="background image">
<DIV style="position:absolute;top:159;left:91"><nobr><span class="ft16">In the navigation system, the <i>Localizer</i> has the algorithm which <br>can calculate the current position based on sensor data via sensors. <br>So, the role of the <i>Localizer</i> is to update the current position of <br>the service robot. In the <i>Path Planner</i> object, there is a method for <br>calculating a path to arrive at the destination based on both sensor <br>information and the current position that is calculated at the <br><i>Localizer</i>. The <i>Navigation Timer</i> is an internal timer that is <br>controlled by the <i>Navigation Control</i>. After the destination is <br>entered from the external user, the <i>Navigation Control</i> starts the <br><i>Navigation Timer</i>, then the timer generates a timer event <br>periodically (i.e., every 200ms) until the <i>Navigation Control</i> stops <br>the timer.  <br>The <i>Navigation  </i>use case starts with the commander entering the <br>destination into the navigation system. The message sequence <br>number starts at 1, which is the first external event initiated by the <br>actor. Subsequence numbering in sequence is from 1.1 to 1.18 as <br>shown in Fig. 7. The next message sequence activated by the <br><i>Navigation Timer</i> is numbered 2, followed by the events 2.1, 2.2, <br>and so forth. The following message sequences are illustrated in <br>the collaboration diagram (see Fig. 7).  <br>The collaboration diagram for the <i>Obstacle Avoidance</i> use case is <br>shown in Fig. 8. When activated by the <i>Obstacle Avoidance <br>Timer</i> every 50 ms, the <i>Sensor Interface</i> object reads sensor data <br>via various sensors (Events 4.1, 5.1, 6.1). If an obstacle is <br>recognized, the <i>Obstacle Avoidance Timer</i> sends the emergency <br>stop message to the <i>Wheel Actuator Interface</i> (Event 4.5). <br>Afterwards, the timer also sends a suspend event to the <br><i>Navigation Control</i>. If the obstacle disappears, the timer sends a <br>restart event to the <i>Navigation Control</i> for the robot to move <br>again. </span></nobr></DIV>
<DIV style="position:absolute;top:765;left:116"><nobr><span class="ft35"><b> : Sensor</b></span></nobr></DIV>
<DIV style="position:absolute;top:765;left:385"><nobr><span class="ft35"><b> : WheelActuator</b></span></nobr></DIV>
<DIV style="position:absolute;top:765;left:287"><nobr><span class="ft35"><b> : WheelActuatorInterface</b></span></nobr></DIV>
<DIV style="position:absolute;top:765;left:191"><nobr><span class="ft35"><b> : SensorInterface</b></span></nobr></DIV>
<DIV style="position:absolute;top:712;left:118"><nobr><span class="ft35"><b> : Clock</b></span></nobr></DIV>
<DIV style="position:absolute;top:712;left:178"><nobr><span class="ft35"><b> : ObstacleAvoidanceTimer</b></span></nobr></DIV>
<DIV style="position:absolute;top:645;left:287"><nobr><span class="ft30">&lt;&lt;state dependent control&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:701;left:109"><nobr><span class="ft30">&lt;&lt;external timer&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:757;left:100"><nobr><span class="ft30">&lt;&lt;external input device&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:703;left:205"><nobr><span class="ft30">&lt;&lt;timer&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:757;left:184"><nobr><span class="ft30">&lt;&lt;input device interface&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:757;left:290"><nobr><span class="ft30">&lt;&lt;output device interface&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:757;left:377"><nobr><span class="ft30">&lt;&lt;external output device&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:654;left:304"><nobr><span class="ft35"><b> : Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:661;left:312"><nobr><span class="ft35"><b>Control</b></span></nobr></DIV>
<DIV style="position:absolute;top:640;left:94"><nobr><span class="ft37"><i><b>Sequencing<br>Layer</b></i></span></nobr></DIV>
<DIV style="position:absolute;top:680;left:94"><nobr><span class="ft37"><i><b>Reactive <br>Layer</b></i></span></nobr></DIV>
<DIV style="position:absolute;top:703;left:336"><nobr><span class="ft30">5.6: Start</span></nobr></DIV>
<DIV style="position:absolute;top:691;left:288"><nobr><span class="ft30">5.9: Started</span></nobr></DIV>
<DIV style="position:absolute;top:694;left:139"><nobr><span class="ft30">4, 5, 6: Timer Event</span></nobr></DIV>
<DIV style="position:absolute;top:748;left:144"><nobr><span class="ft30">4.2, 5.2, 6.2: Read</span></nobr></DIV>
<DIV style="position:absolute;top:782;left:147"><nobr><span class="ft30">4.3, 5.3, 6.3: Data</span></nobr></DIV>
<DIV style="position:absolute;top:745;left:197"><nobr><span class="ft30">4.1, 5.1, 6.1: Read Sensors</span></nobr></DIV>
<DIV style="position:absolute;top:734;left:172"><nobr><span class="ft30">4.4, 5.4, 6.4: Sensor Data</span></nobr></DIV>
<DIV style="position:absolute;top:730;left:256"><nobr><span class="ft30">4.5: Stop</span></nobr></DIV>
<DIV style="position:absolute;top:757;left:256"><nobr><span class="ft30">4.8: Stopped</span></nobr></DIV>
<DIV style="position:absolute;top:665;left:219"><nobr><span class="ft38">4.9: Suspend<br>5.5: Restart</span></nobr></DIV>
<DIV style="position:absolute;top:681;left:219"><nobr><span class="ft30">6.5: Time Expired</span></nobr></DIV>
<DIV style="position:absolute;top:743;left:335"><nobr><span class="ft30">5.7: Start WheelActuator Output</span></nobr></DIV>
<DIV style="position:absolute;top:749;left:334"><nobr><span class="ft30">4.6 : Stop WheelActuator Output</span></nobr></DIV>
<DIV style="position:absolute;top:784;left:352"><nobr><span class="ft30">5.8: Started Ack</span></nobr></DIV>
<DIV style="position:absolute;top:791;left:350"><nobr><span class="ft30">4.7: Stopped Ack</span></nobr></DIV>
<DIV style="position:absolute;top:797;left:450"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:815;left:91"><nobr><span class="ft16"><b>Fig. 8. Collaboration diagram for Obstacle Avoidance use case <br></b>With COMET, the software architecture can be based on a <br>software architectural style (pattern) such as client/server or <br>layers of abstraction. In our project, the layered strategy of the <br>Tripodal schematic design described in section 2 is applied for <br>design and modeling of the robot system, which provides a <br>conceptual diagram of three layers (i.e., deliberate, sequencing, <br>and reactive layers) for arrangement of various hardware and <br>software modules and functions. Therefore, in the collaboration <br>diagrams (see Fig. 7 and 8), the <i>Command Line Interface</i> is <br>located in the deliberate layer and the <i>Sensor Interface</i>,  <i>Wheel <br>Actuator Interface</i>, and <i>Obstacle Avoidance Timer</i> are in the <br>reactive layer. The others are positioned in the sequencing layer.  <br>In our navigation system, after drawing the collaboration <br>diagrams for the <i>Navigation</i> and <i>Obstacle Avoidance</i> use cases <br>which include the <i>Navigation Control</i> state-dependent object, we <br>develop a <i>Navigation Control</i> statechart, which is executed by the <br><i>Navigation Control</i> object. The statechart needs to be considered </span></nobr></DIV>
<DIV style="position:absolute;top:159;left:476"><nobr><span class="ft32">in connection with the collaboration diagram. Specifically, it is <br>required to take into account the messages that are received and <br>sent by the control object, which executes the statechart [14]. An <br>input event (e.g., 1.1: <i>destination entered</i>) into the <i>Navigation <br>Control</i> object on the collaboration diagram should be consistent <br>with the same event shown on the statechart. The output event, <br>which causes an action, enable or disable activity, like 1.2: <i>Read <br>Map</i> (which cases an action) on the statechart must be consistent <br>with the output event depicted on the collaboration diagram.  <br>Because the statechart modeling involves two state-dependent use <br>cases in the navigation system, it is also required to consolidate <br>the two partial statecharts to create a complete statechart. The <br>complete statechart for both the <i>Navigation  </i>and  <i>Obstacle <br>Avoidance </i>use cases is shown in Fig. 9.  </span></nobr></DIV>
<DIV style="position:absolute;top:411;left:632"><nobr><span class="ft19"><b>Idle</b></span></nobr></DIV>
<DIV style="position:absolute;top:550;left:775"><nobr><span class="ft19"><b>Starting</b></span></nobr></DIV>
<DIV style="position:absolute;top:549;left:615"><nobr><span class="ft19"><b>Planning a Path</b></span></nobr></DIV>
<DIV style="position:absolute;top:505;left:776"><nobr><span class="ft19"><b>Checking </b></span></nobr></DIV>
<DIV style="position:absolute;top:511;left:774"><nobr><span class="ft19"><b>Destination</b></span></nobr></DIV>
<DIV style="position:absolute;top:411;left:777"><nobr><span class="ft19"><b>Stopping</b></span></nobr></DIV>
<DIV style="position:absolute;top:410;left:669"><nobr><span class="ft25">3.16: Stopped / 3.17: Stop Timer</span></nobr></DIV>
<DIV style="position:absolute;top:555;left:485"><nobr><span class="ft19"><b>Reading Sensors</b></span></nobr></DIV>
<DIV style="position:absolute;top:462;left:623"><nobr><span class="ft19"><b>Localizing</b></span></nobr></DIV>
<DIV style="position:absolute;top:613;left:627"><nobr><span class="ft19"><b>Moving</b></span></nobr></DIV>
<DIV style="position:absolute;top:587;left:661"><nobr><span class="ft25">1.17, 5.9: Started / 1.18, 5.10: Start Timer</span></nobr></DIV>
<DIV style="position:absolute;top:549;left:669"><nobr><span class="ft25">1.13: Planned Path[ Start ] / 1.14: Start</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:587"><nobr><span class="ft25">2.18: Planned Path[ Move ] / 2.19: Move</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:496"><nobr><span class="ft19"><b>Reading </b></span></nobr></DIV>
<DIV style="position:absolute;top:468;left:503"><nobr><span class="ft19"><b>Map</b></span></nobr></DIV>
<DIV style="position:absolute;top:509;left:482"><nobr><span class="ft25">2.4, 3.4: Sensor Data / 2.5, 3.5: Read Map</span></nobr></DIV>
<DIV style="position:absolute;top:436;left:493"><nobr><span class="ft25">1.1: Destination Entered / 1.2 : Read Map, 1.2a: Store Destination</span></nobr></DIV>
<DIV style="position:absolute;top:455;left:500"><nobr><span class="ft25">1.3, 2.6, 3.6: Map / 1.4, 2.7, 3.7: Read Current Position</span></nobr></DIV>
<DIV style="position:absolute;top:506;left:624"><nobr><span class="ft19"><b>Updating </b></span></nobr></DIV>
<DIV style="position:absolute;top:513;left:631"><nobr><span class="ft19"><b>Map</b></span></nobr></DIV>
<DIV style="position:absolute;top:491;left:655"><nobr><span class="ft25">2.10, 3.10:Current Position[ Move ] / 2.11, 3.11: Check Destination</span></nobr></DIV>
<DIV style="position:absolute;top:483;left:577"><nobr><span class="ft25">1.7: Current Position[ Start ] / 1.8: Update Map</span></nobr></DIV>
<DIV style="position:absolute;top:534;left:578"><nobr><span class="ft25">1.9, 2.14: Updated Map / 1.10, 2.15: Read a Path</span></nobr></DIV>
<DIV style="position:absolute;top:506;left:682"><nobr><span class="ft25">2.12: No / 2.13: Update Map</span></nobr></DIV>
<DIV style="position:absolute;top:465;left:767"><nobr><span class="ft25">3.12 : Yes / 3.13: Stop</span></nobr></DIV>
<DIV style="position:absolute;top:613;left:769"><nobr><span class="ft19"><b>Suspending</b></span></nobr></DIV>
<DIV style="position:absolute;top:591;left:484"><nobr><span class="ft25">2, 3: After( Elapsed Time ) / 2.1, 3.1: Read Sensors</span></nobr></DIV>
<DIV style="position:absolute;top:612;left:676"><nobr><span class="ft25">4.9: Suspend / 4.10: Stop Timer</span></nobr></DIV>
<DIV style="position:absolute;top:583;left:762"><nobr><span class="ft25">5.5: Restart / 5.6: Start</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:793"><nobr><span class="ft36">6.1: Time Expired</span></nobr></DIV>
<DIV style="position:absolute;top:619;left:832"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:637;left:537"><nobr><span class="ft7"><b>Fig. 9. Statechart for Navigation Control </b></span></nobr></DIV>
<DIV style="position:absolute;top:659;left:476"><nobr><span class="ft4"><b>3.3</b></span></nobr></DIV>
<DIV style="position:absolute;top:659;left:498"><nobr><span class="ft9"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:659;left:509"><nobr><span class="ft4"><b>Design Modeling </b></span></nobr></DIV>
<DIV style="position:absolute;top:688;left:476"><nobr><span class="ft22"><i>3.3.1</i></span></nobr></DIV>
<DIV style="position:absolute;top:687;left:508"><nobr><span class="ft23"><i> </i></span></nobr></DIV>
<DIV style="position:absolute;top:688;left:519"><nobr><span class="ft22"><i>Software Architecture </i></span></nobr></DIV>
<DIV style="position:absolute;top:706;left:476"><nobr><span class="ft16">In this phase, all collaboration diagrams developed for use cases <br>in the analysis model are merged into the consolidated <br>collaboration diagram.</span></nobr></DIV>
<DIV style="position:absolute;top:737;left:597"><nobr><span class="ft6"> </span></nobr></DIV>
<DIV style="position:absolute;top:737;left:601"><nobr><span class="ft5">The consolidated collaboration diagram is </span></nobr></DIV>
<DIV style="position:absolute;top:752;left:476"><nobr><span class="ft16">thus intended to be a complete description of all objects and their <br>interactions.  <br>The consolidation of the two collaboration diagrams respectively <br>supporting the two use cases is shown in Fig. 10. Some objects <br>and message interactions appear on more than one collaboration <br>diagram. For instance, the <i>Navigation Control</i>, <i>Navigation Timer</i>, <br><i>Sensor Interface</i> and <i>Wheel Actuator Interface</i> objects participate <br>in both the <i>Navigation</i> and <i>Obstacle Avoidance</i> use cases. For <br>those objects, their message interactions are only shown once in <br>the consolidated collaboration diagram.  </span></nobr></DIV>
<DIV style="position:absolute;top:927;left:476"><nobr><span class="ft22"><i>3.3.2</i></span></nobr></DIV>
<DIV style="position:absolute;top:927;left:508"><nobr><span class="ft23"><i> </i></span></nobr></DIV>
<DIV style="position:absolute;top:927;left:519"><nobr><span class="ft22"><i>Architectural Design of Distributed Real-time </i></span></nobr></DIV>
<DIV style="position:absolute;top:945;left:476"><nobr><span class="ft22"><i>Systems </i></span></nobr></DIV>
<DIV style="position:absolute;top:964;left:476"><nobr><span class="ft16">The robot system is a distributed embedded system and executes <br>on distributed nodes by the communication methods like TCP/IP, <br>CAN (Controller Area Network), and Wire/Wireless LAN. With <br>COMET, a distributed real-time system is structured into <br>distributed subsystems. Tasks in different subsystems may <br>communicate with each other via several types of message <br>communication, such as asynchronous, synchronous with reply, <br>synchronous without reply, and client/server communications, etc. </span></nobr></DIV>
<DIV style="position:absolute;top:1165;left:449"><nobr><span class="ft5">539</span></nobr></DIV>
</DIV>
<!-- Page 7 -->
<a name="7"></a>
<DIV style="position:relative;width:918;height:1263;">
<STYLE type="text/css">
<!--
	.ft40{font-size:2px;font-family:Helvetica;color:#000000;}
	.ft41{font-size:2px;line-height:5px;font-family:Helvetica;color:#000000;}
	.ft42{font-size:2px;line-height:5px;font-family:Helvetica;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1263" src="203007.png" alt="background image">
<DIV style="position:absolute;top:159;left:91"><nobr><span class="ft16">Hence, we should define distributed nodes and their messages to <br>each node.  <br>The overall distributed software architecture for the robot <br>navigation system is depicted in Fig. 11. In the robot system, <br>objects that are part of the navigation are located in the robot <br>navigation system. The robot navigation system communicates <br>with the external I/O devices via synchronous message without <br>reply communication and with the external timer via <br>asynchronous message communication.  </span></nobr></DIV>
<DIV style="position:absolute;top:411;left:249"><nobr><span class="ft24"><b> : Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:417;left:256"><nobr><span class="ft24"><b>Control</b></span></nobr></DIV>
<DIV style="position:absolute;top:328;left:143"><nobr><span class="ft24"><b> : CommandLine</b></span></nobr></DIV>
<DIV style="position:absolute;top:523;left:123"><nobr><span class="ft24"><b> : Sensor</b></span></nobr></DIV>
<DIV style="position:absolute;top:523;left:397"><nobr><span class="ft24"><b> : WheelActuator</b></span></nobr></DIV>
<DIV style="position:absolute;top:523;left:289"><nobr><span class="ft24"><b> : WheelActuatorInterface</b></span></nobr></DIV>
<DIV style="position:absolute;top:523;left:197"><nobr><span class="ft24"><b> : SensorInterface</b></span></nobr></DIV>
<DIV style="position:absolute;top:455;left:142"><nobr><span class="ft24"><b> : Destination</b></span></nobr></DIV>
<DIV style="position:absolute;top:460;left:331"><nobr><span class="ft24"><b> : Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:465;left:341"><nobr><span class="ft24"><b>Path</b></span></nobr></DIV>
<DIV style="position:absolute;top:411;left:397"><nobr><span class="ft24"><b> : Navigation Map</b></span></nobr></DIV>
<DIV style="position:absolute;top:370;left:330"><nobr><span class="ft24"><b> : Current </b></span></nobr></DIV>
<DIV style="position:absolute;top:376;left:332"><nobr><span class="ft24"><b>Position</b></span></nobr></DIV>
<DIV style="position:absolute;top:328;left:235"><nobr><span class="ft24"><b> : CommandLineInterface</b></span></nobr></DIV>
<DIV style="position:absolute;top:374;left:142"><nobr><span class="ft24"><b> : Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:379;left:151"><nobr><span class="ft24"><b>Timer</b></span></nobr></DIV>
<DIV style="position:absolute;top:460;left:414"><nobr><span class="ft24"><b>Path </b></span></nobr></DIV>
<DIV style="position:absolute;top:465;left:410"><nobr><span class="ft24"><b>Planner</b></span></nobr></DIV>
<DIV style="position:absolute;top:370;left:411"><nobr><span class="ft24"><b>Localizer</b></span></nobr></DIV>
<DIV style="position:absolute;top:320;left:142"><nobr><span class="ft36">&lt;&lt;external user&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:320;left:244"><nobr><span class="ft36">&lt;&lt;user interface&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:404;left:237"><nobr><span class="ft36">&lt;&lt;state dependent control&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:367;left:148"><nobr><span class="ft36">&lt;&lt;timer&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:363;left:331"><nobr><span class="ft36">&lt;&lt;entity&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:363;left:406"><nobr><span class="ft36">&lt;&lt;algorithm&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:404;left:406"><nobr><span class="ft36">&lt;&lt;entity&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:448;left:147"><nobr><span class="ft36">&lt;&lt;entity&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:453;left:334"><nobr><span class="ft36">&lt;&lt;entity&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:404"><nobr><span class="ft36">&lt;&lt;algorithm&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:515;left:111"><nobr><span class="ft36">&lt;&lt;external input device&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:516;left:192"><nobr><span class="ft36">&lt;&lt;input device interface&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:516;left:293"><nobr><span class="ft36">&lt;&lt;output device interface&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:516;left:385"><nobr><span class="ft36">&lt;&lt;external output device&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:569;left:127"><nobr><span class="ft24"><b> : Clock</b></span></nobr></DIV>
<DIV style="position:absolute;top:569;left:233"><nobr><span class="ft24"><b> : ObstacleAvoidanceTimer</b></span></nobr></DIV>
<DIV style="position:absolute;top:560;left:117"><nobr><span class="ft36">&lt;&lt;external timer&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:562;left:253"><nobr><span class="ft36">&lt;&lt;timer&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:94"><nobr><span class="ft41"><i><b>Deliberate <br>Layer</b></i></span></nobr></DIV>
<DIV style="position:absolute;top:348;left:94"><nobr><span class="ft41"><i><b>Sequencing<br>Layer</b></i></span></nobr></DIV>
<DIV style="position:absolute;top:488;left:94"><nobr><span class="ft41"><i><b>Reactive <br>Layer</b></i></span></nobr></DIV>
<DIV style="position:absolute;top:448;left:205"><nobr><span class="ft36">Store Destination</span></nobr></DIV>
<DIV style="position:absolute;top:453;left:204"><nobr><span class="ft36">Check Destination</span></nobr></DIV>
<DIV style="position:absolute;top:428;left:200"><nobr><span class="ft36">Yes/No</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:295"><nobr><span class="ft36">Planned Path</span></nobr></DIV>
<DIV style="position:absolute;top:437;left:311"><nobr><span class="ft36">Read a Path</span></nobr></DIV>
<DIV style="position:absolute;top:491;left:313"><nobr><span class="ft36">Start</span></nobr></DIV>
<DIV style="position:absolute;top:497;left:312"><nobr><span class="ft36">Move</span></nobr></DIV>
<DIV style="position:absolute;top:502;left:313"><nobr><span class="ft36">Stop</span></nobr></DIV>
<DIV style="position:absolute;top:498;left:280"><nobr><span class="ft36">Started</span></nobr></DIV>
<DIV style="position:absolute;top:504;left:279"><nobr><span class="ft36">Stopped</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:268"><nobr><span class="ft36">Read Current Position</span></nobr></DIV>
<DIV style="position:absolute;top:395;left:318"><nobr><span class="ft36">Current Position</span></nobr></DIV>
<DIV style="position:absolute;top:402;left:354"><nobr><span class="ft36">Read Map</span></nobr></DIV>
<DIV style="position:absolute;top:408;left:352"><nobr><span class="ft36">Update Map</span></nobr></DIV>
<DIV style="position:absolute;top:422;left:359"><nobr><span class="ft36">Map</span></nobr></DIV>
<DIV style="position:absolute;top:323;left:189"><nobr><span class="ft36">Enter Destination</span></nobr></DIV>
<DIV style="position:absolute;top:499;left:346"><nobr><span class="ft36">Start WheelActuator Output</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:346"><nobr><span class="ft36">Move WheelActuator Output</span></nobr></DIV>
<DIV style="position:absolute;top:511;left:347"><nobr><span class="ft36">Stop WheelActuator Output</span></nobr></DIV>
<DIV style="position:absolute;top:538;left:362"><nobr><span class="ft36">Started Ack</span></nobr></DIV>
<DIV style="position:absolute;top:544;left:360"><nobr><span class="ft36">Stopped Ack</span></nobr></DIV>
<DIV style="position:absolute;top:496;left:192"><nobr><span class="ft36">Read Sensors</span></nobr></DIV>
<DIV style="position:absolute;top:506;left:231"><nobr><span class="ft36">Sensor Data</span></nobr></DIV>
<DIV style="position:absolute;top:516;left:169"><nobr><span class="ft36">Read</span></nobr></DIV>
<DIV style="position:absolute;top:537;left:168"><nobr><span class="ft36">Data</span></nobr></DIV>
<DIV style="position:absolute;top:556;left:209"><nobr><span class="ft36">Read Sensors</span></nobr></DIV>
<DIV style="position:absolute;top:544;left:236"><nobr><span class="ft36">Sensor Data</span></nobr></DIV>
<DIV style="position:absolute;top:363;left:374"><nobr><span class="ft36">Localize</span></nobr></DIV>
<DIV style="position:absolute;top:384;left:365"><nobr><span class="ft36">Current Position</span></nobr></DIV>
<DIV style="position:absolute;top:358;left:213"><nobr><span class="ft36">Destination Entered</span></nobr></DIV>
<DIV style="position:absolute;top:385;left:197"><nobr><span class="ft36">After(Elapsed Time)</span></nobr></DIV>
<DIV style="position:absolute;top:401;left:179"><nobr><span class="ft42">Start Timer<br>Stop Timer</span></nobr></DIV>
<DIV style="position:absolute;top:471;left:380"><nobr><span class="ft36">Path</span></nobr></DIV>
<DIV style="position:absolute;top:456;left:373"><nobr><span class="ft36">Plan a path</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:167"><nobr><span class="ft36">Timer Event</span></nobr></DIV>
<DIV style="position:absolute;top:476;left:239"><nobr><span class="ft36">Suspend</span></nobr></DIV>
<DIV style="position:absolute;top:471;left:242"><nobr><span class="ft36">Restart</span></nobr></DIV>
<DIV style="position:absolute;top:481;left:231"><nobr><span class="ft36">Time Expired</span></nobr></DIV>
<DIV style="position:absolute;top:545;left:278"><nobr><span class="ft36">Stop</span></nobr></DIV>
<DIV style="position:absolute;top:553;left:300"><nobr><span class="ft36">Stopped</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:450"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:596;left:101"><nobr><span class="ft7"><b>Fig. 10. Consolidated collaboration diagram for Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:611;left:246"><nobr><span class="ft7"><b>System  </b></span></nobr></DIV>
<DIV style="position:absolute;top:645;left:108"><nobr><span class="ft18"><b> : CommandLine</b></span></nobr></DIV>
<DIV style="position:absolute;top:731;left:122"><nobr><span class="ft18"><b> : Sensor</b></span></nobr></DIV>
<DIV style="position:absolute;top:729;left:240"><nobr><span class="ft18"><b> : WheelActuator</b></span></nobr></DIV>
<DIV style="position:absolute;top:645;left:234"><nobr><span class="ft18"><b> : Robot Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:653;left:255"><nobr><span class="ft18"><b>System</b></span></nobr></DIV>
<DIV style="position:absolute;top:675;left:277"><nobr><span class="ft20">&lt;&lt; synchronous message without reply&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:676;left:129"><nobr><span class="ft20">&lt;&lt; synchronous message without reply&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:630;left:142"><nobr><span class="ft20">&lt;&lt; synchronous message without reply&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:644;left:401"><nobr><span class="ft18"><b> : Clock</b></span></nobr></DIV>
<DIV style="position:absolute;top:629;left:313"><nobr><span class="ft20">&lt;&lt;asynchronous message&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:636;left:170"><nobr><span class="ft20">Enter Destination</span></nobr></DIV>
<DIV style="position:absolute;top:682;left:278"><nobr><span class="ft20">Start WheelActuator Output</span></nobr></DIV>
<DIV style="position:absolute;top:690;left:278"><nobr><span class="ft20">Stop WheelActuator Output</span></nobr></DIV>
<DIV style="position:absolute;top:698;left:277"><nobr><span class="ft20">Move WheelActuator Output</span></nobr></DIV>
<DIV style="position:absolute;top:689;left:167"><nobr><span class="ft20">Read</span></nobr></DIV>
<DIV style="position:absolute;top:636;left:337"><nobr><span class="ft20">Timer Event</span></nobr></DIV>
<DIV style="position:absolute;top:738;left:433"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:756;left:108"><nobr><span class="ft7"><b>Fig. 11. Distributed software architecture for Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:772;left:246"><nobr><span class="ft7"><b>System</b> </span></nobr></DIV>
<DIV style="position:absolute;top:802;left:91"><nobr><span class="ft22"><i>3.3.3</i></span></nobr></DIV>
<DIV style="position:absolute;top:801;left:124"><nobr><span class="ft23"><i> </i></span></nobr></DIV>
<DIV style="position:absolute;top:802;left:134"><nobr><span class="ft22"><i>Task Structuring </i></span></nobr></DIV>
<DIV style="position:absolute;top:820;left:91"><nobr><span class="ft16">During the task structuring phase, a task architecture can be <br>developed in which the system is structured into concurrent tasks, <br>and the task interfaces and interconnections are defined. A task is <br>an active object and has its own thread of control. In this sense, <br>the term "object" will be used to refer to a passive object in this <br>paper. In COMET, task structuring criteria are provided to help in <br>mapping an object-oriented analysis model of the system to a <br>concurrent tasking architecture. At the end of this phase, a task <br>behavior specification (TBS) is developed.  <br>The task architecture for the <i>Navigation System</i> is shown in Fig. <br>12. In order to determine the tasks in the system, it is necessary to <br>understand how the objects in the application interact with each <br>other based on the collaboration diagrams. In the collaboration <br>diagram of Fig. 7, the <i>Localizer</i> object reads sensor data and the <br>map from the <i>Current Position</i> object, calculates a new current <br>position, and sends the current position to the <i>Current Position</i> <br>object for updating it. Thus, the <i>Localizer</i> object is structured as <br>an asynchronous algorithm task called <i>Localizer</i>. There are two </span></nobr></DIV>
<DIV style="position:absolute;top:159;left:476"><nobr><span class="ft16">asynchronous algorithms, i.e. <i>Localizer</i> and <i>Path Planner</i>, which <br>are internal asynchronous tasks. There are four passive entity <br>objects, i.e. <i>Destination</i>,  <i>Current Position</i>,  <i>Navigation Map</i>, and <br><i>Navigation Path</i>, which do not need a separate thread of control <br>and are further all categorized as data abstraction objects. The <br><i>Sensor</i> and <i>Wheel Actuator</i> are a passive input device and a <br>passive output device, respectively because they do not generate <br>an interrupt on completion of the input or output operation. </span></nobr></DIV>
<DIV style="position:absolute;top:300;left:592"><nobr><span class="ft19"><b> : CommandLine</b></span></nobr></DIV>
<DIV style="position:absolute;top:473;left:502"><nobr><span class="ft19"><b> : Sensor</b></span></nobr></DIV>
<DIV style="position:absolute;top:507;left:711"><nobr><span class="ft19"><b> : WheelActuator</b></span></nobr></DIV>
<DIV style="position:absolute;top:293;left:593"><nobr><span class="ft25">&lt;&lt; external user &gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:489"><nobr><span class="ft25">&lt;&lt; passive input device &gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:367;left:591"><nobr><span class="ft25">&lt;&lt; control clustering &gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:499;left:704"><nobr><span class="ft25">&lt;&lt; passive output device &gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:374;left:493"><nobr><span class="ft19"><b> : Destination</b></span></nobr></DIV>
<DIV style="position:absolute;top:417;left:691"><nobr><span class="ft19"><b> : Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:423;left:702"><nobr><span class="ft19"><b>Path</b></span></nobr></DIV>
<DIV style="position:absolute;top:374;left:775"><nobr><span class="ft19"><b> : Navigation Map</b></span></nobr></DIV>
<DIV style="position:absolute;top:328;left:690"><nobr><span class="ft19"><b> : Current </b></span></nobr></DIV>
<DIV style="position:absolute;top:334;left:692"><nobr><span class="ft19"><b>Position</b></span></nobr></DIV>
<DIV style="position:absolute;top:367;left:488"><nobr><span class="ft25">&lt;&lt; data abstraction &gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:328;left:793"><nobr><span class="ft19"><b> : Localizer</b></span></nobr></DIV>
<DIV style="position:absolute;top:417;left:801"><nobr><span class="ft19"><b> : Path </b></span></nobr></DIV>
<DIV style="position:absolute;top:423;left:800"><nobr><span class="ft19"><b>Planner</b></span></nobr></DIV>
<DIV style="position:absolute;top:320;left:772"><nobr><span class="ft25">&lt;&lt; asynchronous algotithm &gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:409;left:772"><nobr><span class="ft25">&lt;&lt; asynchronous algotithm &gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:374;left:596"><nobr><span class="ft19"><b> : Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:381;left:600"><nobr><span class="ft19"><b>Controller</b></span></nobr></DIV>
<DIV style="position:absolute;top:320;left:681"><nobr><span class="ft25">&lt;&lt; data abstraction &gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:409;left:684"><nobr><span class="ft25">&lt;&lt; data abstraction &gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:367;left:772"><nobr><span class="ft25">&lt;&lt; data abstraction &gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:507;left:504"><nobr><span class="ft19"><b> : Clock</b></span></nobr></DIV>
<DIV style="position:absolute;top:507;left:596"><nobr><span class="ft19"><b> : Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:514;left:600"><nobr><span class="ft19"><b>Controller</b></span></nobr></DIV>
<DIV style="position:absolute;top:500;left:586"><nobr><span class="ft25">&lt;&lt;sequential clustering&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:499;left:496"><nobr><span class="ft25">&lt;&lt;external timer&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:481"><nobr><span class="ft33"><i><b>Reactive <br>Layer</b></i></span></nobr></DIV>
<DIV style="position:absolute;top:290;left:481"><nobr><span class="ft33"><i><b>Deliberate <br>Layer</b></i></span></nobr></DIV>
<DIV style="position:absolute;top:319;left:481"><nobr><span class="ft33"><i><b>Sequencing<br>Layer</b></i></span></nobr></DIV>
<DIV style="position:absolute;top:322;left:612"><nobr><span class="ft25">enter (in destination)</span></nobr></DIV>
<DIV style="position:absolute;top:430;left:544"><nobr><span class="ft25">read(out sensorData)</span></nobr></DIV>
<DIV style="position:absolute;top:485;left:547"><nobr><span class="ft25">read(out sensorData)</span></nobr></DIV>
<DIV style="position:absolute;top:338;left:720"><nobr><span class="ft25">read(out sensorData, out map)</span></nobr></DIV>
<DIV style="position:absolute;top:344;left:725"><nobr><span class="ft25">update(in currentPosition)</span></nobr></DIV>
<DIV style="position:absolute;top:430;left:706"><nobr><span class="ft25">read(out destination,out currentPosition,out map)</span></nobr></DIV>
<DIV style="position:absolute;top:436;left:745"><nobr><span class="ft25">update(in path)</span></nobr></DIV>
<DIV style="position:absolute;top:355;left:544"><nobr><span class="ft25">store(destination)</span></nobr></DIV>
<DIV style="position:absolute;top:361;left:530"><nobr><span class="ft25">check(currentPosition, yes/no)</span></nobr></DIV>
<DIV style="position:absolute;top:344;left:614"><nobr><span class="ft25">read(in sensorData,in map,out currentPosition)</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:639"><nobr><span class="ft25">Start WheelActuator Output</span></nobr></DIV>
<DIV style="position:absolute;top:445;left:639"><nobr><span class="ft25">Move WheelActuator Output</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:639"><nobr><span class="ft25">Stop WheelActuator Output</span></nobr></DIV>
<DIV style="position:absolute;top:392;left:636"><nobr><span class="ft25">read(in destination,in currentPosition,in map, out path)</span></nobr></DIV>
<DIV style="position:absolute;top:364;left:688"><nobr><span class="ft25">read(out map)</span></nobr></DIV>
<DIV style="position:absolute;top:370;left:646"><nobr><span class="ft25">update(in sensorData, in currentPosition, out map)</span></nobr></DIV>
<DIV style="position:absolute;top:454;left:588"><nobr><span class="ft25">suspend()</span></nobr></DIV>
<DIV style="position:absolute;top:469;left:590"><nobr><span class="ft25">restart()</span></nobr></DIV>
<DIV style="position:absolute;top:502;left:539"><nobr><span class="ft25">timerEvent</span></nobr></DIV>
<DIV style="position:absolute;top:518;left:643"><nobr><span class="ft25">stopWheelActuatorOutput</span></nobr></DIV>
<DIV style="position:absolute;top:528;left:845"><nobr><span class="ft7"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:547;left:515"><nobr><span class="ft7"><b>Fig. 12. Task architecture for Navigation System </b></span></nobr></DIV>
<DIV style="position:absolute;top:568;left:476"><nobr><span class="ft16">The  <i>Navigation Control</i> is a state-dependent control object that <br>executes the <i>Navigation Control</i> statechart and is structured as a <br>control task because it needs to have a separate thread of control. <br>The  <i>Navigation Control</i> object can be combined with the <br><i>Command Line Interface</i>, <i>Navigation Timer</i>, <i>Sensor Interface</i>, and <br><i>Wheel Actuator Interface</i> objects into one task, Navigation <br>Controller, based on the control clustering task structuring <br>criterion because it is not possible for them to execute <br>concurrently (see the middle of Fig. 12). The <i>Obstacle Avoidance <br>Timer</i> object is structured as a periodic task, activated periodically <br>to read sensor data. It can be grouped with the <i>Sensor Interface</i> <br>and <i>Wheel Actuator Interface</i> into one sequentially clustered task, <br><i>Obstacle Avoidance Controller</i> based on sequential clustering <br>since those are carried out in a sequential order. The design of <br>those composite tasks, the <i>Navigation Controller</i> and <i>Obstacle <br>Avoidance Controller</i> are considered in the next section (i.e., <br>detailed software design).  <br>After developing the task architecture, a task behavior is <br>described for specifying the characteristics of each task based on <br>COMET. During the task structuring, the TBS focuses on the task <br>inputs and outputs. One part of the TBS, i.e. the task's event <br>sequencing logic is defined in the detailed software design phase.  </span></nobr></DIV>
<DIV style="position:absolute;top:927;left:476"><nobr><span class="ft22"><i>3.3.4</i></span></nobr></DIV>
<DIV style="position:absolute;top:927;left:508"><nobr><span class="ft23"><i> </i></span></nobr></DIV>
<DIV style="position:absolute;top:927;left:519"><nobr><span class="ft22"><i>Detailed Software Design </i></span></nobr></DIV>
<DIV style="position:absolute;top:946;left:476"><nobr><span class="ft16">The internals of composite tasks which have passive objects <br>nested inside them are designed, detailed task synchronization <br>issues are addressed, and each task's internal event sequencing <br>logic is defined in this phase. Before this is done, the information <br>hiding classes (from which the passive objects are instantiated) <br>are designed. In particular, the operations of each class and the <br>design of the class interfaces are determined and specified in a <br>class interface specification (because of space limitation, the <br>detailed TBS and the class interface specification have not been <br>included).  </span></nobr></DIV>
<DIV style="position:absolute;top:1165;left:449"><nobr><span class="ft5">540</span></nobr></DIV>
</DIV>
<!-- Page 8 -->
<a name="8"></a>
<DIV style="position:relative;width:918;height:1263;">
<STYLE type="text/css">
<!--
	.ft43{font-size:3px;line-height:6px;font-family:Helvetica;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1263" src="203008.png" alt="background image">
<DIV style="position:absolute;top:159;left:91"><nobr><span class="ft16">Let us consider the internal design of the <i>Navigation Controller</i>, <br>which is a composite task designed as a control clustering task, to <br>show the nested information hiding objects (see Fig. 13). The <br>information hiding objects are the <i>Navigation Control</i> state-<br>dependent control object, the <i>Sensor Interface</i> and <i>Wheel <br>Actuator Interface</i> objects, the <i>Navigation Timer</i> object and the <br>user interface object, the <i>Command Line Interface</i>. In addition, <br>the <i>Navigation Controller</i> contains one coordinator object called <br><i>Navigation Coordinator</i>, which receives incoming messages and <br>coordinates the execution of the other objects. That is, the <br><i>Navigation Coordinator</i> extracts the event from the request and <br>calls <i>Navigation Control.processEvent (in event, out action)</i> (see <br>Fig. 13). The <i>Navigation Control</i> returns the action to be <br>performed like store, check, start, etc according to the state <br>transition table. Afterwards, the <i>Navigation Coordinator</i> initiates <br>the action. </span></nobr></DIV>
<DIV style="position:absolute;top:456;left:146"><nobr><span class="ft34">&lt;&lt;control clustering&gt;&gt;<br>      :NavigationController</span></nobr></DIV>
<DIV style="position:absolute;top:558;left:232"><nobr><span class="ft19"><b> : Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:564;left:239"><nobr><span class="ft19"><b>Control</b></span></nobr></DIV>
<DIV style="position:absolute;top:499;left:155"><nobr><span class="ft19"><b> : Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:505;left:164"><nobr><span class="ft19"><b>Timer</b></span></nobr></DIV>
<DIV style="position:absolute;top:459;left:217"><nobr><span class="ft19"><b> : CommandLineInterface</b></span></nobr></DIV>
<DIV style="position:absolute;top:419;left:368"><nobr><span class="ft19"><b> : Current </b></span></nobr></DIV>
<DIV style="position:absolute;top:424;left:370"><nobr><span class="ft19"><b>Position</b></span></nobr></DIV>
<DIV style="position:absolute;top:499;left:393"><nobr><span class="ft19"><b> : Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:505;left:405"><nobr><span class="ft19"><b>Map</b></span></nobr></DIV>
<DIV style="position:absolute;top:539;left:394"><nobr><span class="ft19"><b> : Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:545;left:405"><nobr><span class="ft19"><b>Path</b></span></nobr></DIV>
<DIV style="position:absolute;top:558;left:284"><nobr><span class="ft19"><b> : WheelActuatorInterface</b></span></nobr></DIV>
<DIV style="position:absolute;top:605;left:354"><nobr><span class="ft19"><b> : WheelActuator</b></span></nobr></DIV>
<DIV style="position:absolute;top:558;left:153"><nobr><span class="ft19"><b> : SensorInterface</b></span></nobr></DIV>
<DIV style="position:absolute;top:600;left:113"><nobr><span class="ft19"><b> : Sensor</b></span></nobr></DIV>
<DIV style="position:absolute;top:420;left:110"><nobr><span class="ft19"><b> : Destination</b></span></nobr></DIV>
<DIV style="position:absolute;top:499;left:232"><nobr><span class="ft19"><b> : Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:505;left:233"><nobr><span class="ft19"><b>Coordinator</b></span></nobr></DIV>
<DIV style="position:absolute;top:419;left:228"><nobr><span class="ft19"><b> : CommandLine</b></span></nobr></DIV>
<DIV style="position:absolute;top:412;left:227"><nobr><span class="ft25">&lt;&lt; external user &gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:452;left:227"><nobr><span class="ft25">&lt;&lt;user interface&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:492;left:161"><nobr><span class="ft25">&lt;&lt;timer&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:491;left:230"><nobr><span class="ft25">&lt;&lt;coordinator&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:410;left:357"><nobr><span class="ft25">&lt;&lt;data abstraction&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:491;left:386"><nobr><span class="ft25">&lt;&lt;data abstraction&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:530;left:384"><nobr><span class="ft25">&lt;&lt;data abstraction&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:147"><nobr><span class="ft25">&lt;&lt;input device interface&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:217"><nobr><span class="ft25">&lt;&lt;state dependent control&gt;&gt; &lt;&lt;output device interface&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:412;left:101"><nobr><span class="ft25">&lt;&lt;data abstraction&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:360"><nobr><span class="ft25">Start WheelActuator Output</span></nobr></DIV>
<DIV style="position:absolute;top:581;left:359"><nobr><span class="ft25">Move WheelActuator Output</span></nobr></DIV>
<DIV style="position:absolute;top:587;left:360"><nobr><span class="ft25">Stop WheelActuator Output</span></nobr></DIV>
<DIV style="position:absolute;top:587;left:153"><nobr><span class="ft25">read(out sensorData)</span></nobr></DIV>
<DIV style="position:absolute;top:434;left:153"><nobr><span class="ft25">store(in destination)</span></nobr></DIV>
<DIV style="position:absolute;top:440;left:135"><nobr><span class="ft25">check(in currentPosition,out yes/no)</span></nobr></DIV>
<DIV style="position:absolute;top:542;left:192"><nobr><span class="ft25">read(out sensorData)</span></nobr></DIV>
<DIV style="position:absolute;top:513;left:196"><nobr><span class="ft43">startTimer( )<br>stopTimer( )</span></nobr></DIV>
<DIV style="position:absolute;top:493;left:198"><nobr><span class="ft25">activate( )</span></nobr></DIV>
<DIV style="position:absolute;top:441;left:312"><nobr><span class="ft25">read(in sensorData, in map, out CurrentPosition)</span></nobr></DIV>
<DIV style="position:absolute;top:490;left:319"><nobr><span class="ft25">read(out map)</span></nobr></DIV>
<DIV style="position:absolute;top:496;left:287"><nobr><span class="ft25">update(sensorData, currentPosition, map)</span></nobr></DIV>
<DIV style="position:absolute;top:514;left:308"><nobr><span class="ft25">read(destination, currentPosition, map)</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:298"><nobr><span class="ft25">start(in path,out started)</span></nobr></DIV>
<DIV style="position:absolute;top:539;left:310"><nobr><span class="ft25">move(in path)</span></nobr></DIV>
<DIV style="position:absolute;top:545;left:305"><nobr><span class="ft25">stop(out stopped)</span></nobr></DIV>
<DIV style="position:absolute;top:528;left:219"><nobr><span class="ft25">processEvent(in event,out action)</span></nobr></DIV>
<DIV style="position:absolute;top:480;left:223"><nobr><span class="ft25">startRobot(in destination)</span></nobr></DIV>
<DIV style="position:absolute;top:436;left:252"><nobr><span class="ft25">enter(in destination)</span></nobr></DIV>
<DIV style="position:absolute;top:608;left:436"><nobr><span class="ft7"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:627;left:102"><nobr><span class="ft7"><b>Fig. 13. Detailed software design for Navigation Controller </b></span></nobr></DIV>
<DIV style="position:absolute;top:648;left:91"><nobr><span class="ft16">In our system, communication between tasks such as the <br><i>Navigation Controller</i>,  <i>Localizer</i>, and <i>Path Planner</i> is through <br>data abstraction classes like the <i>Current Position</i> and <i>Navigation <br>Path</i>. As a result, connector objects [14] are not used for the <br>message communication interface between tasks. </span></nobr></DIV>
<DIV style="position:absolute;top:735;left:97"><nobr><span class="ft24"><b> : CommandLineInterface</b></span></nobr></DIV>
<DIV style="position:absolute;top:735;left:151"><nobr><span class="ft24"><b> : Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:739;left:156"><nobr><span class="ft24"><b>Control</b></span></nobr></DIV>
<DIV style="position:absolute;top:735;left:184"><nobr><span class="ft24"><b> : Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:739;left:185"><nobr><span class="ft24"><b>Coordinator</b></span></nobr></DIV>
<DIV style="position:absolute;top:735;left:216"><nobr><span class="ft24"><b> : Destination  : Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:740;left:252"><nobr><span class="ft24"><b>Map</b></span></nobr></DIV>
<DIV style="position:absolute;top:735;left:275"><nobr><span class="ft24"><b> : Current </b></span></nobr></DIV>
<DIV style="position:absolute;top:740;left:277"><nobr><span class="ft24"><b>Position</b></span></nobr></DIV>
<DIV style="position:absolute;top:735;left:302"><nobr><span class="ft24"><b> : Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:739;left:310"><nobr><span class="ft24"><b>Path</b></span></nobr></DIV>
<DIV style="position:absolute;top:735;left:333"><nobr><span class="ft24"><b> : WheelActuatorInterface</b></span></nobr></DIV>
<DIV style="position:absolute;top:735;left:388"><nobr><span class="ft24"><b> : Navigation </b></span></nobr></DIV>
<DIV style="position:absolute;top:739;left:395"><nobr><span class="ft24"><b>Timer</b></span></nobr></DIV>
<DIV style="position:absolute;top:735;left:430"><nobr><span class="ft24"><b> : </b></span></nobr></DIV>
<DIV style="position:absolute;top:740;left:416"><nobr><span class="ft24"><b>SensorInterface</b></span></nobr></DIV>
<DIV style="position:absolute;top:745;left:137"><nobr><span class="ft36">1. startRobot(destination)</span></nobr></DIV>
<DIV style="position:absolute;top:763;left:193"><nobr><span class="ft36">1.2. store(destination)</span></nobr></DIV>
<DIV style="position:absolute;top:781;left:201"><nobr><span class="ft36">1.4. read(map)</span></nobr></DIV>
<DIV style="position:absolute;top:803;left:200"><nobr><span class="ft36">1.6. read(sensorData, map, currentPosition)</span></nobr></DIV>
<DIV style="position:absolute;top:756;left:152"><nobr><span class="ft36">1.1. processEvent(event, action)</span></nobr></DIV>
<DIV style="position:absolute;top:774;left:152"><nobr><span class="ft36">1.3. processEvent(event, action)</span></nobr></DIV>
<DIV style="position:absolute;top:792;left:152"><nobr><span class="ft36">1.5. processEvent(event, action)</span></nobr></DIV>
<DIV style="position:absolute;top:813;left:152"><nobr><span class="ft36">1.7. processEvent(event, action)</span></nobr></DIV>
<DIV style="position:absolute;top:819;left:201"><nobr><span class="ft36">1.8. update(sensorData, currentPosition, map)</span></nobr></DIV>
<DIV style="position:absolute;top:830;left:152"><nobr><span class="ft36">1.9. processEvent(event, action)</span></nobr></DIV>
<DIV style="position:absolute;top:836;left:212"><nobr><span class="ft36">1.10. read(destination, currentPosition, map, path)</span></nobr></DIV>
<DIV style="position:absolute;top:848;left:151"><nobr><span class="ft36">1.11. processEvent(event, action)</span></nobr></DIV>
<DIV style="position:absolute;top:853;left:256"><nobr><span class="ft36">1.12. start(path, started)</span></nobr></DIV>
<DIV style="position:absolute;top:864;left:151"><nobr><span class="ft36">1.13. processEvent(event, action)</span></nobr></DIV>
<DIV style="position:absolute;top:868;left:282"><nobr><span class="ft36">1.14. startTimer( )</span></nobr></DIV>
<DIV style="position:absolute;top:885;left:287"><nobr><span class="ft36">2. activate( )</span></nobr></DIV>
<DIV style="position:absolute;top:893;left:152"><nobr><span class="ft36">2.1. processEvent(event, action)</span></nobr></DIV>
<DIV style="position:absolute;top:897;left:295"><nobr><span class="ft36">2.2. read(sensorData)</span></nobr></DIV>
<DIV style="position:absolute;top:908;left:152"><nobr><span class="ft36">2.3. processEvent(event, action)</span></nobr></DIV>
<DIV style="position:absolute;top:913;left:213"><nobr><span class="ft36">2.4. read(map)</span></nobr></DIV>
<DIV style="position:absolute;top:924;left:152"><nobr><span class="ft36">2.5. processEvent(event, action)</span></nobr></DIV>
<DIV style="position:absolute;top:929;left:202"><nobr><span class="ft36">2.6. read(sensorData, map, currentPosition)</span></nobr></DIV>
<DIV style="position:absolute;top:937;left:152"><nobr><span class="ft36">2.7. processEvent(event, action)</span></nobr></DIV>
<DIV style="position:absolute;top:946;left:199"><nobr><span class="ft36">2.8. check(currentPosition, yes/no)</span></nobr></DIV>
<DIV style="position:absolute;top:964;left:199"><nobr><span class="ft36">2.10. update(sensorData, currentPosition, map)</span></nobr></DIV>
<DIV style="position:absolute;top:955;left:152"><nobr><span class="ft36">2.9. processEvent(event, action)</span></nobr></DIV>
<DIV style="position:absolute;top:982;left:212"><nobr><span class="ft36">2.12. read(destination, currentPosition, map, path)</span></nobr></DIV>
<DIV style="position:absolute;top:974;left:151"><nobr><span class="ft36">2.11. processEvent(event, action)</span></nobr></DIV>
<DIV style="position:absolute;top:990;left:151"><nobr><span class="ft36">2.13. processEvent(event, action)</span></nobr></DIV>
<DIV style="position:absolute;top:995;left:262"><nobr><span class="ft36">2.14. move(path)</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:262"><nobr><span class="ft36">3. stop(stopped)</span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:154"><nobr><span class="ft36">4. processEvent(event, action)</span></nobr></DIV>
<DIV style="position:absolute;top:1033;left:285"><nobr><span class="ft36">5. stopTimer( )</span></nobr></DIV>
<DIV style="position:absolute;top:985;left:116"><nobr><span class="ft36">if not desitniation</span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:120"><nobr><span class="ft36">if destination</span></nobr></DIV>
<DIV style="position:absolute;top:1044;left:449"><nobr><span class="ft7"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:1063;left:104"><nobr><span class="ft7"><b>Fig. 14. The task event diagram for Navigation Controller </b></span></nobr></DIV>
<DIV style="position:absolute;top:159;left:476"><nobr><span class="ft16">Lastly, the task's event sequencing logic is specified, which <br>describes how the task responds to each of its message or event <br>inputs. However, instead of using informally Pseudo code in <br>COMET, in this project, task event diagrams are developed for <br>tasks by using the UML sequence diagrams for understanding and <br>readability, which turned out to be very useful when to implement <br>the tasks. Fig. 14 illustrates the task event diagram for the <br><i>Navigation Controller</i>. </span></nobr></DIV>
<DIV style="position:absolute;top:298;left:476"><nobr><span class="ft4"><b>4.</b></span></nobr></DIV>
<DIV style="position:absolute;top:297;left:489"><nobr><span class="ft9"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:298;left:500"><nobr><span class="ft4"><b>LESSONS LEARNED </b></span></nobr></DIV>
<DIV style="position:absolute;top:317;left:476"><nobr><span class="ft16">This section summarizes the lessons learned from the project <br>where we successfully applied the object-oriented method with <br>UML to developing the service robot. </span></nobr></DIV>
<DIV style="position:absolute;top:373;left:476"><nobr><span class="ft4"><b>4.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:373;left:498"><nobr><span class="ft9"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:373;left:509"><nobr><span class="ft4"><b>UML for Service Robot Domain </b></span></nobr></DIV>
<DIV style="position:absolute;top:393;left:476"><nobr><span class="ft16">Through the case study, we found that the UML standard was <br>very useful as a notation for specifying the requirements, <br>documenting the structure, decomposing into objects, and <br>defining relationships between objects especially in a service <br>robot system. Certain diagrams and notations were particularly <br>importance for analyzing, designing, and modeling service robot <br>systems as follows. </span></nobr></DIV>
<DIV style="position:absolute;top:506;left:486"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:507;left:505"><nobr><span class="ft16">Use case diagrams: With the use case model, services or <br>functions (i.e., functional requirements), which a service <br>robot performs or provides, can be defined in terms of actors <br>who are users of the robot system and use cases. Each use <br>case defines the behavior of some aspect of the robot system <br>without revealing its internal structure.  </span></nobr></DIV>
<DIV style="position:absolute;top:605;left:486"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:605;left:505"><nobr><span class="ft16">Class diagrams: The class diagram notation is used to depict <br>the static model, which focuses on the static structure of the <br>robot system. The class diagram shows the classes of objects <br>in the system, their internal structure including attributes, <br>their operations, and their relationships to other classes <br>(such as associations and generalization/inheritance).  </span></nobr></DIV>
<DIV style="position:absolute;top:703;left:486"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:703;left:505"><nobr><span class="ft16">Collaboration diagrams: This diagram shows how objects <br>that participate in each use case interact with each other by <br>sending and receiving messages in the dynamic model. It <br>defines a specific way to use objects in the robot system by <br>showing the possible interactions between them, especially <br>to satisfy the needs described in the use case, namely <br>provide the services. Compared to a sequence diagram, the <br>diagram in particular is useful for synthesizing the <br>collaboration diagrams to create the software architecture of <br>the system as discussed in section 3.3. </span></nobr></DIV>
<DIV style="position:absolute;top:863;left:486"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:863;left:505"><nobr><span class="ft16">Sequence diagrams: This diagram show objects interaction <br>arranged in time sequence and in particular could be used to <br>describe the task event sequencing logic, which describes <br>how the task responds to each of its message or event inputs. <br>In COMET, the event sequencing logic is usually described <br>informally in Pseudo code. We found that the sequence <br>diagram can help the engineers describe the task event <br>sequencing logic and implement the tasks by showing the <br>order in which messages are passed between tasks and <br>objects.  </span></nobr></DIV>
<DIV style="position:absolute;top:1023;left:486"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:1023;left:505"><nobr><span class="ft16">State chart diagrams: The service robot system is highly <br>state-dependent like real-time embedded systems. This <br>diagram describes how state-dependent aspects of the <br>system are defined by a finite state machine and can help <br>design and developing highly state-dependent systems. It is </span></nobr></DIV>
<DIV style="position:absolute;top:1165;left:449"><nobr><span class="ft5">541</span></nobr></DIV>
</DIV>
<!-- Page 9 -->
<a name="9"></a>
<DIV style="position:relative;width:918;height:1263;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1263" src="203009.png" alt="background image">
<DIV style="position:absolute;top:159;left:120"><nobr><span class="ft16">also possible for this diagram to model object behavior over <br>several use cases with the collaboration diagrams. </span></nobr></DIV>
<DIV style="position:absolute;top:196;left:91"><nobr><span class="ft16">In addition, by using the UML notation as a defined standard, <br>different research groups and development teams can <br>communicate among themselves and with others to develop and <br>integrate specific components for providing various services.  </span></nobr></DIV>
<DIV style="position:absolute;top:267;left:91"><nobr><span class="ft4"><b>4.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:266;left:113"><nobr><span class="ft9"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:267;left:124"><nobr><span class="ft4"><b>Importance of Systematic Process/Method </b></span></nobr></DIV>
<DIV style="position:absolute;top:287;left:91"><nobr><span class="ft4"><b>for Service Robot Domain </b></span></nobr></DIV>
<DIV style="position:absolute;top:307;left:91"><nobr><span class="ft16">In order to effectively apply the UML notation and the robot <br>control architecture like the Tripodal schematic control <br>architecture to developing service robots, it is essential to use <br>them with a systematic software engineering process or method,  <br>like an object-oriented analysis and design method, especially for <br>real-time and embedded systems. It is not possible to resolve the <br>issues in integrating and developing the service robots discussed <br>before without systematic and comprehensive software <br>development methods, particularly for service robots. <br>In our case study, we applied COMET/UML method to <br>developing the service robot. The COMET object-oriented <br>software life cycle model is a highly iterative software <br>development process based around the use case concept. In the <br>requirements model, the service or functions (i.e., the function <br>requirements) of the robot system are defined in terms of actors <br>and use cases. In the analysis model, the use case is refined to <br>describe the objects that participate in the use case, and their <br>interactions. In the design model, the robot software architecture <br>is developed, emphasizing issues of distribution, concurrency, and <br>information hiding. This project showed that this was a viable <br>approach because applying the COMET method with UML led to <br>developing an effective service robot architecture by carefully <br>taking into account user needs and requirements, implementing <br>technical components based on the architecture, and integrating <br>these components in a systematic and comprehensive fashion.  </span></nobr></DIV>
<DIV style="position:absolute;top:707;left:91"><nobr><span class="ft4"><b>4.3</b></span></nobr></DIV>
<DIV style="position:absolute;top:707;left:113"><nobr><span class="ft9"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:707;left:124"><nobr><span class="ft4"><b>Customizing the COMET Method for </b></span></nobr></DIV>
<DIV style="position:absolute;top:728;left:91"><nobr><span class="ft4"><b>Service Robot Domain </b></span></nobr></DIV>
<DIV style="position:absolute;top:748;left:91"><nobr><span class="ft16">Service robots like <i>PSR-1</i>,  <i>PSR-2</i>, and <i>Jinny</i> have been built at <br>KIST based on the Tripodal schematic control architecture. The <br>Tripodal schematic design addressed on developing efficient and <br>well-defined control architecture and a system integration strategy <br>for constructing service robots. T-Rot is the next model of the <br>PSR system under development for assisting aged persons. One of <br>our aims is to develop the intelligent service robot for the elderly <br>by cooperating and integrating the results of different research <br>groups in accordance with the Tripodal schematic control <br>architecture that has already been implemented on the PSR and <br>successfully tested. Thus, the layered strategy of the Tripodal <br>schematic design has been applied for design and modeling of the <br>T-Rot. In the collaboration diagrams of the analysis modeling, <br>and the consolidated collaboration diagram and the task <br>architecture of the design modeling, the <i>Command Line Interface</i> <br>is located in the deliberate layer for interfacing with a user, while <br>the  <i>Sensor Interface</i>,  <i>Wheel Actuator Interface</i>, and <i>Obstacle <br>Avoidance Timer </i>are in the reactive layer for controlling and <br>managing the components in the reactive layer. The<i> Navigation <br>Control</i>,  <i>Navigation Timer</i>,  <i>Destination</i>,  <i>Current Position</i>, <br><i>Navigation Path</i>, <i>Navigation Map</i>, <i>Localizer</i>, and <i>Path Planer</i> are <br>positioned in the sequencing layer for controlling the robot <br>motion by executing relatively simple computations in real-time. </span></nobr></DIV>
<DIV style="position:absolute;top:159;left:476"><nobr><span class="ft16">As a result, the Tripodal schematic control architecture was <br>helpful in arranging various hardware and software modules and <br>functions.  <br>Additionally, as stated in section 4.1, in COMET, the event <br>sequencing logic is usually described informally in Pseudo code. <br>We found that the sequence diagram can help the engineers <br>describe the task event sequencing logic and implement the tasks <br>by showing the order in which messages are passed between tasks <br>and objects. Hence, instead of using informal Pseudo code, task <br>event diagrams were developed for tasks by using the UML <br>sequence diagrams to improve understanding and readability. It <br>turned out that these task event diagrams are very useful when <br>implementing these tasks. </span></nobr></DIV>
<DIV style="position:absolute;top:375;left:476"><nobr><span class="ft4"><b>4.4</b></span></nobr></DIV>
<DIV style="position:absolute;top:374;left:498"><nobr><span class="ft9"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:375;left:509"><nobr><span class="ft4"><b>Human Communication </b></span></nobr></DIV>
<DIV style="position:absolute;top:394;left:476"><nobr><span class="ft16">Human communication to understand and develop what is desired <br>of the service robot is likely to be more difficult than expected. In <br>our case study, most engineers who are involved in the project <br>come from the mechanical or robotics engineering field. The <br>different research groups and teams tend to focus on their own <br>technology and components and thus it is not easy to realize how <br>much knowledge they have and how much information will need <br>to be made explicit and communicated to integrate those <br>components for the service robot. Several things can be done to <br>improve the situation. One is for engineers from different teams, <br>especially software engineers and mechanical engineers to work <br>together for analyzing, designing, and developing the robot <br>system during the project. It is very important that all engineers <br>and developers from different groups and teams interact directly. <br>Also, in order to develop a common ground for understanding the <br>domain, technology, process and method, a common medium or <br>language such as UML is critical. In addition to the standard <br>notation like UML, guidelines about what notation to use, when <br>to use it, and how to use the notation comprehensively and <br>systematically are required. This is why the method like COMET <br>is needed. Domain knowledge and experiences in each area will <br>make it much easier to communicate what is desired, e.g. service <br>robot domain, the autonomous robot navigation, vision processing, <br>and so on for software engineers, and object-oriented concepts, <br>software development process, and UML, etc for mechanical <br>engineers. If there is relatively little domain knowledge and <br>experience, to have one day or half-day technical workshop is <br>needed. This has proved useful in a variety of settings in the <br>development of the robot system, such as developing and <br>increasing background knowledge of the domain and technology. </span></nobr></DIV>
<DIV style="position:absolute;top:866;left:476"><nobr><span class="ft4"><b>4.5</b></span></nobr></DIV>
<DIV style="position:absolute;top:866;left:498"><nobr><span class="ft9"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:866;left:509"><nobr><span class="ft4"><b>Necessity of Multi-Aspect Integration </b></span></nobr></DIV>
<DIV style="position:absolute;top:886;left:476"><nobr><span class="ft4"><b>Method for Service Robot Domain </b></span></nobr></DIV>
<DIV style="position:absolute;top:906;left:476"><nobr><span class="ft16">A service robot should be able to perform several tasks <br>autonomously to provide various services for human beings in a <br>dynamic and partially unknown environment by applying both <br>technology and knowledge. In order to be able to achieve <br>complex tasks, perform new tasks, and integrate data learned from <br>experience for the robot services, it is required to consider not <br>only the robot's behavior, but also other robot's characteristics <br>such as learning, planning, decision-making, and knowledge <br>representation. It is necessary to allow existing robot behaviors to <br>be used in new ways, to plan for accomplishing more complex <br>tasks, to reuse the knowledge of one task in other tasks, and to </span></nobr></DIV>
<DIV style="position:absolute;top:1165;left:449"><nobr><span class="ft5">542</span></nobr></DIV>
</DIV>
<!-- Page 10 -->
<a name="10"></a>
<DIV style="position:relative;width:918;height:1263;">
<STYLE type="text/css">
<!--
	.ft44{font-size:12px;font-family:Helvetica;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1263" src="203010.png" alt="background image">
<DIV style="position:absolute;top:159;left:91"><nobr><span class="ft16">complete tasks more efficiently by learning various action <br>sequences.  <br>In the case study, we focused on designing and modeling the <br>robot's behavioral aspect, which is related to the sequencing and <br>reactive layers in the Tripodal layered design, by applying the <br>COMET/UML method. However, it is clear that planning and <br>learning abilities have to also be considered when designing and <br>developing a service robot, which correspond to the deliberate <br>layer that is responsible for interfacing with a user and executing <br>the planning process. As a consequence, a task manager, which is <br>located in the deliberate layer, has been in charge of these robotic <br>abilities in the project. Because the planning process is knowledge <br>based and not reactive, a different analysis and design approach is <br>needed for the task manager. Hence, we are convinced that <br>methods to model the robot's learning, planning and decision <br>making aspects as well as to incorporate, use and maintain task <br>knowledge are necessary. Furthermore, it is essential to integrate <br>these methods with the COMET method into a multi-aspect <br>integration method for developing service robot software.  </span></nobr></DIV>
<DIV style="position:absolute;top:473;left:91"><nobr><span class="ft4"><b>5.</b></span></nobr></DIV>
<DIV style="position:absolute;top:473;left:104"><nobr><span class="ft9"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:473;left:115"><nobr><span class="ft4"><b>CONCLUSIONS AND FUTHER WORK </b></span></nobr></DIV>
<DIV style="position:absolute;top:493;left:91"><nobr><span class="ft16">Service robots have been suggested for a growing number of <br>applications. A service robot is a complex system as it includes <br>various technical components (i.e., hardware and software) to be <br>integrated correctly and many different research groups to <br>develop the components. As a result, it is not only essential to <br>develop complex algorithms or technical components, but also to <br>integrate them adequately and correctly to provide the various <br>robot services.  <br>In the paper, we have presented our case study where we <br>developed the autonomous navigation system for the intelligent <br>service robot for the elderly, T-Rot. The object-oriented method <br>for real-time embedded systems, COMET has been applied to the <br>service robot T-Rot with the industry standard UML. It makes it <br>possible to reconcile specific engineering techniques like robot <br>technologies with the UML notation and furthermore to fit such <br>techniques into a fully defined development process towards <br>developing the service robot system. In this way, we contribute to <br>developing service robot software with UML in a systematic <br>manner.  <br>The service robot T-Rot is still under development (at this point, <br>we are at the first stage of total three stages). Thus, the current <br>status of our work is to extend applications that include vision <br>processing, speech processing and manipulation for providing <br>various robot services. Also, we work on designing the <br>knowledge-based task manager for improving the robot's ability.</span></nobr></DIV>
<DIV style="position:absolute;top:874;left:434"><nobr><span class="ft6"> </span></nobr></DIV>
<DIV style="position:absolute;top:905;left:91"><nobr><span class="ft4"><b>6.</b></span></nobr></DIV>
<DIV style="position:absolute;top:905;left:104"><nobr><span class="ft9"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:905;left:115"><nobr><span class="ft4"><b>ACKNOWLEDGMENTS </b></span></nobr></DIV>
<DIV style="position:absolute;top:925;left:91"><nobr><span class="ft16">This research (paper) was performed for the Intelligent Robotics <br>Development Program, one of the 21st Century Frontier R&amp;D <br>Programs funded by the Ministry of Commerce, Industry and <br>Energy of Korea. </span></nobr></DIV>
<DIV style="position:absolute;top:1001;left:91"><nobr><span class="ft4"><b>7.</b></span></nobr></DIV>
<DIV style="position:absolute;top:1001;left:104"><nobr><span class="ft9"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:1001;left:115"><nobr><span class="ft4"><b>REFERENCES </b></span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:91"><nobr><span class="ft5">[1]</span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:107"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:118"><nobr><span class="ft16">K. Kawamura and M. Iskarous, Trends in service robots for <br>the disabled and the elderly, Proc. of the 1994 IEEE/RSJ Int. <br>Conf. on Intelligent Robots and Systems, Vol. 3 (1994) 1674. </span></nobr></DIV>
<DIV style="position:absolute;top:159;left:476"><nobr><span class="ft5">[2]</span></nobr></DIV>
<DIV style="position:absolute;top:159;left:492"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:159;left:503"><nobr><span class="ft16">R. D. Schraft, "Mechatronics and robotics for service <br>applications," in IEEE Robotics and Automation Magazine, <br>no. 4, pp. 31 - 35, Dec. 1994. </span></nobr></DIV>
<DIV style="position:absolute;top:211;left:476"><nobr><span class="ft5">[3]</span></nobr></DIV>
<DIV style="position:absolute;top:211;left:492"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:211;left:503"><nobr><span class="ft16">Rofer T., Lankenau A. and Moratz R., Service Robotics-<br>Applications and Safety Issues in an Emerging Market, <br>Workshop W20 proc. ECAI2000, Berlin, 2000. </span></nobr></DIV>
<DIV style="position:absolute;top:263;left:476"><nobr><span class="ft5">[4]</span></nobr></DIV>
<DIV style="position:absolute;top:263;left:492"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:263;left:503"><nobr><span class="ft16">B. You et al., "Development of a Home Service Robot <br>`ISSAC'", Proc. of the 1994 IEEE/RSJ Int. Conf. on <br>Intelligent Robots and Systems, Las Vegas, Nevada, 2003, <br>pp. 2630-2635. </span></nobr></DIV>
<DIV style="position:absolute;top:331;left:476"><nobr><span class="ft5">[5]</span></nobr></DIV>
<DIV style="position:absolute;top:331;left:492"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:331;left:503"><nobr><span class="ft16">G. Kim, W. Chung, M. Kim, and C. Lee, "Tripodal <br>Schematic Design of the Control Architecture for the Service <br>Robot PSR," in Proc. of the IEEE Conf. on Robotics and <br>Automation, Taipei, Taiwan, pp.2792-2797, 2003. </span></nobr></DIV>
<DIV style="position:absolute;top:398;left:476"><nobr><span class="ft5">[6]</span></nobr></DIV>
<DIV style="position:absolute;top:398;left:492"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:398;left:503"><nobr><span class="ft16">G. Kim, W. Chung, M. Kim, and C. Lee, &quot;Implementation of <br>Multi-Functional Service Robots Using Tripodal Schematic <br>Control Architecture&quot;, in Proc. of IEEE Conf. on Robotics <br>and Automation, New Orleans, LA, USA, 2004 </span></nobr></DIV>
<DIV style="position:absolute;top:466;left:476"><nobr><span class="ft5">[7]</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:492"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:466;left:503"><nobr><span class="ft32">A. C. Dominguez-Brito, D.Hernandez-Sosa, J. Isern-<br>Gonzalez, and J. Cabrera-Games. Integrating robotics <br>software. <i>IEEE International Conference on Robotics and <br>Automation</i>, 2004. </span></nobr></DIV>
<DIV style="position:absolute;top:533;left:476"><nobr><span class="ft5">[8]</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:492"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:533;left:503"><nobr><span class="ft16">Q. Meng and M.H. Lee, "Learning and Control in Assistive <br>Robotics for the Elderly", Proc. Of the 2004 IEEE Conf. on <br>Robotics, Automation and Mechartonics, Singapore, Dec., <br>2004, pp. 71-76. </span></nobr></DIV>
<DIV style="position:absolute;top:601;left:476"><nobr><span class="ft5">[9]</span></nobr></DIV>
<DIV style="position:absolute;top:600;left:492"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:601;left:503"><nobr><span class="ft16">M. Kim, J. Lee, K. Kang, Y. Hong, and S. Bang, "Re-<br>engineering Software Architecture of Home Service Robots: <br>A Case Study", Proc. Of 27th Int. Conf. on Software <br>Engineering (ICSE2005), St. Louis, USA, May, 2005, <br>pp.505-513. </span></nobr></DIV>
<DIV style="position:absolute;top:684;left:476"><nobr><span class="ft5">[10]</span></nobr></DIV>
<DIV style="position:absolute;top:683;left:498"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:684;left:503"><nobr><span class="ft16">G. Booch, Object-Oriented Analysis and Design with <br>Applications, 2nd ed. Redwood City, CA: Benjamin <br>Cummings, 1994. </span></nobr></DIV>
<DIV style="position:absolute;top:736;left:476"><nobr><span class="ft5">[11]</span></nobr></DIV>
<DIV style="position:absolute;top:735;left:498"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:736;left:503"><nobr><span class="ft16">I. Jacobson, Object-Oriented Software Engineering, Addison <br>Wesley, 1992. </span></nobr></DIV>
<DIV style="position:absolute;top:772;left:476"><nobr><span class="ft5">[12]</span></nobr></DIV>
<DIV style="position:absolute;top:772;left:498"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:772;left:503"><nobr><span class="ft16">Real-Time Application Interface, 2004. Available at: http:// <br>www.rtai.org </span></nobr></DIV>
<DIV style="position:absolute;top:809;left:476"><nobr><span class="ft5">[13]</span></nobr></DIV>
<DIV style="position:absolute;top:809;left:498"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:809;left:503"><nobr><span class="ft16">Gjalt de Jong, "A UML-Based Design Methodology for <br>Real-Time and Embedded Systems", DATE 2002, March, <br>2002. </span></nobr></DIV>
<DIV style="position:absolute;top:861;left:476"><nobr><span class="ft5">[14]</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:498"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:861;left:503"><nobr><span class="ft16">H. Gomaa, Designing Concurrent, Distributed, and Real-<br>Time Application with UML, Addison-Wesley, 2000. </span></nobr></DIV>
<DIV style="position:absolute;top:898;left:476"><nobr><span class="ft5">[15]</span></nobr></DIV>
<DIV style="position:absolute;top:898;left:498"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:898;left:503"><nobr><span class="ft16">OMG Unified Modeling Language, Version 1.5, March 2003. <br>Available at:http://www.uml.org </span></nobr></DIV>
<DIV style="position:absolute;top:934;left:476"><nobr><span class="ft5">[16]</span></nobr></DIV>
<DIV style="position:absolute;top:934;left:498"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:934;left:503"><nobr><span class="ft16">M. Fowler and K. Scott, UML Distilled 2nd Edition, <br>Addison Wesley, 2000. </span></nobr></DIV>
<DIV style="position:absolute;top:971;left:476"><nobr><span class="ft5">[17]</span></nobr></DIV>
<DIV style="position:absolute;top:971;left:498"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:971;left:503"><nobr><span class="ft16">G. Martin, L. Lavagno, and J. Louis-Guerin, "Embedded <br>UML: a merger of real-time UML and codesign", CODES <br>2001, Copenhagen, April 2001, pp.23-28. </span></nobr></DIV>
<DIV style="position:absolute;top:1023;left:476"><nobr><span class="ft5">[18]</span></nobr></DIV>
<DIV style="position:absolute;top:1023;left:498"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:1023;left:503"><nobr><span class="ft16">G. Martin, &quot;UML for Embedded Systems Specification and <br>Design: Motivation and Overview&quot;, DATE 2002, March, <br>2002.</span></nobr></DIV>
<DIV style="position:absolute;top:1075;left:91"><nobr><span class="ft44"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:1165;left:449"><nobr><span class="ft5">543</span></nobr></DIV>
</DIV>
</BODY>
</HTML>
