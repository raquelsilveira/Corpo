<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
<HEAD>
<TITLE>Microsoft Word - f233-si.doc</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<META name="generator" content="pdftohtml 0.35beta">
<META name="date" content="2004-11-08T20:11:25+00:00">
</HEAD>
<BODY bgcolor="#A0A0A0" vlink="blue" link="blue">
<!-- Page 1 -->
<a name="1"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft0{font-size:25px;font-family:Helvetica;color:#000000;}
	.ft1{font-size:16px;font-family:Helvetica;color:#000000;}
	.ft2{font-size:12px;font-family:Helvetica;color:#000000;}
	.ft3{font-size:16px;font-family:Times;color:#000000;}
	.ft4{font-size:16px;font-family:Times;color:#000000;}
	.ft5{font-size:11px;font-family:Times;color:#000000;}
	.ft6{font-size:11px;font-family:Times;color:#000000;}
	.ft7{font-size:17px;font-family:Helvetica;color:#000000;}
	.ft8{font-size:11px;font-family:Times;color:#000000;}
	.ft9{font-size:7px;font-family:Times;color:#000000;}
	.ft10{font-size:10px;font-family:Times;color:#000000;}
	.ft11{font-size:10px;font-family:Times;color:#000000;}
	.ft12{font-size:16px;font-family:Courier;color:#000000;}
	.ft13{font-size:16px;line-height:21px;font-family:Times;color:#000000;}
	.ft14{font-size:11px;line-height:15px;font-family:Times;color:#000000;}
	.ft15{font-size:11px;line-height:14px;font-family:Times;color:#000000;}
	.ft16{font-size:16px;line-height:20px;font-family:Times;color:#000000;}
	.ft17{font-size:11px;line-height:14px;font-family:Times;color:#000000;}
	.ft18{font-size:11px;line-height:15px;font-family:Times;color:#000000;}
	.ft19{font-size:10px;line-height:13px;font-family:Times;color:#000000;}
	.ft20{font-size:10px;line-height:14px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="204001.png" alt="background image">
<DIV style="position:absolute;top:113;left:121"><nobr><span class="ft0"><b>Unified Utility Maximization Framework for Resource </b></span></nobr></DIV>
<DIV style="position:absolute;top:144;left:399"><nobr><span class="ft0"><b>Selection </b></span></nobr></DIV>
<DIV style="position:absolute;top:192;left:231"><nobr><span class="ft1">Luo Si </span></nobr></DIV>
<DIV style="position:absolute;top:218;left:166"><nobr><span class="ft2">Language Technology Inst. </span></nobr></DIV>
<DIV style="position:absolute;top:241;left:164"><nobr><span class="ft2">School of Compute Science </span></nobr></DIV>
<DIV style="position:absolute;top:259;left:167"><nobr><span class="ft2">Carnegie Mellon University </span></nobr></DIV>
<DIV style="position:absolute;top:277;left:186"><nobr><span class="ft2">Pittsburgh, PA 15213 </span></nobr></DIV>
<DIV style="position:absolute;top:301;left:193"><nobr><span class="ft1">lsi@cs.cmu.edu </span></nobr></DIV>
<DIV style="position:absolute;top:192;left:609"><nobr><span class="ft1">Jamie Callan </span></nobr></DIV>
<DIV style="position:absolute;top:218;left:571"><nobr><span class="ft2">Language Technology Inst. </span></nobr></DIV>
<DIV style="position:absolute;top:241;left:569"><nobr><span class="ft2">School of Compute Science </span></nobr></DIV>
<DIV style="position:absolute;top:258;left:572"><nobr><span class="ft2">Carnegie Mellon University </span></nobr></DIV>
<DIV style="position:absolute;top:276;left:591"><nobr><span class="ft2">Pittsburgh, PA 15213 </span></nobr></DIV>
<DIV style="position:absolute;top:299;left:583"><nobr><span class="ft1">callan@cs.cmu.edu </span></nobr></DIV>
<DIV style="position:absolute;top:326;left:81"><nobr><span class="ft13"> <br><b>ABSTRACT </b></span></nobr></DIV>
<DIV style="position:absolute;top:366;left:81"><nobr><span class="ft15">This  paper  presents  a  unified  utility  framework  for  resource <br>selection  of  distributed  text  information  retrieval.  This  new <br>framework  shows  an  efficient  and  effective  way  to  infer  the <br>probabilities  of  relevance  of  all  the  documents  across  the  text <br>databases.  With  the  estimated  relevance  information,  resource <br>selection  can  be  made  by  explicitly  optimizing  the  goals  of <br>different  applications.  Specifically,  when  used  for  database <br>recommendation, the selection is optimized for the goal of high-<br>recall  (include  as  many  relevant  documents  as  possible  in  the <br>selected  databases);  when  used  for  distributed  document <br>retrieval,  the  selection  targets  the  high-precision  goal  (high <br>precision in the final merged list of documents). This new model <br>provides  a  more  solid  framework  for  distributed  information <br>retrieval. Empirical studies show that it is at least as effective as <br>other state-of-the-art algorithms.  <br> </span></nobr></DIV>
<DIV style="position:absolute;top:617;left:81"><nobr><span class="ft4"><b>Categories and Subject Descriptors</b></span></nobr></DIV>
<DIV style="position:absolute;top:616;left:352"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:636;left:81"><nobr><span class="ft5">H.3.3  [<b>Information Search and Retrieval]:  </b> </span></nobr></DIV>
<DIV style="position:absolute;top:657;left:81"><nobr><span class="ft16"><b> <br>General Terms </b></span></nobr></DIV>
<DIV style="position:absolute;top:697;left:81"><nobr><span class="ft5">Algorithms </span></nobr></DIV>
<DIV style="position:absolute;top:714;left:81"><nobr><span class="ft13"> <br><b>Keywords</b></span></nobr></DIV>
<DIV style="position:absolute;top:754;left:81"><nobr><span class="ft5">distributed information retrieval, resource selection  </span></nobr></DIV>
<DIV style="position:absolute;top:789;left:81"><nobr><span class="ft4"><b>1. INTRODUCTION</b></span></nobr></DIV>
<DIV style="position:absolute;top:787;left:243"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:812;left:81"><nobr><span class="ft15">Conventional  search  engines  such  as  Google  or  AltaVista  use <br>ad-hoc  information  retrieval  solution  by  assuming  all  the <br>searchable  documents  can  be  copied  into  a  single  centralized <br>database  for  the  purpose  of  indexing.  <i>Distributed  information <br>retrieval</i>,  also  known  as  <i>federated  search  </i>[1,4,7,11,14,22]  is <br>different  from  ad-hoc  information  retrieval  as  it  addresses  the <br>cases when documents cannot be acquired and stored in a single <br>database.  For  example,  "<i>Hidden  Web</i>"  contents  (also  called <br>"invisible" or "deep" Web contents) are information on the Web </span></nobr></DIV>
<DIV style="position:absolute;top:345;left:486"><nobr><span class="ft14">that  cannot  be  accessed  by  the  conventional  search  engines. <br>Hidden web contents have been estimated to be 2-50 [19] times <br>larger  than  the  contents  that  can  be  searched  by  conventional <br>search engines. Therefore, it is very important to search this type <br>of valuable information. <br> <br>The  architecture  of  distributed  search  solution  is  highly <br>influenced by different environmental characteristics. In a small <br>local  area  network  such  as  small  company  environments,  the <br>information providers may cooperate to provide corpus statistics <br>or  use  the  same  type  of  search  engines.  Early  distributed <br>information  retrieval  research  focused  on  this  type  of <br><i>cooperative</i>  environments  [1,8].  On  the  other  side,  in  a  wide <br>area  network  such  as  very  large  corporate  environments  or  on <br>the Web there are many types of search engines and it is difficult <br>to  assume  that  all  the  information  providers  can  cooperate  as <br>they are required. Even if they are willing to cooperate in these <br>environments, it may be hard to enforce a single solution for all <br>the  information  providers  or  to  detect  whether  information <br>sources  provide  the  correct  information  as  they  are  required. <br>Many  applications  fall  into  the  latter  type  of  <i>uncooperative <br></i>environments  such  as  the  Mind  project  [16]  which  integrates <br>non-cooperating  digital  libraries  or  the  QProber  system  [9] <br>which supports browsing and searching of uncooperative hidden <br>Web databases. In this paper, we focus mainly on uncooperative <br>environments  that  contain  multiple  types  of  independent  search <br>engines. <br> <br>There  are  three  important  sub-problems  in  distributed <br>information  retrieval.  First,  information  about  the  contents  of <br>each  individual  database  must  be  acquired  (<i>resource <br>representation</i>)  [1,8,21].  Second,  given  a  query,  a  set  of <br>resources must be selected to do the search (<i>resource selection</i>) <br>[5,7,21].  Third,  the  results  retrieved  from  all  the  selected <br>resources have to be merged into a single final list before it can <br>be  presented  to  the  end  user  (<i>retrieval  and  results  merging</i>) <br>[1,5,20,22].  <br> <br>Many  types  of  solutions  exist  for  distributed  information <br>retrieval. Invisible-web.net</span></nobr></DIV>
<DIV style="position:absolute;top:928;left:632"><nobr><span class="ft9">1</span></nobr></DIV>
<DIV style="position:absolute;top:931;left:637"><nobr><span class="ft5"> provides <i>guided browsing</i> of hidden </span></nobr></DIV>
<DIV style="position:absolute;top:947;left:486"><nobr><span class="ft14">Web  databases  by  collecting  the  resource  descriptions  of  these <br>databases and building hierarchies of classes that group them by <br>similar  topics.  A  <i>database  recommendation  system</i>  goes  a  step <br>further  than  a  browsing  system  like  Invisible-web.net  by <br>recommending  most  relevant  information  sources  to  users' <br>queries.  It  is  composed  of  the  resource  description  and  the </span></nobr></DIV>
<DIV style="position:absolute;top:1042;left:486"><nobr><span class="ft3">                                                 </span></nobr></DIV>
<DIV style="position:absolute;top:1059;left:486"><nobr><span class="ft9">1</span></nobr></DIV>
<DIV style="position:absolute;top:1061;left:491"><nobr><span class="ft5"> http://www.invisible-web.net </span></nobr></DIV>
<DIV style="position:absolute;top:961;left:81"><nobr><span class="ft20">Permission  to  make  digital  or  hard  copies  of  all  or  part  of  this  work  for <br>personal or classroom use is granted without fee provided that copies are <br>not made or distributed for profit or commercial advantage and that copies <br>bear this notice and the full citation on the first page. To copy otherwise, <br>or  republish,  to  post  on  servers  or  to  redistribute  to  lists,  requires  prior <br>specific permission and/or a fee. <br><i>CIKM '04</i>, November 8--13, 2004, Washington, DC, USA. <br>Copyright 2004 ACM 1-58113-874-1//04/0011...$5.00.</span></nobr></DIV>
<DIV style="position:absolute;top:1054;left:350"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:1116;left:452"><nobr><span class="ft5">32</span></nobr></DIV>
</DIV>
<!-- Page 2 -->
<a name="2"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="204002.png" alt="background image">
<DIV style="position:absolute;top:111;left:81"><nobr><span class="ft14">resource selection components. This solution is useful when the <br>users  want  to  browse  the  selected  databases  by  themselves <br>instead  of  asking  the  system  to  retrieve  relevant  documents <br>automatically.  <i>Distributed  document  retrieval</i>  is  a  more <br>sophisticated  task.  It  selects  relevant  information  sources  for <br>users'  queries  as  the  database  recommendation  system  does. <br>Furthermore,  users'  queries  are  forwarded  to  the  corresponding <br>selected  databases  and  the  returned  individual  ranked  lists  are <br>merged into a single list to present to the users. </span></nobr></DIV>
<DIV style="position:absolute;top:264;left:81"><nobr><span class="ft15">The  goal  of  a  database  recommendation  system  is  to  select  a <br>small  set  of  resources  that  contain  as  many  relevant  documents <br>as possible, which we call a <i>high-recall</i> goal. On the other side, <br>the  effectiveness  of  distributed  document  retrieval  is  often <br>measured  by  the  Precision  of  the  final  merged  document  result <br>list,  which  we  call  a  <i>high-precision</i>  goal.  Prior  research <br>indicated that these two goals are related but not identical [4,21]. <br>However, most previous solutions simply use effective resource <br>selection  algorithm  of  database  recommendation  system  for <br>distributed document retrieval system or solve the inconsistency <br>with heuristic methods [1,4,21].  <br> <br>This paper presents a unified utility maximization framework to <br>integrate  the  resource  selection  problem  of  both  database <br>recommendation and distributed document retrieval together by <br>treating them as different optimization goals. <br> <br>First,  a  <i>centralized  sample  database</i>  is  built  by  randomly <br>sampling a small amount of documents from each database with <br>query-based  sampling  [1];  database  size  statistics  are  also <br>estimated  [21].  A  logistic  transformation  model  is  learned  off <br>line  with  a  small  amount  of  training  queries  to  map  the <br>centralized  document  scores  in  the  centralized  sample  database <br>to the corresponding probabilities of relevance.  <br> <br>Second, after a new query is submitted, the query can be used to <br>search  the  centralized  sample  database  which  produces  a  score <br>for  each  sampled  document.  The  probability  of  relevance  for <br>each  document  in  the  centralized  sample  database  can  be <br>estimated  by  applying  the  logistic  model  to  each  document's <br>score.  Then,  the  probabilities  of  relevance  of  all  the  (mostly <br>unseen)  documents  among  the  available  databases  can  be <br>estimated  using  the  probabilities of  relevance  of  the  documents <br>in  the  centralized  sample  database  and  the  database  size <br>estimates.  <br> <br>For  the  task  of  resource  selection  for  a  database <br>recommendation  system,  the  databases  can  be  ranked  by  the <br>expected  number  of  relevant  documents  to  meet  the  high-recall <br>goal. For resource selection for a distributed document retrieval <br>system, databases containing a small number of documents with <br>large  probabilities  of  relevance  are  favored  over  databases <br>containing  many  documents  with  small  probabilities  of <br>relevance. This selection criterion meets the high-precision goal <br>of  distributed  document  retrieval  application.  Furthermore,  the <br>Semi-supervised  learning  (SSL)  [20,22]  algorithm  is  applied  to <br>merge the returned documents into a final ranked list.  <br> <br>The unified utility framework  makes very  few assumptions and <br>works in uncooperative environments. Two key features make it <br>a  more  solid  model  for  distributed  information  retrieval:  i)  It <br>formalizes  the  resource  selection  problems  of  different <br>applications as various utility functions, and optimizes the utility <br>functions  to  achieve  the  optimal  results  accordingly;  and  ii)  It </span></nobr></DIV>
<DIV style="position:absolute;top:111;left:486"><nobr><span class="ft15">shows an effective and efficient way to estimate the probabilities <br>of relevance of all documents across databases. Specifically, the <br>framework  builds  logistic  models  on  the  centralized  sample <br>database  to  transform  centralized  retrieval  scores  to  the <br>corresponding probabilities of relevance and uses the centralized <br>sample database as the bridge between individual databases and <br>the  logistic  model.  The  human  effort  (relevance  judgment) <br>required  to  train  the  single  centralized  logistic  model  <i>does  not</i> <br>scale  with  the  number  of  databases.  This  is  a  large  advantage <br>over  previous  research,  which  required  the  amount  of  human <br>effort to be linear with the number of databases [7,15].  <br> <br>The  unified  utility  framework  is  not  only  more  theoretically <br>solid  but  also  very  effective.  Empirical  studies  show  the  new <br>model to be at least as accurate as the state-of-the-art algorithms <br>in a variety of configurations.  <br> <br>The next section discusses related work. Section 3 describes the <br>new  unified  utility  maximization  model.  Section  4  explains  our <br>experimental  methodology.  Sections  5  and  6  present  our <br>experimental  results  for  resource  selection  and  document <br>retrieval. Section 7 concludes. </span></nobr></DIV>
<DIV style="position:absolute;top:460;left:486"><nobr><span class="ft4"><b>2. PRIOR RESEARCH </b></span></nobr></DIV>
<DIV style="position:absolute;top:484;left:486"><nobr><span class="ft14">There has been considerable research on all the sub-problems of <br>distributed  information  retrieval.  We  survey  the  most  related <br>work in this section. <br> <br>The first problem of distributed information retrieval is resource <br>representation.  The  STARTS  protocol  is  one  solution  for <br>acquiring resource descriptions in cooperative environments [8]. <br>However, in uncooperative environments, even the databases are <br>willing to share their information, it is not easy to judge whether <br>the  information  they  provide  is  accurate  or  not. Furthermore,  it <br>is  not  easy  to  coordinate  the  databases  to  provide  resource <br>representations  that  are  compatible  with  each  other.  Thus,  in <br>uncooperative environments, one common choice is query-based <br>sampling,  which  randomly  generates  and  sends  queries  to <br>individual search engines and retrieves some documents to build <br>the  descriptions.  As  the  sampled  documents  are  selected  by <br>random  queries,  query-based  sampling  is  not  easily  fooled  by <br>any adversarial spammer that is interested to attract more traffic. <br>Experiments  have  shown  that  rather  accurate  resource <br>descriptions  can  be  built  by  sending  about  80  queries  and <br>downloading about 300 documents [1]. </span></nobr></DIV>
<DIV style="position:absolute;top:821;left:486"><nobr><span class="ft14">Many  resource  selection  algorithms  such  as  gGlOSS/vGlOSS <br>[8]  and  CORI  [1]  have  been  proposed  in  the  last  decade.  The <br>CORI  algorithm  represents  each  database  by  its  terms,  the <br>document  frequencies  and  a  small  number  of  corpus  statistics <br>(details in [1]). As prior research on different datasets has shown <br>the  CORI  algorithm  to  be  the  most  stable  and  effective  of  the <br>three  algorithms  [1,17,18],  we  use  it  as  a  baseline  algorithm  in <br>this  work.  The  relevant  document  distribution  estimation <br>(ReDDE [21]) resource selection algorithm is a recent algorithm <br>that  tries  to  estimate  the  distribution  of  relevant  documents <br>across  the  available  databases  and  ranks  the  databases <br>accordingly. Although the ReDDE algorithm has been shown to <br>be  effective,  it  relies  on  heuristic  constants  that  are  set <br>empirically [21]. <br> <br>The  last  step  of  the  document  retrieval  sub-problem  is  results <br>merging, which is the process of transforming database-specific </span></nobr></DIV>
<DIV style="position:absolute;top:1116;left:452"><nobr><span class="ft5">33</span></nobr></DIV>
</DIV>
<!-- Page 3 -->
<a name="3"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft21{font-size:14px;font-family:Times;color:#000000;}
	.ft22{font-size:15px;font-family:Symbol;color:#000000;}
	.ft23{font-size:5px;font-family:Times;color:#000000;}
	.ft24{font-size:5px;font-family:Times;color:#000000;}
	.ft25{font-size:11px;font-family:Symbol;color:#000000;}
	.ft26{font-size:12px;font-family:Times;color:#000000;}
	.ft27{font-size:6px;font-family:Times;color:#000000;}
	.ft28{font-size:12px;font-family:Times;color:#000000;}
	.ft29{font-size:6px;font-family:Times;color:#000000;}
	.ft30{font-size:4px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="204003.png" alt="background image">
<DIV style="position:absolute;top:111;left:81"><nobr><span class="ft5">document </span></nobr></DIV>
<DIV style="position:absolute;top:111;left:150"><nobr><span class="ft5">scores </span></nobr></DIV>
<DIV style="position:absolute;top:111;left:200"><nobr><span class="ft5">into </span></nobr></DIV>
<DIV style="position:absolute;top:111;left:237"><nobr><span class="ft5">comparable </span></nobr></DIV>
<DIV style="position:absolute;top:111;left:315"><nobr><span class="ft5">database-independent </span></nobr></DIV>
<DIV style="position:absolute;top:127;left:81"><nobr><span class="ft14">document  scores.  The  semi  supervised  learning  (SSL)  [20,22] <br>result merging algorithm uses the documents acquired by query-<br>based sampling as training data and linear regression to learn the <br>database-specific,  query-specific  merging  models.  These  linear <br>models  are  used  to  convert  the  database-specific  document <br>scores  into  the  approximated  centralized  document  scores.  The <br>SSL algorithm has been shown to be effective [22]. It serves as <br>an  important  component  of  our  unified  utility  maximization <br>framework (Section 3).</span></nobr></DIV>
<DIV style="position:absolute;top:248;left:207"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:266;left:81"><nobr><span class="ft15"> <br>In  order  to  achieve  accurate  document  retrieval  results,  many <br>previous  methods  simply  use  resource  selection  algorithms  that <br>are  effective  of  database  recommendation  system.  But  as <br>pointed  out  above,  a  good  resource  selection  algorithm <br>optimized  for  high-recall  may  not  work  well  for  document <br>retrieval,  which  targets  the  high-precision  goal.  This  type  of <br>inconsistency  has  been  observed  in  previous  research  [4,21]. <br>The  research  in [21]  tried  to  solve  the problem  with  a  heuristic <br>method.  <br> <br>The  research  most  similar  to  what  we  propose  here  is  the <br>decision-theoretic  framework  (DTF)  [7,15].  This  framework <br>computes  a  selection  that  minimizes  the  overall  costs  (e.g., <br>retrieval quality, time) of document retrieval system and several <br>methods  [15]  have  been  proposed  to  estimate  the  retrieval <br>quality.  However,  two  points  distinguish  our  research  from  the <br>DTF model. First, the DTF is a framework designed specifically <br>for  document  retrieval,  but  our  new  model  integrates  two <br>distinct  applications  with  different  requirements  (database <br>recommendation  and  distributed  document  retrieval)  into  the <br>same  unified  framework.  Second,  the  DTF  builds  a  model  for <br>each  database  to  calculate  the  probabilities  of  relevance.  This <br>requires  human  relevance  judgments  for  the  results  retrieved <br>from  each  database.  In  contrast,  our  approach  only  builds  one <br>logistic  model  for  the  centralized  sample  database.  The <br>centralized sample database can serve as a bridge to connect the <br>individual databases with the centralized logistic model, thus the <br>probabilities  of  relevance  of  documents  in  different  databases <br>can be estimated. This strategy can save large amount of human <br>judgment  effort  and  is  a  big  advantage  of  the  unified  utility <br>maximization  framework  over  the  DTF  especially  when  there <br>are a large number of databases.  </span></nobr></DIV>
<DIV style="position:absolute;top:781;left:81"><nobr><span class="ft16"><b>3. UNIFIED UTILITY MAXIMIZATION <br>FRAMEWORK </b></span></nobr></DIV>
<DIV style="position:absolute;top:825;left:81"><nobr><span class="ft15">The  Unified  Utility  Maximization  (UUM)  framework  is  based <br>on  estimating  the  probabilities  of  relevance  of  the  (mostly <br>unseen)  documents  available  in  the  distributed  search <br>environment. In this section we describe how the probabilities of <br>relevance  are  estimated  and  how  they  are  used  by  the  Unified <br>Utility  Maximization  model.  We  also  describe  how  the  model <br>can  be  optimized  for  the  high-recall  goal  of  a  database <br>recommendation  system  and  the  high-precision  goal  of  a <br>distributed document retrieval system. <br> </span></nobr></DIV>
<DIV style="position:absolute;top:972;left:81"><nobr><span class="ft3">3.1 Estimating Probabilities of Relevance </span></nobr></DIV>
<DIV style="position:absolute;top:975;left:385"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:990;left:81"><nobr><span class="ft14">As pointed out above, the purpose of resource selection is high-<br>recall and the purpose of document retrieval is high-precision. In <br>order to meet these diverse goals, the key issue is to estimate the <br>probabilities of relevance of the documents in various databases. <br>This  is  a  difficult  problem  because  we  can  only  observe  a <br>sample  of  the  contents  of  each  database  using  query-based </span></nobr></DIV>
<DIV style="position:absolute;top:111;left:486"><nobr><span class="ft14">sampling.  Our  strategy  is  to  make  full  use  of  all  the  available <br>information to calculate the probability estimates. <br> </span></nobr></DIV>
<DIV style="position:absolute;top:154;left:486"><nobr><span class="ft21">3.1.1 Learning Probabilities of Relevance </span></nobr></DIV>
<DIV style="position:absolute;top:171;left:486"><nobr><span class="ft15">In the resource description step, the centralized sample database <br>is  built  by  query-based  sampling  and  the  database  sizes  are <br>estimated  using  the  sample-resample  method  [21].  At  the  same <br>time, an effective retrieval algorithm (Inquery [2]) is applied on <br>the  centralized  sample  database  with  a  small  number  (e.g.,  50) <br>of  training queries. For  each  training query,  the  CORI  resource <br>selection  algorithm  [1]  is  applied  to  select  some  number       <br>(e.g.,  10)  of  databases  and  retrieve  50  document  ids  from  each <br>database. The SSL results  merging algorithm [20,22] is used to <br>merge the results. Then, we can download the top 50 documents <br>in  the  final  merged  list  and  calculate  their  corresponding <br>centralized scores using Inquery and the corpus statistics of the <br>centralized  sample  database.  The  centralized  scores  are  further <br>normalized (divided by the maximum centralized score for each <br>query), as this method has been suggested to improve estimation <br>accuracy in previous research [15]. Human judgment is acquired <br>for  those  documents  and  a  logistic  model  is  built  to  transform <br>the  normalized  centralized  document  scores  to  probabilities  of <br>relevance as follows:  </span></nobr></DIV>
<DIV style="position:absolute;top:467;left:577"><nobr><span class="ft22">(</span></nobr></DIV>
<DIV style="position:absolute;top:467;left:611"><nobr><span class="ft22">)</span></nobr></DIV>
<DIV style="position:absolute;top:493;left:734"><nobr><span class="ft5">))</span></nobr></DIV>
<DIV style="position:absolute;top:493;left:721"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:493;left:645"><nobr><span class="ft5">exp(</span></nobr></DIV>
<DIV style="position:absolute;top:493;left:627"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:726"><nobr><span class="ft5">))</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:713"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:637"><nobr><span class="ft5">exp(</span></nobr></DIV>
<DIV style="position:absolute;top:475;left:598"><nobr><span class="ft5">|</span></nobr></DIV>
<DIV style="position:absolute;top:475;left:550"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:475;left:538"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:484;left:713"><nobr><span class="ft23">_</span></nobr></DIV>
<DIV style="position:absolute;top:458;left:704"><nobr><span class="ft23">_</span></nobr></DIV>
<DIV style="position:absolute;top:493;left:726"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:493;left:708"><nobr><span class="ft8"><i>S</i></span></nobr></DIV>
<DIV style="position:absolute;top:493;left:694"><nobr><span class="ft8"><i>b</i></span></nobr></DIV>
<DIV style="position:absolute;top:493;left:669"><nobr><span class="ft8"><i>a</i></span></nobr></DIV>
<DIV style="position:absolute;top:466;left:718"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:466;left:700"><nobr><span class="ft8"><i>S</i></span></nobr></DIV>
<DIV style="position:absolute;top:466;left:686"><nobr><span class="ft8"><i>b</i></span></nobr></DIV>
<DIV style="position:absolute;top:466;left:660"><nobr><span class="ft8"><i>a</i></span></nobr></DIV>
<DIV style="position:absolute;top:475;left:603"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:475;left:581"><nobr><span class="ft8"><i>rel</i></span></nobr></DIV>
<DIV style="position:absolute;top:475;left:568"><nobr><span class="ft8"><i>P</i></span></nobr></DIV>
<DIV style="position:absolute;top:475;left:543"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:475;left:529"><nobr><span class="ft8"><i>R</i></span></nobr></DIV>
<DIV style="position:absolute;top:500;left:716"><nobr><span class="ft24"><i>c</i></span></nobr></DIV>
<DIV style="position:absolute;top:500;left:701"><nobr><span class="ft24"><i>c</i></span></nobr></DIV>
<DIV style="position:absolute;top:500;left:676"><nobr><span class="ft24"><i>c</i></span></nobr></DIV>
<DIV style="position:absolute;top:473;left:707"><nobr><span class="ft24"><i>c</i></span></nobr></DIV>
<DIV style="position:absolute;top:473;left:692"><nobr><span class="ft24"><i>c</i></span></nobr></DIV>
<DIV style="position:absolute;top:473;left:667"><nobr><span class="ft24"><i>c</i></span></nobr></DIV>
<DIV style="position:absolute;top:488;left:684"><nobr><span class="ft25">+</span></nobr></DIV>
<DIV style="position:absolute;top:488;left:635"><nobr><span class="ft25">+</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:676"><nobr><span class="ft25">+</span></nobr></DIV>
<DIV style="position:absolute;top:471;left:617"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:471;left:558"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:463;left:746"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:476;left:812"><nobr><span class="ft5">(1) </span></nobr></DIV>
<DIV style="position:absolute;top:521;left:486"><nobr><span class="ft5">where </span></nobr></DIV>
<DIV style="position:absolute;top:522;left:552"><nobr><span class="ft26">)</span></nobr></DIV>
<DIV style="position:absolute;top:522;left:538"><nobr><span class="ft26">(</span></nobr></DIV>
<DIV style="position:absolute;top:513;left:529"><nobr><span class="ft27">_</span></nobr></DIV>
<DIV style="position:absolute;top:522;left:543"><nobr><span class="ft28"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:522;left:525"><nobr><span class="ft28"><i>S</i></span></nobr></DIV>
<DIV style="position:absolute;top:529;left:532"><nobr><span class="ft29"><i>c</i></span></nobr></DIV>
<DIV style="position:absolute;top:521;left:559"><nobr><span class="ft5">is  the  normalized  centralized  document  score  and </span></nobr></DIV>
<DIV style="position:absolute;top:542;left:486"><nobr><span class="ft5">a</span></nobr></DIV>
<DIV style="position:absolute;top:547;left:492"><nobr><span class="ft9">c </span></nobr></DIV>
<DIV style="position:absolute;top:542;left:498"><nobr><span class="ft5">and b</span></nobr></DIV>
<DIV style="position:absolute;top:547;left:528"><nobr><span class="ft9">c</span></nobr></DIV>
<DIV style="position:absolute;top:542;left:532"><nobr><span class="ft5"> are the two parameters of the logistic model. These two </span></nobr></DIV>
<DIV style="position:absolute;top:557;left:486"><nobr><span class="ft14">parameters  are  estimated  by  maximizing  the  probabilities  of <br>relevance of the training queries. The logistic model provides us <br>the  tool  to  calculate  the  probabilities  of  relevance  from <br>centralized document scores.  <br> </span></nobr></DIV>
<DIV style="position:absolute;top:635;left:486"><nobr><span class="ft21">3.1.2 Estimating Centralized Document Scores </span></nobr></DIV>
<DIV style="position:absolute;top:654;left:486"><nobr><span class="ft14">When  the  user  submits  a  new  query,  the  centralized  document <br>scores  of  the  documents  in  the  centralized  sample  database  are <br>calculated.  However,  in  order  to  calculate  the  probabilities  of <br>relevance,  we  need  to  estimate  centralized  document  scores  for <br><i>all</i> documents  across  the  databases  instead of  only  the  sampled <br>documents.  This  goal  is  accomplished  using:  the  centralized <br>scores of the documents in the centralized sample database, and <br>the database size statistics. <br> <br>We  define  the  <i>database  scale  factor</i>  for  the  i</span></nobr></DIV>
<DIV style="position:absolute;top:791;left:741"><nobr><span class="ft9">th</span></nobr></DIV>
<DIV style="position:absolute;top:794;left:748"><nobr><span class="ft5">  database  as  the </span></nobr></DIV>
<DIV style="position:absolute;top:809;left:486"><nobr><span class="ft14">ratio  of  the  estimated  database  size  and  the  number  of <br>documents sampled from this database as follows: </span></nobr></DIV>
<DIV style="position:absolute;top:845;left:647"><nobr><span class="ft23">^</span></nobr></DIV>
<DIV style="position:absolute;top:879;left:653"><nobr><span class="ft23">_</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:660"><nobr><span class="ft30"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:872;left:616"><nobr><span class="ft30"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:882;left:649"><nobr><span class="ft30"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:858;left:654"><nobr><span class="ft24"><i>db</i></span></nobr></DIV>
<DIV style="position:absolute;top:869;left:609"><nobr><span class="ft24"><i>db</i></span></nobr></DIV>
<DIV style="position:absolute;top:879;left:643"><nobr><span class="ft24"><i>db</i></span></nobr></DIV>
<DIV style="position:absolute;top:879;left:658"><nobr><span class="ft24"><i>samp</i></span></nobr></DIV>
<DIV style="position:absolute;top:854;left:644"><nobr><span class="ft8"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:862;left:597"><nobr><span class="ft8"><i>SF</i></span></nobr></DIV>
<DIV style="position:absolute;top:872;left:634"><nobr><span class="ft8"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:858;left:623"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:856;left:679"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:860;left:812"><nobr><span class="ft5">(2) </span></nobr></DIV>
<DIV style="position:absolute;top:902;left:486"><nobr><span class="ft5">where </span></nobr></DIV>
<DIV style="position:absolute;top:897;left:529"><nobr><span class="ft23">^</span></nobr></DIV>
<DIV style="position:absolute;top:911;left:543"><nobr><span class="ft30"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:908;left:536"><nobr><span class="ft24"><i>db</i></span></nobr></DIV>
<DIV style="position:absolute;top:904;left:526"><nobr><span class="ft11"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:902;left:549"><nobr><span class="ft5"> is  the  estimated  database  size  and </span></nobr></DIV>
<DIV style="position:absolute;top:911;left:776"><nobr><span class="ft23">_</span></nobr></DIV>
<DIV style="position:absolute;top:914;left:772"><nobr><span class="ft30"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:911;left:766"><nobr><span class="ft24"><i>db</i></span></nobr></DIV>
<DIV style="position:absolute;top:911;left:781"><nobr><span class="ft24"><i>samp</i></span></nobr></DIV>
<DIV style="position:absolute;top:905;left:757"><nobr><span class="ft11"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:902;left:802"><nobr><span class="ft5"> is  the </span></nobr></DIV>
<DIV style="position:absolute;top:925;left:486"><nobr><span class="ft5">number  of  documents  from  the  i</span></nobr></DIV>
<DIV style="position:absolute;top:922;left:673"><nobr><span class="ft9">th</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:680"><nobr><span class="ft5">  database  in  the  centralized </span></nobr></DIV>
<DIV style="position:absolute;top:940;left:486"><nobr><span class="ft14">sample  database.  The  intuition  behind  the  database  scale  factor <br>is that, for a database whose scale factor is 50, if one document <br>from  this  database  in  the  centralized  sample  database  has  a <br>centralized  document  score  of  0.5,  we  may  guess  that  there  are <br>about 50 documents in that database which have scores of about <br>0.5.  Actually,  we  can  apply  a  finer  non-parametric  linear <br>interpolation method to estimate the centralized document score <br>curve  for  each  database.  Formally,  we  rank  all  the  sampled <br>documents  from  the  i</span></nobr></DIV>
<DIV style="position:absolute;top:1062;left:607"><nobr><span class="ft9">th</span></nobr></DIV>
<DIV style="position:absolute;top:1065;left:614"><nobr><span class="ft5">  database  by  their  centralized  document </span></nobr></DIV>
<DIV style="position:absolute;top:1116;left:452"><nobr><span class="ft5">34</span></nobr></DIV>
</DIV>
<!-- Page 4 -->
<a name="4"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft31{font-size:3px;font-family:Times;color:#000000;}
	.ft32{font-size:13px;font-family:Symbol;color:#000000;}
	.ft33{font-size:12px;font-family:Symbol;color:#000000;}
	.ft34{font-size:3px;font-family:Times;color:#000000;}
	.ft35{font-size:4px;font-family:Times;color:#000000;}
	.ft36{font-size:-1px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="204004.png" alt="background image">
<DIV style="position:absolute;top:111;left:81"><nobr><span class="ft14">scores  to  get  the  sampled  centralized  document  score  list <br>{S</span></nobr></DIV>
<DIV style="position:absolute;top:132;left:95"><nobr><span class="ft9">c</span></nobr></DIV>
<DIV style="position:absolute;top:127;left:99"><nobr><span class="ft5">(ds</span></nobr></DIV>
<DIV style="position:absolute;top:132;left:116"><nobr><span class="ft9">i1</span></nobr></DIV>
<DIV style="position:absolute;top:127;left:122"><nobr><span class="ft5">),  S</span></nobr></DIV>
<DIV style="position:absolute;top:132;left:143"><nobr><span class="ft9">c</span></nobr></DIV>
<DIV style="position:absolute;top:127;left:147"><nobr><span class="ft5">(ds</span></nobr></DIV>
<DIV style="position:absolute;top:132;left:163"><nobr><span class="ft9">i2</span></nobr></DIV>
<DIV style="position:absolute;top:127;left:170"><nobr><span class="ft5">),  S</span></nobr></DIV>
<DIV style="position:absolute;top:132;left:191"><nobr><span class="ft9">c</span></nobr></DIV>
<DIV style="position:absolute;top:127;left:195"><nobr><span class="ft5">(ds</span></nobr></DIV>
<DIV style="position:absolute;top:132;left:212"><nobr><span class="ft9">i3</span></nobr></DIV>
<DIV style="position:absolute;top:127;left:218"><nobr><span class="ft5">),.....}  for  the  i</span></nobr></DIV>
<DIV style="position:absolute;top:124;left:304"><nobr><span class="ft9">th</span></nobr></DIV>
<DIV style="position:absolute;top:127;left:311"><nobr><span class="ft5">  database;  we  assume </span></nobr></DIV>
<DIV style="position:absolute;top:142;left:81"><nobr><span class="ft14">that if we could calculate the centralized document scores for all <br>the documents in this database and get the complete centralized <br>document score list, the top document in the sampled list would <br>have  rank  SF</span></nobr></DIV>
<DIV style="position:absolute;top:194;left:160"><nobr><span class="ft9">dbi</span></nobr></DIV>
<DIV style="position:absolute;top:189;left:171"><nobr><span class="ft5">/2,  the  second  document  in  the  sampled  list </span></nobr></DIV>
<DIV style="position:absolute;top:204;left:81"><nobr><span class="ft5">would  rank  SF</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:165"><nobr><span class="ft9">dbi</span></nobr></DIV>
<DIV style="position:absolute;top:204;left:177"><nobr><span class="ft5">3/2,  and  so  on.  Therefore,  the  data  points  of </span></nobr></DIV>
<DIV style="position:absolute;top:220;left:81"><nobr><span class="ft5">sampled documents in the complete list are: {(SF</span></nobr></DIV>
<DIV style="position:absolute;top:225;left:355"><nobr><span class="ft9">dbi</span></nobr></DIV>
<DIV style="position:absolute;top:220;left:366"><nobr><span class="ft5">/2, S</span></nobr></DIV>
<DIV style="position:absolute;top:225;left:392"><nobr><span class="ft9">c</span></nobr></DIV>
<DIV style="position:absolute;top:220;left:396"><nobr><span class="ft5">(ds</span></nobr></DIV>
<DIV style="position:absolute;top:225;left:413"><nobr><span class="ft9">i1</span></nobr></DIV>
<DIV style="position:absolute;top:220;left:419"><nobr><span class="ft5">)), </span></nobr></DIV>
<DIV style="position:absolute;top:235;left:81"><nobr><span class="ft5">(SF</span></nobr></DIV>
<DIV style="position:absolute;top:241;left:101"><nobr><span class="ft9">dbi</span></nobr></DIV>
<DIV style="position:absolute;top:235;left:112"><nobr><span class="ft5">3/2,  S</span></nobr></DIV>
<DIV style="position:absolute;top:241;left:148"><nobr><span class="ft9">c</span></nobr></DIV>
<DIV style="position:absolute;top:235;left:152"><nobr><span class="ft5">(ds</span></nobr></DIV>
<DIV style="position:absolute;top:241;left:168"><nobr><span class="ft9">i2</span></nobr></DIV>
<DIV style="position:absolute;top:235;left:175"><nobr><span class="ft5">)),  (SF</span></nobr></DIV>
<DIV style="position:absolute;top:241;left:215"><nobr><span class="ft9">dbi</span></nobr></DIV>
<DIV style="position:absolute;top:235;left:226"><nobr><span class="ft5">5/2,  S</span></nobr></DIV>
<DIV style="position:absolute;top:241;left:262"><nobr><span class="ft9">c</span></nobr></DIV>
<DIV style="position:absolute;top:235;left:266"><nobr><span class="ft5">(ds</span></nobr></DIV>
<DIV style="position:absolute;top:241;left:283"><nobr><span class="ft9">i3</span></nobr></DIV>
<DIV style="position:absolute;top:235;left:289"><nobr><span class="ft5">)),.....}.  Piecewise  linear </span></nobr></DIV>
<DIV style="position:absolute;top:251;left:81"><nobr><span class="ft14">interpolation  is  applied  to  estimate  the  centralized  document <br>score curve, as illustrated in Figure 1. The complete centralized <br>document score list can be estimated by calculating the values of <br>different  ranks  on  the  centralized  document  curve  as: </span></nobr></DIV>
<DIV style="position:absolute;top:322;left:188"><nobr><span class="ft5">]</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:157"><nobr><span class="ft5">,</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:152"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:148"><nobr><span class="ft5">[</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:121"><nobr><span class="ft5">,</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:116"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:96"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:82"><nobr><span class="ft5">S</span></nobr></DIV>
<DIV style="position:absolute;top:314;left:166"><nobr><span class="ft27">^</span></nobr></DIV>
<DIV style="position:absolute;top:314;left:100"><nobr><span class="ft27">^</span></nobr></DIV>
<DIV style="position:absolute;top:330;left:91"><nobr><span class="ft27">c</span></nobr></DIV>
<DIV style="position:absolute;top:331;left:183"><nobr><span class="ft31"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:327;left:175"><nobr><span class="ft29"><i>db</i></span></nobr></DIV>
<DIV style="position:absolute;top:330;left:109"><nobr><span class="ft29"><i>ij</i></span></nobr></DIV>
<DIV style="position:absolute;top:322;left:163"><nobr><span class="ft8"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:322;left:131"><nobr><span class="ft8"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:322;left:101"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:318;left:137"><nobr><span class="ft25"></span></nobr></DIV>
<DIV style="position:absolute;top:320;left:194"><nobr><span class="ft5">.  </span></nobr></DIV>
<DIV style="position:absolute;top:343;left:81"><nobr><span class="ft14"> <br>It  can  be  seen  from  Figure  1  that  more  sample  data  points <br>produce  more  accurate  estimates  of  the  centralized  document <br>score  curves.  However,  for  databases  with  large  database  scale <br>ratios, this kind of linear interpolation may be rather inaccurate, <br>especially  for  the  top  ranked  (e.g.,  [1,  SF</span></nobr></DIV>
<DIV style="position:absolute;top:426;left:332"><nobr><span class="ft9">dbi</span></nobr></DIV>
<DIV style="position:absolute;top:421;left:343"><nobr><span class="ft5">/2])  documents. </span></nobr></DIV>
<DIV style="position:absolute;top:436;left:81"><nobr><span class="ft14">Therefore,  an  alternative  solution  is  proposed  to  estimate  the <br>centralized  document  scores  of  the  top  ranked  documents  for <br>databases  with  large  scale  ratios  (e.g.,  larger  than  100). <br>Specifically, a logistic model is built for each of these databases. <br>The logistic model is used to estimate the centralized document <br>score  of  the  top  1  document  in  the  corresponding  database  by <br>using  the  two  sampled  documents  from  that  database  with <br>highest centralized scores.  </span></nobr></DIV>
<DIV style="position:absolute;top:589;left:352"><nobr><span class="ft5">))</span></nobr></DIV>
<DIV style="position:absolute;top:589;left:326"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:589;left:278"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:589;left:254"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:589;left:171"><nobr><span class="ft5">exp(</span></nobr></DIV>
<DIV style="position:absolute;top:589;left:152"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:570;left:343"><nobr><span class="ft5">))</span></nobr></DIV>
<DIV style="position:absolute;top:570;left:317"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:570;left:269"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:570;left:245"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:570;left:162"><nobr><span class="ft5">exp(</span></nobr></DIV>
<DIV style="position:absolute;top:579;left:135"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:579;left:115"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:346"><nobr><span class="ft23">2</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:307"><nobr><span class="ft23">2</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:273"><nobr><span class="ft23">1</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:236"><nobr><span class="ft23">1</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:206"><nobr><span class="ft23">0</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:337"><nobr><span class="ft23">2</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:299"><nobr><span class="ft23">2</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:264"><nobr><span class="ft23">1</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:227"><nobr><span class="ft23">1</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:197"><nobr><span class="ft23">0</span></nobr></DIV>
<DIV style="position:absolute;top:571;left:119"><nobr><span class="ft23">^</span></nobr></DIV>
<DIV style="position:absolute;top:586;left:130"><nobr><span class="ft23">1</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:343"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:596;left:320"><nobr><span class="ft24"><i>c</i></span></nobr></DIV>
<DIV style="position:absolute;top:596;left:304"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:596;left:271"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:596;left:248"><nobr><span class="ft24"><i>c</i></span></nobr></DIV>
<DIV style="position:absolute;top:596;left:234"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:596;left:203"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:577;left:334"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:577;left:312"><nobr><span class="ft24"><i>c</i></span></nobr></DIV>
<DIV style="position:absolute;top:577;left:296"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:577;left:262"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:577;left:239"><nobr><span class="ft24"><i>c</i></span></nobr></DIV>
<DIV style="position:absolute;top:577;left:225"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:577;left:194"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:586;left:128"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:586;left:110"><nobr><span class="ft24"><i>c</i></span></nobr></DIV>
<DIV style="position:absolute;top:589;left:331"><nobr><span class="ft8"><i>ds</i></span></nobr></DIV>
<DIV style="position:absolute;top:589;left:313"><nobr><span class="ft8"><i>S</i></span></nobr></DIV>
<DIV style="position:absolute;top:589;left:258"><nobr><span class="ft8"><i>ds</i></span></nobr></DIV>
<DIV style="position:absolute;top:589;left:240"><nobr><span class="ft8"><i>S</i></span></nobr></DIV>
<DIV style="position:absolute;top:570;left:322"><nobr><span class="ft8"><i>ds</i></span></nobr></DIV>
<DIV style="position:absolute;top:570;left:304"><nobr><span class="ft8"><i>S</i></span></nobr></DIV>
<DIV style="position:absolute;top:570;left:250"><nobr><span class="ft8"><i>ds</i></span></nobr></DIV>
<DIV style="position:absolute;top:570;left:232"><nobr><span class="ft8"><i>S</i></span></nobr></DIV>
<DIV style="position:absolute;top:579;left:120"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:579;left:102"><nobr><span class="ft8"><i>S</i></span></nobr></DIV>
<DIV style="position:absolute;top:584;left:295"><nobr><span class="ft25"></span></nobr></DIV>
<DIV style="position:absolute;top:584;left:224"><nobr><span class="ft25"></span></nobr></DIV>
<DIV style="position:absolute;top:584;left:193"><nobr><span class="ft25"></span></nobr></DIV>
<DIV style="position:absolute;top:565;left:286"><nobr><span class="ft25"></span></nobr></DIV>
<DIV style="position:absolute;top:565;left:215"><nobr><span class="ft25"></span></nobr></DIV>
<DIV style="position:absolute;top:565;left:185"><nobr><span class="ft25"></span></nobr></DIV>
<DIV style="position:absolute;top:585;left:285"><nobr><span class="ft25">+</span></nobr></DIV>
<DIV style="position:absolute;top:585;left:215"><nobr><span class="ft25">+</span></nobr></DIV>
<DIV style="position:absolute;top:585;left:161"><nobr><span class="ft25">+</span></nobr></DIV>
<DIV style="position:absolute;top:566;left:277"><nobr><span class="ft25">+</span></nobr></DIV>
<DIV style="position:absolute;top:566;left:206"><nobr><span class="ft25">+</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:142"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:570;left:364"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:580;left:407"><nobr><span class="ft5">(3) </span></nobr></DIV>
<DIV style="position:absolute;top:626;left:95"><nobr><span class="ft27">0</span></nobr></DIV>
<DIV style="position:absolute;top:626;left:92"><nobr><span class="ft29"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:612;left:82"><nobr><span class="ft32"></span></nobr></DIV>
<DIV style="position:absolute;top:617;left:102"><nobr><span class="ft5">, </span></nobr></DIV>
<DIV style="position:absolute;top:626;left:122"><nobr><span class="ft27">1</span></nobr></DIV>
<DIV style="position:absolute;top:626;left:120"><nobr><span class="ft29"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:612;left:109"><nobr><span class="ft32"></span></nobr></DIV>
<DIV style="position:absolute;top:617;left:129"><nobr><span class="ft5"> and </span></nobr></DIV>
<DIV style="position:absolute;top:626;left:170"><nobr><span class="ft27">2</span></nobr></DIV>
<DIV style="position:absolute;top:626;left:167"><nobr><span class="ft29"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:612;left:157"><nobr><span class="ft32"></span></nobr></DIV>
<DIV style="position:absolute;top:617;left:177"><nobr><span class="ft5">are  the  parameters  of  the  logistic  model.  For </span></nobr></DIV>
<DIV style="position:absolute;top:638;left:81"><nobr><span class="ft14">each training query, the top retrieved document of each database <br>is  downloaded  and  the  corresponding  centralized  document <br>score  is  calculated.  Together  with  the  scores  of  the  top  two <br>sampled documents, these parameters can be estimated.  <br> <br>After the centralized score of the top document is estimated, an <br>exponential function is fitted for the top part ([1, SF</span></nobr></DIV>
<DIV style="position:absolute;top:737;left:366"><nobr><span class="ft9">dbi</span></nobr></DIV>
<DIV style="position:absolute;top:731;left:377"><nobr><span class="ft5">/2]) of the </span></nobr></DIV>
<DIV style="position:absolute;top:747;left:81"><nobr><span class="ft5">centralized document score curve as: </span></nobr></DIV>
<DIV style="position:absolute;top:778;left:351"><nobr><span class="ft5">]</span></nobr></DIV>
<DIV style="position:absolute;top:778;left:344"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:778;left:338"><nobr><span class="ft5">/</span></nobr></DIV>
<DIV style="position:absolute;top:778;left:304"><nobr><span class="ft5">,</span></nobr></DIV>
<DIV style="position:absolute;top:778;left:299"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:778;left:295"><nobr><span class="ft5">[</span></nobr></DIV>
<DIV style="position:absolute;top:778;left:246"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:778;left:230"><nobr><span class="ft5">*</span></nobr></DIV>
<DIV style="position:absolute;top:778;left:158"><nobr><span class="ft5">exp(</span></nobr></DIV>
<DIV style="position:absolute;top:778;left:141"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:778;left:122"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:786;left:223"><nobr><span class="ft23">1</span></nobr></DIV>
<DIV style="position:absolute;top:786;left:193"><nobr><span class="ft23">0</span></nobr></DIV>
<DIV style="position:absolute;top:770;left:125"><nobr><span class="ft23">^</span></nobr></DIV>
<DIV style="position:absolute;top:789;left:331"><nobr><span class="ft31"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:786;left:324"><nobr><span class="ft24"><i>db</i></span></nobr></DIV>
<DIV style="position:absolute;top:786;left:221"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:786;left:190"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:786;left:134"><nobr><span class="ft24"><i>ij</i></span></nobr></DIV>
<DIV style="position:absolute;top:786;left:116"><nobr><span class="ft24"><i>c</i></span></nobr></DIV>
<DIV style="position:absolute;top:778;left:309"><nobr><span class="ft8"><i>SF</i></span></nobr></DIV>
<DIV style="position:absolute;top:778;left:280"><nobr><span class="ft8"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:778;left:242"><nobr><span class="ft8"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:778;left:126"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:778;left:108"><nobr><span class="ft8"><i>S</i></span></nobr></DIV>
<DIV style="position:absolute;top:774;left:285"><nobr><span class="ft25"></span></nobr></DIV>
<DIV style="position:absolute;top:774;left:202"><nobr><span class="ft25">+</span></nobr></DIV>
<DIV style="position:absolute;top:774;left:148"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:773;left:212"><nobr><span class="ft25"></span></nobr></DIV>
<DIV style="position:absolute;top:773;left:182"><nobr><span class="ft25"></span></nobr></DIV>
<DIV style="position:absolute;top:772;left:357"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:776;left:407"><nobr><span class="ft5">(4) </span></nobr></DIV>
<DIV style="position:absolute;top:811;left:242"><nobr><span class="ft27">^</span></nobr></DIV>
<DIV style="position:absolute;top:826;left:184"><nobr><span class="ft27">0</span></nobr></DIV>
<DIV style="position:absolute;top:826;left:250"><nobr><span class="ft27">1</span></nobr></DIV>
<DIV style="position:absolute;top:826;left:287"><nobr><span class="ft27">1</span></nobr></DIV>
<DIV style="position:absolute;top:819;left:203"><nobr><span class="ft5">log(</span></nobr></DIV>
<DIV style="position:absolute;top:819;left:237"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:819;left:255"><nobr><span class="ft5">))</span></nobr></DIV>
<DIV style="position:absolute;top:826;left:181"><nobr><span class="ft29"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:826;left:231"><nobr><span class="ft29"><i>c</i></span></nobr></DIV>
<DIV style="position:absolute;top:826;left:248"><nobr><span class="ft29"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:826;left:284"><nobr><span class="ft29"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:819;left:224"><nobr><span class="ft8"><i>S d</i></span></nobr></DIV>
<DIV style="position:absolute;top:814;left:174"><nobr><span class="ft33"></span></nobr></DIV>
<DIV style="position:absolute;top:814;left:277"><nobr><span class="ft33"></span></nobr></DIV>
<DIV style="position:absolute;top:815;left:193"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:815;left:267"><nobr><span class="ft25">-</span></nobr></DIV>
<DIV style="position:absolute;top:815;left:293"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:816;left:407"><nobr><span class="ft5">(5) </span></nobr></DIV>
<DIV style="position:absolute;top:874;left:276"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:874;left:270"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:874;left:252"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:874;left:246"><nobr><span class="ft5">/</span></nobr></DIV>
<DIV style="position:absolute;top:874;left:212"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:854;left:309"><nobr><span class="ft5">))</span></nobr></DIV>
<DIV style="position:absolute;top:854;left:290"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:854;left:255"><nobr><span class="ft5">log(</span></nobr></DIV>
<DIV style="position:absolute;top:854;left:238"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:854;left:213"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:854;left:174"><nobr><span class="ft5">(log(</span></nobr></DIV>
<DIV style="position:absolute;top:846;left:295"><nobr><span class="ft23">^</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:304"><nobr><span class="ft23">1</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:232"><nobr><span class="ft23">1</span></nobr></DIV>
<DIV style="position:absolute;top:870;left:155"><nobr><span class="ft23">1</span></nobr></DIV>
<DIV style="position:absolute;top:869;left:262"><nobr><span class="ft25">-</span></nobr></DIV>
<DIV style="position:absolute;top:850;left:245"><nobr><span class="ft25">-</span></nobr></DIV>
<DIV style="position:absolute;top:859;left:163"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:884;left:239"><nobr><span class="ft31"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:881;left:231"><nobr><span class="ft24"><i>db</i></span></nobr></DIV>
<DIV style="position:absolute;top:861;left:302"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:861;left:284"><nobr><span class="ft24"><i>c</i></span></nobr></DIV>
<DIV style="position:absolute;top:861;left:230"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:861;left:208"><nobr><span class="ft24"><i>c</i></span></nobr></DIV>
<DIV style="position:absolute;top:870;left:153"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:874;left:217"><nobr><span class="ft8"><i>SF</i></span></nobr></DIV>
<DIV style="position:absolute;top:854;left:294"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:854;left:276"><nobr><span class="ft8"><i>S</i></span></nobr></DIV>
<DIV style="position:absolute;top:854;left:218"><nobr><span class="ft8"><i>ds</i></span></nobr></DIV>
<DIV style="position:absolute;top:854;left:200"><nobr><span class="ft8"><i>S</i></span></nobr></DIV>
<DIV style="position:absolute;top:858;left:144"><nobr><span class="ft25"></span></nobr></DIV>
<DIV style="position:absolute;top:853;left:321"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:862;left:407"><nobr><span class="ft5">(6) </span></nobr></DIV>
<DIV style="position:absolute;top:898;left:81"><nobr><span class="ft5">The  two  parameters </span></nobr></DIV>
<DIV style="position:absolute;top:906;left:216"><nobr><span class="ft27">0</span></nobr></DIV>
<DIV style="position:absolute;top:906;left:213"><nobr><span class="ft29"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:893;left:204"><nobr><span class="ft32"></span></nobr></DIV>
<DIV style="position:absolute;top:898;left:224"><nobr><span class="ft5">and </span></nobr></DIV>
<DIV style="position:absolute;top:906;left:263"><nobr><span class="ft27">1</span></nobr></DIV>
<DIV style="position:absolute;top:906;left:260"><nobr><span class="ft29"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:893;left:251"><nobr><span class="ft32"></span></nobr></DIV>
<DIV style="position:absolute;top:898;left:271"><nobr><span class="ft5">are  fitted  to  make  sure  the </span></nobr></DIV>
<DIV style="position:absolute;top:928;left:81"><nobr><span class="ft5">exponential  function  passes  through  the  two  points  (1,</span></nobr></DIV>
<DIV style="position:absolute;top:920;left:404"><nobr><span class="ft27">^</span></nobr></DIV>
<DIV style="position:absolute;top:937;left:415"><nobr><span class="ft27">1</span></nobr></DIV>
<DIV style="position:absolute;top:929;left:420"><nobr><span class="ft26">)</span></nobr></DIV>
<DIV style="position:absolute;top:929;left:400"><nobr><span class="ft26">(</span></nobr></DIV>
<DIV style="position:absolute;top:937;left:413"><nobr><span class="ft29"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:937;left:394"><nobr><span class="ft29"><i>c</i></span></nobr></DIV>
<DIV style="position:absolute;top:929;left:405"><nobr><span class="ft28"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:929;left:387"><nobr><span class="ft28"><i>S</i></span></nobr></DIV>
<DIV style="position:absolute;top:928;left:428"><nobr><span class="ft5">) </span></nobr></DIV>
<DIV style="position:absolute;top:949;left:81"><nobr><span class="ft5">and  (SF</span></nobr></DIV>
<DIV style="position:absolute;top:955;left:125"><nobr><span class="ft9">dbi</span></nobr></DIV>
<DIV style="position:absolute;top:949;left:136"><nobr><span class="ft5">/2,  S</span></nobr></DIV>
<DIV style="position:absolute;top:955;left:162"><nobr><span class="ft9">c</span></nobr></DIV>
<DIV style="position:absolute;top:949;left:166"><nobr><span class="ft5">(ds</span></nobr></DIV>
<DIV style="position:absolute;top:955;left:183"><nobr><span class="ft9">i1</span></nobr></DIV>
<DIV style="position:absolute;top:949;left:190"><nobr><span class="ft5">)).  The  exponential  function  is only  used  to </span></nobr></DIV>
<DIV style="position:absolute;top:965;left:81"><nobr><span class="ft14">adjust the  top  part  of  the  centralized  document  score  curve  and <br>the  lower  part  of  the  curve  is  still  fitted  with  the  linear <br>interpolation method described above. The adjustment by fitting <br>exponential  function  of  the  top  ranked  documents  has  been <br>shown empirically to produce more accurate results. <br>  </span></nobr></DIV>
<DIV style="position:absolute;top:264;left:486"><nobr><span class="ft14">From  the  centralized  document  score  curves,  we  can  estimate <br>the complete centralized document score lists accordingly for all <br>the  available  databases.  After  the  estimated  centralized <br>document  scores  are  normalized,  the  complete  lists  of <br>probabilities of relevance can be constructed out of the complete <br>centralized document score lists by Equation 1. Formally for the <br>i</span></nobr></DIV>
<DIV style="position:absolute;top:355;left:490"><nobr><span class="ft9">th</span></nobr></DIV>
<DIV style="position:absolute;top:357;left:497"><nobr><span class="ft5">  database,  the  complete  list  of  probabilities  of  relevance  is: </span></nobr></DIV>
<DIV style="position:absolute;top:383;left:590"><nobr><span class="ft26">]</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:560"><nobr><span class="ft26">,</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:554"><nobr><span class="ft26">1</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:550"><nobr><span class="ft26">[</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:523"><nobr><span class="ft26">,</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:518"><nobr><span class="ft26">)</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:499"><nobr><span class="ft26">(</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:488"><nobr><span class="ft26">R</span></nobr></DIV>
<DIV style="position:absolute;top:374;left:569"><nobr><span class="ft27">^</span></nobr></DIV>
<DIV style="position:absolute;top:374;left:503"><nobr><span class="ft27">^</span></nobr></DIV>
<DIV style="position:absolute;top:392;left:586"><nobr><span class="ft30"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:388;left:577"><nobr><span class="ft29"><i>db</i></span></nobr></DIV>
<DIV style="position:absolute;top:391;left:512"><nobr><span class="ft29"><i>ij</i></span></nobr></DIV>
<DIV style="position:absolute;top:383;left:566"><nobr><span class="ft28"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:383;left:533"><nobr><span class="ft28"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:383;left:504"><nobr><span class="ft28"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:378;left:539"><nobr><span class="ft33"></span></nobr></DIV>
<DIV style="position:absolute;top:379;left:597"><nobr><span class="ft3">.</span></nobr></DIV>
<DIV style="position:absolute;top:382;left:601"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:405;left:486"><nobr><span class="ft14"> <br> </span></nobr></DIV>
<DIV style="position:absolute;top:432;left:486"><nobr><span class="ft3">3.2 The Unified Utility Maximization Model</span></nobr></DIV>
<DIV style="position:absolute;top:435;left:809"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:451;left:486"><nobr><span class="ft14">In  this  section,  we  formally  define  the  new  unified  utility <br>maximization  model,  which  optimizes  the  resource  selection <br>problems </span></nobr></DIV>
<DIV style="position:absolute;top:482;left:555"><nobr><span class="ft5">for </span></nobr></DIV>
<DIV style="position:absolute;top:482;left:590"><nobr><span class="ft5">two </span></nobr></DIV>
<DIV style="position:absolute;top:482;left:630"><nobr><span class="ft5">goals </span></nobr></DIV>
<DIV style="position:absolute;top:482;left:678"><nobr><span class="ft5">of </span></nobr></DIV>
<DIV style="position:absolute;top:482;left:708"><nobr><span class="ft5">high-recall </span></nobr></DIV>
<DIV style="position:absolute;top:482;left:786"><nobr><span class="ft5">(database </span></nobr></DIV>
<DIV style="position:absolute;top:497;left:486"><nobr><span class="ft14">recommendation)  and  high-precision  (distributed  document <br>retrieval) in the same framework. <br> <br>In  the  task  of  database  recommendation,  the  system  needs  to <br>decide how to rank databases. In the task of document retrieval, <br>the system not only needs to select the databases but also needs <br>to  decide  how  many  documents  to  retrieve  from  each  selected <br>database. We generalize the database recommendation selection <br>process,  which  implicitly  recommends  all  documents  in  every <br>selected database, as a special case of the selection decision for <br>the  document  retrieval  task.  Formally,  we  denote  d</span></nobr></DIV>
<DIV style="position:absolute;top:658;left:791"><nobr><span class="ft9">i</span></nobr></DIV>
<DIV style="position:absolute;top:652;left:794"><nobr><span class="ft5">  as  the </span></nobr></DIV>
<DIV style="position:absolute;top:668;left:486"><nobr><span class="ft5">number  of  documents  we  would  like  to  retrieve  from  the  i</span></nobr></DIV>
<DIV style="position:absolute;top:665;left:830"><nobr><span class="ft9">th</span></nobr></DIV>
<DIV style="position:absolute;top:668;left:837"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:688;left:486"><nobr><span class="ft5">database  and </span></nobr></DIV>
<DIV style="position:absolute;top:689;left:626"><nobr><span class="ft26">,.....}</span></nobr></DIV>
<DIV style="position:absolute;top:689;left:606"><nobr><span class="ft26">,</span></nobr></DIV>
<DIV style="position:absolute;top:689;left:587"><nobr><span class="ft26">{</span></nobr></DIV>
<DIV style="position:absolute;top:696;left:620"><nobr><span class="ft27">2</span></nobr></DIV>
<DIV style="position:absolute;top:696;left:601"><nobr><span class="ft27">1</span></nobr></DIV>
<DIV style="position:absolute;top:689;left:612"><nobr><span class="ft28"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:689;left:593"><nobr><span class="ft28"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:689;left:564"><nobr><span class="ft28"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:684;left:577"><nobr><span class="ft33">=</span></nobr></DIV>
<DIV style="position:absolute;top:688;left:656"><nobr><span class="ft5">as  a  selection  action  for  all  the </span></nobr></DIV>
<DIV style="position:absolute;top:708;left:486"><nobr><span class="ft14">databases.  <br> <br>The  database  selection  decision  is  made  based  on  the  complete <br>lists  of  probabilities  of  relevance  for  all  the  databases.  The <br>complete lists of probabilities of relevance are inferred from all </span></nobr></DIV>
<DIV style="position:absolute;top:789;left:486"><nobr><span class="ft5">the  available  information  specifically </span></nobr></DIV>
<DIV style="position:absolute;top:798;left:707"><nobr><span class="ft29"><i>s</i></span></nobr></DIV>
<DIV style="position:absolute;top:790;left:698"><nobr><span class="ft28"><i>R</i></span></nobr></DIV>
<DIV style="position:absolute;top:789;left:715"><nobr><span class="ft5">,  which  stands  for  the </span></nobr></DIV>
<DIV style="position:absolute;top:810;left:486"><nobr><span class="ft5">resource descriptions acquired by query-based sampling and the </span></nobr></DIV>
<DIV style="position:absolute;top:830;left:486"><nobr><span class="ft5">database size estimates acquired by sample-resample; </span></nobr></DIV>
<DIV style="position:absolute;top:839;left:795"><nobr><span class="ft29"><i>c</i></span></nobr></DIV>
<DIV style="position:absolute;top:831;left:786"><nobr><span class="ft28"><i>S</i></span></nobr></DIV>
<DIV style="position:absolute;top:830;left:803"><nobr><span class="ft5">stands </span></nobr></DIV>
<DIV style="position:absolute;top:851;left:486"><nobr><span class="ft14">for  the  centralized  document  scores  of  the  documents  in  the <br>centralized sample database. <br> <br>If  the  method  of  estimating  centralized  document  scores  and <br>probabilities  of  relevance  in  Section  3.1  is  acceptable,  then  the <br>most probable complete lists of probabilities of relevance can be </span></nobr></DIV>
<DIV style="position:absolute;top:953;left:486"><nobr><span class="ft5">derived  and  we  denote  them  as </span></nobr></DIV>
<DIV style="position:absolute;top:963;left:813"><nobr><span class="ft34">1</span></nobr></DIV>
<DIV style="position:absolute;top:945;left:734"><nobr><span class="ft27">^</span></nobr></DIV>
<DIV style="position:absolute;top:945;left:798"><nobr><span class="ft27">^</span></nobr></DIV>
<DIV style="position:absolute;top:952;left:687"><nobr><span class="ft27">*</span></nobr></DIV>
<DIV style="position:absolute;top:962;left:740"><nobr><span class="ft27">1</span></nobr></DIV>
<DIV style="position:absolute;top:954;left:705"><nobr><span class="ft26">{(R(</span></nobr></DIV>
<DIV style="position:absolute;top:954;left:750"><nobr><span class="ft26">),</span></nobr></DIV>
<DIV style="position:absolute;top:954;left:779"><nobr><span class="ft26">[1,</span></nobr></DIV>
<DIV style="position:absolute;top:954;left:818"><nobr><span class="ft26">]),</span></nobr></DIV>
<DIV style="position:absolute;top:959;left:806"><nobr><span class="ft29"><i>db</i></span></nobr></DIV>
<DIV style="position:absolute;top:962;left:745"><nobr><span class="ft29"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:954;left:733"><nobr><span class="ft28"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:954;left:762"><nobr><span class="ft28"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:954;left:795"><nobr><span class="ft28"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:949;left:678"><nobr><span class="ft32"></span></nobr></DIV>
<DIV style="position:absolute;top:949;left:696"><nobr><span class="ft33">=</span></nobr></DIV>
<DIV style="position:absolute;top:949;left:768"><nobr><span class="ft33"></span></nobr></DIV>
<DIV style="position:absolute;top:953;left:837"><nobr><span class="ft5">  </span></nobr></DIV>
<DIV style="position:absolute;top:994;left:594"><nobr><span class="ft35">2</span></nobr></DIV>
<DIV style="position:absolute;top:976;left:511"><nobr><span class="ft27">^</span></nobr></DIV>
<DIV style="position:absolute;top:976;left:578"><nobr><span class="ft27">^</span></nobr></DIV>
<DIV style="position:absolute;top:993;left:517"><nobr><span class="ft27">2</span></nobr></DIV>
<DIV style="position:absolute;top:985;left:488"><nobr><span class="ft26">(R(</span></nobr></DIV>
<DIV style="position:absolute;top:985;left:528"><nobr><span class="ft26">),</span></nobr></DIV>
<DIV style="position:absolute;top:985;left:559"><nobr><span class="ft26">[1,</span></nobr></DIV>
<DIV style="position:absolute;top:985;left:600"><nobr><span class="ft26">]),.......}</span></nobr></DIV>
<DIV style="position:absolute;top:990;left:586"><nobr><span class="ft29"><i>db</i></span></nobr></DIV>
<DIV style="position:absolute;top:993;left:524"><nobr><span class="ft29"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:985;left:509"><nobr><span class="ft28"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:985;left:541"><nobr><span class="ft28"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:985;left:574"><nobr><span class="ft28"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:980;left:548"><nobr><span class="ft33"></span></nobr></DIV>
<DIV style="position:absolute;top:981;left:650"><nobr><span class="ft3">. </span></nobr></DIV>
<DIV style="position:absolute;top:984;left:664"><nobr><span class="ft5">Random  vector </span></nobr></DIV>
<DIV style="position:absolute;top:983;left:759"><nobr><span class="ft36"> </span></nobr></DIV>
<DIV style="position:absolute;top:984;left:772"><nobr><span class="ft5"> denotes  an </span></nobr></DIV>
<DIV style="position:absolute;top:1007;left:486"><nobr><span class="ft5">arbitrary  set  of  complete  lists  of  probabilities  of  relevance  and </span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:556"><nobr><span class="ft26">)</span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:536"><nobr><span class="ft26">,</span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:514"><nobr><span class="ft26">|</span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:498"><nobr><span class="ft26">(</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:550"><nobr><span class="ft29"><i>c</i></span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:530"><nobr><span class="ft29"><i>s</i></span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:541"><nobr><span class="ft28"><i>S</i></span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:521"><nobr><span class="ft28"><i>R</i></span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:489"><nobr><span class="ft28"><i>P</i></span></nobr></DIV>
<DIV style="position:absolute;top:1022;left:502"><nobr><span class="ft32"></span></nobr></DIV>
<DIV style="position:absolute;top:1026;left:564"><nobr><span class="ft5">as  the  probability  of  generating  this  set  of  lists. </span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:486"><nobr><span class="ft5">Finally, to each selection action </span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:665"><nobr><span class="ft28"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:1049;left:675"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:680"><nobr><span class="ft5">and a set of complete lists of </span></nobr></DIV>
<DIV style="position:absolute;top:204;left:825"><nobr><span class="ft6"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:219;left:497"><nobr><span class="ft6"><b>Figure 1. </b></span></nobr></DIV>
<DIV style="position:absolute;top:219;left:552"><nobr><span class="ft5">Linear interpolation construction of the complete </span></nobr></DIV>
<DIV style="position:absolute;top:237;left:497"><nobr><span class="ft5">centralized document score list (database scale factor is 50). </span></nobr></DIV>
<DIV style="position:absolute;top:253;left:497"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:1116;left:452"><nobr><span class="ft5">35</span></nobr></DIV>
</DIV>
<!-- Page 5 -->
<a name="5"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft37{font-size:6px;font-family:Symbol;color:#000000;}
	.ft38{font-size:17px;font-family:Times;color:#000000;}
	.ft39{font-size:5px;font-family:Symbol;color:#000000;}
	.ft40{font-size:18px;font-family:Times;color:#000000;}
	.ft41{font-size:11px;line-height:16px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="204005.png" alt="background image">
<DIV style="position:absolute;top:112;left:81"><nobr><span class="ft5">probabilities  of  relevance </span></nobr></DIV>
<DIV style="position:absolute;top:106;left:232"><nobr><span class="ft32"></span></nobr></DIV>
<DIV style="position:absolute;top:112;left:245"><nobr><span class="ft5">,  we  associate  a  utility  function </span></nobr></DIV>
<DIV style="position:absolute;top:134;left:123"><nobr><span class="ft26">)</span></nobr></DIV>
<DIV style="position:absolute;top:134;left:108"><nobr><span class="ft26">,</span></nobr></DIV>
<DIV style="position:absolute;top:134;left:95"><nobr><span class="ft26">(</span></nobr></DIV>
<DIV style="position:absolute;top:134;left:114"><nobr><span class="ft28"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:134;left:82"><nobr><span class="ft28"><i>U</i></span></nobr></DIV>
<DIV style="position:absolute;top:129;left:99"><nobr><span class="ft32"></span></nobr></DIV>
<DIV style="position:absolute;top:130;left:134"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:133;left:139"><nobr><span class="ft5">which  indicates  the  benefit  from  making  the </span></nobr></DIV>
<DIV style="position:absolute;top:134;left:421"><nobr><span class="ft28"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:133;left:432"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:153;left:81"><nobr><span class="ft41">selection  when  the  true  complete  lists  of  probabilities  of <br>relevance are </span></nobr></DIV>
<DIV style="position:absolute;top:163;left:157"><nobr><span class="ft32"></span></nobr></DIV>
<DIV style="position:absolute;top:170;left:169"><nobr><span class="ft5">. </span></nobr></DIV>
<DIV style="position:absolute;top:186;left:81"><nobr><span class="ft14"> <br>Therefore,  the  selection  decision  defined  by  the  Bayesian <br>framework is: </span></nobr></DIV>
<DIV style="position:absolute;top:242;left:326"><nobr><span class="ft25"></span></nobr></DIV>
<DIV style="position:absolute;top:242;left:268"><nobr><span class="ft25"></span></nobr></DIV>
<DIV style="position:absolute;top:242;left:240"><nobr><span class="ft25"></span></nobr></DIV>
<DIV style="position:absolute;top:256;left:203"><nobr><span class="ft37"></span></nobr></DIV>
<DIV style="position:absolute;top:247;left:320"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:247;left:300"><nobr><span class="ft8"><i>S</i></span></nobr></DIV>
<DIV style="position:absolute;top:247;left:284"><nobr><span class="ft8"><i>R</i></span></nobr></DIV>
<DIV style="position:absolute;top:247;left:256"><nobr><span class="ft8"><i>P</i></span></nobr></DIV>
<DIV style="position:absolute;top:247;left:228"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:247;left:212"><nobr><span class="ft8"><i>U</i></span></nobr></DIV>
<DIV style="position:absolute;top:247;left:128"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:254;left:308"><nobr><span class="ft24"><i>c</i></span></nobr></DIV>
<DIV style="position:absolute;top:254;left:292"><nobr><span class="ft24"><i>s</i></span></nobr></DIV>
<DIV style="position:absolute;top:264;left:174"><nobr><span class="ft24"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:248;left:313"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:248;left:297"><nobr><span class="ft5">.</span></nobr></DIV>
<DIV style="position:absolute;top:248;left:278"><nobr><span class="ft5">|</span></nobr></DIV>
<DIV style="position:absolute;top:248;left:264"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:248;left:248"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:248;left:235"><nobr><span class="ft5">,</span></nobr></DIV>
<DIV style="position:absolute;top:248;left:223"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:248;left:174"><nobr><span class="ft5">max</span></nobr></DIV>
<DIV style="position:absolute;top:248;left:155"><nobr><span class="ft5">arg</span></nobr></DIV>
<DIV style="position:absolute;top:240;left:136"><nobr><span class="ft23">*</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:145"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:238;left:337"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:250;left:407"><nobr><span class="ft5">(7) </span></nobr></DIV>
<DIV style="position:absolute;top:282;left:81"><nobr><span class="ft14">One  common  approach  to  simplify  the  computation  in  the <br>Bayesian  framework  is  to  only  calculate  the  utility  function  at <br>the  most  probable  parameter  values  instead  of  calculating  the <br>whole  expectation.  In  other  words,  we  only  need  to  calculate </span></nobr></DIV>
<DIV style="position:absolute;top:349;left:129"><nobr><span class="ft26">)</span></nobr></DIV>
<DIV style="position:absolute;top:349;left:115"><nobr><span class="ft26">,</span></nobr></DIV>
<DIV style="position:absolute;top:349;left:95"><nobr><span class="ft26">(</span></nobr></DIV>
<DIV style="position:absolute;top:347;left:109"><nobr><span class="ft27">*</span></nobr></DIV>
<DIV style="position:absolute;top:349;left:120"><nobr><span class="ft28"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:349;left:82"><nobr><span class="ft28"><i>U</i></span></nobr></DIV>
<DIV style="position:absolute;top:344;left:99"><nobr><span class="ft32"></span></nobr></DIV>
<DIV style="position:absolute;top:348;left:137"><nobr><span class="ft5"> and Equation 7 is simplified as follows: </span></nobr></DIV>
<DIV style="position:absolute;top:383;left:285"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:266"><nobr><span class="ft5">,</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:254"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:219"><nobr><span class="ft5">max</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:200"><nobr><span class="ft5">arg</span></nobr></DIV>
<DIV style="position:absolute;top:381;left:280"><nobr><span class="ft23">*</span></nobr></DIV>
<DIV style="position:absolute;top:376;left:182"><nobr><span class="ft23">*</span></nobr></DIV>
<DIV style="position:absolute;top:378;left:270"><nobr><span class="ft25"></span></nobr></DIV>
<DIV style="position:absolute;top:383;left:259"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:383;left:243"><nobr><span class="ft8"><i>U</i></span></nobr></DIV>
<DIV style="position:absolute;top:383;left:173"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:400;left:219"><nobr><span class="ft24"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:379;left:190"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:374;left:292"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:385;left:407"><nobr><span class="ft5">(8) </span></nobr></DIV>
<DIV style="position:absolute;top:417;left:81"><nobr><span class="ft14">This  equation  serves  as  the  basic  model  for  both  the  database <br>recommendation system and the document retrieval system. <br> </span></nobr></DIV>
<DIV style="position:absolute;top:465;left:81"><nobr><span class="ft3">3.3  Resource Selection for High-Recall  </span></nobr></DIV>
<DIV style="position:absolute;top:485;left:81"><nobr><span class="ft14">High-recall  is  the  goal  of  the  resource  selection  algorithm  in <br>federated  search  tasks  such  as  database  recommendation.  The <br>goal  is  to  select  a  small  set  of  resources  (e.g.,  less  than  N</span></nobr></DIV>
<DIV style="position:absolute;top:521;left:420"><nobr><span class="ft9">sdb </span></nobr></DIV>
<DIV style="position:absolute;top:531;left:81"><nobr><span class="ft14">databases) that contain as many relevant documents as possible, <br>which can be formally defined as: </span></nobr></DIV>
<DIV style="position:absolute;top:595;left:266"><nobr><span class="ft39">=</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:205"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:597;left:221"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:570;left:259"><nobr><span class="ft24"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:597;left:263"><nobr><span class="ft24"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:588;left:298"><nobr><span class="ft24"><i>ij</i></span></nobr></DIV>
<DIV style="position:absolute;top:588;left:250"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:574;left:271"><nobr><span class="ft31"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:572;left:266"><nobr><span class="ft31"><i>db</i></span></nobr></DIV>
<DIV style="position:absolute;top:581;left:290"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:581;left:242"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:581;left:231"><nobr><span class="ft8"><i>I</i></span></nobr></DIV>
<DIV style="position:absolute;top:581;left:171"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:581;left:155"><nobr><span class="ft8"><i>U</i></span></nobr></DIV>
<DIV style="position:absolute;top:564;left:261"><nobr><span class="ft34">^</span></nobr></DIV>
<DIV style="position:absolute;top:597;left:269"><nobr><span class="ft23">1</span></nobr></DIV>
<DIV style="position:absolute;top:573;left:291"><nobr><span class="ft23">^</span></nobr></DIV>
<DIV style="position:absolute;top:579;left:192"><nobr><span class="ft23">*</span></nobr></DIV>
<DIV style="position:absolute;top:581;left:305"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:581;left:286"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:581;left:276"><nobr><span class="ft5">R</span></nobr></DIV>
<DIV style="position:absolute;top:581;left:254"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:581;left:237"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:581;left:197"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:581;left:179"><nobr><span class="ft5">,</span></nobr></DIV>
<DIV style="position:absolute;top:581;left:166"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:576;left:183"><nobr><span class="ft25"></span></nobr></DIV>
<DIV style="position:absolute;top:571;left:312"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:579;left:407"><nobr><span class="ft5">(9) </span></nobr></DIV>
<DIV style="position:absolute;top:612;left:81"><nobr><span class="ft5">I(d</span></nobr></DIV>
<DIV style="position:absolute;top:617;left:97"><nobr><span class="ft9">i</span></nobr></DIV>
<DIV style="position:absolute;top:612;left:99"><nobr><span class="ft5">) is the indicator function, which is 1 when the i</span></nobr></DIV>
<DIV style="position:absolute;top:609;left:362"><nobr><span class="ft9">th</span></nobr></DIV>
<DIV style="position:absolute;top:612;left:369"><nobr><span class="ft5"> database is </span></nobr></DIV>
<DIV style="position:absolute;top:627;left:81"><nobr><span class="ft14">selected and 0 otherwise. Plug this equation into the basic model <br>in  Equation  8  and  associate  the  selected  database  number <br>constraint to obtain the following: </span></nobr></DIV>
<DIV style="position:absolute;top:732;left:280"><nobr><span class="ft24"><i>sdb</i></span></nobr></DIV>
<DIV style="position:absolute;top:741;left:218"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:732;left:247"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:709;left:226"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:682;left:264"><nobr><span class="ft24"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:709;left:267"><nobr><span class="ft24"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:700;left:303"><nobr><span class="ft24"><i>ij</i></span></nobr></DIV>
<DIV style="position:absolute;top:700;left:255"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:709;left:195"><nobr><span class="ft24"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:725;left:270"><nobr><span class="ft8"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:725;left:240"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:725;left:229"><nobr><span class="ft8"><i>I</i></span></nobr></DIV>
<DIV style="position:absolute;top:725;left:195"><nobr><span class="ft8"><i>to</i></span></nobr></DIV>
<DIV style="position:absolute;top:725;left:149"><nobr><span class="ft8"><i>Subject</i></span></nobr></DIV>
<DIV style="position:absolute;top:693;left:295"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:693;left:247"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:693;left:236"><nobr><span class="ft8"><i>I</i></span></nobr></DIV>
<DIV style="position:absolute;top:693;left:149"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:685;left:276"><nobr><span class="ft31"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:684;left:271"><nobr><span class="ft31"><i>db</i></span></nobr></DIV>
<DIV style="position:absolute;top:721;left:259"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:688;left:166"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:706;left:270"><nobr><span class="ft39">=</span></nobr></DIV>
<DIV style="position:absolute;top:725;left:252"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:725;left:235"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:725;left:207"><nobr><span class="ft5">:</span></nobr></DIV>
<DIV style="position:absolute;top:693;left:310"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:693;left:290"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:693;left:281"><nobr><span class="ft5">R</span></nobr></DIV>
<DIV style="position:absolute;top:693;left:259"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:693;left:242"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:693;left:195"><nobr><span class="ft5">max</span></nobr></DIV>
<DIV style="position:absolute;top:693;left:176"><nobr><span class="ft5">arg</span></nobr></DIV>
<DIV style="position:absolute;top:676;left:266"><nobr><span class="ft34">^</span></nobr></DIV>
<DIV style="position:absolute;top:709;left:274"><nobr><span class="ft23">1</span></nobr></DIV>
<DIV style="position:absolute;top:685;left:295"><nobr><span class="ft23">^</span></nobr></DIV>
<DIV style="position:absolute;top:686;left:158"><nobr><span class="ft23">*</span></nobr></DIV>
<DIV style="position:absolute;top:689;left:316"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:706;left:404"><nobr><span class="ft5">(10) </span></nobr></DIV>
<DIV style="position:absolute;top:755;left:81"><nobr><span class="ft14">The  solution  of  this  optimization  problem  is  very  simple.  We <br>can  calculate  the  expected  number  of  relevant  documents  for <br>each database as follows: </span></nobr></DIV>
<DIV style="position:absolute;top:834;left:233"><nobr><span class="ft39">=</span></nobr></DIV>
<DIV style="position:absolute;top:816;left:217"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:813;left:239"><nobr><span class="ft31"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:811;left:234"><nobr><span class="ft31"><i>db</i></span></nobr></DIV>
<DIV style="position:absolute;top:830;left:209"><nobr><span class="ft31"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:809;left:227"><nobr><span class="ft24"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:836;left:230"><nobr><span class="ft24"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:827;left:266"><nobr><span class="ft24"><i>ij</i></span></nobr></DIV>
<DIV style="position:absolute;top:827;left:200"><nobr><span class="ft24"><i>Rd</i></span></nobr></DIV>
<DIV style="position:absolute;top:820;left:258"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:820;left:190"><nobr><span class="ft8"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:803;left:229"><nobr><span class="ft34">^</span></nobr></DIV>
<DIV style="position:absolute;top:836;left:237"><nobr><span class="ft23">1</span></nobr></DIV>
<DIV style="position:absolute;top:812;left:258"><nobr><span class="ft23">^</span></nobr></DIV>
<DIV style="position:absolute;top:812;left:199"><nobr><span class="ft23">^</span></nobr></DIV>
<DIV style="position:absolute;top:820;left:273"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:820;left:253"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:820;left:244"><nobr><span class="ft5">R</span></nobr></DIV>
<DIV style="position:absolute;top:811;left:279"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:818;left:404"><nobr><span class="ft5">(11) </span></nobr></DIV>
<DIV style="position:absolute;top:850;left:81"><nobr><span class="ft5">The N</span></nobr></DIV>
<DIV style="position:absolute;top:856;left:116"><nobr><span class="ft9">sdb</span></nobr></DIV>
<DIV style="position:absolute;top:850;left:128"><nobr><span class="ft5"> databases with the largest expected number of relevant </span></nobr></DIV>
<DIV style="position:absolute;top:866;left:81"><nobr><span class="ft14">documents can be selected to meet the high-recall goal. We call <br>this  the  UUM/HR  algorithm  (Unified  Utility  Maximization  for <br>High-Recall). <br> </span></nobr></DIV>
<DIV style="position:absolute;top:929;left:81"><nobr><span class="ft3">3.4  Resource Selection for High-Precision </span></nobr></DIV>
<DIV style="position:absolute;top:949;left:81"><nobr><span class="ft15">High-Precision  is  the  goal  of  resource  selection  algorithm  in <br>federated search tasks such as distributed document retrieval. It <br>is measured by the Precision at the top part of the final merged <br>document  list.  This  high-precision  criterion  is  realized  by  the <br>following  utility  function,  which  measures  the  Precision  of <br>retrieved documents from the selected databases. </span></nobr></DIV>
<DIV style="position:absolute;top:141;left:674"><nobr><span class="ft39">=</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:608"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:143;left:626"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:116;left:671"><nobr><span class="ft24"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:143;left:671"><nobr><span class="ft24"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:134;left:709"><nobr><span class="ft24"><i>ij</i></span></nobr></DIV>
<DIV style="position:absolute;top:134;left:658"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:119;left:676"><nobr><span class="ft31"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:127;left:701"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:127;left:649"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:127;left:638"><nobr><span class="ft8"><i>I</i></span></nobr></DIV>
<DIV style="position:absolute;top:127;left:571"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:127;left:554"><nobr><span class="ft8"><i>U</i></span></nobr></DIV>
<DIV style="position:absolute;top:143;left:678"><nobr><span class="ft23">1</span></nobr></DIV>
<DIV style="position:absolute;top:118;left:701"><nobr><span class="ft23">^</span></nobr></DIV>
<DIV style="position:absolute;top:125;left:594"><nobr><span class="ft23">*</span></nobr></DIV>
<DIV style="position:absolute;top:127;left:717"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:127;left:696"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:127;left:685"><nobr><span class="ft5">R</span></nobr></DIV>
<DIV style="position:absolute;top:127;left:663"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:127;left:644"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:127;left:600"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:127;left:580"><nobr><span class="ft5">,</span></nobr></DIV>
<DIV style="position:absolute;top:127;left:566"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:121;left:584"><nobr><span class="ft33"></span></nobr></DIV>
<DIV style="position:absolute;top:118;left:723"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:128;left:809"><nobr><span class="ft5">(12) </span></nobr></DIV>
<DIV style="position:absolute;top:160;left:486"><nobr><span class="ft15">Note that the key difference between Equation 12 and Equation <br>9 is that Equation 9 sums up the probabilities of relevance of all <br>the documents in a database, while Equation 12 only considers a <br>much smaller part of the ranking. Specifically, we can calculate <br>the optimal selection decision by: </span></nobr></DIV>
<DIV style="position:absolute;top:266;left:675"><nobr><span class="ft39">=</span></nobr></DIV>
<DIV style="position:absolute;top:248;left:572"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:268;left:631"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:241;left:673"><nobr><span class="ft24"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:268;left:672"><nobr><span class="ft24"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:259;left:707"><nobr><span class="ft24"><i>ij</i></span></nobr></DIV>
<DIV style="position:absolute;top:259;left:660"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:268;left:600"><nobr><span class="ft24"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:245;left:677"><nobr><span class="ft31"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:252;left:699"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:252;left:652"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:252;left:642"><nobr><span class="ft8"><i>I</i></span></nobr></DIV>
<DIV style="position:absolute;top:252;left:555"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:268;left:679"><nobr><span class="ft23">1</span></nobr></DIV>
<DIV style="position:absolute;top:244;left:700"><nobr><span class="ft23">^</span></nobr></DIV>
<DIV style="position:absolute;top:245;left:563"><nobr><span class="ft23">*</span></nobr></DIV>
<DIV style="position:absolute;top:252;left:714"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:252;left:695"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:252;left:685"><nobr><span class="ft5">R</span></nobr></DIV>
<DIV style="position:absolute;top:252;left:665"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:252;left:648"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:252;left:600"><nobr><span class="ft5">max</span></nobr></DIV>
<DIV style="position:absolute;top:252;left:582"><nobr><span class="ft5">arg</span></nobr></DIV>
<DIV style="position:absolute;top:242;left:721"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:253;left:809"><nobr><span class="ft5">(13) </span></nobr></DIV>
<DIV style="position:absolute;top:286;left:486"><nobr><span class="ft14">Different kinds of constraints caused by different characteristics <br>of the document retrieval tasks can be associated with the above <br>optimization problem. The most common one is to select a fixed <br>number (N</span></nobr></DIV>
<DIV style="position:absolute;top:336;left:545"><nobr><span class="ft9">sdb</span></nobr></DIV>
<DIV style="position:absolute;top:331;left:557"><nobr><span class="ft5">) of databases and retrieve a fixed number (N</span></nobr></DIV>
<DIV style="position:absolute;top:336;left:802"><nobr><span class="ft9">rdoc</span></nobr></DIV>
<DIV style="position:absolute;top:331;left:818"><nobr><span class="ft5">) of </span></nobr></DIV>
<DIV style="position:absolute;top:346;left:486"><nobr><span class="ft5">documents from each selected database, formally defined as: </span></nobr></DIV>
<DIV style="position:absolute;top:441;left:713"><nobr><span class="ft5">0</span></nobr></DIV>
<DIV style="position:absolute;top:441;left:671"><nobr><span class="ft5">,</span></nobr></DIV>
<DIV style="position:absolute;top:411;left:656"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:411;left:639"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:411;left:611"><nobr><span class="ft5">:</span></nobr></DIV>
<DIV style="position:absolute;top:379;left:713"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:379;left:694"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:379;left:684"><nobr><span class="ft5">R</span></nobr></DIV>
<DIV style="position:absolute;top:379;left:663"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:379;left:647"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:379;left:599"><nobr><span class="ft5">max</span></nobr></DIV>
<DIV style="position:absolute;top:379;left:581"><nobr><span class="ft5">arg</span></nobr></DIV>
<DIV style="position:absolute;top:395;left:678"><nobr><span class="ft23">1</span></nobr></DIV>
<DIV style="position:absolute;top:371;left:699"><nobr><span class="ft23">^</span></nobr></DIV>
<DIV style="position:absolute;top:372;left:562"><nobr><span class="ft23">*</span></nobr></DIV>
<DIV style="position:absolute;top:436;left:703"><nobr><span class="ft25"></span></nobr></DIV>
<DIV style="position:absolute;top:436;left:631"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:407;left:664"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:375;left:571"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:393;left:674"><nobr><span class="ft39">=</span></nobr></DIV>
<DIV style="position:absolute;top:448;left:696"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:448;left:652"><nobr><span class="ft24"><i>rdoc</i></span></nobr></DIV>
<DIV style="position:absolute;top:448;left:624"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:418;left:685"><nobr><span class="ft24"><i>sdb</i></span></nobr></DIV>
<DIV style="position:absolute;top:428;left:623"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:418;left:652"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:395;left:630"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:368;left:672"><nobr><span class="ft24"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:395;left:671"><nobr><span class="ft24"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:386;left:706"><nobr><span class="ft24"><i>ij</i></span></nobr></DIV>
<DIV style="position:absolute;top:386;left:659"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:396;left:599"><nobr><span class="ft24"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:441;left:688"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:441;left:676"><nobr><span class="ft8"><i>if</i></span></nobr></DIV>
<DIV style="position:absolute;top:441;left:642"><nobr><span class="ft8"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:441;left:616"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:411;left:674"><nobr><span class="ft8"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:411;left:644"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:411;left:633"><nobr><span class="ft8"><i>I</i></span></nobr></DIV>
<DIV style="position:absolute;top:411;left:599"><nobr><span class="ft8"><i>to</i></span></nobr></DIV>
<DIV style="position:absolute;top:411;left:554"><nobr><span class="ft8"><i>Subject</i></span></nobr></DIV>
<DIV style="position:absolute;top:379;left:698"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:379;left:651"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:379;left:641"><nobr><span class="ft8"><i>I</i></span></nobr></DIV>
<DIV style="position:absolute;top:379;left:554"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:372;left:676"><nobr><span class="ft31"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:395;left:722"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:406;left:809"><nobr><span class="ft5">(14) </span></nobr></DIV>
<DIV style="position:absolute;top:466;left:486"><nobr><span class="ft15">This  optimization  problem  can  be  solved  easily  by  calculating <br>the number of expected relevant documents in the top part of the <br>each database's complete list of probabilities of relevance:  </span></nobr></DIV>
<DIV style="position:absolute;top:551;left:648"><nobr><span class="ft39">=</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:631"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:530;left:647"><nobr><span class="ft31"><i>rdoc</i></span></nobr></DIV>
<DIV style="position:absolute;top:548;left:623"><nobr><span class="ft31"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:526;left:641"><nobr><span class="ft24"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:553;left:645"><nobr><span class="ft24"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:544;left:681"><nobr><span class="ft24"><i>ij</i></span></nobr></DIV>
<DIV style="position:absolute;top:544;left:614"><nobr><span class="ft24"><i>Rd</i></span></nobr></DIV>
<DIV style="position:absolute;top:544;left:595"><nobr><span class="ft24"><i>Top</i></span></nobr></DIV>
<DIV style="position:absolute;top:537;left:673"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:537;left:585"><nobr><span class="ft8"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:553;left:652"><nobr><span class="ft23">1</span></nobr></DIV>
<DIV style="position:absolute;top:529;left:673"><nobr><span class="ft23">^</span></nobr></DIV>
<DIV style="position:absolute;top:529;left:604"><nobr><span class="ft23">^</span></nobr></DIV>
<DIV style="position:absolute;top:544;left:608"><nobr><span class="ft23">_</span></nobr></DIV>
<DIV style="position:absolute;top:537;left:687"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:537;left:668"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:537;left:659"><nobr><span class="ft5">R</span></nobr></DIV>
<DIV style="position:absolute;top:528;left:694"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:538;left:809"><nobr><span class="ft5">(15) </span></nobr></DIV>
<DIV style="position:absolute;top:581;left:486"><nobr><span class="ft14">Then the databases can be ranked by these values and selected. <br>We  call  this  the  UUM/HP-FL  algorithm  (Unified  Utility <br>Maximization  for  High-Precision  with  Fixed  Length  document <br>rankings from each selected database). <br> <br>A  more  complex  situation  is  to  vary  the  number  of  retrieved <br>documents  from  each  selected  database.  More  specifically,  we <br>allow different selected databases to return different numbers of <br>documents. For simplification, the result list lengths are required <br>to be multiples of a baseline number 10. (This value can also be <br>varied,  but  for  simplification  it  is  set  to  10  in  this  paper.)  This <br>restriction  is  set  to  simulate  the  behavior  of  commercial  search <br>engines  on  the  Web.  (Search  engines  such  as  Google  and <br>AltaVista  return  only  10  or  20  document  ids  for  every  result <br>page.) This procedure saves the computation time of calculating <br>optimal  database  selection  by  allowing  the  step  of  dynamic <br>programming  to  be  10  instead  of  1  (more  detail  is  discussed <br>latterly). For further simplification, we restrict to select  at  most <br>100  documents  from  each  database  (d</span></nobr></DIV>
<DIV style="position:absolute;top:856;left:726"><nobr><span class="ft9">i</span></nobr></DIV>
<DIV style="position:absolute;top:851;left:728"><nobr><span class="ft5">&lt;=100)  Then,  the </span></nobr></DIV>
<DIV style="position:absolute;top:866;left:486"><nobr><span class="ft5">selection optimization problem is formalized as follows: </span></nobr></DIV>
<DIV style="position:absolute;top:988;left:742"><nobr><span class="ft5">]</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:729"><nobr><span class="ft5">10</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:718"><nobr><span class="ft5">..,</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:712"><nobr><span class="ft5">,</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:706"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:700"><nobr><span class="ft5">,</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:695"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:690"><nobr><span class="ft5">,</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:684"><nobr><span class="ft5">0</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:679"><nobr><span class="ft5">[</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:644"><nobr><span class="ft5">,</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:629"><nobr><span class="ft5">*</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:614"><nobr><span class="ft5">10</span></nobr></DIV>
<DIV style="position:absolute;top:928;left:630"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:928;left:613"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:928;left:585"><nobr><span class="ft5">:</span></nobr></DIV>
<DIV style="position:absolute;top:896;left:687"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:896;left:668"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:896;left:658"><nobr><span class="ft5">R</span></nobr></DIV>
<DIV style="position:absolute;top:896;left:637"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:896;left:620"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:896;left:573"><nobr><span class="ft5">max</span></nobr></DIV>
<DIV style="position:absolute;top:896;left:554"><nobr><span class="ft5">arg</span></nobr></DIV>
<DIV style="position:absolute;top:966;left:659"><nobr><span class="ft23">_</span></nobr></DIV>
<DIV style="position:absolute;top:912;left:652"><nobr><span class="ft23">1</span></nobr></DIV>
<DIV style="position:absolute;top:888;left:673"><nobr><span class="ft23">^</span></nobr></DIV>
<DIV style="position:absolute;top:889;left:536"><nobr><span class="ft23">*</span></nobr></DIV>
<DIV style="position:absolute;top:984;left:669"><nobr><span class="ft25"></span></nobr></DIV>
<DIV style="position:absolute;top:984;left:605"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:955;left:620"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:924;left:638"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:892;left:545"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:910;left:648"><nobr><span class="ft39">=</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:661"><nobr><span class="ft8"><i>k</i></span></nobr></DIV>
<DIV style="position:absolute;top:988;left:638"><nobr><span class="ft8"><i>k</i></span></nobr></DIV>
<DIV style="position:absolute;top:988;left:590"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:959;left:631"><nobr><span class="ft8"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:959;left:605"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:928;left:648"><nobr><span class="ft8"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:928;left:618"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:928;left:607"><nobr><span class="ft8"><i>I</i></span></nobr></DIV>
<DIV style="position:absolute;top:928;left:573"><nobr><span class="ft8"><i>to</i></span></nobr></DIV>
<DIV style="position:absolute;top:928;left:528"><nobr><span class="ft8"><i>Subject</i></span></nobr></DIV>
<DIV style="position:absolute;top:896;left:672"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:896;left:625"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:896;left:615"><nobr><span class="ft8"><i>I</i></span></nobr></DIV>
<DIV style="position:absolute;top:896;left:527"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:996;left:598"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:966;left:665"><nobr><span class="ft24"><i>rdoc</i></span></nobr></DIV>
<DIV style="position:absolute;top:966;left:641"><nobr><span class="ft24"><i>Total</i></span></nobr></DIV>
<DIV style="position:absolute;top:975;left:595"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:966;left:613"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:935;left:659"><nobr><span class="ft24"><i>sdb</i></span></nobr></DIV>
<DIV style="position:absolute;top:945;left:597"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:935;left:626"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:912;left:604"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:886;left:645"><nobr><span class="ft24"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:912;left:645"><nobr><span class="ft24"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:903;left:680"><nobr><span class="ft24"><i>ij</i></span></nobr></DIV>
<DIV style="position:absolute;top:903;left:633"><nobr><span class="ft24"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:913;left:573"><nobr><span class="ft24"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:889;left:650"><nobr><span class="ft31"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:913;left:748"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:938;left:809"><nobr><span class="ft5">(16) </span></nobr></DIV>
<DIV style="position:absolute;top:1011;left:486"><nobr><span class="ft5">N</span></nobr></DIV>
<DIV style="position:absolute;top:1016;left:496"><nobr><span class="ft9">Total_rdoc</span></nobr></DIV>
<DIV style="position:absolute;top:1011;left:535"><nobr><span class="ft5"> is the total number of documents to be retrieved.  </span></nobr></DIV>
<DIV style="position:absolute;top:1026;left:486"><nobr><span class="ft15"> <br>Unfortunately,  there  is  no  simple  solution  for  this  optimization <br>problem  as  there  are  for  Equations  10  and  14.  However,  a </span></nobr></DIV>
<DIV style="position:absolute;top:1116;left:452"><nobr><span class="ft5">36</span></nobr></DIV>
</DIV>
<!-- Page 6 -->
<a name="6"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft42{font-size:10px;font-family:Symbol;color:#000000;}
	.ft43{font-size:12px;font-family:Times;color:#000000;}
	.ft44{font-size:16px;line-height:14px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="204006.png" alt="background image">
<DIV style="position:absolute;top:662;left:81"><nobr><span class="ft15">dynamic programming algorithm can be applied to calculate the <br>optimal  solution.  The  basic  steps  of  this dynamic  programming <br>method  are  described  in  Figure  2.  As  this  algorithm  allows <br>retrieving  result  lists  of  varying  lengths  from  each  selected <br>database, it is called UUM/HP-VL algorithm. <br> <br>After the selection decisions are made, the selected databases are <br>searched and the corresponding document ids are retrieved from <br>each  database.  The  final  step  of  document  retrieval  is  to  merge <br>the  returned  results  into  a  single  ranked  list  with  the  semi-<br>supervised learning algorithm. It was pointed out before that the <br>SSL  algorithm  maps  the  database-specific  scores  into  the <br>centralized  document  scores  and  builds  the  final  ranked  list <br>accordingly,  which  is  consistent  with  all  our  selection <br>procedures  where  documents  with  higher  probabilities  of <br>relevance (thus higher centralized document scores) are selected. </span></nobr></DIV>
<DIV style="position:absolute;top:922;left:81"><nobr><span class="ft44"><b>4. EXPERIMENTAL METHODOLOGY <br></b> <br>4.1 Testbeds</span></nobr></DIV>
<DIV style="position:absolute;top:960;left:172"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:975;left:81"><nobr><span class="ft14">It  is  desirable  to  evaluate  distributed  information  retrieval <br>algorithms  with  testbeds  that  closely  simulate  the  real  world <br>applications.  <br> <br>The  TREC  Web  collections  WT2g  or  WT10g  [4,13]  provide  a  <br>way  to  partition  documents  by  different  Web  servers.  In  this <br>way, a large number (O(1000)) of databases with rather diverse </span></nobr></DIV>
<DIV style="position:absolute;top:303;left:486"><nobr><span class="ft14">contents could be created, which may  make this testbed a good <br>candidate to simulate the operational environments such as open <br>domain hidden Web. However, two weakness of this testbed are: <br>i) Each database contains only a small amount of document (259 <br>documents  by  average  for  WT2g)  [4];  and  ii)  The  contents  of <br>WT2g or WT10g are arbitrarily crawled from the Web. It is not <br>likely for a hidden Web database to provide personal homepages <br>or  web  pages  indicating  that  the  pages  are  under  construction <br>and  there  is  no  useful  information  at  all.  These  types  of  web <br>pages  are  contained  in  the  WT2g/WT10g  datasets.  Therefore, <br>the  noisy  Web  data  is  not  similar  with  that  of  high-quality <br>hidden  Web  database  contents,  which  are  usually  organized  by <br>domain experts. </span></nobr></DIV>
<DIV style="position:absolute;top:518;left:486"><nobr><span class="ft14">Another  choice  is  the  TREC  news/government  data  [1,15,17, <br>18,21].  TREC  news/government  data  is  concentrated  on <br>relatively narrow topics. Compared with TREC Web data: i) The <br>news/government  documents  are  much  more  similar  to  the <br>contents provided by a topic-oriented database than an arbitrary <br>web  page,  ii)  A  database  in  this  testbed  is  larger  than  that  of <br>TREC  Web  data.  By  average  a  database  contains  thousands  of <br>documents,  which  is  more  realistic  than  a  database  of  TREC <br>Web data with about 250 documents. As the contents and sizes <br>of the databases in the TREC news/government testbed are more <br>similar  with  that  of  a  topic-oriented  database,  it  is  a  good <br>candidate  to  simulate  the  distributed  information  retrieval <br>environments  of  large  organizations  (companies)  or  domain-<br>specific hidden Web sites, such as West that provides access to <br>legal,  financial  and  news  text  databases  [3].  As  most  current <br>distributed  information  retrieval  systems  are  developed  for  the <br>environments  of  large  organizations  (companies)  or  domain-<br>specific  hidden  Web  other  than  open  domain  hidden  Web, <br>TREC news/government testbed was chosen in this work. </span></nobr></DIV>
<DIV style="position:absolute;top:826;left:486"><nobr><span class="ft14">Trec123-100col-bysource testbed is one of the most used TREC <br>news/government  testbed  [1,15,17,21].  It  was  chosen  in  this <br>work.  Three  testbeds  in  [21]  with  skewed  database  size <br>distributions  and  different  types  of  relevant  document <br>distributions  were  also  used  to  give  more  thorough  simulation <br>for real environments. <br> <br><b>Trec123-100col-bysource:</b></span></nobr></DIV>
<DIV style="position:absolute;top:931;left:635"><nobr><span class="ft5">  100  databases  were  created  from </span></nobr></DIV>
<DIV style="position:absolute;top:947;left:486"><nobr><span class="ft14">TREC  CDs  1,  2  and  3.  They  were  organized  by  source  and <br>publication date [1]. The sizes of the databases are not skewed. <br>Details are in Table 1.</span></nobr></DIV>
<DIV style="position:absolute;top:977;left:606"><nobr><span class="ft26"> </span></nobr></DIV>
<DIV style="position:absolute;top:993;left:486"><nobr><span class="ft15"> <br>Three  testbeds  built  in  [21]  were  based  on  the  trec123-100col-<br>bysource testbed. Each testbed contains many "small" databases <br>and  two  large  databases  created  by  merging  about  10-20  small <br>databases together. </span></nobr></DIV>
<DIV style="position:absolute;top:117;left:92"><nobr><span class="ft6"><b>Input:</b></span></nobr></DIV>
<DIV style="position:absolute;top:117;left:129"><nobr><span class="ft5">    Complete lists of probabilities of relevance for all </span></nobr></DIV>
<DIV style="position:absolute;top:132;left:146"><nobr><span class="ft5">the |DB| databases. </span></nobr></DIV>
<DIV style="position:absolute;top:147;left:92"><nobr><span class="ft6"><b>Output:</b></span></nobr></DIV>
<DIV style="position:absolute;top:147;left:139"><nobr><span class="ft5">  Optimal selection solution for Equation 16. </span></nobr></DIV>
<DIV style="position:absolute;top:162;left:92"><nobr><span class="ft14">i)   Create the three-dimensional array:  <br>     Sel (1..|DB|, 1..N</span></nobr></DIV>
<DIV style="position:absolute;top:182;left:202"><nobr><span class="ft9">Total_rdoc/10</span></nobr></DIV>
<DIV style="position:absolute;top:177;left:253"><nobr><span class="ft5">, 1..N</span></nobr></DIV>
<DIV style="position:absolute;top:182;left:283"><nobr><span class="ft9">sdb</span></nobr></DIV>
<DIV style="position:absolute;top:177;left:295"><nobr><span class="ft5">) </span></nobr></DIV>
<DIV style="position:absolute;top:192;left:110"><nobr><span class="ft15">Each  Sel  (x,  y,  z)  is  associated  with  a  selection <br>decision</span></nobr></DIV>
<DIV style="position:absolute;top:213;left:172"><nobr><span class="ft29"><i>xyz</i></span></nobr></DIV>
<DIV style="position:absolute;top:208;left:162"><nobr><span class="ft28"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:204;left:190"><nobr><span class="ft3">,</span></nobr></DIV>
<DIV style="position:absolute;top:207;left:195"><nobr><span class="ft5">  which  represents  the  best  selection </span></nobr></DIV>
<DIV style="position:absolute;top:222;left:110"><nobr><span class="ft15">decision in the condition: only databases from number 1 <br>to  number  x  are  considered  for  selection;  totally  y*10 <br>documents  will  be  retrieved;  only  z  databases  are <br>selected  out  of  the  x  database  candidates.  And               <br>Sel  (x,  y,  z)  is  the  corresponding  utility  value  by <br>choosing the best selection.  </span></nobr></DIV>
<DIV style="position:absolute;top:312;left:92"><nobr><span class="ft5">ii)  Initialize  Sel  (1,  1..N</span></nobr></DIV>
<DIV style="position:absolute;top:317;left:232"><nobr><span class="ft9">Total_rdoc</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:271"><nobr><span class="ft5">/10,  1..N</span></nobr></DIV>
<DIV style="position:absolute;top:317;left:321"><nobr><span class="ft9">sdb</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:333"><nobr><span class="ft5">)  with  only  the </span></nobr></DIV>
<DIV style="position:absolute;top:327;left:109"><nobr><span class="ft5">estimated relevance information of the 1</span></nobr></DIV>
<DIV style="position:absolute;top:324;left:327"><nobr><span class="ft9">st </span></nobr></DIV>
<DIV style="position:absolute;top:327;left:336"><nobr><span class="ft5">database. </span></nobr></DIV>
<DIV style="position:absolute;top:342;left:92"><nobr><span class="ft15">iii) Iterate the current database candidate i from 2 to |DB| <br>     For each entry Sel (i, y, z): <br>     Find k such that: </span></nobr></DIV>
<DIV style="position:absolute;top:430;left:285"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:430;left:272"><nobr><span class="ft5">10</span></nobr></DIV>
<DIV style="position:absolute;top:430;left:269"><nobr><span class="ft5">,</span></nobr></DIV>
<DIV style="position:absolute;top:430;left:237"><nobr><span class="ft5">min(</span></nobr></DIV>
<DIV style="position:absolute;top:430;left:199"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:430;left:195"><nobr><span class="ft5">:</span></nobr></DIV>
<DIV style="position:absolute;top:399;left:388"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:399;left:384"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:399;left:365"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:399;left:317"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:399;left:312"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:399;left:288"><nobr><span class="ft5">,</span></nobr></DIV>
<DIV style="position:absolute;top:399;left:256"><nobr><span class="ft5">,</span></nobr></DIV>
<DIV style="position:absolute;top:399;left:251"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:399;left:230"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:399;left:209"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:399;left:183"><nobr><span class="ft5">max</span></nobr></DIV>
<DIV style="position:absolute;top:399;left:164"><nobr><span class="ft5">arg</span></nobr></DIV>
<DIV style="position:absolute;top:416;left:351"><nobr><span class="ft23">*</span></nobr></DIV>
<DIV style="position:absolute;top:416;left:343"><nobr><span class="ft23">10</span></nobr></DIV>
<DIV style="position:absolute;top:391;left:370"><nobr><span class="ft23">^</span></nobr></DIV>
<DIV style="position:absolute;top:397;left:146"><nobr><span class="ft23">*</span></nobr></DIV>
<DIV style="position:absolute;top:430;left:263"><nobr><span class="ft8"><i>y</i></span></nobr></DIV>
<DIV style="position:absolute;top:430;left:217"><nobr><span class="ft8"><i>k</i></span></nobr></DIV>
<DIV style="position:absolute;top:430;left:182"><nobr><span class="ft8"><i>to</i></span></nobr></DIV>
<DIV style="position:absolute;top:430;left:138"><nobr><span class="ft8"><i>subject</i></span></nobr></DIV>
<DIV style="position:absolute;top:399;left:369"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:399;left:356"><nobr><span class="ft8"><i>R</i></span></nobr></DIV>
<DIV style="position:absolute;top:399;left:294"><nobr><span class="ft8"><i>z</i></span></nobr></DIV>
<DIV style="position:absolute;top:399;left:282"><nobr><span class="ft8"><i>k</i></span></nobr></DIV>
<DIV style="position:absolute;top:399;left:262"><nobr><span class="ft8"><i>y</i></span></nobr></DIV>
<DIV style="position:absolute;top:399;left:235"><nobr><span class="ft8"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:399;left:214"><nobr><span class="ft8"><i>Sel</i></span></nobr></DIV>
<DIV style="position:absolute;top:399;left:138"><nobr><span class="ft8"><i>k</i></span></nobr></DIV>
<DIV style="position:absolute;top:416;left:355"><nobr><span class="ft24"><i>k</i></span></nobr></DIV>
<DIV style="position:absolute;top:416;left:336"><nobr><span class="ft24"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:406;left:377"><nobr><span class="ft24"><i>ij</i></span></nobr></DIV>
<DIV style="position:absolute;top:413;left:183"><nobr><span class="ft24"><i>k</i></span></nobr></DIV>
<DIV style="position:absolute;top:426;left:227"><nobr><span class="ft25"></span></nobr></DIV>
<DIV style="position:absolute;top:426;left:207"><nobr><span class="ft25"></span></nobr></DIV>
<DIV style="position:absolute;top:395;left:325"><nobr><span class="ft25">+</span></nobr></DIV>
<DIV style="position:absolute;top:395;left:303"><nobr><span class="ft25">-</span></nobr></DIV>
<DIV style="position:absolute;top:395;left:271"><nobr><span class="ft25">-</span></nobr></DIV>
<DIV style="position:absolute;top:395;left:242"><nobr><span class="ft25">-</span></nobr></DIV>
<DIV style="position:absolute;top:395;left:154"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:413;left:339"><nobr><span class="ft39"></span></nobr></DIV>
<DIV style="position:absolute;top:401;left:409"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:466;left:402"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:391"><nobr><span class="ft5">,</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:378"><nobr><span class="ft5">,</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:373"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:353"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:318"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:314"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:295"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:245"><nobr><span class="ft5">)</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:240"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:217"><nobr><span class="ft5">,</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:178"><nobr><span class="ft5">,</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:172"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:152"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:131"><nobr><span class="ft5">(</span></nobr></DIV>
<DIV style="position:absolute;top:481;left:287"><nobr><span class="ft34">*</span></nobr></DIV>
<DIV style="position:absolute;top:483;left:279"><nobr><span class="ft23">*</span></nobr></DIV>
<DIV style="position:absolute;top:483;left:271"><nobr><span class="ft23">10</span></nobr></DIV>
<DIV style="position:absolute;top:457;left:300"><nobr><span class="ft23">^</span></nobr></DIV>
<DIV style="position:absolute;top:463;left:211"><nobr><span class="ft23">*</span></nobr></DIV>
<DIV style="position:absolute;top:465;left:397"><nobr><span class="ft8"><i>z</i></span></nobr></DIV>
<DIV style="position:absolute;top:465;left:385"><nobr><span class="ft8"><i>y</i></span></nobr></DIV>
<DIV style="position:absolute;top:465;left:357"><nobr><span class="ft8"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:465;left:336"><nobr><span class="ft8"><i>Sel</i></span></nobr></DIV>
<DIV style="position:absolute;top:465;left:300"><nobr><span class="ft8"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:465;left:286"><nobr><span class="ft8"><i>R</i></span></nobr></DIV>
<DIV style="position:absolute;top:465;left:222"><nobr><span class="ft8"><i>z</i></span></nobr></DIV>
<DIV style="position:absolute;top:465;left:204"><nobr><span class="ft8"><i>k</i></span></nobr></DIV>
<DIV style="position:absolute;top:465;left:184"><nobr><span class="ft8"><i>y</i></span></nobr></DIV>
<DIV style="position:absolute;top:465;left:157"><nobr><span class="ft8"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:465;left:136"><nobr><span class="ft8"><i>Sel</i></span></nobr></DIV>
<DIV style="position:absolute;top:465;left:117"><nobr><span class="ft8"><i>If</i></span></nobr></DIV>
<DIV style="position:absolute;top:483;left:283"><nobr><span class="ft24"><i>k</i></span></nobr></DIV>
<DIV style="position:absolute;top:483;left:265"><nobr><span class="ft24"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:472;left:307"><nobr><span class="ft24"><i>ij</i></span></nobr></DIV>
<DIV style="position:absolute;top:461;left:364"><nobr><span class="ft25">-</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:326"><nobr><span class="ft25">&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:253"><nobr><span class="ft25">+</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:231"><nobr><span class="ft25">-</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:194"><nobr><span class="ft25">-</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:164"><nobr><span class="ft25">-</span></nobr></DIV>
<DIV style="position:absolute;top:480;left:267"><nobr><span class="ft39"></span></nobr></DIV>
<DIV style="position:absolute;top:480;left:409"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:495;left:113"><nobr><span class="ft5">This  means  that  we  should  retrieve </span></nobr></DIV>
<DIV style="position:absolute;top:495;left:352"><nobr><span class="ft23">*</span></nobr></DIV>
<DIV style="position:absolute;top:497;left:325"><nobr><span class="ft10">10 <i>k</i></span></nobr></DIV>
<DIV style="position:absolute;top:493;left:338"><nobr><span class="ft42"></span></nobr></DIV>
<DIV style="position:absolute;top:495;left:359"><nobr><span class="ft5"> documents </span></nobr></DIV>
<DIV style="position:absolute;top:510;left:113"><nobr><span class="ft5">from the i</span></nobr></DIV>
<DIV style="position:absolute;top:507;left:167"><nobr><span class="ft9">th</span></nobr></DIV>
<DIV style="position:absolute;top:510;left:174"><nobr><span class="ft5"> database, otherwise we should not select this </span></nobr></DIV>
<DIV style="position:absolute;top:525;left:113"><nobr><span class="ft14">database  and  the  previous  best  solution  Sel  (i-1,  y,  z) <br>should be kept.  <br>Then set the value of </span></nobr></DIV>
<DIV style="position:absolute;top:561;left:241"><nobr><span class="ft29"><i>iyz</i></span></nobr></DIV>
<DIV style="position:absolute;top:556;left:232"><nobr><span class="ft28"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:555;left:253"><nobr><span class="ft5"> and Sel (i, y, z) accordingly. </span></nobr></DIV>
<DIV style="position:absolute;top:570;left:92"><nobr><span class="ft5">iv)  The  best  selection  solution  is  given  by </span></nobr></DIV>
<DIV style="position:absolute;top:580;left:377"><nobr><span class="ft34">_</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:393"><nobr><span class="ft34">/10</span></nobr></DIV>
<DIV style="position:absolute;top:576;left:341"><nobr><span class="ft27">|</span></nobr></DIV>
<DIV style="position:absolute;top:576;left:354"><nobr><span class="ft27">|</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:362"><nobr><span class="ft31"><i>Toral</i></span></nobr></DIV>
<DIV style="position:absolute;top:580;left:381"><nobr><span class="ft31"><i>rdoc</i></span></nobr></DIV>
<DIV style="position:absolute;top:580;left:408"><nobr><span class="ft31"><i>sdb</i></span></nobr></DIV>
<DIV style="position:absolute;top:576;left:343"><nobr><span class="ft29"><i>DB N</i></span></nobr></DIV>
<DIV style="position:absolute;top:576;left:402"><nobr><span class="ft29"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:571;left:332"><nobr><span class="ft28"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:570;left:421"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:585;left:113"><nobr><span class="ft14">and  the  corresponding  utility  value  is  Sel  (|DB|, <br>N</span></nobr></DIV>
<DIV style="position:absolute;top:605;left:123"><nobr><span class="ft9">Total_rdoc/10</span></nobr></DIV>
<DIV style="position:absolute;top:600;left:174"><nobr><span class="ft5">, N</span></nobr></DIV>
<DIV style="position:absolute;top:605;left:190"><nobr><span class="ft9">sdb</span></nobr></DIV>
<DIV style="position:absolute;top:600;left:203"><nobr><span class="ft5">).     </span></nobr></DIV>
<DIV style="position:absolute;top:624;left:92"><nobr><span class="ft6"><b>Figure  2.</b></span></nobr></DIV>
<DIV style="position:absolute;top:624;left:155"><nobr><span class="ft5">  The  dynamic  programming  optimization </span></nobr></DIV>
<DIV style="position:absolute;top:639;left:92"><nobr><span class="ft5">procedure for Equation 16. </span></nobr></DIV>
<DIV style="position:absolute;top:655;left:92"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:117;left:588"><nobr><span class="ft6"><b>Table1:</b></span></nobr></DIV>
<DIV style="position:absolute;top:116;left:632"><nobr><span class="ft5">  Testbed statistics. </span></nobr></DIV>
<DIV style="position:absolute;top:146;left:590"><nobr><span class="ft6"><b>Number of documents </b></span></nobr></DIV>
<DIV style="position:absolute;top:146;left:757"><nobr><span class="ft6"><b>Size  (MB) </b></span></nobr></DIV>
<DIV style="position:absolute;top:149;left:506"><nobr><span class="ft6"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:165;left:483"><nobr><span class="ft6"><b>Testbed </b></span></nobr></DIV>
<DIV style="position:absolute;top:149;left:548"><nobr><span class="ft6"><b>Size </b></span></nobr></DIV>
<DIV style="position:absolute;top:165;left:545"><nobr><span class="ft6"><b>(GB) </b></span></nobr></DIV>
<DIV style="position:absolute;top:171;left:591"><nobr><span class="ft6"><b>Min </b></span></nobr></DIV>
<DIV style="position:absolute;top:171;left:637"><nobr><span class="ft6"><b>Avg </b></span></nobr></DIV>
<DIV style="position:absolute;top:171;left:687"><nobr><span class="ft6"><b>Max </b></span></nobr></DIV>
<DIV style="position:absolute;top:171;left:734"><nobr><span class="ft6"><b>Min </b></span></nobr></DIV>
<DIV style="position:absolute;top:171;left:775"><nobr><span class="ft6"><b>Avg </b></span></nobr></DIV>
<DIV style="position:absolute;top:171;left:814"><nobr><span class="ft6"><b>Max </b></span></nobr></DIV>
<DIV style="position:absolute;top:190;left:483"><nobr><span class="ft5">Trec123 </span></nobr></DIV>
<DIV style="position:absolute;top:190;left:551"><nobr><span class="ft5">3.2 </span></nobr></DIV>
<DIV style="position:absolute;top:190;left:592"><nobr><span class="ft5">752 </span></nobr></DIV>
<DIV style="position:absolute;top:190;left:632"><nobr><span class="ft5">10782 </span></nobr></DIV>
<DIV style="position:absolute;top:190;left:683"><nobr><span class="ft5">39713 </span></nobr></DIV>
<DIV style="position:absolute;top:190;left:740"><nobr><span class="ft5">28 </span></nobr></DIV>
<DIV style="position:absolute;top:190;left:779"><nobr><span class="ft5">32 </span></nobr></DIV>
<DIV style="position:absolute;top:190;left:820"><nobr><span class="ft5">42 </span></nobr></DIV>
<DIV style="position:absolute;top:207;left:483"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:215;left:497"><nobr><span class="ft6"><b>                         Table2:</b></span></nobr></DIV>
<DIV style="position:absolute;top:215;left:626"><nobr><span class="ft5">  Query set statistics. </span></nobr></DIV>
<DIV style="position:absolute;top:240;left:531"><nobr><span class="ft6"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:255;left:514"><nobr><span class="ft6"><b>Name </b></span></nobr></DIV>
<DIV style="position:absolute;top:240;left:578"><nobr><span class="ft6"><b>TREC </b></span></nobr></DIV>
<DIV style="position:absolute;top:255;left:570"><nobr><span class="ft6"><b>Topic Set </b></span></nobr></DIV>
<DIV style="position:absolute;top:240;left:654"><nobr><span class="ft6"><b>TREC </b></span></nobr></DIV>
<DIV style="position:absolute;top:255;left:640"><nobr><span class="ft6"><b>Topic Field </b></span></nobr></DIV>
<DIV style="position:absolute;top:240;left:722"><nobr><span class="ft6"><b>Average Length  </b></span></nobr></DIV>
<DIV style="position:absolute;top:255;left:744"><nobr><span class="ft6"><b>(Words) </b></span></nobr></DIV>
<DIV style="position:absolute;top:271;left:509"><nobr><span class="ft5">Trec123 </span></nobr></DIV>
<DIV style="position:absolute;top:271;left:578"><nobr><span class="ft5">51-150 </span></nobr></DIV>
<DIV style="position:absolute;top:271;left:660"><nobr><span class="ft5">Title </span></nobr></DIV>
<DIV style="position:absolute;top:271;left:760"><nobr><span class="ft5">3.1 </span></nobr></DIV>
<DIV style="position:absolute;top:287;left:497"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:1116;left:452"><nobr><span class="ft5">37</span></nobr></DIV>
</DIV>
<!-- Page 7 -->
<a name="7"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft45{font-size:16px;font-family:Times;color:#000000;}
	.ft46{font-size:8px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="204007.png" alt="background image">
<DIV style="position:absolute;top:557;left:81"><nobr><span class="ft6"><b>Trec123-2ldb-60col  ("representative"): </b></span></nobr></DIV>
<DIV style="position:absolute;top:556;left:315"><nobr><span class="ft5">The  databases  in  the </span></nobr></DIV>
<DIV style="position:absolute;top:571;left:81"><nobr><span class="ft14">trec123-100col-bysource  were  sorted  with  alphabetical  order. <br>Two  large  databases  were  created  by  merging  20  small <br>databases  with  the  round-robin  method.  Thus,  the  two  large <br>databases have more relevant documents due to their large sizes, <br>even though the densities of relevant documents are roughly the <br>same as the small databases. <br> <br><b>Trec123-AP-WSJ-60col ("relevant"): </b></span></nobr></DIV>
<DIV style="position:absolute;top:676;left:299"><nobr><span class="ft5">The 24 Associated Press </span></nobr></DIV>
<DIV style="position:absolute;top:691;left:81"><nobr><span class="ft14">collections  and  the  16  Wall  Street  Journal  collections  in  the <br>trec123-100col-bysource  testbed  were  collapsed  into  two  large <br>databases  APall  and  WSJall.  The  other 60  collections  were  left <br>unchanged.  The  APall  and  WSJall  databases  have  higher <br>densities of documents relevant to TREC queries than the small <br>databases.  Thus,  the  two  large  databases  have  many  more <br>relevant documents than the small databases. <br> <br><b>Trec123-FR-DOE-81col  ("nonrelevant"): </b></span></nobr></DIV>
<DIV style="position:absolute;top:811;left:336"><nobr><span class="ft5">The  13  Federal </span></nobr></DIV>
<DIV style="position:absolute;top:826;left:81"><nobr><span class="ft14">Register collections and the 6 Department of Energy collections <br>in  the  trec123-100col-bysource  testbed  were  collapsed  into  two <br>large databases FRall and DOEall. The other 80 collections were <br>left  unchanged.  The  FRall  and  DOEall  databases  have  lower <br>densities of documents relevant to TREC queries than the small <br>databases, even though they are much larger. <br> <br>100  queries  were  created  from  the  title  fields  of  TREC  topics <br>51-150.  The  queries  101-150  were  used  as  training  queries  and <br>the queries 51-100 were used as test queries (details in Table 2). <br> <br> </span></nobr></DIV>
<DIV style="position:absolute;top:1003;left:81"><nobr><span class="ft45"><i>4.2 Search Engines</i></span></nobr></DIV>
<DIV style="position:absolute;top:1006;left:220"><nobr><span class="ft8"><i> </i></span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:81"><nobr><span class="ft5">In </span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:109"><nobr><span class="ft5">the </span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:141"><nobr><span class="ft5">uncooperative </span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:233"><nobr><span class="ft5">distributed </span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:307"><nobr><span class="ft5">information </span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:387"><nobr><span class="ft5">retrieval </span></nobr></DIV>
<DIV style="position:absolute;top:1036;left:81"><nobr><span class="ft15">environments  of  large  organizations  (companies)  or  domain-<br>specific hidden Web, different databases may use different types <br>of  search  engine.  To  simulate  the  multiple  type-engine </span></nobr></DIV>
<DIV style="position:absolute;top:111;left:486"><nobr><span class="ft15">environment,  three  different  types  of  search  engines  were  used <br>in  the  experiments:  INQUERY  [2],  a  unigram  statistical <br>language  model  with  linear  smoothing  [12,20]  and  a  TFIDF <br>retrieval  algorithm  with  "ltc"  weight  [12,20].  All  these <br>algorithms  were  implemented  with  the  Lemur  toolkit  [12]. <br>These  three  kinds  of  search  engines  were  assigned  to  the <br>databases among the four testbeds in a round-robin manner. </span></nobr></DIV>
<DIV style="position:absolute;top:235;left:486"><nobr><span class="ft16"><b>5. RESULTS: RESOURCE SELECTION OF <br>DATABASE RECOMMENDATION  </b></span></nobr></DIV>
<DIV style="position:absolute;top:280;left:486"><nobr><span class="ft41">All  four  testbeds  described  in  Section  4  were  used  in  the <br>experiments  to  evaluate  the  resource  selection  effectiveness  of <br>the database recommendation system. <br> <br>The  resource  descriptions  were  created  using  query-based <br>sampling.  About  80  queries  were  sent  to  each  database  to <br>download  300  unique  documents.  The  database  size  statistics <br>were  estimated  by  the  sample-resample  method  [21].  Fifty <br>queries  (101-150)  were  used  as  training  queries  to  build  the <br>relevant logistic model and to fit the exponential functions of the <br>centralized  document  score  curves  for  large  ratio  databases <br>(details in Section 3.1). Another 50 queries (51-100) were used <br>as test data. <br> <br>Resource  selection  algorithms  of  database  recommendation <br>systems  are  typically  compared  using  the  recall  metric </span></nobr></DIV>
<DIV style="position:absolute;top:512;left:829"><nobr><span class="ft46"><i>n</i></span></nobr></DIV>
<DIV style="position:absolute;top:507;left:821"><nobr><span class="ft8"><i>R </i> </span></nobr></DIV>
<DIV style="position:absolute;top:526;left:486"><nobr><span class="ft14">[1,17,18,21]. Let B denote a baseline ranking, which is often the <br>RBR (relevance based ranking), and E as a ranking provided by <br>a  resource  selection  algorithm.  And  let  B</span></nobr></DIV>
<DIV style="position:absolute;top:563;left:726"><nobr><span class="ft9">i</span></nobr></DIV>
<DIV style="position:absolute;top:557;left:728"><nobr><span class="ft5">  and  E</span></nobr></DIV>
<DIV style="position:absolute;top:563;left:769"><nobr><span class="ft9">i</span></nobr></DIV>
<DIV style="position:absolute;top:557;left:771"><nobr><span class="ft5">  denote  the </span></nobr></DIV>
<DIV style="position:absolute;top:573;left:486"><nobr><span class="ft5">number of relevant documents in the i</span></nobr></DIV>
<DIV style="position:absolute;top:570;left:695"><nobr><span class="ft9">th</span></nobr></DIV>
<DIV style="position:absolute;top:573;left:702"><nobr><span class="ft5"> ranked database of B or </span></nobr></DIV>
<DIV style="position:absolute;top:588;left:486"><nobr><span class="ft5">E. Then R</span></nobr></DIV>
<DIV style="position:absolute;top:594;left:541"><nobr><span class="ft9">n</span></nobr></DIV>
<DIV style="position:absolute;top:588;left:546"><nobr><span class="ft5"> is defined as follows: </span></nobr></DIV>
<DIV style="position:absolute;top:604;left:486"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:661;left:649"><nobr><span class="ft37">=</span></nobr></DIV>
<DIV style="position:absolute;top:635;left:648"><nobr><span class="ft37">=</span></nobr></DIV>
<DIV style="position:absolute;top:636;left:618"><nobr><span class="ft25">=</span></nobr></DIV>
<DIV style="position:absolute;top:650;left:646"><nobr><span class="ft29"><i>k</i></span></nobr></DIV>
<DIV style="position:absolute;top:664;left:645"><nobr><span class="ft29"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:662;left:668"><nobr><span class="ft29"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:624;left:645"><nobr><span class="ft29"><i>k</i></span></nobr></DIV>
<DIV style="position:absolute;top:638;left:645"><nobr><span class="ft29"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:636;left:668"><nobr><span class="ft29"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:648;left:608"><nobr><span class="ft29"><i>k</i></span></nobr></DIV>
<DIV style="position:absolute;top:654;left:659"><nobr><span class="ft8"><i>B</i></span></nobr></DIV>
<DIV style="position:absolute;top:628;left:659"><nobr><span class="ft8"><i>E</i></span></nobr></DIV>
<DIV style="position:absolute;top:640;left:599"><nobr><span class="ft8"><i>R</i></span></nobr></DIV>
<DIV style="position:absolute;top:664;left:653"><nobr><span class="ft27">1</span></nobr></DIV>
<DIV style="position:absolute;top:638;left:653"><nobr><span class="ft27">1</span></nobr></DIV>
<DIV style="position:absolute;top:630;left:676"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:641;left:805"><nobr><span class="ft5">(17) </span></nobr></DIV>
<DIV style="position:absolute;top:679;left:486"><nobr><span class="ft14">Usually the goal is to search only a few databases, so our figures <br>only show results for selecting up to 20 databases.  <br> <br>The  experiments  summarized  in  Figure  3  compared  the <br>effectiveness of the three resource selection algorithms, namely <br>the  CORI,  ReDDE  and  UUM/HR.  The  UUM/HR  algorithm  is <br>described  in  Section  3.3.  It  can  be  seen  from  Figure  3  that  the <br>ReDDE  and  UUM/HR  algorithms  are  more  effective  (on  the <br>representative,  relevant  and  nonrelevant  testbeds) or  as  good  as <br>(on  the  Trec123-100Col  testbed)  the  CORI  resource  selection <br>algorithm.  The  UUM/HR  algorithm  is  more  effective  than  the <br>ReDDE  algorithm  on  the  representative  and  relevant  testbeds <br>and is about the same as the ReDDE algorithm on the Trec123-<br>100Col  and  the  nonrelevant  testbeds.  This  suggests  that  the <br>UUM/HR algorithm is more robust than the ReDDE algorithm. <br>It can be noted that when selecting only a few databases on the <br>Trec123-100Col  or  the  nonrelevant  testbeds,  the  ReDEE <br>algorithm  has  a  small  advantage  over  the  UUM/HR  algorithm. <br>We  attribute  this  to  two  causes:  i)  The  ReDDE  algorithm  was <br>tuned  on  the  Trec123-100Col  testbed;  and  ii)  Although  the <br>difference  is  small,  this  may  suggest  that  our  logistic  model  of <br>estimating  probabilities  of  relevance  is  not  accurate  enough. <br>More  training  data  or  a  more  sophisticated  model  may  help  to <br>solve this minor puzzle. </span></nobr></DIV>
<DIV style="position:absolute;top:269;left:443"><nobr><span class="ft5">      </span></nobr></DIV>
<DIV style="position:absolute;top:281;left:56"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:281;left:110"><nobr><span class="ft5">Collections Selected.                         Collections Selected. </span></nobr></DIV>
<DIV style="position:absolute;top:297;left:56"><nobr><span class="ft5">              Trec123-100Col Testbed.                  Representative Testbed. </span></nobr></DIV>
<DIV style="position:absolute;top:479;left:444"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:491;left:56"><nobr><span class="ft14">                 Collection Selected.                          Collection Selected. <br>                   Relevant Testbed.                           Nonrelevant Testbed.   </span></nobr></DIV>
<DIV style="position:absolute;top:523;left:77"><nobr><span class="ft6"><b>Figure 3. </b></span></nobr></DIV>
<DIV style="position:absolute;top:523;left:133"><nobr><span class="ft5">Resource selection experiments on the four testbeds. </span></nobr></DIV>
<DIV style="position:absolute;top:1116;left:452"><nobr><span class="ft5">38</span></nobr></DIV>
</DIV>
<!-- Page 8 -->
<a name="8"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft47{font-size:2px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="204008.png" alt="background image">
<DIV style="position:absolute;top:808;left:81"><nobr><span class="ft16"><b>6. RESULTS: DOCUMENT RETRIEVAL <br>EFFECTIVENESS </b></span></nobr></DIV>
<DIV style="position:absolute;top:853;left:81"><nobr><span class="ft14">For document retrieval, the selected databases are searched and <br>the  returned  results  are  merged  into  a  single  final  list.  In  all  of <br>the  experiments  discussed  in  this  section  the  results  retrieved <br>from  individual  databases  were  combined  by  the  semi-<br>supervised  learning  results  merging  algorithm.  This  version  of <br>the SSL algorithm [22] is allowed to download a small number <br>of  returned  document  texts  "on  the  fly"  to  create  additional <br>training data in the process of learning the linear models which <br>map  database-specific  document  scores  into  estimated <br>centralized  document  scores.  It  has  been  shown  to  be  very <br>effective  in  environments  where  only  short  result-lists  are <br>retrieved  from  each  selected  database  [22].  This  is  a  common <br>scenario  in  operational  environments  and  was  the  case  for  our <br>experiments. </span></nobr></DIV>
<DIV style="position:absolute;top:789;left:486"><nobr><span class="ft14"> <br>Document  retrieval  effectiveness  was  measured  by  Precision  at <br>the  top  part  of  the  final  document  list.  The  experiments  in  this <br>section  were  conducted  to  study  the  document  retrieval <br>effectiveness  of  five  selection  algorithms,  namely  the  CORI, <br>ReDDE, UUM/HR, UUM/HP-FL and UUM/HP-VL algorithms. <br>The  last  three  algorithms  were  proposed  in  Section  3.  All  the <br>first four algorithms selected 3 or 5 databases, and 50 documents <br>were  retrieved  from  each  selected  database.  The  UUM/HP-FL <br>algorithm  also  selected  3  or  5  databases,  but  it  was  allowed  to <br>adjust  the  number  of  documents  to  retrieve  from  each  selected <br>database; the number retrieved was constrained to be from 10 to <br>100, and a multiple of 10.  <br> <br>The  Trec123-100Col  and  representative  testbeds  were  selected <br>for  document  retrieval  as  they  represent  two  extreme  cases  of <br>resource selection effectiveness; in one case the CORI algorithm <br>is as good as the other algorithms and in the other case it is quite </span></nobr></DIV>
<DIV style="position:absolute;top:456;left:106"><nobr><span class="ft6"><b>Table 5. </b></span></nobr></DIV>
<DIV style="position:absolute;top:456;left:156"><nobr><span class="ft5">Precision on the representative testbed when 3 databases were selected. (The first baseline is CORI; the second baseline for </span></nobr></DIV>
<DIV style="position:absolute;top:474;left:374"><nobr><span class="ft5">UUM/HP methods is UUM/HR.) </span></nobr></DIV>
<DIV style="position:absolute;top:496;left:118"><nobr><span class="ft6"><b>Precision at </b></span></nobr></DIV>
<DIV style="position:absolute;top:512;left:124"><nobr><span class="ft6"><b>Doc Rank </b></span></nobr></DIV>
<DIV style="position:absolute;top:504;left:214"><nobr><span class="ft6"><b>CORI </b></span></nobr></DIV>
<DIV style="position:absolute;top:504;left:298"><nobr><span class="ft6"><b>ReDDE </b></span></nobr></DIV>
<DIV style="position:absolute;top:504;left:408"><nobr><span class="ft6"><b>UUM/HR </b></span></nobr></DIV>
<DIV style="position:absolute;top:504;left:540"><nobr><span class="ft6"><b>UUM/HP-FL </b></span></nobr></DIV>
<DIV style="position:absolute;top:504;left:702"><nobr><span class="ft6"><b>UUM/HP-VL </b></span></nobr></DIV>
<DIV style="position:absolute;top:528;left:135"><nobr><span class="ft5">5 docs </span></nobr></DIV>
<DIV style="position:absolute;top:528;left:213"><nobr><span class="ft5">0.3720 </span></nobr></DIV>
<DIV style="position:absolute;top:528;left:277"><nobr><span class="ft5">0.4080 (+9.7%) </span></nobr></DIV>
<DIV style="position:absolute;top:528;left:390"><nobr><span class="ft5">0.4640 (+24.7%)  </span></nobr></DIV>
<DIV style="position:absolute;top:528;left:511"><nobr><span class="ft5">0.4600 (+23.7%)(-0.9%) </span></nobr></DIV>
<DIV style="position:absolute;top:528;left:673"><nobr><span class="ft5">0.5000 (+34.4%)(+7.8%) </span></nobr></DIV>
<DIV style="position:absolute;top:544;left:131"><nobr><span class="ft5">10 docs </span></nobr></DIV>
<DIV style="position:absolute;top:544;left:213"><nobr><span class="ft5">0.3400 </span></nobr></DIV>
<DIV style="position:absolute;top:544;left:274"><nobr><span class="ft5">0.4060 (+19.4%) </span></nobr></DIV>
<DIV style="position:absolute;top:544;left:390"><nobr><span class="ft5">0.4600 (+35.3%)  </span></nobr></DIV>
<DIV style="position:absolute;top:544;left:511"><nobr><span class="ft5">0.4540 (+33.5%)(-1.3%) </span></nobr></DIV>
<DIV style="position:absolute;top:544;left:673"><nobr><span class="ft5">0.4640 (+36.5%)(+0.9%) </span></nobr></DIV>
<DIV style="position:absolute;top:561;left:131"><nobr><span class="ft5">15 docs </span></nobr></DIV>
<DIV style="position:absolute;top:561;left:213"><nobr><span class="ft5">0.3120 </span></nobr></DIV>
<DIV style="position:absolute;top:561;left:274"><nobr><span class="ft5">0.3880 (+24.4%) </span></nobr></DIV>
<DIV style="position:absolute;top:561;left:390"><nobr><span class="ft5">0.4320 (+38.5%)  </span></nobr></DIV>
<DIV style="position:absolute;top:561;left:511"><nobr><span class="ft5">0.4240 (+35.9%)(-1.9%) </span></nobr></DIV>
<DIV style="position:absolute;top:561;left:679"><nobr><span class="ft5">0.4413 (+41.4%)(+2.2) </span></nobr></DIV>
<DIV style="position:absolute;top:578;left:131"><nobr><span class="ft5">20 docs </span></nobr></DIV>
<DIV style="position:absolute;top:578;left:213"><nobr><span class="ft5">0.3000 </span></nobr></DIV>
<DIV style="position:absolute;top:578;left:274"><nobr><span class="ft5">0.3750 (+25.0%) </span></nobr></DIV>
<DIV style="position:absolute;top:578;left:390"><nobr><span class="ft5">0.4080 (+36.0%) </span></nobr></DIV>
<DIV style="position:absolute;top:578;left:511"><nobr><span class="ft5">0.4040 (+34.7%)(-1.0%) </span></nobr></DIV>
<DIV style="position:absolute;top:578;left:673"><nobr><span class="ft5">0.4240 (+41.3%)(+4.0%) </span></nobr></DIV>
<DIV style="position:absolute;top:594;left:131"><nobr><span class="ft5">30 docs </span></nobr></DIV>
<DIV style="position:absolute;top:594;left:213"><nobr><span class="ft5">0.2533 </span></nobr></DIV>
<DIV style="position:absolute;top:594;left:274"><nobr><span class="ft5">0.3440 (+35.8%) </span></nobr></DIV>
<DIV style="position:absolute;top:594;left:390"><nobr><span class="ft5">0.3847 (+51.9%) </span></nobr></DIV>
<DIV style="position:absolute;top:594;left:511"><nobr><span class="ft5">0.3747 (+47.9%)(-2.6%) </span></nobr></DIV>
<DIV style="position:absolute;top:594;left:673"><nobr><span class="ft5">0.3887 (+53.5%)(+1.0%) </span></nobr></DIV>
<DIV style="position:absolute;top:613;left:105"><nobr><span class="ft47"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:623;left:106"><nobr><span class="ft6"><b>Table 6. </b></span></nobr></DIV>
<DIV style="position:absolute;top:623;left:156"><nobr><span class="ft5">Precision on the representative testbed when 5 databases were selected. (The first baseline is CORI; the second baseline for </span></nobr></DIV>
<DIV style="position:absolute;top:641;left:374"><nobr><span class="ft5">UUM/HP methods is UUM/HR.) </span></nobr></DIV>
<DIV style="position:absolute;top:663;left:116"><nobr><span class="ft5"> <b>Precision at </b></span></nobr></DIV>
<DIV style="position:absolute;top:678;left:123"><nobr><span class="ft6"><b>Doc Rank </b></span></nobr></DIV>
<DIV style="position:absolute;top:670;left:214"><nobr><span class="ft6"><b>CORI </b></span></nobr></DIV>
<DIV style="position:absolute;top:670;left:297"><nobr><span class="ft6"><b>ReDDE </b></span></nobr></DIV>
<DIV style="position:absolute;top:670;left:407"><nobr><span class="ft6"><b>UUM/HR </b></span></nobr></DIV>
<DIV style="position:absolute;top:670;left:538"><nobr><span class="ft6"><b>UUM/HP-FL </b></span></nobr></DIV>
<DIV style="position:absolute;top:670;left:702"><nobr><span class="ft6"><b>UUM/HP-VL </b></span></nobr></DIV>
<DIV style="position:absolute;top:694;left:134"><nobr><span class="ft5">5 docs </span></nobr></DIV>
<DIV style="position:absolute;top:694;left:213"><nobr><span class="ft5">0.3960 </span></nobr></DIV>
<DIV style="position:absolute;top:694;left:276"><nobr><span class="ft5">0.4080 (+3.0%) </span></nobr></DIV>
<DIV style="position:absolute;top:694;left:389"><nobr><span class="ft5">0.4560 (+15.2%)  </span></nobr></DIV>
<DIV style="position:absolute;top:694;left:513"><nobr><span class="ft5">0.4280 (+8.1%)(-6.1%) </span></nobr></DIV>
<DIV style="position:absolute;top:694;left:674"><nobr><span class="ft5">0.4520 (+14.1%)(-0.9%) </span></nobr></DIV>
<DIV style="position:absolute;top:711;left:131"><nobr><span class="ft5">10 docs </span></nobr></DIV>
<DIV style="position:absolute;top:711;left:213"><nobr><span class="ft5">0.3880 </span></nobr></DIV>
<DIV style="position:absolute;top:711;left:276"><nobr><span class="ft5">0.4060 (+4.6%) </span></nobr></DIV>
<DIV style="position:absolute;top:711;left:389"><nobr><span class="ft5">0.4280 (+10.3%)  </span></nobr></DIV>
<DIV style="position:absolute;top:711;left:508"><nobr><span class="ft5">0.4460 (+15.0%)(+4.2%) </span></nobr></DIV>
<DIV style="position:absolute;top:711;left:672"><nobr><span class="ft5">0.4560 (+17.5%)(+6.5%) </span></nobr></DIV>
<DIV style="position:absolute;top:728;left:131"><nobr><span class="ft5">15 docs </span></nobr></DIV>
<DIV style="position:absolute;top:728;left:213"><nobr><span class="ft5">0.3533 </span></nobr></DIV>
<DIV style="position:absolute;top:728;left:273"><nobr><span class="ft5">0.3987 (+12.9%) </span></nobr></DIV>
<DIV style="position:absolute;top:728;left:389"><nobr><span class="ft5">0.4227 (+19.6%)  </span></nobr></DIV>
<DIV style="position:absolute;top:728;left:508"><nobr><span class="ft5">0.4440 (+25.7%)(+5.0%) </span></nobr></DIV>
<DIV style="position:absolute;top:728;left:672"><nobr><span class="ft5">0.4453 (+26.0%)(+5.4%) </span></nobr></DIV>
<DIV style="position:absolute;top:744;left:131"><nobr><span class="ft5">20 docs </span></nobr></DIV>
<DIV style="position:absolute;top:744;left:213"><nobr><span class="ft5">0.3330 </span></nobr></DIV>
<DIV style="position:absolute;top:744;left:273"><nobr><span class="ft5">0.3960 (+18.9%) </span></nobr></DIV>
<DIV style="position:absolute;top:744;left:389"><nobr><span class="ft5">0.4140 (+24.3%) </span></nobr></DIV>
<DIV style="position:absolute;top:744;left:508"><nobr><span class="ft5">0.4290 (+28.8%)(+3.6%) </span></nobr></DIV>
<DIV style="position:absolute;top:744;left:672"><nobr><span class="ft5">0.4350 (+30.6%)(+5.1%) </span></nobr></DIV>
<DIV style="position:absolute;top:761;left:131"><nobr><span class="ft5">30 docs </span></nobr></DIV>
<DIV style="position:absolute;top:761;left:213"><nobr><span class="ft5">0.2967 </span></nobr></DIV>
<DIV style="position:absolute;top:761;left:273"><nobr><span class="ft5">0.3740 (+26.1%) </span></nobr></DIV>
<DIV style="position:absolute;top:761;left:389"><nobr><span class="ft5">0.4013 (+35.3%) </span></nobr></DIV>
<DIV style="position:absolute;top:761;left:510"><nobr><span class="ft5">0.3987 (+34.4%)(-0.7%) </span></nobr></DIV>
<DIV style="position:absolute;top:761;left:672"><nobr><span class="ft5">0.4060 (+36.8%)(+1.2%) </span></nobr></DIV>
<DIV style="position:absolute;top:783;left:105"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:119;left:110"><nobr><span class="ft6"><b>Table 3. </b></span></nobr></DIV>
<DIV style="position:absolute;top:119;left:159"><nobr><span class="ft5">Precision on the trec123-100col-bysource testbed when 3 databases were selected. (The first baseline is CORI; the second </span></nobr></DIV>
<DIV style="position:absolute;top:137;left:341"><nobr><span class="ft5">baseline for UUM/HP methods is UUM/HR.) </span></nobr></DIV>
<DIV style="position:absolute;top:159;left:112"><nobr><span class="ft6"><b>Precision at </b></span></nobr></DIV>
<DIV style="position:absolute;top:174;left:117"><nobr><span class="ft6"><b>Doc Rank </b></span></nobr></DIV>
<DIV style="position:absolute;top:166;left:208"><nobr><span class="ft6"><b>CORI </b></span></nobr></DIV>
<DIV style="position:absolute;top:166;left:294"><nobr><span class="ft6"><b>ReDDE </b></span></nobr></DIV>
<DIV style="position:absolute;top:166;left:408"><nobr><span class="ft6"><b>UUM/HR </b></span></nobr></DIV>
<DIV style="position:absolute;top:166;left:539"><nobr><span class="ft6"><b>UUM/HP-FL </b></span></nobr></DIV>
<DIV style="position:absolute;top:166;left:705"><nobr><span class="ft6"><b>UUM/HP-VL </b></span></nobr></DIV>
<DIV style="position:absolute;top:190;left:128"><nobr><span class="ft5">5 docs </span></nobr></DIV>
<DIV style="position:absolute;top:190;left:207"><nobr><span class="ft5">0.3640 </span></nobr></DIV>
<DIV style="position:absolute;top:190;left:275"><nobr><span class="ft5">0.3480 (-4.4%) </span></nobr></DIV>
<DIV style="position:absolute;top:190;left:393"><nobr><span class="ft5">0.3960 (+8.8%)  </span></nobr></DIV>
<DIV style="position:absolute;top:190;left:506"><nobr><span class="ft5">0.4680 (+28.6%)(+18.1%) </span></nobr></DIV>
<DIV style="position:absolute;top:190;left:672"><nobr><span class="ft5">0.4640 (+27.5%)(+17.2%) </span></nobr></DIV>
<DIV style="position:absolute;top:207;left:125"><nobr><span class="ft5">10 docs </span></nobr></DIV>
<DIV style="position:absolute;top:207;left:207"><nobr><span class="ft5">0.3360 </span></nobr></DIV>
<DIV style="position:absolute;top:207;left:275"><nobr><span class="ft5">0.3200 (-4.8%) </span></nobr></DIV>
<DIV style="position:absolute;top:207;left:393"><nobr><span class="ft5">0.3520 (+4.8%)  </span></nobr></DIV>
<DIV style="position:absolute;top:207;left:506"><nobr><span class="ft5">0.4240 (+26.2%)(+20.5%) </span></nobr></DIV>
<DIV style="position:absolute;top:207;left:672"><nobr><span class="ft5">0.4220 (+25.6%)(+19.9%) </span></nobr></DIV>
<DIV style="position:absolute;top:224;left:125"><nobr><span class="ft5">15 docs </span></nobr></DIV>
<DIV style="position:absolute;top:224;left:207"><nobr><span class="ft5">0.3253 </span></nobr></DIV>
<DIV style="position:absolute;top:224;left:275"><nobr><span class="ft5">0.3187 (-2.0%) </span></nobr></DIV>
<DIV style="position:absolute;top:224;left:393"><nobr><span class="ft5">0.3347 (+2.9%)  </span></nobr></DIV>
<DIV style="position:absolute;top:224;left:506"><nobr><span class="ft5">0.3973 (+22.2%)(+15.7%) </span></nobr></DIV>
<DIV style="position:absolute;top:224;left:672"><nobr><span class="ft5">0.3920 (+20.5%)(+17.1%) </span></nobr></DIV>
<DIV style="position:absolute;top:240;left:125"><nobr><span class="ft5">20 docs </span></nobr></DIV>
<DIV style="position:absolute;top:240;left:207"><nobr><span class="ft5">0.3140 </span></nobr></DIV>
<DIV style="position:absolute;top:240;left:275"><nobr><span class="ft5">0.2980 (-5.1%) </span></nobr></DIV>
<DIV style="position:absolute;top:240;left:393"><nobr><span class="ft5">0.3270 (+4.1%) </span></nobr></DIV>
<DIV style="position:absolute;top:240;left:506"><nobr><span class="ft5">0.3720 (+18.5%)(+13.8%) </span></nobr></DIV>
<DIV style="position:absolute;top:240;left:672"><nobr><span class="ft5">0.3700 (+17.8%)(+13.2%) </span></nobr></DIV>
<DIV style="position:absolute;top:257;left:125"><nobr><span class="ft5">30 docs </span></nobr></DIV>
<DIV style="position:absolute;top:257;left:207"><nobr><span class="ft5">0.2780 </span></nobr></DIV>
<DIV style="position:absolute;top:257;left:275"><nobr><span class="ft5">0.2660 (-4.3%) </span></nobr></DIV>
<DIV style="position:absolute;top:257;left:393"><nobr><span class="ft5">0.2973 (+6.9%) </span></nobr></DIV>
<DIV style="position:absolute;top:257;left:506"><nobr><span class="ft5">0.3413 (+22.8%)(+14.8%) </span></nobr></DIV>
<DIV style="position:absolute;top:257;left:672"><nobr><span class="ft5">0.3400 (+22.3%)(+14.4%) </span></nobr></DIV>
<DIV style="position:absolute;top:276;left:105"><nobr><span class="ft47"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:285;left:110"><nobr><span class="ft6"><b>Table 4. </b></span></nobr></DIV>
<DIV style="position:absolute;top:285;left:159"><nobr><span class="ft5">Precision on the trec123-100col-bysource testbed when 5 databases were selected. (The first baseline is CORI; the second </span></nobr></DIV>
<DIV style="position:absolute;top:303;left:341"><nobr><span class="ft5">baseline for UUM/HP methods is UUM/HR.) </span></nobr></DIV>
<DIV style="position:absolute;top:325;left:116"><nobr><span class="ft5"> <b>Precision at </b></span></nobr></DIV>
<DIV style="position:absolute;top:341;left:123"><nobr><span class="ft6"><b>Doc Rank </b></span></nobr></DIV>
<DIV style="position:absolute;top:333;left:213"><nobr><span class="ft6"><b>CORI </b></span></nobr></DIV>
<DIV style="position:absolute;top:333;left:297"><nobr><span class="ft6"><b>ReDDE </b></span></nobr></DIV>
<DIV style="position:absolute;top:333;left:408"><nobr><span class="ft6"><b>UUM/HR </b></span></nobr></DIV>
<DIV style="position:absolute;top:333;left:539"><nobr><span class="ft6"><b>UUM/HP-FL </b></span></nobr></DIV>
<DIV style="position:absolute;top:333;left:702"><nobr><span class="ft6"><b>UUM/HP-VL </b></span></nobr></DIV>
<DIV style="position:absolute;top:357;left:134"><nobr><span class="ft5">5 docs </span></nobr></DIV>
<DIV style="position:absolute;top:357;left:212"><nobr><span class="ft5">0.4000 </span></nobr></DIV>
<DIV style="position:absolute;top:357;left:278"><nobr><span class="ft5">0.3920 (-2.0%) </span></nobr></DIV>
<DIV style="position:absolute;top:357;left:393"><nobr><span class="ft5">0.4280 (+7.0%)  </span></nobr></DIV>
<DIV style="position:absolute;top:357;left:509"><nobr><span class="ft5">0.4680 (+17.0%)(+9.4%) </span></nobr></DIV>
<DIV style="position:absolute;top:357;left:673"><nobr><span class="ft5">0.4600 (+15.0%)(+7.5%) </span></nobr></DIV>
<DIV style="position:absolute;top:373;left:130"><nobr><span class="ft5">10 docs </span></nobr></DIV>
<DIV style="position:absolute;top:373;left:212"><nobr><span class="ft5">0.3800 </span></nobr></DIV>
<DIV style="position:absolute;top:373;left:278"><nobr><span class="ft5">0.3760 (-1.1%) </span></nobr></DIV>
<DIV style="position:absolute;top:373;left:393"><nobr><span class="ft5">0.3800 (+0.0%)  </span></nobr></DIV>
<DIV style="position:absolute;top:373;left:506"><nobr><span class="ft5">0.4180 (+10.0%)(+10.0%) </span></nobr></DIV>
<DIV style="position:absolute;top:373;left:669"><nobr><span class="ft5">0.4320 (+13.7%)(+13.7%) </span></nobr></DIV>
<DIV style="position:absolute;top:390;left:130"><nobr><span class="ft5">15 docs </span></nobr></DIV>
<DIV style="position:absolute;top:390;left:212"><nobr><span class="ft5">0.3560 </span></nobr></DIV>
<DIV style="position:absolute;top:390;left:276"><nobr><span class="ft5">0.3560 (+0.0%) </span></nobr></DIV>
<DIV style="position:absolute;top:390;left:393"><nobr><span class="ft5">0.3720 (+4.5%)  </span></nobr></DIV>
<DIV style="position:absolute;top:390;left:509"><nobr><span class="ft5">0.3920 (+10.1%)(+5.4%) </span></nobr></DIV>
<DIV style="position:absolute;top:390;left:673"><nobr><span class="ft5">0.4080 (+14.6%)(+9.7%) </span></nobr></DIV>
<DIV style="position:absolute;top:407;left:130"><nobr><span class="ft5">20 docs </span></nobr></DIV>
<DIV style="position:absolute;top:407;left:212"><nobr><span class="ft5">0.3430 </span></nobr></DIV>
<DIV style="position:absolute;top:407;left:278"><nobr><span class="ft5">0.3390 (-1.2%) </span></nobr></DIV>
<DIV style="position:absolute;top:407;left:393"><nobr><span class="ft5">0.3550 (+3.5%) </span></nobr></DIV>
<DIV style="position:absolute;top:407;left:513"><nobr><span class="ft5">0.3710 (+8.2%)(+4.5%) </span></nobr></DIV>
<DIV style="position:absolute;top:407;left:673"><nobr><span class="ft5">0.3830 (+11.7%)(+7.9%) </span></nobr></DIV>
<DIV style="position:absolute;top:423;left:130"><nobr><span class="ft5">30 docs </span></nobr></DIV>
<DIV style="position:absolute;top:423;left:212"><nobr><span class="ft5">0.3240 </span></nobr></DIV>
<DIV style="position:absolute;top:423;left:278"><nobr><span class="ft5">0.3140 (-3.1%) </span></nobr></DIV>
<DIV style="position:absolute;top:423;left:393"><nobr><span class="ft5">0.3313 (+2.3%) </span></nobr></DIV>
<DIV style="position:absolute;top:423;left:513"><nobr><span class="ft5">0.3500 (+8.0%)(+5.6%) </span></nobr></DIV>
<DIV style="position:absolute;top:423;left:676"><nobr><span class="ft5">0.3487 (+7.6%)(+5.3%) </span></nobr></DIV>
<DIV style="position:absolute;top:1116;left:452"><nobr><span class="ft5">39</span></nobr></DIV>
</DIV>
<!-- Page 9 -->
<a name="9"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="204009.png" alt="background image">
<DIV style="position:absolute;top:279;left:81"><nobr><span class="ft14">a  lot  worse  than  the other  algorithms.  Tables  3  and  4  show  the <br>results on the Trec123-100Col testbed, and Tables 5 and 6 show <br>the results on the representative testbed.  <br> <br>On  the  Trec123-100Col  testbed,  the  document  retrieval <br>effectiveness  of  the  CORI  selection  algorithm  is  roughly  the <br>same or a little bit better than the ReDDE algorithm but both of <br>them are worse than the other three algorithms (Tables 3 and 4). <br>The  UUM/HR  algorithm  has  a  small  advantage  over  the  CORI <br>and  ReDDE  algorithms.  One  main  difference  between  the <br>UUM/HR algorithm and the ReDDE algorithm was pointed out <br>before:  The UUM/HR uses training data and linear interpolation <br>to  estimate  the  centralized  document  score  curves,  while  the <br>ReDDE  algorithm  [21]  uses  a  heuristic  method,  assumes  the <br>centralized document score curves are step functions and makes <br>no distinction among the top part of the curves. This difference <br>makes  UUM/HR  better  than  the  ReDDE  algorithm  at <br>distinguishing  documents  with  high  probabilities  of  relevance <br>from  low  probabilities  of  relevance.  Therefore,  the  UUM/HR <br>reflects the high-precision retrieval goal better than the ReDDE <br>algorithm and thus is more effective for document retrieval.  <br> <br>The  UUM/HR  algorithm  does  not  explicitly  optimize  the <br>selection decision with respect to the high-precision goal as the <br>UUM/HP-FL  and  UUM/HP-VL  algorithms  are  designed  to  do. <br>It  can  be  seen  that  on  this  testbed,  the  UUM/HP-FL  and <br>UUM/HP-VL  algorithms  are  much  more  effective  than  all  the <br>other  algorithms.  This  indicates  that  their  power  comes  from <br>explicitly  optimizing  the  high-precision  goal  of  document <br>retrieval in Equations 14 and 16. <br> <br>On the representative testbed, CORI is much less effective than <br>other algorithms for distributed document retrieval (Tables 5 and <br>6).  The  document  retrieval  results  of  the  ReDDE  algorithm  are <br>better  than  that  of  the  CORI  algorithm  but  still  worse  than  the <br>results  of  the  UUM/HR  algorithm.  On  this  testbed  the  three <br>UUM  algorithms  are  about  equally  effective.  Detailed  analysis <br>shows  that  the  overlap  of  the  selected  databases  between  the <br>UUM/HR,  UUM/HP-FL  and  UUM/HP-VL  algorithms  is  much <br>larger  than  the  experiments  on  the  Trec123-100Col  testbed, <br>since  all  of  them  tend  to  select  the  two  large  databases.  This <br>explains  why  they  are  about  equally  effective  for  document <br>retrieval. <br> <br>In  real  operational  environments,  databases  may  return  no <br>document  scores  and  report  only  ranked  lists  of  results.  As  the <br>unified utility maximization model only utilizes retrieval scores <br>of  sampled  documents  with  a  centralized  retrieval  algorithm  to <br>calculate  the  probabilities  of  relevance,  it  makes  database <br>selection  decisions  without  referring  to  the  document  scores <br>from  individual  databases  and  can  be  easily  generalized  to  this </span></nobr></DIV>
<DIV style="position:absolute;top:279;left:486"><nobr><span class="ft14">case of rank lists without document scores. The only adjustment <br>is that the SSL algorithm merges ranked lists without document <br>scores by assigning the documents with pseudo-document scores <br>normalized for their ranks (In a ranked list of 50 documents, the <br>first  one  has  a  score  of  1,  the  second  has  a  score  of  0.98  etc) <br>,which  has  been  studied  in  [22].  The  experiment  results  on <br>trec123-100Col-bysource  testbed  with  3  selected  databases  are <br>shown  in  Table  7.  The  experiment  setting  was  the  same  as <br>before  except  that  the  document  scores  were  eliminated <br>intentionally  and the  selected databases  only  return  ranked lists <br>of  document  ids.  It  can  be  seen  from  the  results  that  the <br>UUM/HP-FL  and  UUM/HP-VL  work  well  with  databases <br>returning  no  document  scores  and  are  still  more  effective  than <br>other  alternatives.  Other  experiments  with  databases  that  return <br>no  document  scores  are  not  reported  but  they  show  similar <br>results to prove the effectiveness of UUM/HP-FL and UUM/HP-<br>VL algorithms. <br> <br>The  above  experiments  suggest  that  it  is  very  important  to <br>optimize  the  high-precision  goal  explicitly  in  document <br>retrieval.  The  new  algorithms  based  on  this  principle  achieve <br>better  or  at  least  as  good  results  as  the  prior  state-of-the-art <br>algorithms in several environments. </span></nobr></DIV>
<DIV style="position:absolute;top:656;left:486"><nobr><span class="ft4"><b>7. CONCLUSION </b></span></nobr></DIV>
<DIV style="position:absolute;top:680;left:486"><nobr><span class="ft14">Distributed  information  retrieval  solves  the  problem  of  finding <br>information that is scattered among many text databases on local <br>area  networks  and  Internets.  Most  previous  research  use <br>effective </span></nobr></DIV>
<DIV style="position:absolute;top:726;left:553"><nobr><span class="ft5">resource </span></nobr></DIV>
<DIV style="position:absolute;top:726;left:619"><nobr><span class="ft5">selection </span></nobr></DIV>
<DIV style="position:absolute;top:726;left:687"><nobr><span class="ft5">algorithm </span></nobr></DIV>
<DIV style="position:absolute;top:726;left:759"><nobr><span class="ft5">of </span></nobr></DIV>
<DIV style="position:absolute;top:726;left:790"><nobr><span class="ft5">database </span></nobr></DIV>
<DIV style="position:absolute;top:742;left:486"><nobr><span class="ft14">recommendation  system  for  distributed  document  retrieval <br>application.  We  argue  that  the  high-recall  resource  selection <br>goal  of  database  recommendation  and  high-precision  goal  of <br>document  retrieval  are  related  but  not  identical.  This  kind  of <br>inconsistency  has  also  been  observed  in  previous  work,  but  the <br>prior  solutions  either  used  heuristic  methods  or  assumed <br>cooperation by individual databases (e.g., all the databases used <br>the same kind of search engines), which is frequently not true in <br>the uncooperative environment. <br> <br>In this work we propose a unified utility maximization model to <br>integrate the resource selection of database recommendation and <br>document retrieval tasks into a single unified framework. In this <br>framework,  the  selection  decisions  are  obtained  by  optimizing <br>different objective functions. As far as we know, this is the first <br>work  that  tries  to  view  and  theoretically  model  the  distributed <br>information retrieval task in an integrated manner.  <br> <br>The  new  framework  continues  a  recent  research  trend  studying <br>the  use  of  query-based  sampling  and  a  centralized  sample <br>database. A single logistic model was trained on the centralized </span></nobr></DIV>
<DIV style="position:absolute;top:112;left:106"><nobr><span class="ft6"><b>Table 7. </b></span></nobr></DIV>
<DIV style="position:absolute;top:111;left:156"><nobr><span class="ft5">Precision on the trec123-100col-bysource testbed when 3 databases were selected (The first baseline is CORI; the second </span></nobr></DIV>
<DIV style="position:absolute;top:129;left:206"><nobr><span class="ft5">baseline for UUM/HP methods is UUM/HR.) (Search engines do not return document scores) </span></nobr></DIV>
<DIV style="position:absolute;top:151;left:116"><nobr><span class="ft6"><b>Precision at </b></span></nobr></DIV>
<DIV style="position:absolute;top:167;left:122"><nobr><span class="ft6"><b>Doc Rank </b></span></nobr></DIV>
<DIV style="position:absolute;top:159;left:210"><nobr><span class="ft6"><b>CORI </b></span></nobr></DIV>
<DIV style="position:absolute;top:159;left:293"><nobr><span class="ft6"><b>ReDDE </b></span></nobr></DIV>
<DIV style="position:absolute;top:159;left:402"><nobr><span class="ft6"><b>UUM/HR </b></span></nobr></DIV>
<DIV style="position:absolute;top:159;left:532"><nobr><span class="ft6"><b>UUM/HP-FL </b></span></nobr></DIV>
<DIV style="position:absolute;top:159;left:694"><nobr><span class="ft6"><b>UUM/HP-VL </b></span></nobr></DIV>
<DIV style="position:absolute;top:183;left:133"><nobr><span class="ft5">5 docs </span></nobr></DIV>
<DIV style="position:absolute;top:183;left:209"><nobr><span class="ft5">0.3520 </span></nobr></DIV>
<DIV style="position:absolute;top:183;left:274"><nobr><span class="ft5">0.3240 (-8.0%) </span></nobr></DIV>
<DIV style="position:absolute;top:183;left:387"><nobr><span class="ft5">0.3680 (+4.6%)  </span></nobr></DIV>
<DIV style="position:absolute;top:183;left:498"><nobr><span class="ft5">0.4520 (+28.4%)(+22.8%) </span></nobr></DIV>
<DIV style="position:absolute;top:183;left:666"><nobr><span class="ft5">0.4520 (+28.4%)(+22.8) </span></nobr></DIV>
<DIV style="position:absolute;top:200;left:129"><nobr><span class="ft5">10 docs </span></nobr></DIV>
<DIV style="position:absolute;top:200;left:209"><nobr><span class="ft5">0.3320 </span></nobr></DIV>
<DIV style="position:absolute;top:200;left:274"><nobr><span class="ft5">0.3140 (-5.4%) </span></nobr></DIV>
<DIV style="position:absolute;top:200;left:387"><nobr><span class="ft5">0.3340 (+0.6%)  </span></nobr></DIV>
<DIV style="position:absolute;top:200;left:498"><nobr><span class="ft5">0.4120 (+24.1%)(+23.4%) </span></nobr></DIV>
<DIV style="position:absolute;top:200;left:661"><nobr><span class="ft5">0.4020 (+21.1%)(+20.4%) </span></nobr></DIV>
<DIV style="position:absolute;top:216;left:129"><nobr><span class="ft5">15 docs </span></nobr></DIV>
<DIV style="position:absolute;top:216;left:209"><nobr><span class="ft5">0.3227 </span></nobr></DIV>
<DIV style="position:absolute;top:216;left:274"><nobr><span class="ft5">0.2987 (-7.4%) </span></nobr></DIV>
<DIV style="position:absolute;top:216;left:387"><nobr><span class="ft5">0.3280 (+1.6%)  </span></nobr></DIV>
<DIV style="position:absolute;top:216;left:498"><nobr><span class="ft5">0.3920 (+21.5%)(+19.5%) </span></nobr></DIV>
<DIV style="position:absolute;top:216;left:661"><nobr><span class="ft5">0.3733 (+15.7%)(+13.8%) </span></nobr></DIV>
<DIV style="position:absolute;top:233;left:129"><nobr><span class="ft5">20 docs </span></nobr></DIV>
<DIV style="position:absolute;top:233;left:209"><nobr><span class="ft5">0.3030 </span></nobr></DIV>
<DIV style="position:absolute;top:233;left:274"><nobr><span class="ft5">0.2860 (-5.6%) </span></nobr></DIV>
<DIV style="position:absolute;top:233;left:387"><nobr><span class="ft5">0.3130 (+3.3%) </span></nobr></DIV>
<DIV style="position:absolute;top:233;left:498"><nobr><span class="ft5">0.3670 (+21.2%)(+17.3%) </span></nobr></DIV>
<DIV style="position:absolute;top:233;left:661"><nobr><span class="ft5">0.3590 (+18.5%)(+14.7%) </span></nobr></DIV>
<DIV style="position:absolute;top:250;left:129"><nobr><span class="ft5">30 docs </span></nobr></DIV>
<DIV style="position:absolute;top:250;left:209"><nobr><span class="ft5">0.2727 </span></nobr></DIV>
<DIV style="position:absolute;top:250;left:274"><nobr><span class="ft5">0.2640 (-3.2%) </span></nobr></DIV>
<DIV style="position:absolute;top:250;left:387"><nobr><span class="ft5">0.2900 (+6.3%) </span></nobr></DIV>
<DIV style="position:absolute;top:250;left:498"><nobr><span class="ft5">0.3273 (+20.0%)(+12.9%) </span></nobr></DIV>
<DIV style="position:absolute;top:250;left:661"><nobr><span class="ft5">0.3273 (+20.0%)(+12.9%) </span></nobr></DIV>
<DIV style="position:absolute;top:269;left:92"><nobr><span class="ft47"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:1116;left:452"><nobr><span class="ft5">40</span></nobr></DIV>
</DIV>
<!-- Page 10 -->
<a name="10"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft48{font-size:11px;font-family:Helvetica;color:#000000;}
	.ft49{font-size:7px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="204010.png" alt="background image">
<DIV style="position:absolute;top:111;left:81"><nobr><span class="ft15">sample  database  to  estimate  the  probabilities  of  relevance  of <br>documents  by  their  centralized  retrieval  scores,  while  the <br>centralized  sample  database  serves  as  a  bridge  to  connect  the <br>individual  databases  with  the  centralized  logistic  model. <br>Therefore,  the  probabilities  of  relevance  for  all  the  documents <br>across the databases can be estimated with very small amount of <br>human  relevance  judgment,  which  is  much  more  efficient  than <br>previous methods that build a separate model for each database. <br>This  framework  is  not  only  more  theoretically  solid  but  also <br>very effective. One algorithm for resource selection (UUM/HR) <br>and  two  algorithms  for  document  retrieval  (UUM/HP-FL  and <br>UUM/HP-VL)  are  derived  from  this  framework.  Empirical <br>studies  have  been  conducted  on  testbeds  to  simulate  the <br>distributed  search  solutions  of  large  organizations  (companies) <br>or domain-specific hidden Web. Furthermore, the UUM/HP-FL <br>and  UUM/HP-VL  resource  selection  algorithms  are  extended <br>with  a  variant  of  SSL  results  merging  algorithm  to  address  the <br>distributed  document  retrieval  task  when  selected  databases  do <br>not return document scores. Experiments have shown that these <br>algorithms  achieve  results  that  are  at  least  as  good  as  the  prior <br>state-of-the-art,  and  sometimes  considerably  better.  Detailed <br>analysis  indicates  that  the  advantage  of  these  algorithms  comes <br>from explicitly optimizing the goals of the specific tasks. <br> <br>The unified utility maximization framework is open for different <br>extensions.  When  cost  is  associated  with  searching  the  online <br>databases, the utility framework can be adjusted to automatically <br>estimate  the  best  number  of  databases  to  search  so  that  a  large <br>amount  of  relevant  documents  can  be  retrieved  with  relatively <br>small  costs.  Another  extension  of  the  framework  is  to  consider <br>the  retrieval  effectiveness  of  the  online  databases,  which  is  an <br>important issue in the operational environments. All of these are <br>the directions of future research. </span></nobr></DIV>
<DIV style="position:absolute;top:630;left:81"><nobr><span class="ft4"><b>ACKNOWLEDGEMENT </b></span></nobr></DIV>
<DIV style="position:absolute;top:653;left:81"><nobr><span class="ft14">This  research  was  supported  by  NSF  grants  EIA-9983253  and <br>IIS-0118767. </span></nobr></DIV>
<DIV style="position:absolute;top:668;left:169"><nobr><span class="ft5">Any </span></nobr></DIV>
<DIV style="position:absolute;top:668;left:208"><nobr><span class="ft5">opinions, </span></nobr></DIV>
<DIV style="position:absolute;top:668;left:274"><nobr><span class="ft5">findings, </span></nobr></DIV>
<DIV style="position:absolute;top:668;left:338"><nobr><span class="ft5">conclusions, </span></nobr></DIV>
<DIV style="position:absolute;top:668;left:421"><nobr><span class="ft5">or </span></nobr></DIV>
<DIV style="position:absolute;top:683;left:81"><nobr><span class="ft15">recommendations  expressed  in  this  paper  are  the  authors',  and <br>do not necessarily reflect those of the sponsor. </span></nobr></DIV>
<DIV style="position:absolute;top:733;left:81"><nobr><span class="ft4"><b>REFERENCES </b></span></nobr></DIV>
<DIV style="position:absolute;top:757;left:81"><nobr><span class="ft5">[1]</span></nobr></DIV>
<DIV style="position:absolute;top:756;left:97"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:757;left:108"><nobr><span class="ft14">J. Callan. (2000). Distributed information retrieval. In W.B. <br>Croft,  editor,  <i>Advances  in  Information  Retrieval</i>.  Kluwer <br>Academic Publishers. (pp. 127-150). </span></nobr></DIV>
<DIV style="position:absolute;top:808;left:81"><nobr><span class="ft5">[2]</span></nobr></DIV>
<DIV style="position:absolute;top:807;left:97"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:808;left:108"><nobr><span class="ft18">J.  Callan,  W.B.  Croft,  and  J.  Broglio.  (1995).  TREC  and <br>TIPSTER  experiments  with  INQUERY.  <i>Information <br>Processing and Management</i>, 31(3). (pp. 327-343). </span></nobr></DIV>
<DIV style="position:absolute;top:859;left:81"><nobr><span class="ft5">[3]</span></nobr></DIV>
<DIV style="position:absolute;top:858;left:97"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:859;left:108"><nobr><span class="ft14">J.  G.  Conrad,  X.  S.  Guo,  P.  Jackson  and  M.  Meziou. <br>(2002).  Database  selection  using  actual  physical  and <br>acquired logical collection resources in a  massive domain-<br>specific  operational  environment.  Distributed  search  over <br>the  hidden  web:  Hierarchical  database  sampling  and <br>selection.  In<i>  Proceedings  of  the  28</i></span></nobr></DIV>
<DIV style="position:absolute;top:933;left:341"><nobr><span class="ft49"><i>th</i></span></nobr></DIV>
<DIV style="position:absolute;top:936;left:348"><nobr><span class="ft8"><i>  International </i></span></nobr></DIV>
<DIV style="position:absolute;top:952;left:108"><nobr><span class="ft8"><i>Conference on Very Large Databases (VLDB)</i>.<i> </i></span></nobr></DIV>
<DIV style="position:absolute;top:972;left:81"><nobr><span class="ft5">[4]</span></nobr></DIV>
<DIV style="position:absolute;top:971;left:97"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:972;left:108"><nobr><span class="ft14">N.  Craswell.  (2000).  Methods  for  distributed  information <br>retrieval. Ph. D. thesis, The Australian Nation University.  </span></nobr></DIV>
<DIV style="position:absolute;top:1007;left:81"><nobr><span class="ft5">[5]</span></nobr></DIV>
<DIV style="position:absolute;top:1007;left:97"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:1007;left:108"><nobr><span class="ft14">N.  Craswell,  D.  Hawking,  and  P.  Thistlewaite.  (1999). <br>Merging  results  from  isolated  search  engines.  In <br><i>Proceedings of  10th Australasian Database Conference. </i></span></nobr></DIV>
<DIV style="position:absolute;top:111;left:486"><nobr><span class="ft5">[6]</span></nobr></DIV>
<DIV style="position:absolute;top:110;left:502"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:111;left:513"><nobr><span class="ft18">D. D'Souza, J. Thom, and J. Zobel. (2000). A comparison <br>of techniques for selecting text collections. In <i>Proceedings <br>of the 11th Australasian Database Conference.</i> </span></nobr></DIV>
<DIV style="position:absolute;top:162;left:486"><nobr><span class="ft5">[7]</span></nobr></DIV>
<DIV style="position:absolute;top:162;left:502"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:162;left:513"><nobr><span class="ft18">N.  Fuhr.  (1999).  A  Decision-Theoretic  approach  to <br>database  selection  in networked  IR.  <i>ACM  Transactions on <br>Information Systems</i>, 17(3). (pp. 229-249). </span></nobr></DIV>
<DIV style="position:absolute;top:213;left:486"><nobr><span class="ft5">[8]</span></nobr></DIV>
<DIV style="position:absolute;top:212;left:502"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:213;left:513"><nobr><span class="ft18">L. Gravano, C. Chang, H. Garcia-Molina, and A. Paepcke. <br>(1997).  STARTS:  Stanford  proposal  for  internet  meta-<br>searching.  In<i>  Proceedings  of  the  20th  ACM-SIGMOD <br>International Conference on Management of Data</i>.  </span></nobr></DIV>
<DIV style="position:absolute;top:280;left:486"><nobr><span class="ft5">[9]</span></nobr></DIV>
<DIV style="position:absolute;top:279;left:502"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:280;left:513"><nobr><span class="ft14">L.  Gravano,  P.  Ipeirotis  and  M.  Sahami.  (2003).  QProber: <br>A  System  for  Automatic  Classification  of  Hidden-Web <br>Databases.  <i>ACM  Transactions  on  Information  Systems,</i> <br>21(1).<i> </i></span></nobr></DIV>
<DIV style="position:absolute;top:346;left:486"><nobr><span class="ft5">[10]</span></nobr></DIV>
<DIV style="position:absolute;top:346;left:509"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:346;left:513"><nobr><span class="ft18">P. Ipeirotis and L. Gravano. (2002). Distributed search over <br>the  hidden  web:  Hierarchical  database  sampling  and <br>selection.  In<i>  Proceedings  of  the  28th  International <br>Conference on Very Large Databases (VLDB)</i>. </span></nobr></DIV>
<DIV style="position:absolute;top:413;left:486"><nobr><span class="ft5">[11]</span></nobr></DIV>
<DIV style="position:absolute;top:412;left:509"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:413;left:513"><nobr><span class="ft5">InvisibleWeb.com. http://www.invisibleweb.com  </span></nobr></DIV>
<DIV style="position:absolute;top:433;left:486"><nobr><span class="ft5">[12]</span></nobr></DIV>
<DIV style="position:absolute;top:432;left:509"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:433;left:513"><nobr><span class="ft5">The lemur toolkit. http://www.cs.cmu.edu/~lemur </span></nobr></DIV>
<DIV style="position:absolute;top:453;left:486"><nobr><span class="ft5">[13]</span></nobr></DIV>
<DIV style="position:absolute;top:452;left:509"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:453;left:513"><nobr><span class="ft18">J.  Lu  and  J.  Callan.  (2003).  Content-based  information <br>retrieval  in  peer-to-peer  networks.  In  <i>Proceedings  of  the <br>12th  International  Conference  on  Information  and <br>Knowledge Management</i>.<i> </i></span></nobr></DIV>
<DIV style="position:absolute;top:520;left:486"><nobr><span class="ft5">[14]</span></nobr></DIV>
<DIV style="position:absolute;top:519;left:509"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:520;left:513"><nobr><span class="ft18">W. Meng, C.T. Yu and K.L. Liu. (2002) Building efficient <br>and  effective  metasearch  engines.  <i>ACM  Comput.  Surv. <br></i>34(1). </span></nobr></DIV>
<DIV style="position:absolute;top:571;left:486"><nobr><span class="ft5">[15]</span></nobr></DIV>
<DIV style="position:absolute;top:570;left:509"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:571;left:513"><nobr><span class="ft18">H.  Nottelmann  and  N.  Fuhr.  (2003).  Evaluating  different <br>method  of  estimating  retrieval  quality  for  resource <br>selection.  In <i>Proceedings  of  the 25th  Annual  International <br>ACM  SIGIR  Conference  on  Research  and  Development  in <br>Information Retrieval.  </i></span></nobr></DIV>
<DIV style="position:absolute;top:653;left:486"><nobr><span class="ft5">[16]</span></nobr></DIV>
<DIV style="position:absolute;top:652;left:509"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:653;left:513"><nobr><span class="ft18">H.,  Nottelmann  and  N.,  Fuhr.  (2003).  The  MIND <br>architecture for heterogeneous multimedia federated digital <br>libraries.  <i>ACM  SIGIR  2003  Workshop  on  Distributed <br>Information Retrieval. </i></span></nobr></DIV>
<DIV style="position:absolute;top:719;left:486"><nobr><span class="ft5">[17]</span></nobr></DIV>
<DIV style="position:absolute;top:719;left:509"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:719;left:513"><nobr><span class="ft18">A.L.  Powell,  J.C.  French,  J.  Callan,  M.  Connell,  and  C.L. <br>Viles.  (2000).  The  impact  of  database  selection  on <br>distributed  searching.  In  <i>Proceedings  of  the  23rd  Annual <br>International  ACM  SIGIR  Conference  on  Research  and <br>Development in Information Retrieval</i>. </span></nobr></DIV>
<DIV style="position:absolute;top:801;left:486"><nobr><span class="ft5">[18]</span></nobr></DIV>
<DIV style="position:absolute;top:801;left:509"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:801;left:513"><nobr><span class="ft18">A.L.  Powell  and  J.C.  French.  (2003).  Comparing  the <br>performance  of  database  selection  algorithms.  <i>ACM <br>Transactions on Information Systems</i>, 21(4). (pp. 412-456).  </span></nobr></DIV>
<DIV style="position:absolute;top:853;left:486"><nobr><span class="ft5">[19]</span></nobr></DIV>
<DIV style="position:absolute;top:852;left:509"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:853;left:513"><nobr><span class="ft14">C. Sherman (2001). Search for the invisible web. Guardian <br>Unlimited.<i> </i></span></nobr></DIV>
<DIV style="position:absolute;top:888;left:486"><nobr><span class="ft5">[20]</span></nobr></DIV>
<DIV style="position:absolute;top:887;left:509"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:888;left:513"><nobr><span class="ft18">L.  Si  and  J.  Callan.  (2002).  Using  sampled  data  and <br>regression  to  merge  search  engine  results.  In  <i>Proceedings <br>of  the  25th  Annual  International  ACM  SIGIR  Conference <br>on Research and Development in Information Retrieval.</i> </span></nobr></DIV>
<DIV style="position:absolute;top:955;left:486"><nobr><span class="ft5">[21]</span></nobr></DIV>
<DIV style="position:absolute;top:954;left:509"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:955;left:513"><nobr><span class="ft18">L. Si and J. Callan. (2003). Relevant document distribution <br>estimation method for resource selection. In <i>Proceedings of <br>the  26th  Annual  International  ACM  SIGIR  Conference  on <br>Research and Development in Information Retrieval.</i> </span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:486"><nobr><span class="ft5">[22]</span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:509"><nobr><span class="ft48"> </span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:513"><nobr><span class="ft18">L.  Si  and  J.  Callan.  (2003).  A  Semi-Supervised  learning <br>method to merge search engine results. <i>ACM Transactions <br>on Information Systems</i>, 21(4). (pp. 457-491).  </span></nobr></DIV>
<DIV style="position:absolute;top:1116;left:452"><nobr><span class="ft5">41</span></nobr></DIV>
</DIV>
</BODY>
</HTML>
