<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
<HEAD>
<TITLE>Microsoft Word - p501-zhang.doc</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<META name="generator" content="pdftohtml 0.35beta">
<META name="author" content="hongz">
<META name="date" content="2004-08-05T21:35:42+00:00">
</HEAD>
<BODY bgcolor="#A0A0A0" vlink="blue" link="blue">
<!-- Page 1 -->
<a name="1"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft0{font-size:25px;font-family:Helvetica;color:#000000;}
	.ft1{font-size:16px;font-family:Helvetica;color:#000000;}
	.ft2{font-size:13px;font-family:Helvetica;color:#000000;}
	.ft3{font-size:16px;font-family:Times;color:#000000;}
	.ft4{font-size:11px;font-family:Times;color:#000000;}
	.ft5{font-size:11px;font-family:Times;color:#000000;}
	.ft6{font-size:16px;font-family:Helvetica;color:#000000;}
	.ft7{font-size:8px;font-family:Courier;color:#000000;}
	.ft8{font-size:8px;font-family:Times;color:#000000;}
	.ft9{font-size:4px;font-family:Courier;color:#000000;}
	.ft10{font-size:8px;font-family:Times;color:#000000;}
	.ft11{font-size:9px;font-family:Times;color:#000000;}
	.ft12{font-size:9px;font-family:Times;color:#000000;}
	.ft13{font-size:16px;font-family:Courier;color:#000000;}
	.ft14{font-size:13px;font-family:Helvetica;color:#000000;}
	.ft15{font-size:16px;line-height:25px;font-family:Helvetica;color:#000000;}
	.ft16{font-size:11px;line-height:15px;font-family:Times;color:#000000;}
	.ft17{font-size:9px;line-height:14px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="144001.png" alt="background image">
<DIV style="position:absolute;top:109;left:191"><nobr><span class="ft0"><b>On the Discovery of Significant Statistical  </b></span></nobr></DIV>
<DIV style="position:absolute;top:140;left:340"><nobr><span class="ft0"><b>Quantitative Rules </b></span></nobr></DIV>
<DIV style="position:absolute;top:175;left:158"><nobr><span class="ft1">Hong Zhang </span></nobr></DIV>
<DIV style="position:absolute;top:196;left:148"><nobr><span class="ft2">OPIM Department </span></nobr></DIV>
<DIV style="position:absolute;top:213;left:140"><nobr><span class="ft2">The Wharton School </span></nobr></DIV>
<DIV style="position:absolute;top:230;left:121"><nobr><span class="ft2">University of Pennsylvania </span></nobr></DIV>
<DIV style="position:absolute;top:248;left:131"><nobr><span class="ft2">Philadelphia, PA 19104 </span></nobr></DIV>
<DIV style="position:absolute;top:271;left:98"><nobr><span class="ft1">hongz@wharton.upenn.edu </span></nobr></DIV>
<DIV style="position:absolute;top:175;left:378"><nobr><span class="ft1">Balaji Padmanabhan </span></nobr></DIV>
<DIV style="position:absolute;top:196;left:400"><nobr><span class="ft2">OPIM Department </span></nobr></DIV>
<DIV style="position:absolute;top:213;left:392"><nobr><span class="ft2">The Wharton School </span></nobr></DIV>
<DIV style="position:absolute;top:230;left:373"><nobr><span class="ft2">University of Pennsylvania </span></nobr></DIV>
<DIV style="position:absolute;top:248;left:383"><nobr><span class="ft2">Philadelphia, PA 19104 </span></nobr></DIV>
<DIV style="position:absolute;top:271;left:354"><nobr><span class="ft1">balaji@wharton.upenn.edu </span></nobr></DIV>
<DIV style="position:absolute;top:175;left:639"><nobr><span class="ft1">Alexander Tuzhilin </span></nobr></DIV>
<DIV style="position:absolute;top:196;left:652"><nobr><span class="ft2">IOMS Department </span></nobr></DIV>
<DIV style="position:absolute;top:213;left:591"><nobr><span class="ft2">Leonard N. Stern School of Business </span></nobr></DIV>
<DIV style="position:absolute;top:230;left:645"><nobr><span class="ft2">New York University </span></nobr></DIV>
<DIV style="position:absolute;top:248;left:642"><nobr><span class="ft2">New York, NY 10012 </span></nobr></DIV>
<DIV style="position:absolute;top:271;left:621"><nobr><span class="ft1">atuzhili@stern.nyu.edu </span></nobr></DIV>
<DIV style="position:absolute;top:296;left:711"><nobr><span class="ft15"> <br> </span></nobr></DIV>
<DIV style="position:absolute;top:347;left:81"><nobr><span class="ft3"><b>ABSTRACT</b></span></nobr></DIV>
<DIV style="position:absolute;top:351;left:179"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:368;left:81"><nobr><span class="ft16">In this paper we study market share rules, rules that have a certain <br>market share statistic associated with them. Such rules are <br>particularly relevant for decision making from a business <br>perspective. Motivated by market share rules, in this paper we <br>consider statistical quantitative rules (SQ rules) that are <br>quantitative rules in which the RHS can be any statistic that is <br>computed for the segment satisfying the LHS of the rule. Building <br>on prior work, we present a statistical approach for learning all <br>significant SQ rules, i.e., SQ rules for which a desired statistic lies <br>outside a confidence interval computed for this rule. In particular <br>we show how resampling techniques can be effectively used to <br>learn significant rules. Since our method considers the <br>significance of a large number of rules in parallel, it is susceptible <br>to learning a certain number of &quot;false&quot; rules. To address this, we <br>present a technique that can determine the number of significant <br>SQ rules that can be expected by chance alone, and suggest that <br>this number can be used to determine a &quot;false discovery rate&quot; for <br>the learning procedure. We apply our methods to online consumer <br>purchase data and report the results.    </span></nobr></DIV>
<DIV style="position:absolute;top:687;left:81"><nobr><span class="ft3"><b>Categories and Subject Descriptors </b></span></nobr></DIV>
<DIV style="position:absolute;top:708;left:81"><nobr><span class="ft16">H.2.8 [<b>Database Management</b>]: Database Applications - Data <br>Mining. </span></nobr></DIV>
<DIV style="position:absolute;top:758;left:81"><nobr><span class="ft3"><b>General Terms</b></span></nobr></DIV>
<DIV style="position:absolute;top:762;left:198"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:779;left:81"><nobr><span class="ft4">Algorithms, Management. </span></nobr></DIV>
<DIV style="position:absolute;top:813;left:81"><nobr><span class="ft3"><b>Keywords</b></span></nobr></DIV>
<DIV style="position:absolute;top:834;left:81"><nobr><span class="ft16">Rule discovery, market share rules, statistical quantitative rules, <br>nonparametric methods, resampling. </span></nobr></DIV>
<DIV style="position:absolute;top:884;left:81"><nobr><span class="ft3"><b>1.</b></span></nobr></DIV>
<DIV style="position:absolute;top:884;left:95"><nobr><span class="ft6"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:884;left:105"><nobr><span class="ft3"><b>INTRODUCTION </b></span></nobr></DIV>
<DIV style="position:absolute;top:905;left:81"><nobr><span class="ft16">Rule discovery is widely used in data mining for learning <br>interesting patterns. Some of the early approaches for rule </span></nobr></DIV>
<DIV style="position:absolute;top:347;left:477"><nobr><span class="ft16">learning were in the machine learning literature [11, 12, 21]. More <br>recently there have been many algorithms [1, 25, 28, 31] proposed <br>in the data mining literature, most of which are based on the <br>concept of association rules [1]. While all these various <br>approaches have been successfully used in many applications [8, <br>22, 24], there are still situations that these types of rules do not <br>capture. The problem studied in this paper is motivated by market <br>share rules, a specific type of rule that cannot be represented as <br>association rules. Informally, a market share rule is a rule that <br>specifies the market share of a product or a firm under some <br>conditions.  </span></nobr></DIV>
<DIV style="position:absolute;top:530;left:477"><nobr><span class="ft16">The results we report in this paper are from real user-level Web <br>browsing data provided to us by comScore Networks. The data <br>consists of browsing behavior of 100,000 users over 6 months. In <br>addition to customer specific attributes, two attributes in a <br>transaction that are used to compute the market share are the site <br>at which a purchase was made and the purchase amount. Consider <br>the example rules below that we discovered from the data: </span></nobr></DIV>
<DIV style="position:absolute;top:653;left:477"><nobr><span class="ft7">(1)  Household Size = 3 </span></nobr></DIV>
<DIV style="position:absolute;top:652;left:624"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:653;left:630"><nobr><span class="ft7"> 35K &lt; Income &lt; 50K </span></nobr></DIV>
<DIV style="position:absolute;top:652;left:756"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:653;left:762"><nobr><span class="ft7"> ISP = </span></nobr></DIV>
<DIV style="position:absolute;top:667;left:504"><nobr><span class="ft7">Dialup </span></nobr></DIV>
<DIV style="position:absolute;top:665;left:548"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:667;left:558"><nobr><span class="ft7"> marketshare</span></nobr></DIV>
<DIV style="position:absolute;top:672;left:634"><nobr><span class="ft9">Expedia</span></nobr></DIV>
<DIV style="position:absolute;top:667;left:662"><nobr><span class="ft7"> = 27.76%, support = 2.1% </span></nobr></DIV>
<DIV style="position:absolute;top:686;left:477"><nobr><span class="ft7">(2)  Region = North East </span></nobr></DIV>
<DIV style="position:absolute;top:685;left:630"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:686;left:636"><nobr><span class="ft7"> Household Size = 1 </span></nobr></DIV>
<DIV style="position:absolute;top:685;left:762"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:686;left:773"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:698;left:504"><nobr><span class="ft7">marketshare</span></nobr></DIV>
<DIV style="position:absolute;top:702;left:573"><nobr><span class="ft9">Expedia</span></nobr></DIV>
<DIV style="position:absolute;top:698;left:601"><nobr><span class="ft7"> = 25.15%, support = 2.2% </span></nobr></DIV>
<DIV style="position:absolute;top:717;left:477"><nobr><span class="ft7">(3) Education</span></nobr></DIV>
<DIV style="position:absolute;top:721;left:561"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:717;left:564"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:721;left:570"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:717;left:574"><nobr><span class="ft7">College </span></nobr></DIV>
<DIV style="position:absolute;top:715;left:624"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:717;left:631"><nobr><span class="ft7"> Region = West </span></nobr></DIV>
<DIV style="position:absolute;top:715;left:725"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:717;left:732"><nobr><span class="ft7"> 50 &lt; Household </span></nobr></DIV>
<DIV style="position:absolute;top:731;left:504"><nobr><span class="ft7">Eldest</span></nobr></DIV>
<DIV style="position:absolute;top:734;left:542"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:731;left:545"><nobr><span class="ft7">Age</span></nobr></DIV>
<DIV style="position:absolute;top:730;left:564"><nobr><span class="ft10"> </span></nobr></DIV>
<DIV style="position:absolute;top:731;left:567"><nobr><span class="ft7">&lt;</span></nobr></DIV>
<DIV style="position:absolute;top:734;left:573"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:731;left:577"><nobr><span class="ft7">55</span></nobr></DIV>
<DIV style="position:absolute;top:734;left:589"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:729;left:593"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:734;left:603"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:731;left:607"><nobr><span class="ft7">marketshare</span></nobr></DIV>
<DIV style="position:absolute;top:735;left:676"><nobr><span class="ft9">Expedia </span></nobr></DIV>
<DIV style="position:absolute;top:731;left:708"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:734;left:714"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:731;left:718"><nobr><span class="ft7">2.92%,</span></nobr></DIV>
<DIV style="position:absolute;top:734;left:756"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:731;left:759"><nobr><span class="ft7">support=2.2% </span></nobr></DIV>
<DIV style="position:absolute;top:750;left:477"><nobr><span class="ft7">(4)  18 &lt; Household Eldest Age &lt; 20 </span></nobr></DIV>
<DIV style="position:absolute;top:748;left:699"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:750;left:709"><nobr><span class="ft7"> marketshare</span></nobr></DIV>
<DIV style="position:absolute;top:755;left:785"><nobr><span class="ft9">Expedia</span></nobr></DIV>
<DIV style="position:absolute;top:750;left:813"><nobr><span class="ft7"> = </span></nobr></DIV>
<DIV style="position:absolute;top:761;left:504"><nobr><span class="ft7">8.16%, support = 2.4% </span></nobr></DIV>
<DIV style="position:absolute;top:782;left:477"><nobr><span class="ft16">The market share for a specific site, e.g. Expedia.com, is <br>computed as the dollar value of flight ticket purchases (satisfying <br>the LHS of the rule) made at Expedia.com, divided by the total <br>dollar value of all flight ticket purchases satisfying the LHS. The <br>discovered rules suggest that Expedia seems to be doing <br>particularly well among the single households in the North East <br>region (rule 2), while it cedes some market in the segment of <br>teenagers (rule 4). Rules such as these are particularly relevant for <br>business since they suggest natural actions that may be taken. For <br>example, it may be worth investigating the higher market share <br>segments to study if there is something particularly good that is <br>being done, which is not being done in the lower market share <br>segments. </span></nobr></DIV>
<DIV style="position:absolute;top:997;left:477"><nobr><span class="ft16">More generally, "market share" is an example of a statistic that is <br>computed based on the segment satisfying the antecedent of the <br>rule. Besides market share, various other quantitative statistics on <br>the set of transactions satisfying the LHS of a rule can be <br>computed, including mean and variance of an attribute. Prior </span></nobr></DIV>
<DIV style="position:absolute;top:946;left:87"><nobr><span class="ft17"> <br>Permission to make digital or hard copies of all or part of this work for <br>personal or classroom use is granted without fee provided that copies are <br>not made or distributed for profit or commercial advantage and that <br>copies bear this notice and the full citation on the first page. To copy <br>otherwise, or republish, to post on servers or to redistribute to lists, <br>requires prior specific permission and/or a fee. <br><i>KDD'04</i>, August 22­25, 2004, Seattle, Washington, USA. <br>Copyright 2004 ACM 1-58113-888-1/04/0008...$5.00. </span></nobr></DIV>
<DIV style="position:absolute;top:1073;left:87"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:449"><nobr><span class="ft4">374</span></nobr></DIV>
<DIV style="position:absolute;top:54;left:80"><nobr><span class="ft14"><b>Research Track Paper</b></span></nobr></DIV>
</DIV>
<!-- Page 2 -->
<a name="2"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft18{font-size:11px;font-family:Times;color:#000000;}
	.ft19{font-size:7px;font-family:Times;color:#000000;}
	.ft20{font-size:7px;font-family:Times;color:#000000;}
	.ft21{font-size:11px;font-family:Times;color:#000000;}
	.ft22{font-size:12px;font-family:Times;color:#000000;}
	.ft23{font-size:4px;font-family:Times;color:#000000;}
	.ft24{font-size:4px;font-family:Times;color:#000000;}
	.ft25{font-size:11px;font-family:Times;color:#000000;}
	.ft26{font-size:7px;font-family:Times;color:#000000;}
	.ft27{font-size:11px;font-family:Helvetica;color:#000000;}
	.ft28{font-size:11px;font-family:Helvetica;color:#000000;}
	.ft29{font-size:9px;font-family:Times;color:#000000;}
	.ft30{font-size:5px;font-family:Times;color:#000000;}
	.ft31{font-size:9px;font-family:Times;color:#000000;}
	.ft32{font-size:11px;line-height:16px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="144002.png" alt="background image">
<DIV style="position:absolute;top:109;left:81"><nobr><span class="ft16">work on learning quantitative association rules [2, 33] studied the <br>discovery of rules with statistics such as the mean, variance, or <br>minimum/maximum of a single attribute on the RHS of a rule. In <br>this paper we generalize the structure of the rules considered in <br>[2] to rules in which the RHS can be any quantitative statistic that <br>can be computed for the subset of data satisfying the LHS. This <br>statistic can even be computed based on multiple attributes. We <br>term such rules as <i>statistical quantitative rules </i>(<i>SQ rules</i>).  </span></nobr></DIV>
<DIV style="position:absolute;top:244;left:81"><nobr><span class="ft16">With respect to learning SQ rules from data, we formulate the <br>problem as learning <i>significant</i> SQ rules that have adequate <br>support. We define an SQ rule to be significant if the specific <br>statistic computed for the rule lies outside a certain confidence <br>interval. This confidence interval represents a range in which the <br>statistic can be expected by <i>chance alone</i>. This is an important <br>range to identify if the rules discovered are to be interpreted as <br>suggesting fundamental relationships between the LHS and the <br>market share. For example, by chance alone if it is highly likely <br>that the market share of Expedia is between 25% and 30% for any <br>subset of data, then it is not at all clear that the rule relating <br>income and Expedia's market share (rule 1 in the example) is <br>identifying a fundamental relationship between income and the <br>market share. </span></nobr></DIV>
<DIV style="position:absolute;top:475;left:81"><nobr><span class="ft16">While prior work [6, 9] has used confidence intervals to identify <br>significant rules, most of these approaches are either parametric <br>or specific for binary data. Building on prior work in this paper <br>we present a statistical approach for learning significant SQ rules <br>that is entirely non-parametric. In particular we show how <br>resampling techniques, such as permutation, can be effectively <br>used to learn confidence intervals for rules. Based on these <br>confidence intervals, significant rules can be identified. However, <br>since our method considers the significance of a large number of <br>rules in parallel, for a given significance level it is susceptible to <br>learning a certain number of <i>false</i> rules. To address this we <br>present an intuitive resampling technique that can determine the <br>number of false rules, and argue that this number can be used to <br>determine a &quot;false discovery rate&quot; for the learning procedure. The <br>practical significance of this approach is that we learn significant <br>SQ rules from data and specify what the false discovery rate <br>exactly is.  </span></nobr></DIV>
<DIV style="position:absolute;top:753;left:81"><nobr><span class="ft16">The paper is organized as follows. We first define SQ rules in the <br>next section. Section 3 presents an algorithm for computing <br>confidence intervals and Section 4 presents an algorithm for <br>learning significant SQ rules. In Section 5 we explain how the <br>false discovery rate for our approach can be computed. We <br>present detailed experimental results on real web browsing data in <br>Section 6 followed by a literature review and conclusions. </span></nobr></DIV>
<DIV style="position:absolute;top:883;left:81"><nobr><span class="ft3"><b>2.</b></span></nobr></DIV>
<DIV style="position:absolute;top:883;left:95"><nobr><span class="ft6"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:883;left:105"><nobr><span class="ft3"><b>STATISTICAL QUANTITATIVE RULES </b></span></nobr></DIV>
<DIV style="position:absolute;top:903;left:81"><nobr><span class="ft16">In this section we define SQ rules and significant SQ rules. Let <br><i>A</i>= {<i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:925;left:118"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:123"><nobr><span class="ft18"><i>, A</i></span></nobr></DIV>
<DIV style="position:absolute;top:925;left:141"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:146"><nobr><span class="ft18"><i>,..., A</i></span></nobr></DIV>
<DIV style="position:absolute;top:925;left:179"><nobr><span class="ft20"><i>n</i></span></nobr></DIV>
<DIV style="position:absolute;top:919;left:184"><nobr><span class="ft4">} be a set of attributes that will be used to </span></nobr></DIV>
<DIV style="position:absolute;top:935;left:81"><nobr><span class="ft4">describe segments and <i>B</i> = {<i>B</i></span></nobr></DIV>
<DIV style="position:absolute;top:941;left:260"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:935;left:265"><nobr><span class="ft18"><i>, B</i></span></nobr></DIV>
<DIV style="position:absolute;top:941;left:283"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:935;left:288"><nobr><span class="ft18"><i>,..., B</i></span></nobr></DIV>
<DIV style="position:absolute;top:941;left:322"><nobr><span class="ft20"><i>m</i></span></nobr></DIV>
<DIV style="position:absolute;top:935;left:328"><nobr><span class="ft4">} be another set of </span></nobr></DIV>
<DIV style="position:absolute;top:951;left:81"><nobr><span class="ft16">attributes that will be used to compute various statistics that <br>describe the segment. Let <i>dom</i>(<i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:973;left:265"><nobr><span class="ft20"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:967;left:268"><nobr><span class="ft4">) and <i>dom</i>(<i>B</i></span></nobr></DIV>
<DIV style="position:absolute;top:973;left:338"><nobr><span class="ft20"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:967;left:340"><nobr><span class="ft4">) represent the set </span></nobr></DIV>
<DIV style="position:absolute;top:982;left:81"><nobr><span class="ft4">of values that can be taken by attribute <i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:989;left:308"><nobr><span class="ft20"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:982;left:310"><nobr><span class="ft4"> and <i>B</i></span></nobr></DIV>
<DIV style="position:absolute;top:989;left:346"><nobr><span class="ft20"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:982;left:348"><nobr><span class="ft4"> respectively, for </span></nobr></DIV>
<DIV style="position:absolute;top:999;left:81"><nobr><span class="ft4">any <i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:1006;left:113"><nobr><span class="ft20"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:999;left:115"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:998;left:119"><nobr><span class="ft21"> <i>A</i> and<i> B</i></span></nobr></DIV>
<DIV style="position:absolute;top:1006;left:176"><nobr><span class="ft20"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:999;left:178"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:998;left:182"><nobr><span class="ft21"> <i>B</i>. Let <i>D</i> be a dataset of <i>N</i> transactions where </span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:81"><nobr><span class="ft4">each transaction is of the form {<i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:267"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:272"><nobr><span class="ft4"> =<i> a</i></span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:294"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:299"><nobr><span class="ft4">, <i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:314"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:319"><nobr><span class="ft4"> =<i> a</i></span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:341"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:346"><nobr><span class="ft4">,..., <i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:378"><nobr><span class="ft20"><i>n</i></span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:383"><nobr><span class="ft4"> =<i> a</i></span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:405"><nobr><span class="ft20"><i>n</i></span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:409"><nobr><span class="ft4">, <i>B</i></span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:425"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:430"><nobr><span class="ft18"><i> </i>= </span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:81"><nobr><span class="ft18"><i>b</i></span></nobr></DIV>
<DIV style="position:absolute;top:1038;left:88"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:92"><nobr><span class="ft4">, <i>B</i></span></nobr></DIV>
<DIV style="position:absolute;top:1038;left:108"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:112"><nobr><span class="ft18"><i> </i>= <i>b</i></span></nobr></DIV>
<DIV style="position:absolute;top:1038;left:134"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:138"><nobr><span class="ft4">,..., <i>B</i></span></nobr></DIV>
<DIV style="position:absolute;top:1038;left:170"><nobr><span class="ft20"><i>m</i></span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:177"><nobr><span class="ft4"> = <i>b</i></span></nobr></DIV>
<DIV style="position:absolute;top:1038;left:198"><nobr><span class="ft20"><i>m</i></span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:205"><nobr><span class="ft4">} where <i>a</i></span></nobr></DIV>
<DIV style="position:absolute;top:1038;left:258"><nobr><span class="ft20"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:261"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:265"><nobr><span class="ft21"> <i>dom</i>(<i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:1038;left:314"><nobr><span class="ft20"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:316"><nobr><span class="ft4">) and <i>b</i></span></nobr></DIV>
<DIV style="position:absolute;top:1038;left:354"><nobr><span class="ft20"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:356"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:360"><nobr><span class="ft21"> <i>dom</i>(<i>B</i></span></nobr></DIV>
<DIV style="position:absolute;top:1038;left:409"><nobr><span class="ft20"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:412"><nobr><span class="ft4">). Let </span></nobr></DIV>
<DIV style="position:absolute;top:1049;left:81"><nobr><span class="ft4">an atomic condition be a proposition of the form <i>value</i></span></nobr></DIV>
<DIV style="position:absolute;top:1055;left:395"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:1049;left:399"><nobr><span class="ft18"><i> </i></span></nobr></DIV>
<DIV style="position:absolute;top:1046;left:405"><nobr><span class="ft22"></span></nobr></DIV>
<DIV style="position:absolute;top:1049;left:412"><nobr><span class="ft18"><i>  A</i></span></nobr></DIV>
<DIV style="position:absolute;top:1055;left:426"><nobr><span class="ft20"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:1049;left:428"><nobr><span class="ft18"><i> </i></span></nobr></DIV>
<DIV style="position:absolute;top:1046;left:434"><nobr><span class="ft22"></span></nobr></DIV>
<DIV style="position:absolute;top:1049;left:441"><nobr><span class="ft18"><i> </i></span></nobr></DIV>
<DIV style="position:absolute;top:1065;left:81"><nobr><span class="ft18"><i>value</i></span></nobr></DIV>
<DIV style="position:absolute;top:1071;left:110"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:1072;left:115"><nobr><span class="ft23"> </span></nobr></DIV>
<DIV style="position:absolute;top:1065;left:122"><nobr><span class="ft4">for ordered attributes and <i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:1071;left:294"><nobr><span class="ft20"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:1065;left:296"><nobr><span class="ft18"><i> = value </i>for unordered </span></nobr></DIV>
<DIV style="position:absolute;top:109;left:477"><nobr><span class="ft4">attributes where <i>value, value</i></span></nobr></DIV>
<DIV style="position:absolute;top:117;left:640"><nobr><span class="ft24"><i>1</i></span></nobr></DIV>
<DIV style="position:absolute;top:109;left:643"><nobr><span class="ft18"><i>, value</i></span></nobr></DIV>
<DIV style="position:absolute;top:117;left:681"><nobr><span class="ft24"><i>2</i></span></nobr></DIV>
<DIV style="position:absolute;top:109;left:684"><nobr><span class="ft4"> belong to the finite set of </span></nobr></DIV>
<DIV style="position:absolute;top:124;left:477"><nobr><span class="ft4">discrete values taken by <i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:131;left:619"><nobr><span class="ft20"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:124;left:622"><nobr><span class="ft4"> in <i>D</i>. Finally, let an itemset represent a </span></nobr></DIV>
<DIV style="position:absolute;top:140;left:477"><nobr><span class="ft4">conjunction of atomic conditions.<b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:165;left:477"><nobr><span class="ft16"><b>Definition 2.1 (SQ rule)</b>. Given (i) sets of attributes <i>A</i> and <i>B</i>, (ii) <br>a dataset <i>D</i> and (iii) a function <i>f</i> that computes a desired statistic <br>of interest on any subset of data, an SQ rule is a rule of the form:<b> </b> </span></nobr></DIV>
<DIV style="position:absolute;top:223;left:479"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:223;left:558"><nobr><span class="ft25"><i><b>X</i> </b></span></nobr></DIV>
<DIV style="position:absolute;top:221;left:571"><nobr><span class="ft21"><b> <i>f</i>(<i>D</b></i></span></nobr></DIV>
<DIV style="position:absolute;top:229;left:606"><nobr><span class="ft26"><i><b>X</b></i></span></nobr></DIV>
<DIV style="position:absolute;top:223;left:612"><nobr><span class="ft5"><b>) = <i>statistic</i>, <i>support</i> = <i>sup</b></i></span></nobr></DIV>
<DIV style="position:absolute;top:224;left:756"><nobr><span class="ft23">1</span></nobr></DIV>
<DIV style="position:absolute;top:223;left:760"><nobr><span class="ft25"><i><b> </b></i> (2.1) </span></nobr></DIV>
<DIV style="position:absolute;top:248;left:477"><nobr><span class="ft4">where  <i>X</i> is an itemset involving attributes in <i>A</i> only, <i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:254;left:795"><nobr><span class="ft20"><i>X</i></span></nobr></DIV>
<DIV style="position:absolute;top:248;left:800"><nobr><span class="ft4"> is the </span></nobr></DIV>
<DIV style="position:absolute;top:264;left:477"><nobr><span class="ft16">subset of <i>D</i> satisfying <i>X</i>, the function <i>f</i> computes some statistic <br>from the values of the <i>B</i> attributes in the subset <i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:286;left:748"><nobr><span class="ft20"><i>X</i></span></nobr></DIV>
<DIV style="position:absolute;top:279;left:754"><nobr><span class="ft4">, and support is </span></nobr></DIV>
<DIV style="position:absolute;top:295;left:477"><nobr><span class="ft4">the number of transactions in <i>D</i> satisfying <i>X</i>.  </span></nobr></DIV>
<DIV style="position:absolute;top:295;left:747"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:295;left:813"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:320;left:477"><nobr><span class="ft16">Note that the statistic on the RHS of the rule can be computed <br>using the values of multiple attributes. The following examples <br>are listed to demonstrate different types of rules that an SQ rule <br>can represent. For ease of exposition we use the name of the <br>desired statistic in the RHS instead of referring to it as <i>f</i>(<i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:390;left:792"><nobr><span class="ft20"><i>X</i></span></nobr></DIV>
<DIV style="position:absolute;top:383;left:798"><nobr><span class="ft4">). </span></nobr></DIV>
<DIV style="position:absolute;top:408;left:477"><nobr><span class="ft4">1.</span></nobr></DIV>
<DIV style="position:absolute;top:408;left:487"><nobr><span class="ft27"> </span></nobr></DIV>
<DIV style="position:absolute;top:408;left:504"><nobr><span class="ft25"><i><b>Quantitative association rules</b></i> [2]:  </span></nobr></DIV>
<DIV style="position:absolute;top:434;left:477"><nobr><span class="ft25"><i><b>population</i>-<i>subset</i> </b></span></nobr></DIV>
<DIV style="position:absolute;top:433;left:579"><nobr><span class="ft21"><b> <i>mean or variance values for the subset </b></i>(2.2)<b><i> </b></i></span></nobr></DIV>
<DIV style="position:absolute;top:459;left:477"><nobr><span class="ft32">Quantitative association rules are a popular representation for <br>rules in the data mining literature in which the RHS of a rule <br>represents the mean or variance of some attribute. Example: <br><i>Education</i> = <i>graduate</i> </span></nobr></DIV>
<DIV style="position:absolute;top:506;left:608"><nobr><span class="ft21">  <i>Mean</i>(<i>purchase</i>) = $15.00. (2.2) is a </span></nobr></DIV>
<DIV style="position:absolute;top:523;left:477"><nobr><span class="ft16">special case of (2.1), where <i>f</i>(<i>subset</i>) is the mean of some attribute <br><i>B</i></span></nobr></DIV>
<DIV style="position:absolute;top:545;left:485"><nobr><span class="ft20"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:539;left:488"><nobr><span class="ft4"> in the subset of data.  </span></nobr></DIV>
<DIV style="position:absolute;top:564;left:477"><nobr><span class="ft5"><b>2.</b></span></nobr></DIV>
<DIV style="position:absolute;top:564;left:487"><nobr><span class="ft28"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:564;left:504"><nobr><span class="ft25"><i><b>Market share rules</i>: </b></span></nobr></DIV>
<DIV style="position:absolute;top:589;left:477"><nobr><span class="ft4">Let {<i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:595;left:514"><nobr><span class="ft20"><i>1</i></span></nobr></DIV>
<DIV style="position:absolute;top:589;left:519"><nobr><span class="ft18"><i>, A</i></span></nobr></DIV>
<DIV style="position:absolute;top:595;left:535"><nobr><span class="ft20"><i>2</i></span></nobr></DIV>
<DIV style="position:absolute;top:589;left:540"><nobr><span class="ft18"><i>,..., A</i></span></nobr></DIV>
<DIV style="position:absolute;top:595;left:571"><nobr><span class="ft20"><i>n</i></span></nobr></DIV>
<DIV style="position:absolute;top:589;left:576"><nobr><span class="ft18"><i>, MSV, P</i>} be a set of attributes in a dataset <i>D</i>. </span></nobr></DIV>
<DIV style="position:absolute;top:605;left:477"><nobr><span class="ft16"><i>MSV</i> (Market Share Variable) is a special categorical attribute for <br>which the market share values are to be computed. <i>P</i> is a special <br>continuous variable that is the basis for the market share <br>computation for <i>MSV</i>. For example, each transaction <i>T</i></span></nobr></DIV>
<DIV style="position:absolute;top:659;left:802"><nobr><span class="ft20"><i>k</i></span></nobr></DIV>
<DIV style="position:absolute;top:652;left:806"><nobr><span class="ft4"> may </span></nobr></DIV>
<DIV style="position:absolute;top:668;left:477"><nobr><span class="ft4">represent a book</span></nobr></DIV>
<DIV style="position:absolute;top:666;left:569"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:668;left:573"><nobr><span class="ft4"> purchased online. <i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:674;left:688"><nobr><span class="ft20"><i>1 </i></span></nobr></DIV>
<DIV style="position:absolute;top:668;left:695"><nobr><span class="ft4">through <i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:674;left:750"><nobr><span class="ft20"><i>n</i></span></nobr></DIV>
<DIV style="position:absolute;top:668;left:755"><nobr><span class="ft4"> may represent </span></nobr></DIV>
<DIV style="position:absolute;top:684;left:477"><nobr><span class="ft32">attributes of the customer who makes the purchase, such as <br>income, region of residence and household size. For each <br>transaction, <i>MSV</i> is the variable indicating the online book retailer <br>where the purchase was made. <i>dom(MSV)</i> may be {Amazon, <br>Barnes&amp;Noble, Ebay} and <i>P</i> is the price of the book purchased. <br>For a specific <i>v</i> </span></nobr></DIV>
<DIV style="position:absolute;top:763;left:577"><nobr><span class="ft21">  <i>dom(MSV)</i> a market share statistic can be </span></nobr></DIV>
<DIV style="position:absolute;top:780;left:477"><nobr><span class="ft16">computed as described below. Market share rules have the <br>following form: </span></nobr></DIV>
<DIV style="position:absolute;top:825;left:477"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:825;left:544"><nobr><span class="ft25"><i><b>X</i> </b></span></nobr></DIV>
<DIV style="position:absolute;top:824;left:557"><nobr><span class="ft21"><b> <i>marketshare</b></i></span></nobr></DIV>
<DIV style="position:absolute;top:829;left:643"><nobr><span class="ft29"><i><b>v</b></i></span></nobr></DIV>
<DIV style="position:absolute;top:826;left:649"><nobr><span class="ft3"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:825;left:653"><nobr><span class="ft5"><b>= <i>msh</i>, <i>support</i> = <i>sup</b></i>  </span></nobr></DIV>
<DIV style="position:absolute;top:825;left:811"><nobr><span class="ft4">(2.3) </span></nobr></DIV>
<DIV style="position:absolute;top:851;left:477"><nobr><span class="ft4">where  <i>X</i> is an itemset consisting of attributes in {<i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:857;left:768"><nobr><span class="ft20"><i>1</i></span></nobr></DIV>
<DIV style="position:absolute;top:851;left:772"><nobr><span class="ft18"><i>, A</i></span></nobr></DIV>
<DIV style="position:absolute;top:857;left:789"><nobr><span class="ft20"><i>2</i></span></nobr></DIV>
<DIV style="position:absolute;top:851;left:794"><nobr><span class="ft18"><i>,..., A</i></span></nobr></DIV>
<DIV style="position:absolute;top:857;left:826"><nobr><span class="ft20"><i>n</i></span></nobr></DIV>
<DIV style="position:absolute;top:851;left:831"><nobr><span class="ft4">} </span></nobr></DIV>
<DIV style="position:absolute;top:866;left:477"><nobr><span class="ft4">and <i>marketshare</i></span></nobr></DIV>
<DIV style="position:absolute;top:873;left:567"><nobr><span class="ft20"><i>v</i></span></nobr></DIV>
<DIV style="position:absolute;top:866;left:571"><nobr><span class="ft4"> is a statistic that represents the market share of a </span></nobr></DIV>
<DIV style="position:absolute;top:883;left:477"><nobr><span class="ft4">specific  <i>v</i> </span></nobr></DIV>
<DIV style="position:absolute;top:882;left:538"><nobr><span class="ft21">  <i>dom(MSV)</i>. This is computed as follows. Let <i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:889;left:832"><nobr><span class="ft20"><i>X</i></span></nobr></DIV>
<DIV style="position:absolute;top:883;left:837"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:899;left:477"><nobr><span class="ft4">represent the subset of transactions satisfying <i>X</i> and <i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:905;left:796"><nobr><span class="ft20"><i>X, MSV=v</i></span></nobr></DIV>
<DIV style="position:absolute;top:899;left:837"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:919;left:477"><nobr><span class="ft4">                                                                 </span></nobr></DIV>
<DIV style="position:absolute;top:940;left:477"><nobr><span class="ft30">1</span></nobr></DIV>
<DIV style="position:absolute;top:940;left:481"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:941;left:484"><nobr><span class="ft11">In association rules, <i>support</i> is the number of transactions satisfying <b>both</b> </span></nobr></DIV>
<DIV style="position:absolute;top:955;left:488"><nobr><span class="ft17">LHS and RHS of a rule. In SQ rules, since the RHS is not an itemset, we <br>define <i>support</i> as the number of transactions satisfying the LHS of a rule <br><b>only</b>. </span></nobr></DIV>
<DIV style="position:absolute;top:1003;left:477"><nobr><span class="ft30">2 </span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:488"><nobr><span class="ft17">The provider, comScore Networks categorizes each purchase into <br>categories such as "book", "travel" and "consumer electronics". Hence <br>we can generate datasets in which all transactions represent purchases in <br>a single category, and this helps in the generation of market share rules <br>representing specific categories. </span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:449"><nobr><span class="ft4">375</span></nobr></DIV>
<DIV style="position:absolute;top:54;left:681"><nobr><span class="ft14"><b>Research Track Paper</b></span></nobr></DIV>
</DIV>
<!-- Page 3 -->
<a name="3"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft33{font-size:11px;font-family:Courier;color:#000000;}
	.ft34{font-size:9px;font-family:Courier;color:#000000;}
	.ft35{font-size:9px;font-family:Courier;color:#000000;}
	.ft36{font-size:5px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="144003.png" alt="background image">
<DIV style="position:absolute;top:110;left:81"><nobr><span class="ft4">represent the subset of transactions<i>  </i>satisfying (<i>X</i> </span></nobr></DIV>
<DIV style="position:absolute;top:108;left:366"><nobr><span class="ft21">  <i>MSV</i>  =<i>  v</i>). </span></nobr></DIV>
<DIV style="position:absolute;top:125;left:81"><nobr><span class="ft4">Then <i>marketshare</i></span></nobr></DIV>
<DIV style="position:absolute;top:132;left:180"><nobr><span class="ft20"><i>v</i></span></nobr></DIV>
<DIV style="position:absolute;top:125;left:184"><nobr><span class="ft4"> is computed as <i>sum</i>(<i>P</i>, <i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:132;left:323"><nobr><span class="ft20"><i>X, MSV=v</i></span></nobr></DIV>
<DIV style="position:absolute;top:125;left:361"><nobr><span class="ft4">) / <i>sum</i>(<i>P</i>, <i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:132;left:428"><nobr><span class="ft20"><i>X</i></span></nobr></DIV>
<DIV style="position:absolute;top:125;left:433"><nobr><span class="ft4">), </span></nobr></DIV>
<DIV style="position:absolute;top:141;left:81"><nobr><span class="ft16">where <i>sum</i>(<i>P</i>, <i>D</i>) is the sum of all the values of attribute <i>P</i> in the <br>transactions in <i>D</i>.  </span></nobr></DIV>
<DIV style="position:absolute;top:182;left:81"><nobr><span class="ft16">Market share rules naturally occur in various applications, <br>including online purchases at various Web sites, sales <br>applications, and knowledge management applications. The <br>examples presented in the introduction are real market share rules <br>discovered in online purchase data. The following additional <br>examples illustrate the versatility and usefulness of market share <br>rules.  </span></nobr></DIV>
<DIV style="position:absolute;top:301;left:81"><nobr><span class="ft21">·</span></nobr></DIV>
<DIV style="position:absolute;top:303;left:87"><nobr><span class="ft27"> </span></nobr></DIV>
<DIV style="position:absolute;top:303;left:108"><nobr><span class="ft16">Within a specific product category (e.g. shoes) Footlocker <br>sells competing brands of shoes. In their transaction data, the <br>brand of the shoe can be the <i>MSV</i> and the purchase price is <br><i>P</i>. </span></nobr></DIV>
<DIV style="position:absolute;top:375;left:81"><nobr><span class="ft21">·</span></nobr></DIV>
<DIV style="position:absolute;top:376;left:87"><nobr><span class="ft27"> </span></nobr></DIV>
<DIV style="position:absolute;top:376;left:108"><nobr><span class="ft16">Consider a dataset of patents associated with some area (e.g. <br>hard disks). Each record may consist of several attributes <br>describing a patent, including one attribute (<i>MSV</i>) which <br>represents the organization to which the patent belongs and <br>another attribute that is always 1 (representing <i>P</i> and <br>indicating a granted patent) in the data. For a specific <br>organization, e.g. IBM, market share rules will represent the <br>percentage of patents that belong to IBM under some <br>conditions involving other attributes of the patent.  </span></nobr></DIV>
<DIV style="position:absolute;top:528;left:81"><nobr><span class="ft16">Definition 2.1 differs from the definition of quantitative rule [2, <br>33] as follows. First, it is not limited to mean and variance <br>statistics and assumes a much broader class of statistics, including <br>the market share statistics. Second, unlike quantitative rules, the <br>statistic of interest in the RHS of a rule can be computed based on <br><i>multiple</i> attributes. </span></nobr></DIV>
<DIV style="position:absolute;top:632;left:81"><nobr><span class="ft32"><b>Definition 2.2 (Significant SQ rule)</b>. For a given significance <br>level </span></nobr></DIV>
<DIV style="position:absolute;top:647;left:111"><nobr><span class="ft22"></span></nobr></DIV>
<DIV style="position:absolute;top:649;left:119"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:647;left:123"><nobr><span class="ft21"> (0, 1), let (<i>stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:655;left:214"><nobr><span class="ft20"><i>L</i></span></nobr></DIV>
<DIV style="position:absolute;top:649;left:219"><nobr><span class="ft4">, <i>stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:655;left:245"><nobr><span class="ft20"><i>H</i></span></nobr></DIV>
<DIV style="position:absolute;top:649;left:252"><nobr><span class="ft4">) be the (1 ­ </span></nobr></DIV>
<DIV style="position:absolute;top:647;left:320"><nobr><span class="ft21">) confidence interval </span></nobr></DIV>
<DIV style="position:absolute;top:665;left:81"><nobr><span class="ft32">for a desired statistic, where this confidence interval represents <br>the range in which the statistic can be expected by chance alone. <br>An SQ rule <i>X</i> </span></nobr></DIV>
<DIV style="position:absolute;top:695;left:162"><nobr><span class="ft22"></span></nobr></DIV>
<DIV style="position:absolute;top:697;left:175"><nobr><span class="ft18"><i> f(D</i></span></nobr></DIV>
<DIV style="position:absolute;top:704;left:198"><nobr><span class="ft20"><i>X</i></span></nobr></DIV>
<DIV style="position:absolute;top:697;left:203"><nobr><span class="ft18"><i>) = statistic, support = sup </i>is significant if </span></nobr></DIV>
<DIV style="position:absolute;top:713;left:81"><nobr><span class="ft18"><i>statistic</i> lies outside the range (<i>stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:719;left:269"><nobr><span class="ft20"><i>L</i></span></nobr></DIV>
<DIV style="position:absolute;top:713;left:274"><nobr><span class="ft4">, <i>stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:719;left:300"><nobr><span class="ft20"><i>H</i></span></nobr></DIV>
<DIV style="position:absolute;top:713;left:307"><nobr><span class="ft4">).  </span></nobr></DIV>
<DIV style="position:absolute;top:713;left:417"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:738;left:81"><nobr><span class="ft16">The main objective of this paper is to discover all significant SQ <br>rules. The first challenge in learning significant SQ rules is in <br>constructing a confidence interval for the desired statistic such <br>that this interval represents a range of values for the RHS statistic <br>that can be expected by chance alone. In the next section we <br>present an algorithm for learning these confidence intervals. </span></nobr></DIV>
<DIV style="position:absolute;top:852;left:81"><nobr><span class="ft3"><b>3.</b></span></nobr></DIV>
<DIV style="position:absolute;top:851;left:95"><nobr><span class="ft6"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:852;left:105"><nobr><span class="ft3"><b>COMPUTING CONF. INTERVALS </b></span></nobr></DIV>
<DIV style="position:absolute;top:872;left:81"><nobr><span class="ft16">The first question that needs to be addressed is what is meant by <br>"a range for the statistic that can be expected by chance alone". In <br>this section we start by addressing this question and outline a <br>procedure by which such a range can be computed. Next we will <br>point out the computational challenge in implementing such a <br>procedure for learning these intervals for several SQ rules and <br>then outline three observations that will substantially help address <br>the computational problems. Based on these observations we <br>present a resampling-based algorithm for computing the <br>confidence intervals. </span></nobr></DIV>
<DIV style="position:absolute;top:109;left:477"><nobr><span class="ft3"><b>3.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:109;left:499"><nobr><span class="ft6"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:109;left:510"><nobr><span class="ft3"><b>Motivation and outline of a procedure </b></span></nobr></DIV>
<DIV style="position:absolute;top:130;left:477"><nobr><span class="ft16">For a given SQ rule, the desired confidence interval theoretically <br>represents the range in which the statistic can be expected when <br>there is <i>no</i> fundamental relationship between the LHS of the rule <br>and the statistic. More precisely, since the statistic is computed <br>from the values of the <i>B</i> attributes, the confidence interval <br>represents the range in which the statistic can be expected when <br>the <i>A</i> attributes are truly independent of the <i>B</i> attributes. </span></nobr></DIV>
<DIV style="position:absolute;top:250;left:477"><nobr><span class="ft32">Without making any parametric distributional assumptions, such a <br>confidence interval can be generated using the classical non-<br>parametric technique of permutation. Indeed permutation-based <br>approaches have been commonly used to generate confidence <br>intervals in the statistics literature [16]. If <i>R</i> is the set of all <br>attributes in a dataset, the basic idea in permutation is to create <br>multiple datasets by randomly permuting the values of some <br>attributes  <i>R</i></span></nobr></DIV>
<DIV style="position:absolute;top:368;left:541"><nobr><span class="ft20"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:361;left:543"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:360;left:549"><nobr><span class="ft21">  <i>R</i>. Such a permutation would create a dataset in </span></nobr></DIV>
<DIV style="position:absolute;top:377;left:477"><nobr><span class="ft4">which  <i>R</i></span></nobr></DIV>
<DIV style="position:absolute;top:383;left:525"><nobr><span class="ft20"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:377;left:528"><nobr><span class="ft4"> is independent of (<i>R</i>  ­<i>  R</i></span></nobr></DIV>
<DIV style="position:absolute;top:383;left:684"><nobr><span class="ft20"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:377;left:686"><nobr><span class="ft4">), but would maintain the </span></nobr></DIV>
<DIV style="position:absolute;top:393;left:477"><nobr><span class="ft4">distributions of <i>R</i></span></nobr></DIV>
<DIV style="position:absolute;top:399;left:571"><nobr><span class="ft20"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:393;left:574"><nobr><span class="ft4"> and (<i>R</i> ­<i> R</i></span></nobr></DIV>
<DIV style="position:absolute;top:399;left:635"><nobr><span class="ft20"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:393;left:638"><nobr><span class="ft4">) in the permutation dataset to be the </span></nobr></DIV>
<DIV style="position:absolute;top:409;left:477"><nobr><span class="ft4">same as the distributions of these attributes in the original dataset.  </span></nobr></DIV>
<DIV style="position:absolute;top:435;left:477"><nobr><span class="ft4">Table 3.1 illustrates one example of a permutation dataset <i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:433;left:818"><nobr><span class="ft21"> in </span></nobr></DIV>
<DIV style="position:absolute;top:451;left:477"><nobr><span class="ft16">which the <i>B</i> attributes are randomly permuted. Since a desired <br>statistic can be computed on each permutation dataset, a <br>distribution for the statistic can be computed based on its values <br>from the multiple permutation datasets. A confidence interval can <br>then be computed from this distribution. </span></nobr></DIV>
<DIV style="position:absolute;top:539;left:567"><nobr><span class="ft5"><b>Table 3.1  Dataset permutation </b></span></nobr></DIV>
<DIV style="position:absolute;top:561;left:479"><nobr><span class="ft4">Original dataset <i>D</i>:<i> </i></span></nobr></DIV>
<DIV style="position:absolute;top:561;left:650"><nobr><span class="ft33"> </span></nobr></DIV>
<DIV style="position:absolute;top:562;left:680"><nobr><span class="ft4">Permutation dataset <i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:560;left:800"><nobr><span class="ft21">:<i> </i></span></nobr></DIV>
<DIV style="position:absolute;top:584;left:486"><nobr><span class="ft18"><i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:590;left:494"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:584;left:498"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:584;left:528"><nobr><span class="ft18"><i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:590;left:537"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:584;left:541"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:584;left:571"><nobr><span class="ft18"><i>B</i></span></nobr></DIV>
<DIV style="position:absolute;top:590;left:580"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:584;left:584"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:584;left:614"><nobr><span class="ft18"><i>B</i></span></nobr></DIV>
<DIV style="position:absolute;top:590;left:623"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:584;left:627"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:584;left:687"><nobr><span class="ft18"><i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:590;left:695"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:584;left:699"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:584;left:730"><nobr><span class="ft18"><i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:590;left:738"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:584;left:742"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:584;left:772"><nobr><span class="ft18"><i>B</i></span></nobr></DIV>
<DIV style="position:absolute;top:590;left:781"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:584;left:785"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:584;left:815"><nobr><span class="ft18"><i>B</i></span></nobr></DIV>
<DIV style="position:absolute;top:590;left:824"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:584;left:828"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:602;left:489"><nobr><span class="ft34">1 2 <b><i>3 8 </b></i></span></nobr></DIV>
<DIV style="position:absolute;top:602;left:690"><nobr><span class="ft34">1 2 <b><i>5 6 </b></i></span></nobr></DIV>
<DIV style="position:absolute;top:619;left:489"><nobr><span class="ft34">1 3 <b><i>5 6 </b></i></span></nobr></DIV>
<DIV style="position:absolute;top:619;left:690"><nobr><span class="ft34">1 3 <b><i>7 4 </b></i></span></nobr></DIV>
<DIV style="position:absolute;top:635;left:489"><nobr><span class="ft34">2 3 <b><i>7 4 </b></i></span></nobr></DIV>
<DIV style="position:absolute;top:608;left:650"><nobr><span class="ft21"></span></nobr></DIV>
<DIV style="position:absolute;top:610;left:664"><nobr><span class="ft33"> </span></nobr></DIV>
<DIV style="position:absolute;top:635;left:690"><nobr><span class="ft34">2 3 <b><i>3 8 </b></i></span></nobr></DIV>
<DIV style="position:absolute;top:660;left:477"><nobr><span class="ft16">As mentioned above, this is a commonly used procedure in non-<br>parametric statistics. The reason this procedure makes sense is as <br>follows. Even if there is a relationship between the LHS of an SQ <br>rule and the <i>statistic </i>on the RHS, by holding the <i>A</i> attributes fixed <br>and randomly re-ordering the values of the <i>B</i> attributes the <br>relationship is destroyed and the <i>A</i> attributes and <i>B</i> attributes are <br>now independent of each other. Repeating this procedure many <br>times provides many datasets in which the <i>A</i> attributes and <i>B</i> <br>attributes are independent of each other, while maintaining the <br>distributions of the <i>A</i> and <i>B</i> attributes to be the same as their <br>distributions in the original dataset. The values for the statistic <br>computed from the many permutation datasets is used to construct <br>a distribution for the statistic that can be expected when the <i>A</i> <br>attributes are truly independent of the <i>B</i> attributes.  </span></nobr></DIV>
<DIV style="position:absolute;top:891;left:477"><nobr><span class="ft32">Specifically, for the same itemset <i>X</i>, compare the following two <br>SQ rules in <i>D </i>and<i> D</i></span></nobr></DIV>
<DIV style="position:absolute;top:906;left:587"><nobr><span class="ft21">, </span></nobr></DIV>
<DIV style="position:absolute;top:933;left:477"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:933;left:553"><nobr><span class="ft18"><i>D</i>: <i>X</i> </span></nobr></DIV>
<DIV style="position:absolute;top:932;left:581"><nobr><span class="ft21"> <i>f</i>(</span></nobr></DIV>
<DIV style="position:absolute;top:942;left:619"><nobr><span class="ft36"><i>X</i></span></nobr></DIV>
<DIV style="position:absolute;top:933;left:610"><nobr><span class="ft18"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:933;left:629"><nobr><span class="ft4">) = <i>stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:940;left:667"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:933;left:674"><nobr><span class="ft4">, <i>support</i> = <i>sup</i></span></nobr></DIV>
<DIV style="position:absolute;top:940;left:755"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:933;left:762"><nobr><span class="ft4"> (3.1) </span></nobr></DIV>
<DIV style="position:absolute;top:963;left:477"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:963;left:548"><nobr><span class="ft18"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:962;left:557"><nobr><span class="ft21">: <i>X</i>  <i>f</i>(</span></nobr></DIV>
<DIV style="position:absolute;top:972;left:618"><nobr><span class="ft36"><i>X</i></span></nobr></DIV>
<DIV style="position:absolute;top:963;left:608"><nobr><span class="ft18"><i>D</i> ) = <i>stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:970;left:666"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:962;left:672"><nobr><span class="ft21">, <i>support</i> = <i>sup</i></span></nobr></DIV>
<DIV style="position:absolute;top:970;left:757"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:962;left:763"><nobr><span class="ft21"> (3.2) </span></nobr></DIV>
<DIV style="position:absolute;top:993;left:477"><nobr><span class="ft16">First note that the supports of the rules are the same since the <br>number of records satisfying <i>X</i> in the permutation dataset is the <br>same as the original dataset. We will use this observation to build <br>a more efficient method for computing confidence intervals </span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:449"><nobr><span class="ft4">376</span></nobr></DIV>
<DIV style="position:absolute;top:54;left:80"><nobr><span class="ft14"><b>Research Track Paper</b></span></nobr></DIV>
</DIV>
<!-- Page 4 -->
<a name="4"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft37{font-size:7px;font-family:Times;color:#000000;}
	.ft38{font-size:16px;font-family:Times;color:#000000;}
	.ft39{font-size:8px;font-family:Courier;color:#000000;}
	.ft40{font-size:8px;font-family:Times;color:#000000;}
	.ft41{font-size:8px;font-family:Courier;color:#000000;}
	.ft42{font-size:11px;line-height:21px;font-family:Times;color:#000000;}
	.ft43{font-size:11px;line-height:15px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="144004.png" alt="background image">
<DIV style="position:absolute;top:109;left:81"><nobr><span class="ft16">shortly. A confidence interval for the rule in (3.1) can be <br>computed using the following naïve procedure. </span></nobr></DIV>
<DIV style="position:absolute;top:150;left:81"><nobr><span class="ft4">1.</span></nobr></DIV>
<DIV style="position:absolute;top:150;left:91"><nobr><span class="ft27"> </span></nobr></DIV>
<DIV style="position:absolute;top:150;left:108"><nobr><span class="ft4">Create permutation dataset <i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:149;left:275"><nobr><span class="ft21"> from the original dataset <i>D</i> </span></nobr></DIV>
<DIV style="position:absolute;top:167;left:108"><nobr><span class="ft4">and compute <i>stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:173;left:206"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:172;left:212"><nobr><span class="ft37"></span></nobr></DIV>
<DIV style="position:absolute;top:167;left:214"><nobr><span class="ft4"> (as mentioned earlier in Section 2, the </span></nobr></DIV>
<DIV style="position:absolute;top:183;left:108"><nobr><span class="ft16">function  <i>f</i> computes this number based on the records <br>satisfying <i>X</i>).  </span></nobr></DIV>
<DIV style="position:absolute;top:225;left:81"><nobr><span class="ft4">2.</span></nobr></DIV>
<DIV style="position:absolute;top:224;left:91"><nobr><span class="ft27"> </span></nobr></DIV>
<DIV style="position:absolute;top:225;left:108"><nobr><span class="ft4">Repeat step 1 <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:231;left:200"><nobr><span class="ft20"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:225;left:219"><nobr><span class="ft4"> &gt; 1000 times</span></nobr></DIV>
<DIV style="position:absolute;top:226;left:300"><nobr><span class="ft23">3</span></nobr></DIV>
<DIV style="position:absolute;top:225;left:303"><nobr><span class="ft4">, sort all the <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:231;left:389"><nobr><span class="ft20"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:225;left:407"><nobr><span class="ft4">  <i>stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:231;left:432"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:230;left:439"><nobr><span class="ft37"></span></nobr></DIV>
<DIV style="position:absolute;top:225;left:441"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:241;left:108"><nobr><span class="ft4">values in an ascending order (<i>stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:248;left:293"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:247;left:300"><nobr><span class="ft37">-1</span></nobr></DIV>
<DIV style="position:absolute;top:241;left:309"><nobr><span class="ft4">, <i> stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:248;left:340"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:247;left:347"><nobr><span class="ft37">-2</span></nobr></DIV>
<DIV style="position:absolute;top:241;left:357"><nobr><span class="ft4">,..., <i>stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:248;left:401"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:247;left:407"><nobr><span class="ft37">-<i>Nperm</i></span></nobr></DIV>
<DIV style="position:absolute;top:241;left:437"><nobr><span class="ft4">) </span></nobr></DIV>
<DIV style="position:absolute;top:258;left:108"><nobr><span class="ft4">and let the </span></nobr></DIV>
<DIV style="position:absolute;top:257;left:171"><nobr><span class="ft21">/2</span></nobr></DIV>
<DIV style="position:absolute;top:256;left:190"><nobr><span class="ft19">th</span></nobr></DIV>
<DIV style="position:absolute;top:258;left:197"><nobr><span class="ft4"> and (1 ­ </span></nobr></DIV>
<DIV style="position:absolute;top:257;left:251"><nobr><span class="ft21">/2)</span></nobr></DIV>
<DIV style="position:absolute;top:256;left:275"><nobr><span class="ft19">th</span></nobr></DIV>
<DIV style="position:absolute;top:258;left:282"><nobr><span class="ft4"> percentiles</span></nobr></DIV>
<DIV style="position:absolute;top:256;left:345"><nobr><span class="ft19">4</span></nobr></DIV>
<DIV style="position:absolute;top:258;left:349"><nobr><span class="ft4"> from this list be </span></nobr></DIV>
<DIV style="position:absolute;top:275;left:108"><nobr><span class="ft18"><i>stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:281;left:128"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:280;left:134"><nobr><span class="ft37">-<i>L</i></span></nobr></DIV>
<DIV style="position:absolute;top:275;left:144"><nobr><span class="ft4"> and <i>stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:281;left:203"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:280;left:209"><nobr><span class="ft37">-<i>H</i></span></nobr></DIV>
<DIV style="position:absolute;top:275;left:221"><nobr><span class="ft4">. The <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:281;left:274"><nobr><span class="ft20"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:275;left:292"><nobr><span class="ft4"> values computed above </span></nobr></DIV>
<DIV style="position:absolute;top:291;left:108"><nobr><span class="ft16">represents a distribution for the statistic that can be expected <br>by chance alone, while the percentile values from this <br>distribution determine a specific confidence interval. (Below <br>we use the terms "distribution" and "confidence interval" <br>frequently.) </span></nobr></DIV>
<DIV style="position:absolute;top:380;left:81"><nobr><span class="ft4">3.</span></nobr></DIV>
<DIV style="position:absolute;top:380;left:91"><nobr><span class="ft27"> </span></nobr></DIV>
<DIV style="position:absolute;top:380;left:108"><nobr><span class="ft4">The (1 ­ </span></nobr></DIV>
<DIV style="position:absolute;top:379;left:161"><nobr><span class="ft21">) confidence interval for the SQ rule in Equation </span></nobr></DIV>
<DIV style="position:absolute;top:397;left:108"><nobr><span class="ft4">(3.1) is (<i>stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:403;left:174"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:402;left:180"><nobr><span class="ft37">-<i>L</i></span></nobr></DIV>
<DIV style="position:absolute;top:397;left:191"><nobr><span class="ft4">, <i>stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:403;left:217"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:402;left:223"><nobr><span class="ft37">-<i>H</i></span></nobr></DIV>
<DIV style="position:absolute;top:397;left:235"><nobr><span class="ft4">). </span></nobr></DIV>
<DIV style="position:absolute;top:422;left:81"><nobr><span class="ft3"><b>3.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:422;left:104"><nobr><span class="ft6"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:422;left:114"><nobr><span class="ft3"><b>Computational challenges and solutions </b></span></nobr></DIV>
<DIV style="position:absolute;top:443;left:81"><nobr><span class="ft32">Computing these confidence intervals for multiple candidate SQ <br>rules creates several computational problems which we will <br>address in this section. For example, if we need to test 10,000 <br>potential significant rules (which is a reasonably small number for <br>data mining tasks), then we would need to repeat the above steps <br>10,000 times, and this means generating permutation datasets <br>10,000 </span></nobr></DIV>
<DIV style="position:absolute;top:537;left:122"><nobr><span class="ft21">× <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:545;left:143"><nobr><span class="ft20"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:539;left:161"><nobr><span class="ft4"> &gt; 10</span></nobr></DIV>
<DIV style="position:absolute;top:537;left:191"><nobr><span class="ft19">7</span></nobr></DIV>
<DIV style="position:absolute;top:539;left:195"><nobr><span class="ft4"> times and to compute the desired statistic in </span></nobr></DIV>
<DIV style="position:absolute;top:555;left:81"><nobr><span class="ft4">each permutation dataset.  </span></nobr></DIV>
<DIV style="position:absolute;top:580;left:81"><nobr><span class="ft32">The following observations substantially reduce the <br>computational complexity of the procedure. <br>1. <i>Sampling can be used instead of creating permutation datasets</i>. <br>For the SQ rule in Equation (3.1), computing <i>stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:640;left:395"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:639;left:401"><nobr><span class="ft37"></span></nobr></DIV>
<DIV style="position:absolute;top:634;left:403"><nobr><span class="ft4"> on a </span></nobr></DIV>
<DIV style="position:absolute;top:651;left:81"><nobr><span class="ft4">permutation dataset is really equivalent to computing <i>stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:657;left:399"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:656;left:405"><nobr><span class="ft37"> </span></nobr></DIV>
<DIV style="position:absolute;top:651;left:410"><nobr><span class="ft4">based </span></nobr></DIV>
<DIV style="position:absolute;top:667;left:81"><nobr><span class="ft4">on a random sample of <i>sup</i></span></nobr></DIV>
<DIV style="position:absolute;top:673;left:233"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:667;left:240"><nobr><span class="ft4"> records in <i>D</i>. This is the case since </span></nobr></DIV>
<DIV style="position:absolute;top:683;left:81"><nobr><span class="ft16">none of the <i>A</i> attributes play a role in the computation of the <br>statistic. Permuting the dataset, identifying the (<i>sup</i></span></nobr></DIV>
<DIV style="position:absolute;top:705;left:383"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:698;left:390"><nobr><span class="ft4">) records </span></nobr></DIV>
<DIV style="position:absolute;top:714;left:81"><nobr><span class="ft16">where  <i>X</i> holds, and then computing the statistic on this subset <br>achieves the same effect as picking a random sample of <i>sup</i></span></nobr></DIV>
<DIV style="position:absolute;top:736;left:435"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:730;left:441"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:746;left:81"><nobr><span class="ft16">records from <i>D</i> and computing the statistic on this random subset. <br>Hence to determine the confidence interval for the SQ rule in <br>Equation (3.1), instead of permuting the dataset <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:784;left:360"><nobr><span class="ft20"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:778;left:378"><nobr><span class="ft4"> times, it is </span></nobr></DIV>
<DIV style="position:absolute;top:793;left:81"><nobr><span class="ft4">enough to sample <i>sup</i></span></nobr></DIV>
<DIV style="position:absolute;top:800;left:199"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:793;left:205"><nobr><span class="ft4"> records from <i>D</i> for <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:800;left:323"><nobr><span class="ft20"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:793;left:341"><nobr><span class="ft4"> times.  </span></nobr></DIV>
<DIV style="position:absolute;top:818;left:81"><nobr><span class="ft16">2. <i>Some of the candidate SQ rules have the same support values <br>as other rules</i>. Based on this observation, confidence intervals for <br>two SQ rules with the same support can be approximated by the <br>same interval. This is the case since for a given rule the interval is <br>generated by sampling <i>sup</i></span></nobr></DIV>
<DIV style="position:absolute;top:888;left:233"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:882;left:239"><nobr><span class="ft4"> records many times and if another </span></nobr></DIV>
<DIV style="position:absolute;top:898;left:81"><nobr><span class="ft4">rule has <i>support</i> = <i>sup</i></span></nobr></DIV>
<DIV style="position:absolute;top:904;left:213"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:898;left:219"><nobr><span class="ft4"> then the interval for that rule will be </span></nobr></DIV>
<DIV style="position:absolute;top:913;left:81"><nobr><span class="ft32">similar if the same procedure is repeated (it will not be exactly the <br>                                                                 </span></nobr></DIV>
<DIV style="position:absolute;top:950;left:81"><nobr><span class="ft19">3</span></nobr></DIV>
<DIV style="position:absolute;top:952;left:86"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:953;left:89"><nobr><span class="ft12"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:959;left:97"><nobr><span class="ft36"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:953;left:113"><nobr><span class="ft11"> is typically a big number. If we let <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:959;left:295"><nobr><span class="ft36"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:953;left:311"><nobr><span class="ft11"> = <i>N</i>!, which is the number </span></nobr></DIV>
<DIV style="position:absolute;top:968;left:92"><nobr><span class="ft17">of all possible permutations, we will be implementing a Monte Carlo <br>test. On large datasets, such a test is impractical. For a <i>statistic</i> like <br>market share whose value is limited by 0 and 1, <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:1002;left:336"><nobr><span class="ft36"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:996;left:351"><nobr><span class="ft11"> &gt; 1000 makes the </span></nobr></DIV>
<DIV style="position:absolute;top:1010;left:92"><nobr><span class="ft11">distribution precise to the third decimal place. In our experiments, <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:1016;left:426"><nobr><span class="ft36"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:1010;left:441"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:1024;left:92"><nobr><span class="ft11">= 1999. </span></nobr></DIV>
<DIV style="position:absolute;top:1043;left:81"><nobr><span class="ft19">4</span></nobr></DIV>
<DIV style="position:absolute;top:1045;left:86"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:1046;left:90"><nobr><span class="ft11">Since we do not have any prior assumption about the expected value of </span></nobr></DIV>
<DIV style="position:absolute;top:1060;left:92"><nobr><span class="ft11">the statistic we use a two sided <i>p</i>-value. </span></nobr></DIV>
<DIV style="position:absolute;top:109;left:477"><nobr><span class="ft16">same because of randomization). Therefore, fewer confidence <br>intervals need to be generated.  </span></nobr></DIV>
<DIV style="position:absolute;top:149;left:477"><nobr><span class="ft16">3.  <i>It is adequate to generate a fixed number of intervals, <br>independent of the number of rules considered</i>. We observe that <br>the interval for an SQ rule with <i>support</i> = <i>sup</i></span></nobr></DIV>
<DIV style="position:absolute;top:187;left:780"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:181;left:786"><nobr><span class="ft4"> can be </span></nobr></DIV>
<DIV style="position:absolute;top:197;left:477"><nobr><span class="ft4">approximated by an interval computed by sampling <i>sup</i></span></nobr></DIV>
<DIV style="position:absolute;top:203;left:787"><nobr><span class="ft20"><i>E</i></span></nobr></DIV>
<DIV style="position:absolute;top:197;left:793"><nobr><span class="ft4"> records </span></nobr></DIV>
<DIV style="position:absolute;top:213;left:477"><nobr><span class="ft4">where <i>sup</i></span></nobr></DIV>
<DIV style="position:absolute;top:219;left:533"><nobr><span class="ft20"><i>E</i></span></nobr></DIV>
<DIV style="position:absolute;top:213;left:539"><nobr><span class="ft4"> is "reasonably close" to <i>sup</i></span></nobr></DIV>
<DIV style="position:absolute;top:219;left:698"><nobr><span class="ft20"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:213;left:705"><nobr><span class="ft4">. This is a heuristic that </span></nobr></DIV>
<DIV style="position:absolute;top:228;left:477"><nobr><span class="ft16">we use to considerably reduce the complexity of the procedure. <br>Denote <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:251;left:529"><nobr><span class="ft20"><i>Rule</i></span></nobr></DIV>
<DIV style="position:absolute;top:244;left:546"><nobr><span class="ft4"> as the number of rules to be tested. If all rules have </span></nobr></DIV>
<DIV style="position:absolute;top:260;left:477"><nobr><span class="ft4">different <i>support</i> values, we need to construct <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:266;left:745"><nobr><span class="ft20"><i>Rule</i></span></nobr></DIV>
<DIV style="position:absolute;top:260;left:761"><nobr><span class="ft4"> distributions. </span></nobr></DIV>
<DIV style="position:absolute;top:276;left:477"><nobr><span class="ft4">Instead, we would construct a fixed number <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:282;left:747"><nobr><span class="ft20"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:276;left:760"><nobr><span class="ft4"> distributions, </span></nobr></DIV>
<DIV style="position:absolute;top:293;left:477"><nobr><span class="ft4">such that for rule "<i>X</i> </span></nobr></DIV>
<DIV style="position:absolute;top:291;left:594"><nobr><span class="ft21"> <i>f</i>(<i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:299;left:630"><nobr><span class="ft20"><i>X</i></span></nobr></DIV>
<DIV style="position:absolute;top:293;left:635"><nobr><span class="ft4">) = <i>statistic</i>, <i>support</i> = <i>sup</i>", <i>statistic</i> </span></nobr></DIV>
<DIV style="position:absolute;top:309;left:477"><nobr><span class="ft16">is compared with the distribution that is constructed by sampling <br>the closest number of transactions to <i>sup</i>. This heuristic is more <br>meaningful when we consider <i>support</i> in terms of percentage of <br>transactions satisfying LHS of a rule, which is a number between <br>0 and 1.  </span></nobr></DIV>
<DIV style="position:absolute;top:397;left:477"><nobr><span class="ft3"><b>3.3</b></span></nobr></DIV>
<DIV style="position:absolute;top:397;left:499"><nobr><span class="ft6"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:397;left:510"><nobr><span class="ft3"><b>Algorithm <i>CIComp</i> </b></span></nobr></DIV>
<DIV style="position:absolute;top:418;left:477"><nobr><span class="ft16">Based on the above observations, we present in Figure 3.1 <br>algorithm  <i>CIComp</i> for constructing <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:440;left:714"><nobr><span class="ft20"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:434;left:727"><nobr><span class="ft4"> distributions and </span></nobr></DIV>
<DIV style="position:absolute;top:451;left:477"><nobr><span class="ft4">determining the (1 ­ </span></nobr></DIV>
<DIV style="position:absolute;top:449;left:617"><nobr><span class="ft21">) confidence intervals for a given </span></nobr></DIV>
<DIV style="position:absolute;top:466;left:477"><nobr><span class="ft4">significance level. </span></nobr></DIV>
<DIV style="position:absolute;top:501;left:477"><nobr><span class="ft39"><b>Input</b>: dataset </span></nobr></DIV>
<DIV style="position:absolute;top:500;left:581"><nobr><span class="ft40"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:501;left:588"><nobr><span class="ft7"> with </span></nobr></DIV>
<DIV style="position:absolute;top:500;left:635"><nobr><span class="ft40"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:501;left:642"><nobr><span class="ft7"> transactions, the number of </span></nobr></DIV>
<DIV style="position:absolute;top:514;left:477"><nobr><span class="ft7">distributions </span></nobr></DIV>
<DIV style="position:absolute;top:513;left:574"><nobr><span class="ft40"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:518;left:581"><nobr><span class="ft24"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:514;left:591"><nobr><span class="ft7">, the number of points in each </span></nobr></DIV>
<DIV style="position:absolute;top:528;left:477"><nobr><span class="ft7">distribution </span></nobr></DIV>
<DIV style="position:absolute;top:527;left:560"><nobr><span class="ft40"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:532;left:567"><nobr><span class="ft24"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:528;left:581"><nobr><span class="ft7">, a function </span></nobr></DIV>
<DIV style="position:absolute;top:526;left:666"><nobr><span class="ft12"><i>f</i></span></nobr></DIV>
<DIV style="position:absolute;top:528;left:669"><nobr><span class="ft7"> that computes the desired </span></nobr></DIV>
<DIV style="position:absolute;top:541;left:477"><nobr><span class="ft7">statistic, and significance level </span></nobr></DIV>
<DIV style="position:absolute;top:539;left:691"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:541;left:698"><nobr><span class="ft7">. </span></nobr></DIV>
<DIV style="position:absolute;top:560;left:477"><nobr><span class="ft39"><b>Output</b>: </span></nobr></DIV>
<DIV style="position:absolute;top:559;left:527"><nobr><span class="ft40"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:564;left:534"><nobr><span class="ft24"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:560;left:544"><nobr><span class="ft7"> distributions and significance thresholds. </span></nobr></DIV>
<DIV style="position:absolute;top:581;left:477"><nobr><span class="ft7">1 </span></nobr></DIV>
<DIV style="position:absolute;top:583;left:506"><nobr><span class="ft7">for ( </span></nobr></DIV>
<DIV style="position:absolute;top:582;left:544"><nobr><span class="ft40"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:583;left:559"><nobr><span class="ft7"> = 1; </span></nobr></DIV>
<DIV style="position:absolute;top:582;left:597"><nobr><span class="ft40"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:583;left:612"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:581;left:618"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:583;left:624"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:582;left:630"><nobr><span class="ft40"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:587;left:637"><nobr><span class="ft24"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:583;left:647"><nobr><span class="ft7">; </span></nobr></DIV>
<DIV style="position:absolute;top:582;left:660"><nobr><span class="ft40"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:583;left:675"><nobr><span class="ft7">++ ) { </span></nobr></DIV>
<DIV style="position:absolute;top:594;left:477"><nobr><span class="ft7">2 </span></nobr></DIV>
<DIV style="position:absolute;top:596;left:506"><nobr><span class="ft7">    </span></nobr></DIV>
<DIV style="position:absolute;top:596;left:531"><nobr><span class="ft40"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:601;left:538"><nobr><span class="ft24"><i>sample</i></span></nobr></DIV>
<DIV style="position:absolute;top:596;left:557"><nobr><span class="ft7"> = </span></nobr></DIV>
<DIV style="position:absolute;top:596;left:576"><nobr><span class="ft40"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:596;left:591"><nobr><span class="ft7">/</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:598"><nobr><span class="ft40"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:601;left:605"><nobr><span class="ft24"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:596;left:615"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:594;left:621"><nobr><span class="ft8">×</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:627"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:596;left:633"><nobr><span class="ft40"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:596;left:640"><nobr><span class="ft7">;    </span></nobr></DIV>
<DIV style="position:absolute;top:608;left:477"><nobr><span class="ft7">3 </span></nobr></DIV>
<DIV style="position:absolute;top:609;left:506"><nobr><span class="ft7">    for ( </span></nobr></DIV>
<DIV style="position:absolute;top:608;left:569"><nobr><span class="ft40"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:609;left:590"><nobr><span class="ft7"> = 1; </span></nobr></DIV>
<DIV style="position:absolute;top:608;left:628"><nobr><span class="ft40"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:609;left:650"><nobr><span class="ft7"> &lt; </span></nobr></DIV>
<DIV style="position:absolute;top:608;left:669"><nobr><span class="ft40"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:613;left:676"><nobr><span class="ft24"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:609;left:690"><nobr><span class="ft7">; </span></nobr></DIV>
<DIV style="position:absolute;top:608;left:702"><nobr><span class="ft40"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:609;left:724"><nobr><span class="ft7">++ ) { </span></nobr></DIV>
<DIV style="position:absolute;top:620;left:477"><nobr><span class="ft7">4 </span></nobr></DIV>
<DIV style="position:absolute;top:622;left:506"><nobr><span class="ft7">        </span></nobr></DIV>
<DIV style="position:absolute;top:621;left:556"><nobr><span class="ft40"><i>S</i></span></nobr></DIV>
<DIV style="position:absolute;top:622;left:561"><nobr><span class="ft7"> = </span></nobr></DIV>
<DIV style="position:absolute;top:621;left:581"><nobr><span class="ft40"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:626;left:588"><nobr><span class="ft24"><i>sample</i></span></nobr></DIV>
<DIV style="position:absolute;top:622;left:607"><nobr><span class="ft7"> transactions from </span></nobr></DIV>
<DIV style="position:absolute;top:621;left:728"><nobr><span class="ft40"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:622;left:736"><nobr><span class="ft7"> sampled without </span></nobr></DIV>
<DIV style="position:absolute;top:637;left:589"><nobr><span class="ft7">replacements</span></nobr></DIV>
<DIV style="position:absolute;top:632;left:665"><nobr><span class="ft19">5</span></nobr></DIV>
<DIV style="position:absolute;top:637;left:669"><nobr><span class="ft7">; </span></nobr></DIV>
<DIV style="position:absolute;top:649;left:477"><nobr><span class="ft7">5 </span></nobr></DIV>
<DIV style="position:absolute;top:650;left:506"><nobr><span class="ft7">        <i>stat</i>[</span></nobr></DIV>
<DIV style="position:absolute;top:650;left:588"><nobr><span class="ft40"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:650;left:603"><nobr><span class="ft7">][</span></nobr></DIV>
<DIV style="position:absolute;top:650;left:616"><nobr><span class="ft40"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:650;left:637"><nobr><span class="ft7">] = </span></nobr></DIV>
<DIV style="position:absolute;top:650;left:662"><nobr><span class="ft40"><i>f</i></span></nobr></DIV>
<DIV style="position:absolute;top:650;left:665"><nobr><span class="ft7">(</span></nobr></DIV>
<DIV style="position:absolute;top:650;left:672"><nobr><span class="ft40"><i>S</i></span></nobr></DIV>
<DIV style="position:absolute;top:650;left:677"><nobr><span class="ft7">); </span></nobr></DIV>
<DIV style="position:absolute;top:661;left:477"><nobr><span class="ft7">6 </span></nobr></DIV>
<DIV style="position:absolute;top:661;left:506"><nobr><span class="ft7">    } </span></nobr></DIV>
<DIV style="position:absolute;top:673;left:477"><nobr><span class="ft7">7 </span></nobr></DIV>
<DIV style="position:absolute;top:674;left:506"><nobr><span class="ft7">    sort(<i>stat</i>[</span></nobr></DIV>
<DIV style="position:absolute;top:674;left:594"><nobr><span class="ft40"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:674;left:609"><nobr><span class="ft7">]); </span></nobr></DIV>
<DIV style="position:absolute;top:685;left:477"><nobr><span class="ft7">8 </span></nobr></DIV>
<DIV style="position:absolute;top:688;left:506"><nobr><span class="ft7">    <i>LowerCI</i>[</span></nobr></DIV>
<DIV style="position:absolute;top:687;left:581"><nobr><span class="ft40"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:688;left:597"><nobr><span class="ft7">] = <i>stat</i>[</span></nobr></DIV>
<DIV style="position:absolute;top:687;left:653"><nobr><span class="ft40"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:688;left:669"><nobr><span class="ft7">][(</span></nobr></DIV>
<DIV style="position:absolute;top:687;left:688"><nobr><span class="ft40"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:692;left:695"><nobr><span class="ft24"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:688;left:709"><nobr><span class="ft7"> + 1) </span></nobr></DIV>
<DIV style="position:absolute;top:686;left:746"><nobr><span class="ft8">×</span></nobr></DIV>
<DIV style="position:absolute;top:688;left:752"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:686;left:758"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:688;left:765"><nobr><span class="ft7">/2]; </span></nobr></DIV>
<DIV style="position:absolute;top:699;left:477"><nobr><span class="ft7">9 </span></nobr></DIV>
<DIV style="position:absolute;top:701;left:506"><nobr><span class="ft7">    <i>UpperCI</i>[</span></nobr></DIV>
<DIV style="position:absolute;top:701;left:581"><nobr><span class="ft40"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:701;left:597"><nobr><span class="ft7">] = <i>stat</i>[</span></nobr></DIV>
<DIV style="position:absolute;top:701;left:653"><nobr><span class="ft40"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:701;left:669"><nobr><span class="ft7">][(</span></nobr></DIV>
<DIV style="position:absolute;top:701;left:688"><nobr><span class="ft40"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:705;left:695"><nobr><span class="ft24"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:701;left:709"><nobr><span class="ft7"> + 1) </span></nobr></DIV>
<DIV style="position:absolute;top:699;left:746"><nobr><span class="ft8">×</span></nobr></DIV>
<DIV style="position:absolute;top:701;left:752"><nobr><span class="ft7"> (1 ­ </span></nobr></DIV>
<DIV style="position:absolute;top:699;left:790"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:701;left:797"><nobr><span class="ft7">/2)]; </span></nobr></DIV>
<DIV style="position:absolute;top:712;left:477"><nobr><span class="ft7">10 } </span></nobr></DIV>
<DIV style="position:absolute;top:724;left:477"><nobr><span class="ft7">11  Output <i>stat</i>[][], <i>LowerCI</i>[], <i>UpperCI</i>[] </span></nobr></DIV>
<DIV style="position:absolute;top:745;left:569"><nobr><span class="ft5"><b>Figure 3.1  Algorithm <i>CIComp</i> </b></span></nobr></DIV>
<DIV style="position:absolute;top:777;left:477"><nobr><span class="ft4">In the above algorithm, <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:783;left:636"><nobr><span class="ft20"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:777;left:649"><nobr><span class="ft4">,  <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:783;left:669"><nobr><span class="ft20"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:777;left:688"><nobr><span class="ft4">, and </span></nobr></DIV>
<DIV style="position:absolute;top:775;left:728"><nobr><span class="ft21"> are user-defined </span></nobr></DIV>
<DIV style="position:absolute;top:794;left:477"><nobr><span class="ft4">parameters. </span></nobr></DIV>
<DIV style="position:absolute;top:792;left:544"><nobr><span class="ft21"> is usually chosen to be 5%, 2.5% or 1%. For <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:800;left:824"><nobr><span class="ft20"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:794;left:837"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:809;left:477"><nobr><span class="ft4">and  <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:816;left:511"><nobr><span class="ft20"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:809;left:529"><nobr><span class="ft4">, the larger they are, the more precise the distributions </span></nobr></DIV>
<DIV style="position:absolute;top:826;left:477"><nobr><span class="ft4">will be. Let <i>N</i> = 1000, <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:833;left:615"><nobr><span class="ft20"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:826;left:628"><nobr><span class="ft4"> = 100, <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:833;left:681"><nobr><span class="ft20"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:826;left:700"><nobr><span class="ft4"> = 999, and </span></nobr></DIV>
<DIV style="position:absolute;top:825;left:768"><nobr><span class="ft21"> = 5%. We </span></nobr></DIV>
<DIV style="position:absolute;top:842;left:477"><nobr><span class="ft32">use these numbers as an example to explain the algorithm. For <br>step 2, the first distribution corresponds to <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:865;left:725"><nobr><span class="ft20"><i>sample</i></span></nobr></DIV>
<DIV style="position:absolute;top:859;left:750"><nobr><span class="ft4"> = <i>dist/N</i></span></nobr></DIV>
<DIV style="position:absolute;top:865;left:799"><nobr><span class="ft20"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:859;left:812"><nobr><span class="ft18"><i> </i></span></nobr></DIV>
<DIV style="position:absolute;top:857;left:816"><nobr><span class="ft22">×</span></nobr></DIV>
<DIV style="position:absolute;top:859;left:824"><nobr><span class="ft18"><i> N</i> </span></nobr></DIV>
<DIV style="position:absolute;top:876;left:477"><nobr><span class="ft4">= 1/100 </span></nobr></DIV>
<DIV style="position:absolute;top:874;left:525"><nobr><span class="ft21">× 1000 = 10 transactions. Step 3 to 6 computes <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:882;left:806"><nobr><span class="ft20"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:876;left:824"><nobr><span class="ft4"> = </span></nobr></DIV>
<DIV style="position:absolute;top:892;left:477"><nobr><span class="ft32">999 statistics for 10 randomly sampled transactions from dataset <br><i>D</i>. Then we sort these 999 statistics and pick </span></nobr></DIV>
<DIV style="position:absolute;top:907;left:743"><nobr><span class="ft21">/2 and 1 ­ /2 </span></nobr></DIV>
<DIV style="position:absolute;top:924;left:477"><nobr><span class="ft4">percentiles, which are the 25</span></nobr></DIV>
<DIV style="position:absolute;top:922;left:659"><nobr><span class="ft19">th</span></nobr></DIV>
<DIV style="position:absolute;top:924;left:666"><nobr><span class="ft4"> and 975</span></nobr></DIV>
<DIV style="position:absolute;top:922;left:726"><nobr><span class="ft19">th</span></nobr></DIV>
<DIV style="position:absolute;top:924;left:733"><nobr><span class="ft4"> numbers in the </span></nobr></DIV>
<DIV style="position:absolute;top:941;left:477"><nobr><span class="ft4">distribution, as the lower and upper thresholds for the (1 ­ </span></nobr></DIV>
<DIV style="position:absolute;top:940;left:824"><nobr><span class="ft21">) </span></nobr></DIV>
<DIV style="position:absolute;top:957;left:477"><nobr><span class="ft4">confidence interval. Steps 2 through 9 are repeated <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:963;left:784"><nobr><span class="ft20"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:957;left:797"><nobr><span class="ft4"> = 100 </span></nobr></DIV>
<DIV style="position:absolute;top:973;left:477"><nobr><span class="ft42">times to get the desired number of distributions and confidence <br>intervals.  <br>                                                                 </span></nobr></DIV>
<DIV style="position:absolute;top:1031;left:477"><nobr><span class="ft30">5</span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:481"><nobr><span class="ft11"> If the sampling is done with replacement then the interval will be the </span></nobr></DIV>
<DIV style="position:absolute;top:1046;left:488"><nobr><span class="ft17">bootstrap confidence interval. The two intervals will essentially be the <br>same when the support of the itemset is small. </span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:449"><nobr><span class="ft4">377</span></nobr></DIV>
<DIV style="position:absolute;top:54;left:681"><nobr><span class="ft14"><b>Research Track Paper</b></span></nobr></DIV>
</DIV>
<!-- Page 5 -->
<a name="5"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft44{font-size:4px;font-family:Courier;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="144005.png" alt="background image">
<DIV style="position:absolute;top:109;left:81"><nobr><span class="ft16">The computation complexity of the algorithm in Figure 3.1 is O(<i>N</i> <br>× <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:132;left:101"><nobr><span class="ft20"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:125;left:120"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:124;left:123"><nobr><span class="ft21">× <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:132;left:144"><nobr><span class="ft20"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:125;left:157"><nobr><span class="ft4">), whereas the complexity of naïve method is O(<i>N</i> </span></nobr></DIV>
<DIV style="position:absolute;top:124;left:434"><nobr><span class="ft21">× </span></nobr></DIV>
<DIV style="position:absolute;top:142;left:81"><nobr><span class="ft18"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:148;left:90"><nobr><span class="ft20"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:142;left:108"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:141;left:114"><nobr><span class="ft21">×  <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:148;left:135"><nobr><span class="ft20"><i>rule</i></span></nobr></DIV>
<DIV style="position:absolute;top:142;left:150"><nobr><span class="ft4">). Note that <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:148;left:229"><nobr><span class="ft20"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:142;left:242"><nobr><span class="ft4"> can be fixed to a reasonable small </span></nobr></DIV>
<DIV style="position:absolute;top:158;left:81"><nobr><span class="ft4">number, e.g. 100, whereas <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:164;left:245"><nobr><span class="ft20"><i>rule</i></span></nobr></DIV>
<DIV style="position:absolute;top:158;left:260"><nobr><span class="ft4"> is the number of rules that are </span></nobr></DIV>
<DIV style="position:absolute;top:174;left:81"><nobr><span class="ft16">being tested and can easily be orders of magnitude more than <br><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:196;left:90"><nobr><span class="ft20"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:190;left:103"><nobr><span class="ft4">.  </span></nobr></DIV>
<DIV style="position:absolute;top:224;left:81"><nobr><span class="ft3"><b>4.</b></span></nobr></DIV>
<DIV style="position:absolute;top:224;left:95"><nobr><span class="ft6"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:224;left:105"><nobr><span class="ft3"><b>DISCOVERING SQ RULES </b></span></nobr></DIV>
<DIV style="position:absolute;top:245;left:81"><nobr><span class="ft16">Given the distributions and confidence intervals, discovering all <br>significant statistical rules is straightforward. Algorithm <br><i>SigSQrules</i> is presented in Figure 4.1. </span></nobr></DIV>
<DIV style="position:absolute;top:311;left:81"><nobr><span class="ft39"><b>Input</b>: dataset </span></nobr></DIV>
<DIV style="position:absolute;top:310;left:177"><nobr><span class="ft40"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:311;left:185"><nobr><span class="ft7"> with </span></nobr></DIV>
<DIV style="position:absolute;top:310;left:224"><nobr><span class="ft40"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:311;left:231"><nobr><span class="ft7"> transactions, sets of attributes </span></nobr></DIV>
<DIV style="position:absolute;top:322;left:81"><nobr><span class="ft41"><i>A</i> and <i>B</i>,  <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:327;left:153"><nobr><span class="ft44"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:322;left:169"><nobr><span class="ft7">,  <i>stat</i>[][],  <i>LowerCI</i>[], and <i>UpperCI</i>[] from </span></nobr></DIV>
<DIV style="position:absolute;top:335;left:81"><nobr><span class="ft7">algorithm </span></nobr></DIV>
<DIV style="position:absolute;top:334;left:146"><nobr><span class="ft40"><i>CIComp</i></span></nobr></DIV>
<DIV style="position:absolute;top:335;left:181"><nobr><span class="ft7">, a function </span></nobr></DIV>
<DIV style="position:absolute;top:334;left:268"><nobr><span class="ft40"><i>f</i></span></nobr></DIV>
<DIV style="position:absolute;top:335;left:271"><nobr><span class="ft7"> that computes the desired </span></nobr></DIV>
<DIV style="position:absolute;top:348;left:81"><nobr><span class="ft7">statistic, minimum support </span></nobr></DIV>
<DIV style="position:absolute;top:347;left:266"><nobr><span class="ft40"><i>minsup</i></span></nobr></DIV>
<DIV style="position:absolute;top:348;left:296"><nobr><span class="ft7"> and a large itemset </span></nobr></DIV>
<DIV style="position:absolute;top:360;left:81"><nobr><span class="ft7">generation procedure </span></nobr></DIV>
<DIV style="position:absolute;top:360;left:213"><nobr><span class="ft40"><i>largeitemsets</i></span></nobr></DIV>
<DIV style="position:absolute;top:360;left:270"><nobr><span class="ft7">. </span></nobr></DIV>
<DIV style="position:absolute;top:380;left:81"><nobr><span class="ft39"><b>Output</b>: set of </span></nobr></DIV>
<DIV style="position:absolute;top:378;left:176"><nobr><span class="ft8"> </span></nobr></DIV>
<DIV style="position:absolute;top:380;left:185"><nobr><span class="ft7">Significant rules, <i>sigrules</i>. </span></nobr></DIV>
<DIV style="position:absolute;top:400;left:81"><nobr><span class="ft7">1 </span></nobr></DIV>
<DIV style="position:absolute;top:402;left:110"><nobr><span class="ft7">L = </span></nobr></DIV>
<DIV style="position:absolute;top:401;left:135"><nobr><span class="ft40"><i>largeitemsets</i></span></nobr></DIV>
<DIV style="position:absolute;top:402;left:192"><nobr><span class="ft7">(</span></nobr></DIV>
<DIV style="position:absolute;top:401;left:198"><nobr><span class="ft40"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:402;left:205"><nobr><span class="ft7">, </span></nobr></DIV>
<DIV style="position:absolute;top:401;left:218"><nobr><span class="ft40"><i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:402;left:224"><nobr><span class="ft7">, </span></nobr></DIV>
<DIV style="position:absolute;top:401;left:237"><nobr><span class="ft40"><i>minsup</i></span></nobr></DIV>
<DIV style="position:absolute;top:402;left:268"><nobr><span class="ft7">) # generates large </span></nobr></DIV>
<DIV style="position:absolute;top:413;left:110"><nobr><span class="ft7">itemsets involving attributes in A </span></nobr></DIV>
<DIV style="position:absolute;top:424;left:81"><nobr><span class="ft7">2 </span></nobr></DIV>
<DIV style="position:absolute;top:424;left:110"><nobr><span class="ft7">sigrules = {} </span></nobr></DIV>
<DIV style="position:absolute;top:436;left:81"><nobr><span class="ft7">3 </span></nobr></DIV>
<DIV style="position:absolute;top:438;left:110"><nobr><span class="ft7">forall (itemsets </span></nobr></DIV>
<DIV style="position:absolute;top:437;left:217"><nobr><span class="ft12"><i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:438;left:222"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:437;left:229"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:438;left:236"><nobr><span class="ft7"> L) { </span></nobr></DIV>
<DIV style="position:absolute;top:450;left:81"><nobr><span class="ft7">4 </span></nobr></DIV>
<DIV style="position:absolute;top:453;left:110"><nobr><span class="ft7">    </span></nobr></DIV>
<DIV style="position:absolute;top:451;left:135"><nobr><span class="ft12"><i>x.stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:453;left:161"><nobr><span class="ft7"> = </span></nobr></DIV>
<DIV style="position:absolute;top:452;left:180"><nobr><span class="ft40"><i>f</i></span></nobr></DIV>
<DIV style="position:absolute;top:453;left:183"><nobr><span class="ft7">(</span></nobr></DIV>
<DIV style="position:absolute;top:452;left:189"><nobr><span class="ft40"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:457;left:196"><nobr><span class="ft24"><i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:453;left:199"><nobr><span class="ft7">) // statistic computed on </span></nobr></DIV>
<DIV style="position:absolute;top:465;left:168"><nobr><span class="ft7">transactions satisfying </span></nobr></DIV>
<DIV style="position:absolute;top:465;left:319"><nobr><span class="ft40"><i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:465;left:324"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:477;left:81"><nobr><span class="ft7">5 </span></nobr></DIV>
<DIV style="position:absolute;top:479;left:110"><nobr><span class="ft7">    </span></nobr></DIV>
<DIV style="position:absolute;top:478;left:135"><nobr><span class="ft40"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:479;left:150"><nobr><span class="ft7"> = <i>round</i>(</span></nobr></DIV>
<DIV style="position:absolute;top:478;left:207"><nobr><span class="ft40"><i>support</i>(<i>x</i>) </span></nobr></DIV>
<DIV style="position:absolute;top:479;left:254"><nobr><span class="ft7">/ </span></nobr></DIV>
<DIV style="position:absolute;top:478;left:267"><nobr><span class="ft40"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:479;left:274"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:477;left:280"><nobr><span class="ft8">×</span></nobr></DIV>
<DIV style="position:absolute;top:479;left:286"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:478;left:292"><nobr><span class="ft40"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:483;left:299"><nobr><span class="ft24"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:479;left:309"><nobr><span class="ft7">) </span></nobr></DIV>
<DIV style="position:absolute;top:490;left:81"><nobr><span class="ft7">6 </span></nobr></DIV>
<DIV style="position:absolute;top:493;left:135"><nobr><span class="ft7">if </span></nobr></DIV>
<DIV style="position:absolute;top:491;left:154"><nobr><span class="ft12"><i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:492;left:159"><nobr><span class="ft40"><i>.stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:493;left:177"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:491;left:183"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:493;left:191"><nobr><span class="ft7"> (<i>LowerCI</i>[</span></nobr></DIV>
<DIV style="position:absolute;top:492;left:254"><nobr><span class="ft40"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:493;left:269"><nobr><span class="ft7">], <i>UpperCI</i>[</span></nobr></DIV>
<DIV style="position:absolute;top:492;left:338"><nobr><span class="ft40"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:493;left:354"><nobr><span class="ft7">]) { </span></nobr></DIV>
<DIV style="position:absolute;top:506;left:135"><nobr><span class="ft7">      // </span></nobr></DIV>
<DIV style="position:absolute;top:506;left:191"><nobr><span class="ft40"><i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:506;left:196"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:505;left:202"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:506;left:213"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:506;left:219"><nobr><span class="ft40"><i>f</i></span></nobr></DIV>
<DIV style="position:absolute;top:506;left:222"><nobr><span class="ft7">(</span></nobr></DIV>
<DIV style="position:absolute;top:506;left:228"><nobr><span class="ft40"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:511;left:236"><nobr><span class="ft24"><i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:506;left:239"><nobr><span class="ft7">)</span></nobr></DIV>
<DIV style="position:absolute;top:506;left:245"><nobr><span class="ft10"> </span></nobr></DIV>
<DIV style="position:absolute;top:506;left:248"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:506;left:254"><nobr><span class="ft10"> <i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:506;left:261"><nobr><span class="ft7">.</span></nobr></DIV>
<DIV style="position:absolute;top:506;left:268"><nobr><span class="ft40"><i>stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:506;left:283"><nobr><span class="ft7"> is significant </span></nobr></DIV>
<DIV style="position:absolute;top:518;left:81"><nobr><span class="ft7">7 </span></nobr></DIV>
<DIV style="position:absolute;top:520;left:110"><nobr><span class="ft7">          </span></nobr></DIV>
<DIV style="position:absolute;top:519;left:173"><nobr><span class="ft40"><i>x.pvalue</i></span></nobr></DIV>
<DIV style="position:absolute;top:520;left:208"><nobr><span class="ft7"> = 2 </span></nobr></DIV>
<DIV style="position:absolute;top:518;left:240"><nobr><span class="ft8">×</span></nobr></DIV>
<DIV style="position:absolute;top:520;left:246"><nobr><span class="ft7"> percentile of </span></nobr></DIV>
<DIV style="position:absolute;top:519;left:340"><nobr><span class="ft40"><i>x.stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:520;left:363"><nobr><span class="ft7"> in </span></nobr></DIV>
<DIV style="position:absolute;top:533;left:222"><nobr><span class="ft41"><i>stat</i>[</span></nobr></DIV>
<DIV style="position:absolute;top:532;left:254"><nobr><span class="ft40"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:533;left:269"><nobr><span class="ft7">][1..</span></nobr></DIV>
<DIV style="position:absolute;top:532;left:301"><nobr><span class="ft40"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:537;left:308"><nobr><span class="ft24"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:533;left:322"><nobr><span class="ft7">] </span></nobr></DIV>
<DIV style="position:absolute;top:544;left:81"><nobr><span class="ft7">8 </span></nobr></DIV>
<DIV style="position:absolute;top:546;left:110"><nobr><span class="ft7">          sigrules = sigrules </span></nobr></DIV>
<DIV style="position:absolute;top:544;left:299"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:546;left:307"><nobr><span class="ft7"> { </span></nobr></DIV>
<DIV style="position:absolute;top:545;left:326"><nobr><span class="ft40"><i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:546;left:331"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:544;left:337"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:546;left:347"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:545;left:354"><nobr><span class="ft40"><i>f</i></span></nobr></DIV>
<DIV style="position:absolute;top:546;left:356"><nobr><span class="ft7">(</span></nobr></DIV>
<DIV style="position:absolute;top:545;left:363"><nobr><span class="ft40"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:550;left:370"><nobr><span class="ft24"><i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:546;left:373"><nobr><span class="ft7">)</span></nobr></DIV>
<DIV style="position:absolute;top:545;left:380"><nobr><span class="ft10"> </span></nobr></DIV>
<DIV style="position:absolute;top:546;left:382"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:545;left:389"><nobr><span class="ft10"> <i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:546;left:396"><nobr><span class="ft7">.</span></nobr></DIV>
<DIV style="position:absolute;top:545;left:402"><nobr><span class="ft40"><i>stat</i></span></nobr></DIV>
<DIV style="position:absolute;top:546;left:418"><nobr><span class="ft7">, </span></nobr></DIV>
<DIV style="position:absolute;top:558;left:222"><nobr><span class="ft40"><i>support </i></span></nobr></DIV>
<DIV style="position:absolute;top:559;left:257"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:558;left:264"><nobr><span class="ft40"><i> support</i></span></nobr></DIV>
<DIV style="position:absolute;top:559;left:299"><nobr><span class="ft7">(</span></nobr></DIV>
<DIV style="position:absolute;top:558;left:305"><nobr><span class="ft40"><i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:559;left:310"><nobr><span class="ft7">)} </span></nobr></DIV>
<DIV style="position:absolute;top:570;left:81"><nobr><span class="ft7">9 </span></nobr></DIV>
<DIV style="position:absolute;top:570;left:110"><nobr><span class="ft7">    } </span></nobr></DIV>
<DIV style="position:absolute;top:581;left:81"><nobr><span class="ft7">10 } </span></nobr></DIV>
<DIV style="position:absolute;top:594;left:165"><nobr><span class="ft5"><b>Figure 4.1  Algorithm <i>SigSQrules</i> </b></span></nobr></DIV>
<DIV style="position:absolute;top:618;left:81"><nobr><span class="ft4">Given <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:625;left:127"><nobr><span class="ft20"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:618;left:140"><nobr><span class="ft4"> distributions constructed from the algorithm <i>CIComp,</i> </span></nobr></DIV>
<DIV style="position:absolute;top:634;left:81"><nobr><span class="ft16">we use the above algorithm to discover all significant SQ rules. <br>We continue to use the example <i>N</i> = 1000, <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:656;left:325"><nobr><span class="ft20"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:650;left:338"><nobr><span class="ft4"> = 100, and <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:656;left:412"><nobr><span class="ft20"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:650;left:430"><nobr><span class="ft4"> = </span></nobr></DIV>
<DIV style="position:absolute;top:666;left:81"><nobr><span class="ft16">999 to describe the steps in Figure 4.1. Note that the attributes in <br><i>A</i> represent the attributes in the dataset that are used to describe <br>segments for which statistics can be computed. Step 1 uses any <br>large itemset generation procedure in rule discovery literature to <br>generate all large itemsets involving attributes in <i>A</i>. The exact <br>procedure used will depend on whether the attributes in <i>A</i> are all <br>categorical or not. If they are, then <i>Apriori</i> algorithm can be used <br>to learn all large itemsets. If some of them are continuous then <br>other methods such as the ones described in [31] can be used. </span></nobr></DIV>
<DIV style="position:absolute;top:817;left:81"><nobr><span class="ft32">Step 4 computes the <i>statistic</i> function for each large itemset, <i>x</i>. In <br>step 5, we find out which distribution is to be used for <br>significance test. For example, if <i>support</i>(<i>x</i>) = 23, then <br><i>support</i>(<i>x</i>)/<i>N</i> </span></nobr></DIV>
<DIV style="position:absolute;top:864;left:155"><nobr><span class="ft21">× <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:872;left:176"><nobr><span class="ft20"><i>dist</i></span></nobr></DIV>
<DIV style="position:absolute;top:866;left:189"><nobr><span class="ft4"> = (23/1000) </span></nobr></DIV>
<DIV style="position:absolute;top:864;left:263"><nobr><span class="ft21">× 100 = 2.3, and hence <i>dist</i> will </span></nobr></DIV>
<DIV style="position:absolute;top:882;left:81"><nobr><span class="ft32">be  <i>round</i>(2.3) = 2. We would compare <i>x.stat</i> with its <br>corresponding confidence interval (<i>LowerCI</i>[2],  <i>UpperCI</i>[2]) in <br>step 6. If <i>x.stat</i> is outside of the confidence interval, the rule is <br>significant, and we use step 7 to calculate its 2-side <i>p</i>-value. If <br><i>x.stat</i> is the <i>q</i>th percentile, the 2-side <i>p</i>-value is 2 </span></nobr></DIV>
<DIV style="position:absolute;top:945;left:364"><nobr><span class="ft21">× min(<i>q</i>%, 1­</span></nobr></DIV>
<DIV style="position:absolute;top:962;left:81"><nobr><span class="ft16"><i>q</i>%). The <i>p</i>-value is not only a value to understand how <br>significant a rule is, but is also useful for determining the false <br>discovery rate in Section 5. Note that the confidence interval used <br>to test significance of a rule is approximate since we do not <br>compute this interval for the exact value of the support of this <br>rule. Instead we use the closest interval (which was pre-computed <br>as described in Section 3.2) corresponding to this support value. </span></nobr></DIV>
<DIV style="position:absolute;top:109;left:477"><nobr><span class="ft16">In future research we will quantify the effects of this <br>approximation. </span></nobr></DIV>
<DIV style="position:absolute;top:149;left:477"><nobr><span class="ft16">We would also like to point out that in many cases (see below) the <br>computation of the statistic can be done efficiently <i>within</i> the <br>itemset generation procedure (<i>largeitems</i>) itself.  This can be used <br>to modify the algorithm to make it more efficient once a specific <br>itemset generation procedure is used. This is the case if the <br>function <i>f</i> that computes the statistic on transactions <i>T</i></span></nobr></DIV>
<DIV style="position:absolute;top:235;left:778"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:228;left:783"><nobr><span class="ft18"><i>, T</i></span></nobr></DIV>
<DIV style="position:absolute;top:235;left:798"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:228;left:803"><nobr><span class="ft18"><i>,..., T</i></span></nobr></DIV>
<DIV style="position:absolute;top:235;left:833"><nobr><span class="ft20"><i>s</i></span></nobr></DIV>
<DIV style="position:absolute;top:228;left:837"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:244;left:477"><nobr><span class="ft4">is a recursive function on <i>s</i>, that is,  </span></nobr></DIV>
<DIV style="position:absolute;top:269;left:477"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:269;left:539"><nobr><span class="ft18"><i>f</i>(<i>T</i></span></nobr></DIV>
<DIV style="position:absolute;top:275;left:554"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:269;left:559"><nobr><span class="ft4">, <i>T</i></span></nobr></DIV>
<DIV style="position:absolute;top:275;left:573"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:269;left:578"><nobr><span class="ft4">,..., <i>T</i></span></nobr></DIV>
<DIV style="position:absolute;top:275;left:609"><nobr><span class="ft20"><i>s</i></span></nobr></DIV>
<DIV style="position:absolute;top:269;left:613"><nobr><span class="ft4">) = <i>g</i>(<i>f</i>(<i>T</i></span></nobr></DIV>
<DIV style="position:absolute;top:275;left:659"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:269;left:663"><nobr><span class="ft4">, <i>T</i></span></nobr></DIV>
<DIV style="position:absolute;top:275;left:677"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:269;left:682"><nobr><span class="ft4">,..., <i>T</i></span></nobr></DIV>
<DIV style="position:absolute;top:275;left:713"><nobr><span class="ft20"><i>s</i>-1</span></nobr></DIV>
<DIV style="position:absolute;top:269;left:724"><nobr><span class="ft4">), <i>f</i>(<i>T</i></span></nobr></DIV>
<DIV style="position:absolute;top:275;left:751"><nobr><span class="ft20"><i>s</i></span></nobr></DIV>
<DIV style="position:absolute;top:269;left:755"><nobr><span class="ft4">), <i>s</i>)  </span></nobr></DIV>
<DIV style="position:absolute;top:269;left:811"><nobr><span class="ft4">(4.1) </span></nobr></DIV>
<DIV style="position:absolute;top:294;left:477"><nobr><span class="ft32">Many statistics, such as <i>mean</i> and <i>market share</i>, are recursive. For <br>example, <i>Mean</i>(<i>T</i></span></nobr></DIV>
<DIV style="position:absolute;top:317;left:573"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:577"><nobr><span class="ft18"><i>, T</i></span></nobr></DIV>
<DIV style="position:absolute;top:317;left:592"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:597"><nobr><span class="ft18"><i>,..., T</i></span></nobr></DIV>
<DIV style="position:absolute;top:317;left:627"><nobr><span class="ft20"><i>s</i></span></nobr></DIV>
<DIV style="position:absolute;top:311;left:630"><nobr><span class="ft4">) = [<i>Mean</i>(<i>T</i></span></nobr></DIV>
<DIV style="position:absolute;top:317;left:698"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:702"><nobr><span class="ft18"><i>, T</i></span></nobr></DIV>
<DIV style="position:absolute;top:317;left:717"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:722"><nobr><span class="ft18"><i>,..., T</i></span></nobr></DIV>
<DIV style="position:absolute;top:317;left:752"><nobr><span class="ft20"><i>s</i> ­ 1</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:770"><nobr><span class="ft4">) </span></nobr></DIV>
<DIV style="position:absolute;top:309;left:778"><nobr><span class="ft21">× (<i>s</i> ­ 1) + </span></nobr></DIV>
<DIV style="position:absolute;top:327;left:477"><nobr><span class="ft18"><i>Mean</i>(<i>T</i></span></nobr></DIV>
<DIV style="position:absolute;top:333;left:520"><nobr><span class="ft20"><i>s</i></span></nobr></DIV>
<DIV style="position:absolute;top:327;left:523"><nobr><span class="ft4">)] / <i>s</i>.   </span></nobr></DIV>
<DIV style="position:absolute;top:351;left:477"><nobr><span class="ft16">In this section we presented an algorithm <i>SigSQrules</i> for <br>generating significant SQ rules. However, as mentioned in the <br>introduction, for any given level of significance for a rule, the fact <br>that thousands of rules are evaluated for their significance makes <br>it possible to discover a certain number of false rules. This is the <br>well known multiple hypothesis testing problem [4]. While it is <br>difficult to eliminate this problem, it is possible to quantify this <br>effect. In the next section we discuss the problem of false <br>discovery in detail and present an algorithm for determining the <br>false discovery rate associated with the discovery of significant <br>SQ rules. </span></nobr></DIV>
<DIV style="position:absolute;top:544;left:477"><nobr><span class="ft3"><b>5.</b></span></nobr></DIV>
<DIV style="position:absolute;top:544;left:490"><nobr><span class="ft6"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:544;left:501"><nobr><span class="ft3"><b>FALSE DISCOVERY OF SQ RULES </b></span></nobr></DIV>
<DIV style="position:absolute;top:565;left:477"><nobr><span class="ft16">As mentioned above, when multiple rules are tested in parallel for <br>significance, it is possible to learn a number of "false" rules by <br>chance alone. Indeed, this is a problem for many rule discovery <br>methods in the data mining literature. The <i>false discovery rate</i> <br>(<i>FDR</i>) is the expected percentage of false rules among all the <br>discovered rules. Prior work in statistics has taken two approaches <br>to deal with the multiple hypothesis testing problem [4, 17, 34]. <br>One approach attempts to lower the false discovery rate by <br>adjusting the significance level at which each rule is tested. As we <br>will describe below, this approach is not suitable for data mining <br>since it will result in very few rules being discovered. The second <br>approach assumes that a given number of false discoveries should <br>be expected, and focuses on estimating what the false discovery <br>rate (<i>FDR</i>) exactly is. This is more useful for data mining, since it <br>permits the discovery of a reasonable number of rules, but at the <br>same time computes a <i>FDR</i> that can give users an idea of what <br>percentage of the discovered rules are spurious. In this section, we <br>first review key ideas related to the multiple hypotheses testing <br>problem and then present a nonparametric method to determine <br>false discovery rate for our procedure. </span></nobr></DIV>
<DIV style="position:absolute;top:892;left:477"><nobr><span class="ft4">For significance tests for a single rule, the significance level </span></nobr></DIV>
<DIV style="position:absolute;top:890;left:815"><nobr><span class="ft21"> is </span></nobr></DIV>
<DIV style="position:absolute;top:907;left:477"><nobr><span class="ft32">defined as the probability of discovering a significant rule when <br>the LHS and RHS of the rule are actually independent of each <br>other; in other words, </span></nobr></DIV>
<DIV style="position:absolute;top:939;left:606"><nobr><span class="ft21"> is the probability of a false (spurious) </span></nobr></DIV>
<DIV style="position:absolute;top:956;left:477"><nobr><span class="ft32">discovery. For example, on a random dataset where all attributes <br>are independent, if we test 10,000 rules, then by definition of </span></nobr></DIV>
<DIV style="position:absolute;top:971;left:825"><nobr><span class="ft21">, </span></nobr></DIV>
<DIV style="position:absolute;top:990;left:477"><nobr><span class="ft4">we expect 10,000 </span></nobr></DIV>
<DIV style="position:absolute;top:988;left:581"><nobr><span class="ft21">× 5% = 500 false discoveries by pure chance </span></nobr></DIV>
<DIV style="position:absolute;top:1005;left:477"><nobr><span class="ft16">alone. When some of the attributes are dependent on each other, <br>as is the case for most datasets on which rule discovery methods <br>are used, the above approach cannot be used to get an expectation <br>for the number of false rules. In such cases, two approaches are </span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:449"><nobr><span class="ft4">378</span></nobr></DIV>
<DIV style="position:absolute;top:54;left:80"><nobr><span class="ft14"><b>Research Track Paper</b></span></nobr></DIV>
</DIV>
<!-- Page 6 -->
<a name="6"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft45{font-size:13px;font-family:Times;color:#000000;}
	.ft46{font-size:11px;line-height:16px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="144006.png" alt="background image">
<DIV style="position:absolute;top:109;left:81"><nobr><span class="ft32">possible. In statistics, a measure called familywise error rate <br>(<i>FWER</i>) is defined as the probability of getting at least one false <br>rule output. Most conventional approaches in statistics that deals <br>with the multiple hypotheses testing problem use different <br>methods to control <i>FWER</i> by lowering significance level for <br>individual rule, </span></nobr></DIV>
<DIV style="position:absolute;top:187;left:175"><nobr><span class="ft21"></span></nobr></DIV>
<DIV style="position:absolute;top:195;left:183"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:189;left:195"><nobr><span class="ft4">. For example, Bonferroni-type procedures </span></nobr></DIV>
<DIV style="position:absolute;top:206;left:81"><nobr><span class="ft4">would have </span></nobr></DIV>
<DIV style="position:absolute;top:204;left:150"><nobr><span class="ft21"></span></nobr></DIV>
<DIV style="position:absolute;top:212;left:158"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:206;left:170"><nobr><span class="ft4"> = </span></nobr></DIV>
<DIV style="position:absolute;top:204;left:187"><nobr><span class="ft21"> / the number of rules tested, which is 5% / </span></nobr></DIV>
<DIV style="position:absolute;top:222;left:81"><nobr><span class="ft4">10,000 = 5 </span></nobr></DIV>
<DIV style="position:absolute;top:221;left:152"><nobr><span class="ft21">× 10</span></nobr></DIV>
<DIV style="position:absolute;top:220;left:180"><nobr><span class="ft19">-6</span></nobr></DIV>
<DIV style="position:absolute;top:222;left:187"><nobr><span class="ft4">. However, when the number of hypotheses </span></nobr></DIV>
<DIV style="position:absolute;top:238;left:81"><nobr><span class="ft32">tested is large (as is the case in data mining algorithms), extreme <br>low </span></nobr></DIV>
<DIV style="position:absolute;top:254;left:105"><nobr><span class="ft21"> value, e.g. 5 × 10</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:211"><nobr><span class="ft19">-6</span></nobr></DIV>
<DIV style="position:absolute;top:255;left:219"><nobr><span class="ft4">, will result in very few rules discovered. </span></nobr></DIV>
<DIV style="position:absolute;top:271;left:81"><nobr><span class="ft16">The other type of approach, as taken recently in [4] estimates the <br>false discovery rate (<i>FDR</i>), the expectation of the proportion of <br>false discoveries in all discoveries.  </span></nobr></DIV>
<DIV style="position:absolute;top:328;left:114"><nobr><span class="ft5"><b>Table 5.1  Confusion matrix of the number of rules </b></span></nobr></DIV>
<DIV style="position:absolute;top:350;left:157"><nobr><span class="ft4"> Non-Significant </span></nobr></DIV>
<DIV style="position:absolute;top:366;left:273"><nobr><span class="ft4">Rules </span></nobr></DIV>
<DIV style="position:absolute;top:350;left:362"><nobr><span class="ft4">Significant </span></nobr></DIV>
<DIV style="position:absolute;top:366;left:377"><nobr><span class="ft4">Rules </span></nobr></DIV>
<DIV style="position:absolute;top:389;left:87"><nobr><span class="ft4">LHS independent of RHS </span></nobr></DIV>
<DIV style="position:absolute;top:389;left:285"><nobr><span class="ft18"><i>a b </i></span></nobr></DIV>
<DIV style="position:absolute;top:414;left:92"><nobr><span class="ft4">LHS dependent on RHS </span></nobr></DIV>
<DIV style="position:absolute;top:414;left:285"><nobr><span class="ft18"><i>c d </i></span></nobr></DIV>
<DIV style="position:absolute;top:446;left:81"><nobr><span class="ft16">In Table 5.1, the number of rules tested is (<i>a </i>+ <i>b </i>+ <i>c </i>+ <i>d</i>), out of <br>which (<i>a </i>+ <i>b</i>) is the number of rules where the LHS of the rules is <br>truly independent of the RHS, and (<i>c </i>+ <i>d</i>) is the number of rules <br>where there is a real relationship between the LHS and the RHS <br>of the rules. The columns determine how many tested rules are <br>output as significant or non-significant. The two terms <i>FDR</i> and <br><i>FWER</i> can be defined precisely as <i>FDR</i> = <i>Exp</i>(<i>b</i> / <i>b</i> + <i>d</i>) and <br><i>FWER</i> = <i>Prob</i>(<i>b</i> &gt;0). </span></nobr></DIV>
<DIV style="position:absolute;top:582;left:81"><nobr><span class="ft32">We adopt <i>FDR</i> estimation in this section because it effectively <br>estimates false discoveries without rejecting too many discovered <br>rules. However, the method proposed in the literature [4, 7, 35] <br>for <i>FDR</i> cannot be used for large scale rule discovery because of <br>the following two reasons: first, the assumption that statistics of <br>the rules tested are independent from each other (which some of <br>the approaches use) is not true. For example, rules <i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:684;left:390"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:678;left:395"><nobr><span class="ft4"> = 1 </span></nobr></DIV>
<DIV style="position:absolute;top:677;left:428"><nobr><span class="ft21"> </span></nobr></DIV>
<DIV style="position:absolute;top:695;left:81"><nobr><span class="ft18"><i>Mean</i>(<i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:701;left:126"><nobr><span class="ft20"><i>A</i>1 = 1</span></nobr></DIV>
<DIV style="position:absolute;top:695;left:151"><nobr><span class="ft4">) and <i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:701;left:191"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:695;left:195"><nobr><span class="ft4"> = 1 </span></nobr></DIV>
<DIV style="position:absolute;top:693;left:221"><nobr><span class="ft21"> <i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:701;left:242"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:695;left:246"><nobr><span class="ft4"> = 2 </span></nobr></DIV>
<DIV style="position:absolute;top:693;left:272"><nobr><span class="ft21"> <i>Mean</i>(<i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:701;left:335"><nobr><span class="ft20"><i>A</i>1 = 1 </span></nobr></DIV>
<DIV style="position:absolute;top:700;left:362"><nobr><span class="ft37"> <i>A</i>2 = 2</span></nobr></DIV>
<DIV style="position:absolute;top:695;left:395"><nobr><span class="ft4">) are not </span></nobr></DIV>
<DIV style="position:absolute;top:711;left:81"><nobr><span class="ft16">independent. In fact a large number of rules are related to each <br>other in rule discovery because their LHS share common <br>conditions and RHS come from the same attributes. Second, <br>methods in statistics draw conclusions based on the number of <br>rules tested (= <i>a</i> + <i>b</i> + <i>c</i> + <i>d</i>), however, as indicated in [25], <i>a</i> and <br><i>c</i> are unknown values due to the filtering by <i>support</i> constraint. <br>Without making any assumptions, below we present another <br>permutation-based method to estimate the <i>FDR</i> for our procedure <br>for learning significant SQ rules. </span></nobr></DIV>
<DIV style="position:absolute;top:863;left:81"><nobr><span class="ft4">Denote  <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:870;left:135"><nobr><span class="ft20"><i>sig</i></span></nobr></DIV>
<DIV style="position:absolute;top:863;left:145"><nobr><span class="ft4">(</span></nobr></DIV>
<DIV style="position:absolute;top:862;left:150"><nobr><span class="ft21">) to be the number of significant rules discovered </span></nobr></DIV>
<DIV style="position:absolute;top:880;left:81"><nobr><span class="ft4">from dataset <i>D</i> when the significant level = </span></nobr></DIV>
<DIV style="position:absolute;top:879;left:346"><nobr><span class="ft21">. In Table 5.1, </span></nobr></DIV>
<DIV style="position:absolute;top:897;left:81"><nobr><span class="ft18"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:903;left:90"><nobr><span class="ft20"><i>sig</i></span></nobr></DIV>
<DIV style="position:absolute;top:897;left:101"><nobr><span class="ft4">(</span></nobr></DIV>
<DIV style="position:absolute;top:896;left:105"><nobr><span class="ft21">) = <i>b</i> + <i>d</i>. Similar to the procedure described in Section 3, </span></nobr></DIV>
<DIV style="position:absolute;top:913;left:81"><nobr><span class="ft46">by keeping the values in attributes <i>A</i> intact and permuting the <i>B <br></i>attributes, we get a permutation dataset <i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:928;left:311"><nobr><span class="ft21">. Since we remove any </span></nobr></DIV>
<DIV style="position:absolute;top:946;left:81"><nobr><span class="ft32">relationship between <i>A</i> and <i>B</i> attributes by this procedure, all the <br>LHS and RHS statistic of each rule tested in <i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:961;left:343"><nobr><span class="ft21"> are independent. </span></nobr></DIV>
<DIV style="position:absolute;top:978;left:81"><nobr><span class="ft32">If we apply the significant rule discovery algorithm <i>SigSQrules</i>, <br>the number of significant rules discovered from <i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:994;left:378"><nobr><span class="ft21"> when the </span></nobr></DIV>
<DIV style="position:absolute;top:1012;left:81"><nobr><span class="ft4">significant level = </span></nobr></DIV>
<DIV style="position:absolute;top:1010;left:186"><nobr><span class="ft21"> will be one instance of false discovery, that </span></nobr></DIV>
<DIV style="position:absolute;top:1029;left:81"><nobr><span class="ft4">is,  <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:109"><nobr><span class="ft20"><i>sig</i>-<i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:1029;left:141"><nobr><span class="ft4">(</span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:146"><nobr><span class="ft21">) = <i>b</i>. It is easy to see that by creating multiple </span></nobr></DIV>
<DIV style="position:absolute;top:1045;left:81"><nobr><span class="ft16">permutation datasets, we can estimate the expectation of the <br>number of false discoveries and thus compute a false discovery </span></nobr></DIV>
<DIV style="position:absolute;top:110;left:477"><nobr><span class="ft4">rate <i>FDR</i> = <i>Exp</i>(<i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:116;left:579"><nobr><span class="ft20"><i>sig</i>-<i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:110;left:611"><nobr><span class="ft4">(</span></nobr></DIV>
<DIV style="position:absolute;top:108;left:616"><nobr><span class="ft21">)) / <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:116;left:655"><nobr><span class="ft20"><i>sig</i></span></nobr></DIV>
<DIV style="position:absolute;top:110;left:665"><nobr><span class="ft4">(</span></nobr></DIV>
<DIV style="position:absolute;top:108;left:670"><nobr><span class="ft21">). We will describe the steps </span></nobr></DIV>
<DIV style="position:absolute;top:126;left:477"><nobr><span class="ft4">how <i>FDR</i>(</span></nobr></DIV>
<DIV style="position:absolute;top:125;left:534"><nobr><span class="ft21">) can be estimated in detail in the Appendix. </span></nobr></DIV>
<DIV style="position:absolute;top:151;left:477"><nobr><span class="ft16">In this section, we described the problem of multiple hypotheses <br>testing and pointed out that for any given significance level a <br>certain number of significant SQ rules will be discovered by <br>chance alone. We then described an intuitive permutation based <br>procedure to compute the false discovery rate. From a practical <br>point of view the procedure described above can be used in <br>conjunction with <i>SigSQrules</i> to discover a set of significant SQ <br>rules and provide a number representing the percentage of these <br>rules that are likely to be spurious. </span></nobr></DIV>
<DIV style="position:absolute;top:312;left:477"><nobr><span class="ft3"><b>6.</b></span></nobr></DIV>
<DIV style="position:absolute;top:312;left:490"><nobr><span class="ft6"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:312;left:501"><nobr><span class="ft3"><b>EXPERIMENTS </b></span></nobr></DIV>
<DIV style="position:absolute;top:333;left:477"><nobr><span class="ft16">In this section we present results from learning significant market <br>share rules, a specific type of SQ rules. We started with user-level <br>online purchase data gathered by comScore Networks, a market <br>data vendor. The data consist of 100,000 users' online browsing <br>and purchase behavior over a period of six months. The market <br>data vendor tracks all online purchases explicitly by parsing the <br>content of all pages delivered to each user. Starting from the raw <br>data we created a dataset of purchases where each transaction <br>represents a purchase made at an online retailer. Attributes of the <br>transaction include user demographics, the site at which the <br>purchase was made, the primary category (e.g. books, home <br>electronics etc) of the site, the product purchased and the price <br>paid for the product. Within a specific category, e.g. books, <br>significant market share rules would be particularly interesting to <br>discover. We selected many datasets with purchases belonging to <br>each specific category and applied our method to learn several <br>interesting significant market share rules. For space limitations we <br>do not present all the results, but report the results for learning <br>market share rules for the top three retailers in the online book <br>industry. Specifically the dataset consists of all transactions in <br>which a book was purchased at any site and we use the methods <br>presented in the paper to learn market share rules for the top 3 <br>sites ­ Amazon.com, Barnes&amp;Noble and Ebay. The total number <br>of transactions was 26,439 records and we limit the rules to <br>having at most five items on the LHS of a rule.  </span></nobr></DIV>
<DIV style="position:absolute;top:738;left:477"><nobr><span class="ft3"><b>6.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:738;left:499"><nobr><span class="ft6"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:738;left:510"><nobr><span class="ft3"><b>Rule Examples </b></span></nobr></DIV>
<DIV style="position:absolute;top:759;left:477"><nobr><span class="ft16">Among the most significant market share rules (as determined by <br>the <i>p</i>-values of these rules), we picked four rules to list that were <br>particularly interesting for each online retailer.  </span></nobr></DIV>
<DIV style="position:absolute;top:816;left:615"><nobr><span class="ft45"><b>Amazon.com </b></span></nobr></DIV>
<DIV style="position:absolute;top:837;left:477"><nobr><span class="ft7">(1) Education</span></nobr></DIV>
<DIV style="position:absolute;top:840;left:559"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:837;left:562"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:840;left:569"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:837;left:572"><nobr><span class="ft7">High</span></nobr></DIV>
<DIV style="position:absolute;top:840;left:597"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:837;left:601"><nobr><span class="ft7">School</span></nobr></DIV>
<DIV style="position:absolute;top:840;left:639"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:835;left:642"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:840;left:653"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:837;left:656"><nobr><span class="ft7">marketshare</span></nobr></DIV>
<DIV style="position:absolute;top:841;left:726"><nobr><span class="ft9">Amazon </span></nobr></DIV>
<DIV style="position:absolute;top:837;left:754"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:840;left:760"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:837;left:763"><nobr><span class="ft7">42.72%, </span></nobr></DIV>
<DIV style="position:absolute;top:848;left:477"><nobr><span class="ft7">support</span></nobr></DIV>
<DIV style="position:absolute;top:852;left:521"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:848;left:525"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:852;left:531"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:848;left:534"><nobr><span class="ft7">20.7%, CI</span></nobr></DIV>
<DIV style="position:absolute;top:852;left:591"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:848;left:595"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:852;left:601"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:848;left:605"><nobr><span class="ft7">(46.07%,</span></nobr></DIV>
<DIV style="position:absolute;top:852;left:655"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:848;left:659"><nobr><span class="ft7">50.92%) </span></nobr></DIV>
<DIV style="position:absolute;top:861;left:477"><nobr><span class="ft7">(2) Region</span></nobr></DIV>
<DIV style="position:absolute;top:865;left:540"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:861;left:543"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:865;left:550"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:861;left:553"><nobr><span class="ft7">West</span></nobr></DIV>
<DIV style="position:absolute;top:865;left:579"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:859;left:582"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:865;left:589"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:861;left:592"><nobr><span class="ft7">Household</span></nobr></DIV>
<DIV style="position:absolute;top:865;left:649"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:861;left:652"><nobr><span class="ft7">Size</span></nobr></DIV>
<DIV style="position:absolute;top:865;left:678"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:861;left:681"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:865;left:688"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:861;left:691"><nobr><span class="ft7">2 </span></nobr></DIV>
<DIV style="position:absolute;top:859;left:704"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:861;left:714"><nobr><span class="ft7"> marketshare</span></nobr></DIV>
<DIV style="position:absolute;top:866;left:790"><nobr><span class="ft9">Amazon </span></nobr></DIV>
<DIV style="position:absolute;top:861;left:818"><nobr><span class="ft7">= </span></nobr></DIV>
<DIV style="position:absolute;top:873;left:477"><nobr><span class="ft7">57.93%, support</span></nobr></DIV>
<DIV style="position:absolute;top:876;left:571"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:873;left:575"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:876;left:581"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:873;left:585"><nobr><span class="ft7">7.9%, CI</span></nobr></DIV>
<DIV style="position:absolute;top:876;left:635"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:873;left:639"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:876;left:645"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:873;left:649"><nobr><span class="ft7">(44.36%, 52.50%) </span></nobr></DIV>
<DIV style="position:absolute;top:886;left:477"><nobr><span class="ft7">(3) Region</span></nobr></DIV>
<DIV style="position:absolute;top:890;left:540"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:886;left:543"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:890;left:550"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:886;left:553"><nobr><span class="ft7">South</span></nobr></DIV>
<DIV style="position:absolute;top:890;left:585"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:884;left:588"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:890;left:595"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:886;left:598"><nobr><span class="ft7">Household Size</span></nobr></DIV>
<DIV style="position:absolute;top:890;left:687"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:886;left:690"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:890;left:697"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:886;left:700"><nobr><span class="ft7">4 </span></nobr></DIV>
<DIV style="position:absolute;top:884;left:713"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:886;left:723"><nobr><span class="ft7"> marketshare</span></nobr></DIV>
<DIV style="position:absolute;top:891;left:799"><nobr><span class="ft9">Amazon</span></nobr></DIV>
<DIV style="position:absolute;top:886;left:823"><nobr><span class="ft7"> = </span></nobr></DIV>
<DIV style="position:absolute;top:897;left:477"><nobr><span class="ft7">38.54%, support</span></nobr></DIV>
<DIV style="position:absolute;top:901;left:571"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:897;left:575"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:901;left:581"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:897;left:585"><nobr><span class="ft7">5.4%, CI</span></nobr></DIV>
<DIV style="position:absolute;top:901;left:635"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:897;left:639"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:901;left:645"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:897;left:649"><nobr><span class="ft7">(43.76%, 53.39%) </span></nobr></DIV>
<DIV style="position:absolute;top:911;left:477"><nobr><span class="ft7">(4) 35</span></nobr></DIV>
<DIV style="position:absolute;top:915;left:515"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:911;left:518"><nobr><span class="ft7">&lt;</span></nobr></DIV>
<DIV style="position:absolute;top:915;left:525"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:911;left:528"><nobr><span class="ft7">Household</span></nobr></DIV>
<DIV style="position:absolute;top:915;left:585"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:911;left:588"><nobr><span class="ft7">Eldest</span></nobr></DIV>
<DIV style="position:absolute;top:915;left:626"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:911;left:630"><nobr><span class="ft7">Age</span></nobr></DIV>
<DIV style="position:absolute;top:915;left:649"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:911;left:652"><nobr><span class="ft7">&lt;</span></nobr></DIV>
<DIV style="position:absolute;top:915;left:659"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:911;left:662"><nobr><span class="ft7">40</span></nobr></DIV>
<DIV style="position:absolute;top:915;left:675"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:909;left:678"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:915;left:685"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:911;left:688"><nobr><span class="ft7">ISP</span></nobr></DIV>
<DIV style="position:absolute;top:915;left:707"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:911;left:711"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:915;left:717"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:911;left:721"><nobr><span class="ft7">Broadband</span></nobr></DIV>
<DIV style="position:absolute;top:915;left:778"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:909;left:781"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:911;left:791"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:922;left:477"><nobr><span class="ft7">marketshare</span></nobr></DIV>
<DIV style="position:absolute;top:927;left:546"><nobr><span class="ft9">Amazon </span></nobr></DIV>
<DIV style="position:absolute;top:922;left:574"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:580"><nobr><span class="ft23"> </span></nobr></DIV>
<DIV style="position:absolute;top:922;left:582"><nobr><span class="ft7">60.52%,</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:626"><nobr><span class="ft23"> </span></nobr></DIV>
<DIV style="position:absolute;top:922;left:627"><nobr><span class="ft7">support</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:672"><nobr><span class="ft23"> </span></nobr></DIV>
<DIV style="position:absolute;top:922;left:673"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:679"><nobr><span class="ft23"> </span></nobr></DIV>
<DIV style="position:absolute;top:922;left:681"><nobr><span class="ft7">4.3%,</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:712"><nobr><span class="ft23"> </span></nobr></DIV>
<DIV style="position:absolute;top:922;left:714"><nobr><span class="ft7">CI</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:727"><nobr><span class="ft23"> </span></nobr></DIV>
<DIV style="position:absolute;top:922;left:728"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:734"><nobr><span class="ft23"> </span></nobr></DIV>
<DIV style="position:absolute;top:922;left:736"><nobr><span class="ft7">(42.88%, 53.99%) </span></nobr></DIV>
<DIV style="position:absolute;top:946;left:589"><nobr><span class="ft45"><b>Barnesandnoble.com </b></span></nobr></DIV>
<DIV style="position:absolute;top:966;left:477"><nobr><span class="ft7">(1) Education</span></nobr></DIV>
<DIV style="position:absolute;top:970;left:559"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:966;left:562"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:970;left:569"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:966;left:572"><nobr><span class="ft7">Graduate</span></nobr></DIV>
<DIV style="position:absolute;top:970;left:623"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:965;left:626"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:970;left:633"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:966;left:636"><nobr><span class="ft7">Household</span></nobr></DIV>
<DIV style="position:absolute;top:970;left:693"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:966;left:697"><nobr><span class="ft7">Size</span></nobr></DIV>
<DIV style="position:absolute;top:970;left:722"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:966;left:725"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:970;left:732"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:966;left:735"><nobr><span class="ft7">2 </span></nobr></DIV>
<DIV style="position:absolute;top:965;left:748"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:966;left:758"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:978;left:477"><nobr><span class="ft7">marketshare</span></nobr></DIV>
<DIV style="position:absolute;top:982;left:546"><nobr><span class="ft9">BN </span></nobr></DIV>
<DIV style="position:absolute;top:978;left:558"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:981;left:564"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:978;left:568"><nobr><span class="ft7">13.12%,</span></nobr></DIV>
<DIV style="position:absolute;top:981;left:612"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:978;left:615"><nobr><span class="ft7">support</span></nobr></DIV>
<DIV style="position:absolute;top:981;left:660"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:978;left:663"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:981;left:669"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:978;left:673"><nobr><span class="ft7">6.0%,</span></nobr></DIV>
<DIV style="position:absolute;top:981;left:705"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:978;left:708"><nobr><span class="ft7">CI</span></nobr></DIV>
<DIV style="position:absolute;top:981;left:721"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:978;left:724"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:981;left:731"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:978;left:734"><nobr><span class="ft7">(16.81%, 25.68%) </span></nobr></DIV>
<DIV style="position:absolute;top:991;left:477"><nobr><span class="ft7">(2) 50 &lt; Household Eldest Age &lt; 55 </span></nobr></DIV>
<DIV style="position:absolute;top:989;left:697"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:991;left:704"><nobr><span class="ft7"> Income &gt; 100K </span></nobr></DIV>
<DIV style="position:absolute;top:989;left:798"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:991;left:809"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:1002;left:477"><nobr><span class="ft7">marketshare</span></nobr></DIV>
<DIV style="position:absolute;top:1007;left:546"><nobr><span class="ft9">BN </span></nobr></DIV>
<DIV style="position:absolute;top:1002;left:558"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:1006;left:564"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:1002;left:568"><nobr><span class="ft7">30.28%,</span></nobr></DIV>
<DIV style="position:absolute;top:1006;left:612"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:1002;left:615"><nobr><span class="ft7">support</span></nobr></DIV>
<DIV style="position:absolute;top:1006;left:660"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:1002;left:663"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:1006;left:669"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:1002;left:673"><nobr><span class="ft7">4.2%,</span></nobr></DIV>
<DIV style="position:absolute;top:1006;left:705"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:1002;left:708"><nobr><span class="ft7">CI</span></nobr></DIV>
<DIV style="position:absolute;top:1006;left:721"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:1002;left:724"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:1006;left:731"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:1002;left:734"><nobr><span class="ft7">(16.05%, 26.79%) </span></nobr></DIV>
<DIV style="position:absolute;top:1016;left:477"><nobr><span class="ft7">(3) Region = South </span></nobr></DIV>
<DIV style="position:absolute;top:1014;left:597"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:1016;left:603"><nobr><span class="ft7"> Household Size = 3 </span></nobr></DIV>
<DIV style="position:absolute;top:1014;left:729"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:1016;left:735"><nobr><span class="ft7"> Child = Yes </span></nobr></DIV>
<DIV style="position:absolute;top:1014;left:817"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:1016;left:828"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:477"><nobr><span class="ft7">marketshare</span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:546"><nobr><span class="ft9">BN </span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:558"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:1031;left:564"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:568"><nobr><span class="ft7">13.27%,</span></nobr></DIV>
<DIV style="position:absolute;top:1031;left:612"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:615"><nobr><span class="ft7">support</span></nobr></DIV>
<DIV style="position:absolute;top:1031;left:660"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:663"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:1031;left:669"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:673"><nobr><span class="ft7">4.2%,</span></nobr></DIV>
<DIV style="position:absolute;top:1031;left:705"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:708"><nobr><span class="ft7">CI</span></nobr></DIV>
<DIV style="position:absolute;top:1031;left:721"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:724"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:1031;left:731"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:734"><nobr><span class="ft7">(16.68%, 26.10%) </span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:477"><nobr><span class="ft7">(4) Region = South </span></nobr></DIV>
<DIV style="position:absolute;top:1039;left:597"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:603"><nobr><span class="ft7"> 60 &lt; Household Eldest Age &lt; 65 </span></nobr></DIV>
<DIV style="position:absolute;top:1039;left:805"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:815"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:477"><nobr><span class="ft7">marketshare</span></nobr></DIV>
<DIV style="position:absolute;top:1057;left:546"><nobr><span class="ft9">BN </span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:558"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:1056;left:564"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:568"><nobr><span class="ft7">39.84%,</span></nobr></DIV>
<DIV style="position:absolute;top:1056;left:612"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:615"><nobr><span class="ft7">support</span></nobr></DIV>
<DIV style="position:absolute;top:1056;left:660"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:663"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:1056;left:669"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:673"><nobr><span class="ft7">2.8%,</span></nobr></DIV>
<DIV style="position:absolute;top:1056;left:705"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:708"><nobr><span class="ft7">CI</span></nobr></DIV>
<DIV style="position:absolute;top:1056;left:721"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:724"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:1056;left:731"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:734"><nobr><span class="ft7">(15.55%, 27.10%) </span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:449"><nobr><span class="ft4">379</span></nobr></DIV>
<DIV style="position:absolute;top:54;left:681"><nobr><span class="ft14"><b>Research Track Paper</b></span></nobr></DIV>
</DIV>
<!-- Page 7 -->
<a name="7"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft47{font-size:6px;font-family:Helvetica;color:#000000;}
	.ft48{font-size:10px;font-family:Helvetica;color:#000000;}
	.ft49{font-size:10px;font-family:Times;color:#000000;}
	.ft50{font-size:8px;font-family:Helvetica;color:#000000;}
	.ft51{font-size:7px;font-family:Helvetica;color:#000000;}
	.ft52{font-size:10px;line-height:-6px;font-family:Helvetica;color:#000000;}
	.ft53{font-size:10px;line-height:-13px;font-family:Helvetica;color:#000000;}
	.ft54{font-size:10px;line-height:-9px;font-family:Helvetica;color:#000000;}
	.ft55{font-size:10px;line-height:-2px;font-family:Helvetica;color:#000000;}
	.ft56{font-size:10px;line-height:-3px;font-family:Helvetica;color:#000000;}
	.ft57{font-size:10px;line-height:-7px;font-family:Helvetica;color:#000000;}
	.ft58{font-size:8px;line-height:16px;font-family:Helvetica;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="144007.png" alt="background image">
<DIV style="position:absolute;top:109;left:229"><nobr><span class="ft45"><b>Ebay.com </b></span></nobr></DIV>
<DIV style="position:absolute;top:130;left:81"><nobr><span class="ft7">(1) Education = College </span></nobr></DIV>
<DIV style="position:absolute;top:128;left:232"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:130;left:239"><nobr><span class="ft7"> Region = South </span></nobr></DIV>
<DIV style="position:absolute;top:128;left:339"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:130;left:350"><nobr><span class="ft7">  </span></nobr></DIV>
<DIV style="position:absolute;top:141;left:81"><nobr><span class="ft7">marketshare</span></nobr></DIV>
<DIV style="position:absolute;top:146;left:150"><nobr><span class="ft9">Ebay </span></nobr></DIV>
<DIV style="position:absolute;top:141;left:170"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:145;left:176"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:141;left:180"><nobr><span class="ft7">8.28%,</span></nobr></DIV>
<DIV style="position:absolute;top:145;left:218"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:141;left:221"><nobr><span class="ft7">support</span></nobr></DIV>
<DIV style="position:absolute;top:145;left:266"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:141;left:269"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:145;left:275"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:141;left:279"><nobr><span class="ft7">6.9%,</span></nobr></DIV>
<DIV style="position:absolute;top:145;left:311"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:141;left:314"><nobr><span class="ft7">CI</span></nobr></DIV>
<DIV style="position:absolute;top:145;left:327"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:141;left:330"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:145;left:337"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:141;left:340"><nobr><span class="ft7">(11.70%, 17.71%) </span></nobr></DIV>
<DIV style="position:absolute;top:154;left:81"><nobr><span class="ft7">(2) Education = College </span></nobr></DIV>
<DIV style="position:absolute;top:153;left:232"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:154;left:239"><nobr><span class="ft7"> Region = North Central </span></nobr></DIV>
<DIV style="position:absolute;top:153;left:390"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:154;left:400"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:166;left:81"><nobr><span class="ft7">marketshare</span></nobr></DIV>
<DIV style="position:absolute;top:170;left:150"><nobr><span class="ft9">Ebay </span></nobr></DIV>
<DIV style="position:absolute;top:166;left:170"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:169;left:176"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:166;left:180"><nobr><span class="ft7">21.77%,</span></nobr></DIV>
<DIV style="position:absolute;top:169;left:224"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:166;left:228"><nobr><span class="ft7">support</span></nobr></DIV>
<DIV style="position:absolute;top:169;left:272"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:166;left:275"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:169;left:282"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:166;left:285"><nobr><span class="ft7">4.0%,</span></nobr></DIV>
<DIV style="position:absolute;top:169;left:317"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:166;left:320"><nobr><span class="ft7">CI</span></nobr></DIV>
<DIV style="position:absolute;top:169;left:333"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:166;left:337"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:169;left:343"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:166;left:347"><nobr><span class="ft7">(11.05%, 18.29%) </span></nobr></DIV>
<DIV style="position:absolute;top:179;left:81"><nobr><span class="ft7">(3) Region</span></nobr></DIV>
<DIV style="position:absolute;top:183;left:144"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:179;left:148"><nobr><span class="ft7">= South </span></nobr></DIV>
<DIV style="position:absolute;top:177;left:198"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:179;left:204"><nobr><span class="ft7"> Income &gt; 100K </span></nobr></DIV>
<DIV style="position:absolute;top:177;left:299"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:179;left:309"><nobr><span class="ft7"> marketshare</span></nobr></DIV>
<DIV style="position:absolute;top:184;left:385"><nobr><span class="ft9">Ebay</span></nobr></DIV>
<DIV style="position:absolute;top:179;left:401"><nobr><span class="ft7"> =  </span></nobr></DIV>
<DIV style="position:absolute;top:190;left:81"><nobr><span class="ft7">4.83%,</span></nobr></DIV>
<DIV style="position:absolute;top:194;left:119"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:190;left:122"><nobr><span class="ft7">support</span></nobr></DIV>
<DIV style="position:absolute;top:194;left:167"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:190;left:170"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:194;left:176"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:190;left:180"><nobr><span class="ft7">2.9%,</span></nobr></DIV>
<DIV style="position:absolute;top:194;left:212"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:190;left:215"><nobr><span class="ft7">CI</span></nobr></DIV>
<DIV style="position:absolute;top:194;left:228"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:190;left:231"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:194;left:238"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:190;left:241"><nobr><span class="ft7">(9.54%, 20.46%) </span></nobr></DIV>
<DIV style="position:absolute;top:204;left:81"><nobr><span class="ft7">(4) 18 &lt; Household Eldest Age &lt; 20 </span></nobr></DIV>
<DIV style="position:absolute;top:202;left:302"><nobr><span class="ft8"></span></nobr></DIV>
<DIV style="position:absolute;top:204;left:312"><nobr><span class="ft7"> marketshare</span></nobr></DIV>
<DIV style="position:absolute;top:209;left:387"><nobr><span class="ft9">Ebay</span></nobr></DIV>
<DIV style="position:absolute;top:204;left:404"><nobr><span class="ft7"> = </span></nobr></DIV>
<DIV style="position:absolute;top:215;left:81"><nobr><span class="ft7">27.50%, support = 2.8%,</span></nobr></DIV>
<DIV style="position:absolute;top:219;left:226"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:215;left:230"><nobr><span class="ft7">CI</span></nobr></DIV>
<DIV style="position:absolute;top:219;left:242"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:215;left:246"><nobr><span class="ft7">=</span></nobr></DIV>
<DIV style="position:absolute;top:219;left:252"><nobr><span class="ft9"> </span></nobr></DIV>
<DIV style="position:absolute;top:215;left:256"><nobr><span class="ft7">(10.12%, 19.70%) </span></nobr></DIV>
<DIV style="position:absolute;top:239;left:81"><nobr><span class="ft16">Rule (4) for Amazon.com indicates that it is doing particularly <br>well in households with middle-aged heads that have broadband <br>access. The market share for Amazon.com in this segment lies <br>significantly outside the confidence interval computed for the <br>rule. On the other hand, rule (1) for Barnesandnoble.com shows <br>that they are doing poorly selling to a segment which perhaps <br>represents well educated couples. Given that this is a large <br>segment (support = 6%), this rule suggests that they could try and <br>examine why this is the case and how they can achieve greater <br>penetration in this segment. In Ebay's case, all four rules are very <br>interesting. Rule (4) indicates that they have high market share <br>among teenagers, while rule (3) describes a segment they clearly <br>have trouble penetrating. For many other categories too (travel <br>and home electronics in particular) the significant SQ rules that </span></nobr></DIV>
<DIV style="position:absolute;top:109;left:477"><nobr><span class="ft16">we learned were highly interesting. As these examples suggest, <br>these rules can be insightful, identify interesting segments and <br>have significant business potential. </span></nobr></DIV>
<DIV style="position:absolute;top:166;left:477"><nobr><span class="ft3"><b>6.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:165;left:499"><nobr><span class="ft6"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:166;left:510"><nobr><span class="ft3"><b>Varying support and significance levels </b></span></nobr></DIV>
<DIV style="position:absolute;top:186;left:477"><nobr><span class="ft32">To test how the methods perform as the minimum support and <br>significance levels vary, for one site we generated significant SQ <br>rules for many values of the minimum support and significance <br>level parameters. Figures 6.1 and 6.2 show how the number of <br>significant rules and the false discovery rate vary with support.  <br>As the minimum support threshold is lowered the number of <br>significant SQ rules discovered increases. However the <i>FDR</i> <br>increases as the support threshold is lowered, suggesting a <br>tradeoff between discovering many significant rules while <br>keeping the <i>FDR</i> low. A practical outcome is that it may be <br>desirable to have higher minimum supports (to keep <i>FDR</i> low), <br>but not too high that very few rules are discovered.  Figures 6.3 <br>and 6.4 illustrate a similar tradeoff for the significance level <br>parameter. As </span></nobr></DIV>
<DIV style="position:absolute;top:398;left:557"><nobr><span class="ft21"> decreases <i>FDR</i> is lower, but this results in fewer </span></nobr></DIV>
<DIV style="position:absolute;top:415;left:477"><nobr><span class="ft32">number of significant rules being discovered. Again, the <br>implication is that it may be desirable to have a low </span></nobr></DIV>
<DIV style="position:absolute;top:430;left:778"><nobr><span class="ft21"> (to keep </span></nobr></DIV>
<DIV style="position:absolute;top:448;left:477"><nobr><span class="ft18"><i>FDR</i> low) but not too low that very few rules are discovered.  </span></nobr></DIV>
<DIV style="position:absolute;top:692;left:118"><nobr><span class="ft47">0</span></nobr></DIV>
<DIV style="position:absolute;top:659;left:108"><nobr><span class="ft47">500</span></nobr></DIV>
<DIV style="position:absolute;top:626;left:103"><nobr><span class="ft47">1000</span></nobr></DIV>
<DIV style="position:absolute;top:593;left:103"><nobr><span class="ft47">1500</span></nobr></DIV>
<DIV style="position:absolute;top:560;left:103"><nobr><span class="ft47">2000</span></nobr></DIV>
<DIV style="position:absolute;top:527;left:103"><nobr><span class="ft47">2500</span></nobr></DIV>
<DIV style="position:absolute;top:705;left:120"><nobr><span class="ft47">0.0%</span></nobr></DIV>
<DIV style="position:absolute;top:705;left:174"><nobr><span class="ft47">2.0%</span></nobr></DIV>
<DIV style="position:absolute;top:705;left:229"><nobr><span class="ft47">4.0%</span></nobr></DIV>
<DIV style="position:absolute;top:705;left:283"><nobr><span class="ft47">6.0%</span></nobr></DIV>
<DIV style="position:absolute;top:705;left:338"><nobr><span class="ft47">8.0%</span></nobr></DIV>
<DIV style="position:absolute;top:705;left:390"><nobr><span class="ft47">10.0%</span></nobr></DIV>
<DIV style="position:absolute;top:718;left:251"><nobr><span class="ft48">support</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:91"><nobr><span class="ft52">#<br> of<br> s<br>i<br>gn<br>i<br>f<br>i<br>c<br>an<br>t<br> r<br>u<br>l<br>e<br>s</span></nobr></DIV>
<DIV style="position:absolute;top:543;left:288"><nobr><span class="ft8"> = 10%</span></nobr></DIV>
<DIV style="position:absolute;top:543;left:375"><nobr><span class="ft8"> = 5%</span></nobr></DIV>
<DIV style="position:absolute;top:562;left:288"><nobr><span class="ft8"> = 2.5%</span></nobr></DIV>
<DIV style="position:absolute;top:562;left:375"><nobr><span class="ft8"> = 1%</span></nobr></DIV>
<DIV style="position:absolute;top:690;left:483"><nobr><span class="ft47">0.0%</span></nobr></DIV>
<DIV style="position:absolute;top:666;left:483"><nobr><span class="ft47">5.0%</span></nobr></DIV>
<DIV style="position:absolute;top:643;left:478"><nobr><span class="ft47">10.0%</span></nobr></DIV>
<DIV style="position:absolute;top:619;left:478"><nobr><span class="ft47">15.0%</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:478"><nobr><span class="ft47">20.0%</span></nobr></DIV>
<DIV style="position:absolute;top:572;left:478"><nobr><span class="ft47">25.0%</span></nobr></DIV>
<DIV style="position:absolute;top:548;left:478"><nobr><span class="ft47">30.0%</span></nobr></DIV>
<DIV style="position:absolute;top:525;left:478"><nobr><span class="ft47">35.0%</span></nobr></DIV>
<DIV style="position:absolute;top:704;left:500"><nobr><span class="ft47">0.0%</span></nobr></DIV>
<DIV style="position:absolute;top:704;left:555"><nobr><span class="ft47">2.0%</span></nobr></DIV>
<DIV style="position:absolute;top:704;left:609"><nobr><span class="ft47">4.0%</span></nobr></DIV>
<DIV style="position:absolute;top:704;left:663"><nobr><span class="ft47">6.0%</span></nobr></DIV>
<DIV style="position:absolute;top:704;left:718"><nobr><span class="ft47">8.0%</span></nobr></DIV>
<DIV style="position:absolute;top:704;left:770"><nobr><span class="ft47">10.0%</span></nobr></DIV>
<DIV style="position:absolute;top:717;left:638"><nobr><span class="ft48">support</span></nobr></DIV>
<DIV style="position:absolute;top:614;left:469"><nobr><span class="ft48">FD</span></nobr></DIV>
<DIV style="position:absolute;top:598;left:469"><nobr><span class="ft48">R</span></nobr></DIV>
<DIV style="position:absolute;top:537;left:662"><nobr><span class="ft8"> = 10%</span></nobr></DIV>
<DIV style="position:absolute;top:537;left:754"><nobr><span class="ft8"> = 5%</span></nobr></DIV>
<DIV style="position:absolute;top:554;left:662"><nobr><span class="ft8"> = 2.5%</span></nobr></DIV>
<DIV style="position:absolute;top:554;left:754"><nobr><span class="ft8"> = 1%</span></nobr></DIV>
<DIV style="position:absolute;top:730;left:833"><nobr><span class="ft5"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:749;left:84"><nobr><span class="ft5"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:749;left:146"><nobr><span class="ft5"><b>Figure 6.1. Effect of support on # of rules </b></span></nobr></DIV>
<DIV style="position:absolute;top:749;left:545"><nobr><span class="ft5"><b>Figure 6.2. Effect of support on FDR </b></span></nobr></DIV>
<DIV style="position:absolute;top:958;left:99"><nobr><span class="ft47">0.00%</span></nobr></DIV>
<DIV style="position:absolute;top:932;left:99"><nobr><span class="ft47">5.00%</span></nobr></DIV>
<DIV style="position:absolute;top:905;left:94"><nobr><span class="ft47">10.00%</span></nobr></DIV>
<DIV style="position:absolute;top:879;left:94"><nobr><span class="ft47">15.00%</span></nobr></DIV>
<DIV style="position:absolute;top:852;left:94"><nobr><span class="ft47">20.00%</span></nobr></DIV>
<DIV style="position:absolute;top:825;left:94"><nobr><span class="ft47">25.00%</span></nobr></DIV>
<DIV style="position:absolute;top:799;left:94"><nobr><span class="ft47">30.00%</span></nobr></DIV>
<DIV style="position:absolute;top:971;left:118"><nobr><span class="ft47">0.00%</span></nobr></DIV>
<DIV style="position:absolute;top:971;left:169"><nobr><span class="ft47">2.00%</span></nobr></DIV>
<DIV style="position:absolute;top:971;left:219"><nobr><span class="ft47">4.00%</span></nobr></DIV>
<DIV style="position:absolute;top:971;left:270"><nobr><span class="ft47">6.00%</span></nobr></DIV>
<DIV style="position:absolute;top:971;left:321"><nobr><span class="ft47">8.00%</span></nobr></DIV>
<DIV style="position:absolute;top:971;left:369"><nobr><span class="ft47">10.00%</span></nobr></DIV>
<DIV style="position:absolute;top:984;left:212"><nobr><span class="ft48">significance level </span></nobr></DIV>
<DIV style="position:absolute;top:983;left:307"><nobr><span class="ft49"></span></nobr></DIV>
<DIV style="position:absolute;top:887;left:91"><nobr><span class="ft48">FD</span></nobr></DIV>
<DIV style="position:absolute;top:871;left:91"><nobr><span class="ft48">R</span></nobr></DIV>
<DIV style="position:absolute;top:808;left:179"><nobr><span class="ft58">support = 1%<br>support = 2%<br>support = 5%<br>support = 10%</span></nobr></DIV>
<DIV style="position:absolute;top:996;left:432"><nobr><span class="ft5"><b>    </b></span></nobr></DIV>
<DIV style="position:absolute;top:956;left:496"><nobr><span class="ft47">0</span></nobr></DIV>
<DIV style="position:absolute;top:932;left:486"><nobr><span class="ft47">200</span></nobr></DIV>
<DIV style="position:absolute;top:908;left:486"><nobr><span class="ft47">400</span></nobr></DIV>
<DIV style="position:absolute;top:884;left:486"><nobr><span class="ft47">600</span></nobr></DIV>
<DIV style="position:absolute;top:860;left:486"><nobr><span class="ft47">800</span></nobr></DIV>
<DIV style="position:absolute;top:836;left:481"><nobr><span class="ft47">1000</span></nobr></DIV>
<DIV style="position:absolute;top:812;left:481"><nobr><span class="ft47">1200</span></nobr></DIV>
<DIV style="position:absolute;top:788;left:481"><nobr><span class="ft47">1400</span></nobr></DIV>
<DIV style="position:absolute;top:969;left:498"><nobr><span class="ft47">0.0%</span></nobr></DIV>
<DIV style="position:absolute;top:969;left:553"><nobr><span class="ft47">2.0%</span></nobr></DIV>
<DIV style="position:absolute;top:969;left:608"><nobr><span class="ft47">4.0%</span></nobr></DIV>
<DIV style="position:absolute;top:969;left:664"><nobr><span class="ft47">6.0%</span></nobr></DIV>
<DIV style="position:absolute;top:969;left:719"><nobr><span class="ft47">8.0%</span></nobr></DIV>
<DIV style="position:absolute;top:969;left:772"><nobr><span class="ft47">10.0%</span></nobr></DIV>
<DIV style="position:absolute;top:983;left:608"><nobr><span class="ft48">significance level </span></nobr></DIV>
<DIV style="position:absolute;top:982;left:702"><nobr><span class="ft49"></span></nobr></DIV>
<DIV style="position:absolute;top:917;left:466"><nobr><span class="ft48"># o</span></nobr></DIV>
<DIV style="position:absolute;top:901;left:466"><nobr><span class="ft52">f<br> s<br>i<br>g<br>n<br>ificant r</span></nobr></DIV>
<DIV style="position:absolute;top:833;left:466"><nobr><span class="ft54">u<br>le<br>s</span></nobr></DIV>
<DIV style="position:absolute;top:799;left:558"><nobr><span class="ft51">support = 1%</span></nobr></DIV>
<DIV style="position:absolute;top:815;left:558"><nobr><span class="ft51">support = 2%</span></nobr></DIV>
<DIV style="position:absolute;top:832;left:558"><nobr><span class="ft51">support = 5%</span></nobr></DIV>
<DIV style="position:absolute;top:848;left:558"><nobr><span class="ft51">support = 10%</span></nobr></DIV>
<DIV style="position:absolute;top:996;left:818"><nobr><span class="ft5"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:84"><nobr><span class="ft5"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:177"><nobr><span class="ft5"><b>Figure 6.3. Effect of </b></span></nobr></DIV>
<DIV style="position:absolute;top:1014;left:295"><nobr><span class="ft21"><b> on FDR </b></span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:551"><nobr><span class="ft5"><b>Figure 6.4. Effect of </b></span></nobr></DIV>
<DIV style="position:absolute;top:1014;left:669"><nobr><span class="ft21"><b> on # of rules </b></span></nobr></DIV>
<DIV style="position:absolute;top:1037;left:84"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:449"><nobr><span class="ft4">380</span></nobr></DIV>
<DIV style="position:absolute;top:54;left:80"><nobr><span class="ft14"><b>Research Track Paper</b></span></nobr></DIV>
</DIV>
<!-- Page 8 -->
<a name="8"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft59{font-size:11px;line-height:22px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="144008.png" alt="background image">
<DIV style="position:absolute;top:109;left:81"><nobr><span class="ft3"><b>6.3</b></span></nobr></DIV>
<DIV style="position:absolute;top:109;left:104"><nobr><span class="ft6"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:109;left:114"><nobr><span class="ft3"><b>Summary results for online book retailers </b></span></nobr></DIV>
<DIV style="position:absolute;top:130;left:81"><nobr><span class="ft32">Based on this general tradeoff we chose minimum support of 2% <br>and chose an </span></nobr></DIV>
<DIV style="position:absolute;top:145;left:156"><nobr><span class="ft21"> of 2.5% in order to report summary results for the </span></nobr></DIV>
<DIV style="position:absolute;top:162;left:81"><nobr><span class="ft16">three sites. Table 6.1 summarizes the number of significant rules <br>discovered and the false discovery rates of the procedure. As the <br>values in the table and the examples above show, our procedure <br>can be used effectively to learn a good set of significant SQ rules <br>while keeping the false discovery rates reasonable. </span></nobr></DIV>
<DIV style="position:absolute;top:248;left:176"><nobr><span class="ft5"><b>Table 6.1 Summary of results </b></span></nobr></DIV>
<DIV style="position:absolute;top:273;left:121"><nobr><span class="ft31"><b>Web site </b></span></nobr></DIV>
<DIV style="position:absolute;top:273;left:208"><nobr><span class="ft31"><b>Significant Rules </b></span></nobr></DIV>
<DIV style="position:absolute;top:273;left:329"><nobr><span class="ft31"><b>False Discovery </b></span></nobr></DIV>
<DIV style="position:absolute;top:288;left:357"><nobr><span class="ft31"><b>Rate </b></span></nobr></DIV>
<DIV style="position:absolute;top:304;left:123"><nobr><span class="ft11">Amazon 651 </span></nobr></DIV>
<DIV style="position:absolute;top:304;left:353"><nobr><span class="ft11">6.30% </span></nobr></DIV>
<DIV style="position:absolute;top:323;left:105"><nobr><span class="ft11">Barnesandnoble 393 </span></nobr></DIV>
<DIV style="position:absolute;top:323;left:353"><nobr><span class="ft11">9.67% </span></nobr></DIV>
<DIV style="position:absolute;top:342;left:131"><nobr><span class="ft11">Ebay 679  5.60% </span></nobr></DIV>
<DIV style="position:absolute;top:368;left:81"><nobr><span class="ft32">In this section we first presented compelling examples of rules <br>discovered that illustrate the potential of learning significant <br>market share rules. We then examined how the number of <br>significant rules discovered and the false discovery rate changes <br>with the support and significance level (</span></nobr></DIV>
<DIV style="position:absolute;top:431;left:299"><nobr><span class="ft21">) parameters. The results </span></nobr></DIV>
<DIV style="position:absolute;top:448;left:81"><nobr><span class="ft16">of this analysis suggested a tradeoff between generating <br>significant rules and keeping the false discovery rate low. Based <br>on this tradeoff we identified a specific value of the support and <br>significance parameters and showed the number of rules <br>discovered for these values.  </span></nobr></DIV>
<DIV style="position:absolute;top:534;left:81"><nobr><span class="ft3"><b>7.</b></span></nobr></DIV>
<DIV style="position:absolute;top:534;left:95"><nobr><span class="ft6"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:534;left:105"><nobr><span class="ft3"><b>RELATED WORK </b></span></nobr></DIV>
<DIV style="position:absolute;top:555;left:81"><nobr><span class="ft32">We compare our work with the literature based on three aspects: <br>rule structure, rule significance, and methodology. <br><b>Rule structure</b>. Rule discovery methods on a quantitative dataset <br>can be traced back to [29], where rules of the form <i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:616;left:370"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:609;left:374"><nobr><span class="ft4"> &lt; <i>A</i> &lt; <i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:616;left:419"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:609;left:424"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:608;left:428"><nobr><span class="ft21"> </span></nobr></DIV>
<DIV style="position:absolute;top:625;left:81"><nobr><span class="ft18"><i>y</i></span></nobr></DIV>
<DIV style="position:absolute;top:631;left:87"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:625;left:92"><nobr><span class="ft4"> &lt; <i>B</i> &lt; <i>y</i></span></nobr></DIV>
<DIV style="position:absolute;top:631;left:150"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:625;left:154"><nobr><span class="ft4"> are discovered. [31] extends the structure to be </span></nobr></DIV>
<DIV style="position:absolute;top:641;left:81"><nobr><span class="ft16">conjunctions of multiple conditions on both antecedent and <br>consequent of a rule, and proposes their discovery method based <br>on the <i>Apriori</i> algorithm [1]. Although rules in [31] are important, <br>partitions like <i>y</i></span></nobr></DIV>
<DIV style="position:absolute;top:695;left:166"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:689;left:171"><nobr><span class="ft4"> &lt; <i>B</i> &lt; <i>y</i></span></nobr></DIV>
<DIV style="position:absolute;top:695;left:216"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:689;left:221"><nobr><span class="ft4"> for continuous attributes on the RHS of </span></nobr></DIV>
<DIV style="position:absolute;top:704;left:81"><nobr><span class="ft16">a rule only gives partial description of the subset satisfying the <br>LHS of the rule and partial descriptions sometimes are <br>misleading. Observing this problem, [2] introduces a new <br>structure where the consequent of a rule is <i>Mean</i>(<i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:758;left:410"><nobr><span class="ft20"><i>X</i></span></nobr></DIV>
<DIV style="position:absolute;top:752;left:416"><nobr><span class="ft4">) or </span></nobr></DIV>
<DIV style="position:absolute;top:768;left:81"><nobr><span class="ft18"><i>Variance</i>(<i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:774;left:145"><nobr><span class="ft20"><i>X</i></span></nobr></DIV>
<DIV style="position:absolute;top:768;left:150"><nobr><span class="ft4">) to summarize the behavior of the subset satisfying </span></nobr></DIV>
<DIV style="position:absolute;top:784;left:81"><nobr><span class="ft16">the antecedent. [33] further extends the form of the consequent of <br>the rule, such that it can be of <i>Min</i>(<i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:806;left:298"><nobr><span class="ft20"><i>X</i></span></nobr></DIV>
<DIV style="position:absolute;top:799;left:303"><nobr><span class="ft4">),  <i>Max</i>(<i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:806;left:355"><nobr><span class="ft20"><i>X</i></span></nobr></DIV>
<DIV style="position:absolute;top:799;left:360"><nobr><span class="ft4">), or <i>Sum</i>(<i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:806;left:428"><nobr><span class="ft20"><i>X</i></span></nobr></DIV>
<DIV style="position:absolute;top:799;left:433"><nobr><span class="ft4">). </span></nobr></DIV>
<DIV style="position:absolute;top:815;left:81"><nobr><span class="ft16">Our rule structure is based on prior work: the antecedent is <br>conjunctions of conditions, while the consequent can be any <br>aggregate function <i>f</i> on multiple attributes to describe the <br>behavior of the subset satisfying the antecedent. </span></nobr></DIV>
<DIV style="position:absolute;top:888;left:81"><nobr><span class="ft16"><b>Rule significance</b>. Any combination of attributes with conditions <br>can potentially form a rule. Researchers use different <br>measurements, e.g. support and confidence, to select only <br><i>important</i> rules from all possible rules. Based on the support and <br>confidence framework, many metrics have been developed, such <br>as gain [15], conviction [10], unexpectedness [27]. Although <br>these metrics can be generalized to rules where the antecedent and <br>consequent are both conjunctions of the form <i>value</i></span></nobr></DIV>
<DIV style="position:absolute;top:1005;left:362"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:999;left:366"><nobr><span class="ft4"> &lt; <i>Attribute</i> &lt; </span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:81"><nobr><span class="ft18"><i>value</i></span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:110"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:115"><nobr><span class="ft4"> for quantitative datasets, they are not applicable for rules </span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:81"><nobr><span class="ft4">whose consequent is a function, such as <i>Mean</i>(<i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:1037;left:350"><nobr><span class="ft20"><i>X</i></span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:356"><nobr><span class="ft4">), or in general, </span></nobr></DIV>
<DIV style="position:absolute;top:1046;left:81"><nobr><span class="ft18"><i>f</i>(<i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:99"><nobr><span class="ft20"><i>X</i></span></nobr></DIV>
<DIV style="position:absolute;top:1046;left:104"><nobr><span class="ft4">). To solve this non-trivial problem, we use statistical </span></nobr></DIV>
<DIV style="position:absolute;top:1062;left:81"><nobr><span class="ft4">significance tests to evaluate rules, so that the consequent of a </span></nobr></DIV>
<DIV style="position:absolute;top:109;left:477"><nobr><span class="ft32">rule is not expected by chance alone. In the data mining literature, <br>statistical significance tests are commonly used in many <br>applications. For example, chi-square (</span></nobr></DIV>
<DIV style="position:absolute;top:139;left:701"><nobr><span class="ft22"></span></nobr></DIV>
<DIV style="position:absolute;top:139;left:709"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:141;left:713"><nobr><span class="ft4">) is a statistic to test </span></nobr></DIV>
<DIV style="position:absolute;top:157;left:477"><nobr><span class="ft16">correlations between attributes in binary or categorical data, and it <br>has been applied to discover correlation rules [9], actionable rules <br>[23], and contrast sets [3, 32]. For sparse data, [35, 36] employ <br>Fisher's Exact Test to detect anomaly patterns for disease <br>outbreaks. As mentioned in Section 3, these two tests are special <br>cases of our significance test when we apply our significance <br>definition to categorical data. For quantitative rules in [2], the <br>authors use a standard Z-test to determine the significance of <br>inequality of means between a subset <i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:290;left:696"><nobr><span class="ft20"><i>X</i></span></nobr></DIV>
<DIV style="position:absolute;top:284;left:701"><nobr><span class="ft4"> and its complement <i>D</i> ­ </span></nobr></DIV>
<DIV style="position:absolute;top:300;left:477"><nobr><span class="ft18"><i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:306;left:487"><nobr><span class="ft20"><i>X</i></span></nobr></DIV>
<DIV style="position:absolute;top:300;left:492"><nobr><span class="ft4">. [33] defines a new measurement, <i>impact</i>, to evaluate </span></nobr></DIV>
<DIV style="position:absolute;top:315;left:477"><nobr><span class="ft16">quantitative rules, where <i>impact</i> can identify those groups that <br>contribute most to some outcome, such as profits or costs. For <br>areas other than rule discovery, standard Z-tests with log-linear <br>models is used in Exploratory Data Analysis for OLAP data cubes <br>[30]. Our significance test is different from the above primarily <br>because (i) our significance definition is applicable to any user-<br>defined aggregate function <i>f</i>(<i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:417;left:645"><nobr><span class="ft20"><i>X</i></span></nobr></DIV>
<DIV style="position:absolute;top:411;left:651"><nobr><span class="ft4">), and (ii) we using nonparametric </span></nobr></DIV>
<DIV style="position:absolute;top:426;left:477"><nobr><span class="ft16">methods to construct distributions and confidence intervals, in <br>which <i>f</i>(<i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:448;left:531"><nobr><span class="ft20"><i>X</i></span></nobr></DIV>
<DIV style="position:absolute;top:442;left:537"><nobr><span class="ft4">) is expected from random effects alone. </span></nobr></DIV>
<DIV style="position:absolute;top:467;left:477"><nobr><span class="ft32"><b>Methodology</b>. Nonparametric statistics is philosophically related <br>to data mining, in that both methods typically make no <br>assumptions on distributions of data or test statistics. Even with <br>known distribution of a statistic, nonparametric methods are <br>useful to estimate parameters of the distribution [13]. <br>Nonparametric methods are widely used on testing models that <br>are built from data: as earliest in [18], the author uses <br>randomization tests to tackle a model overfitting problem; [20] <br>compares bootstrap and cross-validation for model accuracy <br>estimation; for decision trees, [14, 26] use permutation tests to <br>select attributes based on 2</span></nobr></DIV>
<DIV style="position:absolute;top:625;left:626"><nobr><span class="ft21">×2 contingency tables. Rule discovery </span></nobr></DIV>
<DIV style="position:absolute;top:643;left:477"><nobr><span class="ft16">is to learn local features, which is inherently different from <br>models. Although we have seen methods using parametric <br>hypothesis testing approach to learning rules from dataset [5, 6], <br>no prior work has been found on discovering large number of <br>rules based on nonparametric significance tests.  </span></nobr></DIV>
<DIV style="position:absolute;top:731;left:477"><nobr><span class="ft16">The problem of multiple hypothesis testing/multiple comparison <br>is well known in rule discovery, a good review of which can be <br>found in [19]. On sparse binary data, [25] shows that with proper <br>support and confidence control, very few false rules will be <br>discovered. However, rule discovery on quantitative data faces <br>much more complicated challenges, and conventional <i>p</i>-value <br>adjustment methods cannot be directly applied. To solve this <br>problem, we employ false discovery rate [4] metric to estimate the <br>number of false rules discovered due to testing a large number of <br>rules. In data mining, FDR has been shown useful in [7, 36] for <br>categorical data with known number of hypotheses, and we <br>extend it to quantitative rules with resampling methods. </span></nobr></DIV>
<DIV style="position:absolute;top:936;left:477"><nobr><span class="ft3"><b>8.</b></span></nobr></DIV>
<DIV style="position:absolute;top:936;left:490"><nobr><span class="ft6"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:936;left:501"><nobr><span class="ft3"><b>CONCLUSION  </b></span></nobr></DIV>
<DIV style="position:absolute;top:957;left:477"><nobr><span class="ft16">In this paper we defined a new category of rules, SQ rules, and <br>the significance of SQ rules, on quantitative data. Then we <br>presented a permutation-based algorithm for learning significant <br>SQ rules. Furthermore, we show how an explicit false discovery <br>rate can be estimated for our procedure, which makes the <br>approach useful from a practical perspective. We presented <br>experiments in which we discovered market share rules, a specific </span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:449"><nobr><span class="ft4">381</span></nobr></DIV>
<DIV style="position:absolute;top:54;left:681"><nobr><span class="ft14"><b>Research Track Paper</b></span></nobr></DIV>
</DIV>
<!-- Page 9 -->
<a name="9"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="144009.png" alt="background image">
<DIV style="position:absolute;top:109;left:81"><nobr><span class="ft16">type of SQ rules, in real online purchase datasets and <br>demonstrated that our approach can be used to learn interesting <br>rules from data.  <br>We would also like to point out that it is possible to compute the <br>false discovery rate (<i>FDR</i>) for several possible significance levels <br>in an efficient manner (without creating permutation datasets for <br>each significance level). Although a detailed presentation of this <br>is beyond the scope of this paper, in the appendix we provide an <br>overview of how this can be done. One main advantage of being <br>able to do this is that significant SQ rules can be discovered at a <br>chosen significance level that is computed from some desired <br><i>FDR</i>. Hence rather than just <i>estimating</i> <i>FDR</i> we may be able to <br>discover significant rules <i>given</i> a specific <i>FDR</i>. However this <br>needs to be studied in greater detail in future work. </span></nobr></DIV>
<DIV style="position:absolute;top:355;left:81"><nobr><span class="ft3"><b>9.</b></span></nobr></DIV>
<DIV style="position:absolute;top:355;left:95"><nobr><span class="ft6"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:355;left:105"><nobr><span class="ft3"><b>REFERENCES </b></span></nobr></DIV>
<DIV style="position:absolute;top:375;left:81"><nobr><span class="ft4">[1]  Agrawal, R. and Srikant, R., Fast Algorithms for Mining </span></nobr></DIV>
<DIV style="position:absolute;top:391;left:108"><nobr><span class="ft43">Association Rules, in <i>Proceedings of the 20th International <br>Conference on Very Large Databases</i>, Santiago, Chile, 1994. </span></nobr></DIV>
<DIV style="position:absolute;top:423;left:81"><nobr><span class="ft4">[2]  Aumann, Y. and Lindell, Y., A Statistical Theory for </span></nobr></DIV>
<DIV style="position:absolute;top:439;left:108"><nobr><span class="ft43">Quantitative Association Rules, in <i>Proceedings of The Fifth <br>ACM SIGKDD Int'l Conference on Knowledge Discovery <br>and Data Mining</i>, pp. 261-270, San Diego, CA, 1999. </span></nobr></DIV>
<DIV style="position:absolute;top:486;left:81"><nobr><span class="ft4">[3]  Bay, S. D. and Pazzani, M. J., Detecting Change in </span></nobr></DIV>
<DIV style="position:absolute;top:502;left:108"><nobr><span class="ft16">Categorical Data: Mining Contrast Sets, in <i>Proceedings of <br>the Fifth ACM SIGKDD International Conference on <br>Knowledge Discovery and Data Mining</i>, pp. 302 - 306, San <br>Diego, CA, 1999. </span></nobr></DIV>
<DIV style="position:absolute;top:565;left:81"><nobr><span class="ft4">[4]  Benjamini, Y. and Hochberg, Y., Controlling the False </span></nobr></DIV>
<DIV style="position:absolute;top:581;left:108"><nobr><span class="ft16">Discovery Rate: A Practical and Powerful Approach to <br>Multiple Testing, <i>Journal of Royal Statistical Society B</i>, vol. <br>57, iss. 1, pp. 289-300, 1995. </span></nobr></DIV>
<DIV style="position:absolute;top:629;left:81"><nobr><span class="ft4">[5]  Bolton, R. and Adams, N., An Iterative Hypothesis-Testing </span></nobr></DIV>
<DIV style="position:absolute;top:645;left:108"><nobr><span class="ft43">Strategy for Pattern Discovery, in <i>Proceedings of the Ninth <br>ACM SIGKDD Int'l Conference on Knowledge Discovery <br>and Data Mining</i>, pp. 49-58, Washington, DC, 2003. </span></nobr></DIV>
<DIV style="position:absolute;top:692;left:81"><nobr><span class="ft4">[6]  Bolton, R. J. and Hand, D. J., Significance Tests for Patterns </span></nobr></DIV>
<DIV style="position:absolute;top:708;left:108"><nobr><span class="ft16">in Continuous Data, in <i>Proceedings of the 2001 IEEE <br>International Conference on Data Mining</i>, pp. 67-74, San <br>Jose, CA, 2001. </span></nobr></DIV>
<DIV style="position:absolute;top:756;left:81"><nobr><span class="ft4">[7]  Bolton, R. J., Hand, D. J., and Adams, N. M., Determining </span></nobr></DIV>
<DIV style="position:absolute;top:771;left:108"><nobr><span class="ft16">Hit Rate in Pattern Search, in <i>Pattern Detection and <br>Discovery, ESF Exploratory Workshop</i>, pp. 36-48, London, <br>UK, 2002. </span></nobr></DIV>
<DIV style="position:absolute;top:819;left:81"><nobr><span class="ft4">[8]  Brijs, T., Swinnen, G., Vanhoof, K., and Wets, G., Using </span></nobr></DIV>
<DIV style="position:absolute;top:835;left:108"><nobr><span class="ft43">Association Rules for Product Assortment: Decisions Case <br>Study, in <i>Proceedings of the Fifth ACM SIGKDD <br>International Conference on Knowledge Discovery and Data <br>Mining</i>, pp. 254-260, San Diego, CA, 1999. </span></nobr></DIV>
<DIV style="position:absolute;top:898;left:81"><nobr><span class="ft4">[9]  Brin, S., Motwani, R., and Silverstein, C., Beyond Market </span></nobr></DIV>
<DIV style="position:absolute;top:914;left:108"><nobr><span class="ft43">Baskets: Generalizing Association Rules to Correlations, in <br><i>Proceedings of the ACM SIGMOD/PODS '97 Joint <br>Conference</i>, pp. 265-276, Tucson, AZ, 1997. </span></nobr></DIV>
<DIV style="position:absolute;top:961;left:81"><nobr><span class="ft4">[10] Brin, S., Motwani, R., Ullman, J. D., and Tsur, S., Dynamic </span></nobr></DIV>
<DIV style="position:absolute;top:977;left:108"><nobr><span class="ft16">Itemset Counting and Implication Rules for Market Basket <br>Data, in <i>Proceedings ACM SIGMOD International <br>Conference on Management of Data (SIGMOD'97)</i>, pp. 255-<br>264, Tucson, AZ, 1997. </span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:81"><nobr><span class="ft4">[11] Clark, P. and Niblett, T., The Cn2 Induction Algorithm, </span></nobr></DIV>
<DIV style="position:absolute;top:1057;left:108"><nobr><span class="ft18"><i>Machine Learning</i>, vol. 3, pp. 261-283, 1989. </span></nobr></DIV>
<DIV style="position:absolute;top:109;left:477"><nobr><span class="ft4">[12] Clearwater, S. and Provost, F., Rl4: A Tool for Knowledge-</span></nobr></DIV>
<DIV style="position:absolute;top:124;left:504"><nobr><span class="ft16">Based Induction, in <i>Procs. of the Second International IEEE <br>Conference on Tools for Artificial Intelligence</i>, pp. 24-30, <br>1990. </span></nobr></DIV>
<DIV style="position:absolute;top:172;left:477"><nobr><span class="ft4">[13] Efron, B. and Tibshirani, R. J., <i>An Introduction to the </i></span></nobr></DIV>
<DIV style="position:absolute;top:188;left:504"><nobr><span class="ft18"><i>Bootstrap</i>. New York, NY: Chapman &amp; Hall, 1993. </span></nobr></DIV>
<DIV style="position:absolute;top:204;left:477"><nobr><span class="ft4">[14] Frank, E. and Witten, I. H., Using a Permutation Test for </span></nobr></DIV>
<DIV style="position:absolute;top:219;left:504"><nobr><span class="ft43">Attribute Selection in Decision Trees, in <i>Proceedings of 15th <br>Int'l Conference on Machine Learning</i>, pp. 152-160, 1998. </span></nobr></DIV>
<DIV style="position:absolute;top:251;left:477"><nobr><span class="ft4">[15] Fukuda, T., Morimoto, Y., Morishita, S., and Tokuyama, T., </span></nobr></DIV>
<DIV style="position:absolute;top:267;left:504"><nobr><span class="ft16">Data Mining Using Two-Dimensional Optimized <br>Association Rules: Scheme, Algorithms and Visualization, in <br><i>Proceedings of the 1996 ACM SIGMOD International <br>Conference on Management of Data (SIGMOD'96)</i>, pp. 13-<br>23, Montreal, Quebec, Canada, 1996. </span></nobr></DIV>
<DIV style="position:absolute;top:346;left:477"><nobr><span class="ft4">[16] Good, P., <i>Permutation Tests: A Practical Guide to </i></span></nobr></DIV>
<DIV style="position:absolute;top:362;left:504"><nobr><span class="ft16"><i>Resampling Methods for Testing Hypotheses - 2nd Edition</i>. <br>New York: Springer, 2000. </span></nobr></DIV>
<DIV style="position:absolute;top:394;left:477"><nobr><span class="ft4">[17] Hsu, J. C., <i>Multiple Comparisons - Theory and Methods</i>. </span></nobr></DIV>
<DIV style="position:absolute;top:410;left:504"><nobr><span class="ft4">London, UK: Chapman &amp; Hall, 1996. </span></nobr></DIV>
<DIV style="position:absolute;top:425;left:477"><nobr><span class="ft4">[18] Jensen, D., Knowledge Discovery through Induction with </span></nobr></DIV>
<DIV style="position:absolute;top:441;left:504"><nobr><span class="ft16">Randomization Testing, in <i>Proceedings of the 1991 <br>Knowledge Discovery in Databases Workshop</i>, pp. 148-159, <br>Menlo Park, 1991. </span></nobr></DIV>
<DIV style="position:absolute;top:489;left:477"><nobr><span class="ft4">[19] Jensen, D. and Cohen, P. R., Multiple Comparisons in </span></nobr></DIV>
<DIV style="position:absolute;top:505;left:504"><nobr><span class="ft16">Induction Algorithms, <i>Machine Learning</i>, vol. 38, pp. 309-<br>338, 2000. </span></nobr></DIV>
<DIV style="position:absolute;top:536;left:477"><nobr><span class="ft4">[20] Kohavi, R., A Study of Cross-Validation and Bootstrap for </span></nobr></DIV>
<DIV style="position:absolute;top:552;left:504"><nobr><span class="ft43">Accuracy Estimation and Model Selection, in <i>Proceedings of <br>the Fourteenth International Joint Conference on Artificial <br>Intelligence</i>, pp. 1137-1143, San Mateo, CA, 1995. </span></nobr></DIV>
<DIV style="position:absolute;top:600;left:477"><nobr><span class="ft4">[21] Lee, Y., Buchanan, B. G., and Aronis, J. M., Knowledge-</span></nobr></DIV>
<DIV style="position:absolute;top:615;left:504"><nobr><span class="ft16">Based Learning in Exploratory Science: Learning Rules to <br>Predict Rodent Carcinogenicity, <i>Machine Learning</i>, vol. 30, <br>pp. 217-240, 1998. </span></nobr></DIV>
<DIV style="position:absolute;top:663;left:477"><nobr><span class="ft4">[22] Ling, C. X. and Li, C., Data Mining for Direct Marketing: </span></nobr></DIV>
<DIV style="position:absolute;top:679;left:504"><nobr><span class="ft43">Problems and Solutions, in <i>Proceedings of the Fourth <br>International Conference on Knowledge Discovery and Data <br>Mining</i>, pp. 73-79, New York, NY, 1998. </span></nobr></DIV>
<DIV style="position:absolute;top:726;left:477"><nobr><span class="ft4">[23] Liu, B., Hsu, W., and Ma, Y., Identifying Non-Actionable </span></nobr></DIV>
<DIV style="position:absolute;top:742;left:504"><nobr><span class="ft43">Association Rules, in <i>Proceedings of the Seventh ACM <br>SIGKDD International Conference on Knowledge Discovery <br>and Data Mining</i>, pp. 329-334, San Francisco, CA, 2001. </span></nobr></DIV>
<DIV style="position:absolute;top:790;left:477"><nobr><span class="ft4">[24] Mani, D. R., Drew, J., Betz, A., and Datta, P., Statistics and </span></nobr></DIV>
<DIV style="position:absolute;top:806;left:504"><nobr><span class="ft16">Data Mining Techniques for Lifetime Value Modeling, in <br><i>Proceedings of the Fifth ACM SIGKDD International <br>Conference on Knowledge Discovery and Data Mining</i>, pp. <br>94-103, San Diego, CA, 1999. </span></nobr></DIV>
<DIV style="position:absolute;top:869;left:477"><nobr><span class="ft4">[25] Megiddo, N. and Srikant, R., Discovering Predictive </span></nobr></DIV>
<DIV style="position:absolute;top:885;left:504"><nobr><span class="ft43">Association Rules, in <i>Proceedings of the Fourth <br>International Conference on Knowledge Discovery and Data <br>Mining</i>, pp. 274-278, New York, NY, 1998. </span></nobr></DIV>
<DIV style="position:absolute;top:932;left:477"><nobr><span class="ft4">[26] Oates, T. and Jensen, D., Large Datasets Lead to Overly </span></nobr></DIV>
<DIV style="position:absolute;top:948;left:504"><nobr><span class="ft16">Complex Models: An Explanation and a Solution, in <br><i>Proceedings of the Fourth International Conference on <br>Knowledge Discovery and Data Mining</i>, pp. 294-298, Menlo <br>Park, CA, 1998. </span></nobr></DIV>
<DIV style="position:absolute;top:1011;left:477"><nobr><span class="ft4">[27] Padmanabhan, B. and Tuzhilin, A., A Belief-Driven Method </span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:504"><nobr><span class="ft43">for Discovering Unexpected Patterns, in <i>Proceedings of the <br>Fourth International Conference on Knowledge Discovery <br>and Data Mining</i>, pp. 94-100, New York, NY, 1998. </span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:449"><nobr><span class="ft4">382</span></nobr></DIV>
<DIV style="position:absolute;top:54;left:80"><nobr><span class="ft14"><b>Research Track Paper</b></span></nobr></DIV>
</DIV>
<!-- Page 10 -->
<a name="10"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="144010.png" alt="background image">
<DIV style="position:absolute;top:109;left:81"><nobr><span class="ft4">[28] Padmanabhan, B. and Tuzhilin, A., Small Is Beautiful:  </span></nobr></DIV>
<DIV style="position:absolute;top:124;left:108"><nobr><span class="ft16">Discovering the Minimal Set of Unexpected Patterns, in <br><i>Proceedings of the Sixth ACM SIGKDD International <br>Conference on Knowledge Discovery &amp; Data Mining</i>, pp. 54-<br>63, Boston, MA, 2000. </span></nobr></DIV>
<DIV style="position:absolute;top:188;left:81"><nobr><span class="ft4">[29] Piatesky-Shapiro, G., Discovery, Analysis, and Presentation </span></nobr></DIV>
<DIV style="position:absolute;top:204;left:108"><nobr><span class="ft16">of Strong Rules, in <i>Knowledge Discovery in Databases</i>, <br>Piatesky-Shapiro, G. and Frawley, W. J., Eds. Menlo Park, <br>CA: AAAI/MIT Press, pp. 229-248, 1991. </span></nobr></DIV>
<DIV style="position:absolute;top:251;left:81"><nobr><span class="ft4">[30] Sarawagi, S., Agrawal, R., and Megiddo, N., Discovery-</span></nobr></DIV>
<DIV style="position:absolute;top:267;left:108"><nobr><span class="ft43">Driven Exploration of Olap Data Cubes, in <i>Proceedings of <br>the Sixth International Conference on Extending Database <br>Technology (EDBT'98)</i>, pp. 168-182, Valencia, Spain, 1998. </span></nobr></DIV>
<DIV style="position:absolute;top:314;left:81"><nobr><span class="ft4">[31] Srikant, R. and Agrawal, R., Mining Quantitative </span></nobr></DIV>
<DIV style="position:absolute;top:330;left:108"><nobr><span class="ft43">Association Rules in Large Relational Tables, in <br><i>Proceedings of the 1996 ACM SIGMOD International <br>Conference on Management of Data</i>, 1996. </span></nobr></DIV>
<DIV style="position:absolute;top:378;left:81"><nobr><span class="ft4">[32] Webb, G., Butler, S., and Newlands, D., On Detecting </span></nobr></DIV>
<DIV style="position:absolute;top:394;left:108"><nobr><span class="ft43">Differences between Groups, in <i>Proceedings of the Ninth <br>ACM SIGKDD Int'l Conference on Knowledge Discovery <br>and Data Mining</i>, pp. 256-265, Washington, DC, 2003. </span></nobr></DIV>
<DIV style="position:absolute;top:441;left:81"><nobr><span class="ft4">[33] Webb, G. I., Discovering Associations with Numeric </span></nobr></DIV>
<DIV style="position:absolute;top:457;left:108"><nobr><span class="ft43">Variables, in <i>Proceedings of The Seventh ACM SIGKDD <br>International Conference on Knowledge Discovery and Data <br>Mining</i>, San Francisco, CA, 2001. </span></nobr></DIV>
<DIV style="position:absolute;top:505;left:81"><nobr><span class="ft4">[34] Westfall, P. H. and Young, S. S., <i>Resampling-Based Multiple </i></span></nobr></DIV>
<DIV style="position:absolute;top:520;left:108"><nobr><span class="ft16"><i>Testing - Examples and Methods for P-Value Adjustment</i>. <br>New York, NY: John Wiley &amp; Sons, Inc, 1993. </span></nobr></DIV>
<DIV style="position:absolute;top:552;left:81"><nobr><span class="ft4">[35] Wong, W.-K., Moore, A., Cooper, G., and Wagner, M., </span></nobr></DIV>
<DIV style="position:absolute;top:568;left:108"><nobr><span class="ft16">Rule-Based Anomaly Pattern Detection for Detecting <br>Disease Outbreaks, in <i>Proceedings of the Eighteenth <br>National Conference on Artificial Intelligence (AAAI-2002)</i>, <br>Edmonton, Canada, 2002. </span></nobr></DIV>
<DIV style="position:absolute;top:631;left:81"><nobr><span class="ft4">[36] Wong, W.-K., Moore, A., Cooper, G., and Wagner, M., </span></nobr></DIV>
<DIV style="position:absolute;top:647;left:108"><nobr><span class="ft16">Bayesian Network Anomaly Pattern Detection for Disease <br>Outbreaks, in <i>Proceedings of the Twentieth International <br>Conference on Machine Learning (ICML-2003)</i>, <br>Washington, DC, 2003. </span></nobr></DIV>
<DIV style="position:absolute;top:710;left:81"><nobr><span class="ft4">  </span></nobr></DIV>
<DIV style="position:absolute;top:727;left:128"><nobr><span class="ft5"><b>APPENDIX</b>: <b>Discovering false discovery rates  </b></span></nobr></DIV>
<DIV style="position:absolute;top:743;left:174"><nobr><span class="ft5"><b>for multiple significance levels</b> </span></nobr></DIV>
<DIV style="position:absolute;top:768;left:81"><nobr><span class="ft4">Let us continue to use the example <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:775;left:290"><nobr><span class="ft20"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:768;left:308"><nobr><span class="ft4"> = 999 and </span></nobr></DIV>
<DIV style="position:absolute;top:767;left:374"><nobr><span class="ft21"> = 5%. On </span></nobr></DIV>
<DIV style="position:absolute;top:784;left:81"><nobr><span class="ft16">the dataset <i>D</i>, from the algorithm <i>SigSQrules</i> we generate <br>significant rules as well as each rule's <i>p</i>-value. Because there are <br><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:822;left:90"><nobr><span class="ft20"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:816;left:108"><nobr><span class="ft4"> values in each distribution, the smallest possible <i>p</i>-value </span></nobr></DIV>
<DIV style="position:absolute;top:832;left:81"><nobr><span class="ft4">from the permutation tests is 1/(<i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:838;left:264"><nobr><span class="ft20"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:832;left:282"><nobr><span class="ft4">+ 1) = 0.001, and all possible </span></nobr></DIV>
<DIV style="position:absolute;top:110;left:477"><nobr><span class="ft18"><i>p</i>-values are <i>S</i> = { 1/(<i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:116;left:602"><nobr><span class="ft20"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:110;left:620"><nobr><span class="ft4">+ 1) = 0.001, 2/(<i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:116;left:719"><nobr><span class="ft20"><i>perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:110;left:737"><nobr><span class="ft4">+ 1) = 0.002, ... </span></nobr></DIV>
<DIV style="position:absolute;top:108;left:828"><nobr><span class="ft21"> </span></nobr></DIV>
<DIV style="position:absolute;top:126;left:477"><nobr><span class="ft4">= 0.05 }. Let <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:133;left:559"><nobr><span class="ft20"><i>sig</i></span></nobr></DIV>
<DIV style="position:absolute;top:126;left:570"><nobr><span class="ft4">[</span></nobr></DIV>
<DIV style="position:absolute;top:125;left:574"><nobr><span class="ft21"></span></nobr></DIV>
<DIV style="position:absolute;top:133;left:583"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:126;left:594"><nobr><span class="ft4">] be the number of significant rules whose <i>p</i>-</span></nobr></DIV>
<DIV style="position:absolute;top:143;left:477"><nobr><span class="ft4">value is no larger than </span></nobr></DIV>
<DIV style="position:absolute;top:142;left:603"><nobr><span class="ft21"></span></nobr></DIV>
<DIV style="position:absolute;top:149;left:611"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:143;left:623"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:142;left:627"><nobr><span class="ft21"> <i>S</i>. For example, if there are 50 rules </span></nobr></DIV>
<DIV style="position:absolute;top:159;left:477"><nobr><span class="ft16">whose <i>p</i>-value = 0.001, and 30 rules whose <i>p</i>-value = 0.002, then <br><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:181;left:486"><nobr><span class="ft20"><i>sig</i></span></nobr></DIV>
<DIV style="position:absolute;top:175;left:496"><nobr><span class="ft4">[0.001] = 50 and <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:181;left:603"><nobr><span class="ft20"><i>sig</i></span></nobr></DIV>
<DIV style="position:absolute;top:175;left:614"><nobr><span class="ft4">[0.002] = 50 + 30 = 80. Without further </span></nobr></DIV>
<DIV style="position:absolute;top:191;left:477"><nobr><span class="ft4">permutation tests, with <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:197;left:619"><nobr><span class="ft20"><i>sig</i></span></nobr></DIV>
<DIV style="position:absolute;top:191;left:630"><nobr><span class="ft4">[] we know how many rules will be </span></nobr></DIV>
<DIV style="position:absolute;top:208;left:477"><nobr><span class="ft4">discovered if we lower the significance level from </span></nobr></DIV>
<DIV style="position:absolute;top:206;left:762"><nobr><span class="ft21"> to </span></nobr></DIV>
<DIV style="position:absolute;top:214;left:799"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:208;left:810"><nobr><span class="ft4">. For </span></nobr></DIV>
<DIV style="position:absolute;top:224;left:477"><nobr><span class="ft4">example, if </span></nobr></DIV>
<DIV style="position:absolute;top:223;left:547"><nobr><span class="ft21"></span></nobr></DIV>
<DIV style="position:absolute;top:231;left:555"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:224;left:567"><nobr><span class="ft4"> = 0.002, there are only <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:231;left:722"><nobr><span class="ft20"><i>sig</i></span></nobr></DIV>
<DIV style="position:absolute;top:224;left:732"><nobr><span class="ft4">[0.002] = 80 rules </span></nobr></DIV>
<DIV style="position:absolute;top:241;left:477"><nobr><span class="ft4">whose <i>p</i>-value is no larger than </span></nobr></DIV>
<DIV style="position:absolute;top:240;left:655"><nobr><span class="ft21"></span></nobr></DIV>
<DIV style="position:absolute;top:247;left:663"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:241;left:675"><nobr><span class="ft4"> = 0.002, therefore we expect </span></nobr></DIV>
<DIV style="position:absolute;top:257;left:477"><nobr><span class="ft4">to discover 80 rules. </span></nobr></DIV>
<DIV style="position:absolute;top:283;left:477"><nobr><span class="ft4">Similarly, for each permutation dataset <i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:281;left:713"><nobr><span class="ft21">, at each significance </span></nobr></DIV>
<DIV style="position:absolute;top:300;left:477"><nobr><span class="ft4">level </span></nobr></DIV>
<DIV style="position:absolute;top:298;left:507"><nobr><span class="ft21"></span></nobr></DIV>
<DIV style="position:absolute;top:306;left:516"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:300;left:527"><nobr><span class="ft4"> &lt; </span></nobr></DIV>
<DIV style="position:absolute;top:298;left:542"><nobr><span class="ft21"> we can compute the number of significant rules and </span></nobr></DIV>
<DIV style="position:absolute;top:316;left:477"><nobr><span class="ft32">their  <i>p</i>-values by applying <i>SigSQrules</i> only once. Note that all <br>discoveries from <i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:331;left:601"><nobr><span class="ft21"> are false discoveries, because the </span></nobr></DIV>
<DIV style="position:absolute;top:349;left:477"><nobr><span class="ft4">relationships between <i>A</i> and <i>B</i> are removed. Let <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:355;left:763"><nobr><span class="ft20"><i>sig-perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:349;left:795"><nobr><span class="ft4">[<i>i</i>][</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:813"><nobr><span class="ft21"></span></nobr></DIV>
<DIV style="position:absolute;top:355;left:821"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:349;left:833"><nobr><span class="ft4">] </span></nobr></DIV>
<DIV style="position:absolute;top:366;left:477"><nobr><span class="ft4">be the number of discoveries from permutation datasets <i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:365;left:795"><nobr><span class="ft21">[<i>i</i>]. For </span></nobr></DIV>
<DIV style="position:absolute;top:382;left:477"><nobr><span class="ft4">example,  <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:388;left:541"><nobr><span class="ft20"><i>sig-perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:382;left:572"><nobr><span class="ft4">[1][0.002] = 20 means we have 20 discoveries </span></nobr></DIV>
<DIV style="position:absolute;top:399;left:477"><nobr><span class="ft4">from the permutation dataset <i>D</i></span></nobr></DIV>
<DIV style="position:absolute;top:397;left:647"><nobr><span class="ft21">[1] at </span></nobr></DIV>
<DIV style="position:absolute;top:405;left:692"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:399;left:704"><nobr><span class="ft4"> = 0.002. We implement </span></nobr></DIV>
<DIV style="position:absolute;top:415;left:477"><nobr><span class="ft32">this procedure on multiple permutation datasets, and <i>Median</i>(  <br><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:438;left:486"><nobr><span class="ft20"><i>sig-perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:431;left:518"><nobr><span class="ft4">[][</span></nobr></DIV>
<DIV style="position:absolute;top:430;left:531"><nobr><span class="ft21"></span></nobr></DIV>
<DIV style="position:absolute;top:438;left:540"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:431;left:551"><nobr><span class="ft4">]) is the estimate of false discoveries at each </span></nobr></DIV>
<DIV style="position:absolute;top:448;left:477"><nobr><span class="ft4">significance level </span></nobr></DIV>
<DIV style="position:absolute;top:447;left:591"><nobr><span class="ft21"></span></nobr></DIV>
<DIV style="position:absolute;top:454;left:599"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:448;left:611"><nobr><span class="ft4"> on permutation datasets. Therefore, </span></nobr></DIV>
<DIV style="position:absolute;top:465;left:477"><nobr><span class="ft18"><i>FDR</i>(</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:508"><nobr><span class="ft21"></span></nobr></DIV>
<DIV style="position:absolute;top:471;left:516"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:465;left:528"><nobr><span class="ft4">) = <i>Median</i>(<i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:471;left:605"><nobr><span class="ft20"><i>sig-perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:465;left:636"><nobr><span class="ft4">[][</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:650"><nobr><span class="ft21"></span></nobr></DIV>
<DIV style="position:absolute;top:471;left:658"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:465;left:670"><nobr><span class="ft4">]) / <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:471;left:701"><nobr><span class="ft20"><i>sig</i></span></nobr></DIV>
<DIV style="position:absolute;top:465;left:712"><nobr><span class="ft4">[</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:716"><nobr><span class="ft21"></span></nobr></DIV>
<DIV style="position:absolute;top:471;left:725"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:465;left:737"><nobr><span class="ft4">]. We use <i>Median</i> </span></nobr></DIV>
<DIV style="position:absolute;top:481;left:477"><nobr><span class="ft16">to estimate the expectation, which conforms to nonparametric <br>statistical considerations (median is the best estimator for <br>expectation when the underlying distribution is unknown). </span></nobr></DIV>
<DIV style="position:absolute;top:538;left:477"><nobr><span class="ft4">Empirically, we showed in Figure 6.3 that <i>FDR</i>(</span></nobr></DIV>
<DIV style="position:absolute;top:537;left:774"><nobr><span class="ft21"></span></nobr></DIV>
<DIV style="position:absolute;top:545;left:782"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:538;left:794"><nobr><span class="ft4">) is an </span></nobr></DIV>
<DIV style="position:absolute;top:555;left:477"><nobr><span class="ft4">increasing function on </span></nobr></DIV>
<DIV style="position:absolute;top:554;left:606"><nobr><span class="ft21"></span></nobr></DIV>
<DIV style="position:absolute;top:562;left:614"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:555;left:626"><nobr><span class="ft4">. It means that by decreasing </span></nobr></DIV>
<DIV style="position:absolute;top:554;left:793"><nobr><span class="ft21"></span></nobr></DIV>
<DIV style="position:absolute;top:562;left:801"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:555;left:813"><nobr><span class="ft4">, we </span></nobr></DIV>
<DIV style="position:absolute;top:572;left:477"><nobr><span class="ft4">can control <i>FDR</i>(</span></nobr></DIV>
<DIV style="position:absolute;top:571;left:578"><nobr><span class="ft21"></span></nobr></DIV>
<DIV style="position:absolute;top:578;left:587"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:572;left:599"><nobr><span class="ft4">) to a smaller value. We are not always </span></nobr></DIV>
<DIV style="position:absolute;top:588;left:477"><nobr><span class="ft32">guaranteed, though, to be able to set an individual significance <br>level such that <i>FDR</i> &lt; 5%. It is possible that even when we <br>decrease </span></nobr></DIV>
<DIV style="position:absolute;top:619;left:528"><nobr><span class="ft21"></span></nobr></DIV>
<DIV style="position:absolute;top:627;left:537"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:621;left:548"><nobr><span class="ft4"> to a level that almost no rules are discovered, <i>FDR</i> </span></nobr></DIV>
<DIV style="position:absolute;top:636;left:477"><nobr><span class="ft32">is still much larger than 5%. In other words, there are always a <br>large proportion of spurious rules discovered from some datasets. <br>For example, if attributes independent based on a test <i>statistic</i>, <br>then  <i>Median</i>(<i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:691;left:564"><nobr><span class="ft20"><i>sig-perm</i></span></nobr></DIV>
<DIV style="position:absolute;top:685;left:596"><nobr><span class="ft4">[][</span></nobr></DIV>
<DIV style="position:absolute;top:683;left:610"><nobr><span class="ft21"></span></nobr></DIV>
<DIV style="position:absolute;top:691;left:618"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:685;left:630"><nobr><span class="ft4">]) </span></nobr></DIV>
<DIV style="position:absolute;top:683;left:648"><nobr><span class="ft21">  <i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:691;left:674"><nobr><span class="ft20"><i>sig</i></span></nobr></DIV>
<DIV style="position:absolute;top:685;left:685"><nobr><span class="ft4">[</span></nobr></DIV>
<DIV style="position:absolute;top:683;left:689"><nobr><span class="ft21"></span></nobr></DIV>
<DIV style="position:absolute;top:691;left:698"><nobr><span class="ft20"><i>ind</i></span></nobr></DIV>
<DIV style="position:absolute;top:685;left:709"><nobr><span class="ft4">] for all significance </span></nobr></DIV>
<DIV style="position:absolute;top:702;left:477"><nobr><span class="ft4">levels, and <i>FDR</i> </span></nobr></DIV>
<DIV style="position:absolute;top:700;left:570"><nobr><span class="ft21"> 1. We want to point out that this is a desirable </span></nobr></DIV>
<DIV style="position:absolute;top:718;left:477"><nobr><span class="ft16">property of our method on controlling <i>FDR</i>, because there are <br>many real-world datasets whose attributes are truly independent <br>from each other. Traditional methods cannot estimate how many <br>rules should be discovered, but with our technique, we can draw <br>the conclusion that, there is no rule to be discovered because none <br>of the rules is better than chance. This nonparametric method to <br>estimate and control <i>FDR</i> is applicable to quantitative datasets <br>and broad types of rules. </span></nobr></DIV>
<DIV style="position:absolute;top:851;left:81"><nobr><span class="ft0"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:449"><nobr><span class="ft4">383</span></nobr></DIV>
<DIV style="position:absolute;top:54;left:681"><nobr><span class="ft14"><b>Research Track Paper</b></span></nobr></DIV>
</DIV>
</BODY>
</HTML>
