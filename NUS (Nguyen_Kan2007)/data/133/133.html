<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
<HEAD>
<TITLE>Microsoft Word - Machine Learning in DNA Microarra Analysis for Cancer Clas¡¦</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<META name="generator" content="pdftohtml 0.35beta">
<META name="author" content="Administrator">
<META name="date" content="2002-11-13T18:03:50+00:00">
</HEAD>
<BODY bgcolor="#A0A0A0" vlink="blue" link="blue">
<!-- Page 1 -->
<a name="1"></a>
<DIV style="position:relative;width:892;height:1263;">
<STYLE type="text/css">
<!--
	.ft0{font-size:22px;font-family:Times;color:#000000;}
	.ft1{font-size:16px;font-family:Times;color:#000000;}
	.ft2{font-size:13px;font-family:Times;color:#000000;}
	.ft3{font-size:11px;font-family:Courier;color:#000000;}
	.ft4{font-size:11px;font-family:Times;color:#000000;}
	.ft5{font-size:7px;font-family:Times;color:#000000;}
	.ft6{font-size:14px;font-family:Times;color:#000000;}
	.ft7{font-size:11px;line-height:15px;font-family:Times;color:#000000;}
	.ft8{font-size:11px;line-height:16px;font-family:Times;color:#000000;}
	.ft9{font-size:13px;line-height:17px;font-family:Times;color:#000000;}
	.ft10{font-size:13px;line-height:18px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="892" height="1263" src="133001.png" alt="background image">
<DIV style="position:absolute;top:92;left:183"><nobr><span class="ft0"><b>Machine Learning in DNA Microarray Analysis for </b></span></nobr></DIV>
<DIV style="position:absolute;top:128;left:337"><nobr><span class="ft0"><b>Cancer Classification </b></span></nobr></DIV>
<DIV style="position:absolute;top:178;left:312"><nobr><span class="ft1"><b>Sung-Bae Cho and Hong-Hee Won </b></span></nobr></DIV>
<DIV style="position:absolute;top:203;left:306"><nobr><span class="ft2">Dept. of Computer Science, Yonsei University </span></nobr></DIV>
<DIV style="position:absolute;top:220;left:268"><nobr><span class="ft2">134 Shinchon-dong, Sudaemoon-ku, Seoul 120-749, Korea </span></nobr></DIV>
<DIV style="position:absolute;top:246;left:261"><nobr><span class="ft3">sbcho@cs.yonsei.ac.kr  cool@candy.yonsei.ac.kr </span></nobr></DIV>
<DIV style="position:absolute;top:268;left:446"><nobr><span class="ft3"> </span></nobr></DIV>
<DIV style="position:absolute;top:287;left:86"><nobr><span class="ft6"><b>Abstract </b></span></nobr></DIV>
<DIV style="position:absolute;top:317;left:86"><nobr><span class="ft8">The development of microarray technology has supplied a large <br>volume of data to many fields. In particular, it has been applied <br>to prediction and diagnosis of cancer, so that it expectedly helps <br>us to exactly predict and diagnose cancer. To precisely classify <br>cancer we have to select genes related to cancer because <br>extracted genes from microarray have many noises. In this paper, <br>we attempt to explore many features and classifiers using three <br>benchmark datasets to systematically evaluate the performances <br>of the feature selection methods and machine learning classifiers. <br>Three benchmark datasets are Leukemia cancer dataset, Colon <br>cancer dataset and Lymphoma cancer data set. Pearson's and <br>Spearman's correlation coefficients, Euclidean distance, cosine <br>coefficient, information gain, mutual information and signal to <br>noise ratio have been used for feature selection. Multi-layer <br>perceptron, k-nearest neighbour, support vector machine and <br>structure adaptive self­organizing map have been used for <br>classification. Also, we have combined the classifiers to improve <br>the performance of classification. Experimental results show that <br>the ensemble with several basis classifiers produces the best <br>recognition rate on the benchmark dataset.</span></nobr></DIV>
<DIV style="position:absolute;top:610;left:316"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:609;left:318"><nobr><span class="ft5"> </span></nobr></DIV>
<DIV style="position:absolute;top:612;left:320"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:637;left:86"><nobr><span class="ft7">Keywords:  Biological data mining, feature selection, <br>classification, gene expression profile, MLP, KNN, SVM, <br>SASOM, ensemble classifier</span></nobr></DIV>
<DIV style="position:absolute;top:667;left:243"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:702;left:86"><nobr><span class="ft6"><b>1 </b></span></nobr></DIV>
<DIV style="position:absolute;top:702;left:119"><nobr><span class="ft6"><b>Introduction </b></span></nobr></DIV>
<DIV style="position:absolute;top:730;left:86"><nobr><span class="ft9">The need to study whole genome such as Human <br>Genomic Project (HGP) is recently increasing because <br>fragmentary knowledge about life phenomenon with <br>complex control functions of molecular-level is limited. <br>DNA chips have been developed during that process <br>because understanding the functions of genome <br>sequences is essential at that time. </span></nobr></DIV>
<DIV style="position:absolute;top:859;left:86"><nobr><span class="ft9">The development of DNA microarray technology has <br>been produced large amount of gene data and has made it <br>easy to monitor the expression patterns of thousands of <br>genes simultaneously under particular experimental <br>environments and conditions (Harrington et al. 2000). <br>Also, we can analyze the gene information very rapidly <br>and precisely by managing them at one time (Eisen et al. <br>1999). </span></nobr></DIV>
<DIV style="position:absolute;top:1006;left:86"><nobr><span class="ft9">Microarray technology has been applied to the field of <br>accurate prediction and diagnosis of cancer and expected </span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:86"><nobr><span class="ft2">                                                           </span></nobr></DIV>
<DIV style="position:absolute;top:1079;left:86"><nobr><span class="ft7">Copyright © 2003, Australian Computer Society, Inc.  This <br>paper appeared at First Asia-Pacific Bioinformatics Conference, <br>Adelaide, Australia.  Conferences in Research and Practice in <br>Information Technology, Vol. 19. Yi-Ping Phoebe Chen, Ed. <br>Reproduction for academic, not-for profit purposes permitted <br>provided this text is included.</span></nobr></DIV>
<DIV style="position:absolute;top:1155;left:247"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:283;left:457"><nobr><span class="ft9">that it would help them. Especially accurate classification <br>of cancer is very important issue for treatment of cancer. <br>Many researchers have been studying many problems of <br>cancer classification using gene expression profile data <br>and attempting to propose the optimal classification <br>technique to work out these problems (Dudoit et al. 2000, <br>Ben-Dor  et al. 2000) as shown in Table . Some <br>produce better results than others, but there have been <br>still no comprehensive work to compare the possible <br>feature selection methods and classifiers. We need a <br>thorough effort to give the evaluation of the possible <br>methods to solve the problems of analyzing gene <br>expression data. </span></nobr></DIV>
<DIV style="position:absolute;top:518;left:457"><nobr><span class="ft9">The gene expression data usually consist of huge number <br>of genes, and the necessity of tools analysing them to get <br>useful information gets radical. There is research that <br>systematically analyzes the results of test using a variety <br>of feature selection methods and classifiers for selecting <br>informative genes to help classification of cancer and <br>classifying cancer (Ryu et al. 2002). However, the results <br>were not verified enough because only one benchmark <br>dataset was used. Due to the reason, it is necessary to <br>analyse systematically the performance of classifiers <br>using a variety of benchmark datasets. </span></nobr></DIV>
<DIV style="position:absolute;top:717;left:457"><nobr><span class="ft9">In this paper, we attempt to explore many features and <br>classifiers that precisely classify cancer using three <br>recently published benchmark dataset. We adopted seven <br>feature selection methods and four classifiers, which are <br>commonly used in the field of data mining and pattern <br>recognition. Feature selection methods include Pearson's <br>and Spearman's correlation coefficients, Euclidean <br>distance, cosine coefficient, information gain, mutual <br>information and signal to noise ratio. Also, classification <br>methods include multi-layer perceptron (MLP), k-nearest <br>neighbour (KNN), support vector machine (SVM) and <br>structure adaptive self ­organizing map (SOM). We also <br>attempt to combine some of the classifiers with majority <br>voting to improve the performance of classification. </span></nobr></DIV>
<DIV style="position:absolute;top:976;left:457"><nobr><span class="ft6"><b>2 </b></span></nobr></DIV>
<DIV style="position:absolute;top:976;left:490"><nobr><span class="ft6"><b>Backgrounds </b></span></nobr></DIV>
<DIV style="position:absolute;top:1013;left:457"><nobr><span class="ft6"><b>2.1  DNA Microarray </b></span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:457"><nobr><span class="ft9">DNA arrays consist of a large number of DNA molecules <br>spotted in a systemic order on a solid substrate. <br>Depending on the size of each DNA spot on the array, <br>DNA arrays can be categorized as microarrays when the <br>diameter of DNA spot is less than 250 microns, and <br>macroarrays when the diameter is bigger than 300 <br>microns. The arrays with the small solid substrate are also </span></nobr></DIV>
</DIV>
<!-- Page 2 -->
<a name="2"></a>
<DIV style="position:relative;width:892;height:1263;">
<STYLE type="text/css">
<!--
	.ft11{font-size:5px;font-family:Times;color:#000000;}
	.ft12{font-size:12px;font-family:Times;color:#000000;}
	.ft13{font-size:6px;font-family:Times;color:#000000;}
	.ft14{font-size:5px;line-height:-8px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="892" height="1263" src="133002.png" alt="background image">
<DIV style="position:absolute;top:87;left:86"><nobr><span class="ft9">referred to as DNA chips. It is so powerful that we can <br>investigate the gene information in short time, because at <br>least hundreds of genes can be put on the DNA <br>microarray to be analyzed. </span></nobr></DIV>
<DIV style="position:absolute;top:403;left:417"><nobr><span class="ft11">0</span></nobr></DIV>
<DIV style="position:absolute;top:379;left:417"><nobr><span class="ft11">0.1</span></nobr></DIV>
<DIV style="position:absolute;top:356;left:417"><nobr><span class="ft11">0.2</span></nobr></DIV>
<DIV style="position:absolute;top:332;left:417"><nobr><span class="ft11">0.3</span></nobr></DIV>
<DIV style="position:absolute;top:309;left:417"><nobr><span class="ft11">0.4</span></nobr></DIV>
<DIV style="position:absolute;top:285;left:417"><nobr><span class="ft11">0.5</span></nobr></DIV>
<DIV style="position:absolute;top:262;left:417"><nobr><span class="ft11">0.6</span></nobr></DIV>
<DIV style="position:absolute;top:239;left:417"><nobr><span class="ft11">0.7</span></nobr></DIV>
<DIV style="position:absolute;top:215;left:417"><nobr><span class="ft11">0.8</span></nobr></DIV>
<DIV style="position:absolute;top:192;left:417"><nobr><span class="ft11">0.9</span></nobr></DIV>
<DIV style="position:absolute;top:168;left:417"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:420;left:323"><nobr><span class="ft11">Sam ple</span></nobr></DIV>
<DIV style="position:absolute;top:295;left:252"><nobr><span class="ft11">Ge</span></nobr></DIV>
<DIV style="position:absolute;top:285;left:252"><nobr><span class="ft14">ne<br>s</span></nobr></DIV>
<DIV style="position:absolute;top:410;left:203"><nobr><span class="ft11">                                                    ALL</span></nobr></DIV>
<DIV style="position:absolute;top:410;left:286"><nobr><span class="ft11">                                    AML             </span></nobr></DIV>
<DIV style="position:absolute;top:201;left:257"><nobr><span class="ft11">1000</span></nobr></DIV>
<DIV style="position:absolute;top:234;left:257"><nobr><span class="ft11">2000</span></nobr></DIV>
<DIV style="position:absolute;top:267;left:257"><nobr><span class="ft11">3000</span></nobr></DIV>
<DIV style="position:absolute;top:300;left:257"><nobr><span class="ft11">4000</span></nobr></DIV>
<DIV style="position:absolute;top:333;left:257"><nobr><span class="ft11">5000</span></nobr></DIV>
<DIV style="position:absolute;top:366;left:257"><nobr><span class="ft11">6000</span></nobr></DIV>
<DIV style="position:absolute;top:403;left:257"><nobr><span class="ft11">7129</span></nobr></DIV>
<DIV style="position:absolute;top:392;left:156"><nobr><span class="ft5">Gene expression data</span></nobr></DIV>
<DIV style="position:absolute;top:251;left:113"><nobr><span class="ft5">DNA microarray</span></nobr></DIV>
<DIV style="position:absolute;top:368;left:119"><nobr><span class="ft5">Image scanner</span></nobr></DIV>
<DIV style="position:absolute;top:417;left:431"><nobr><span class="ft6"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:441;left:92"><nobr><span class="ft2">Fig. 1. General process of acquiring the gene expression </span></nobr></DIV>
<DIV style="position:absolute;top:458;left:179"><nobr><span class="ft2">data from DNA microarray </span></nobr></DIV>
<DIV style="position:absolute;top:87;left:457"><nobr><span class="ft9"> DNA microarrays are composed of thousands of <br>individual DNA sequences printed in a high density array <br>on a glass microscope slide using a robotic arrayer as <br>shown in Fig. 1. The relative abundance of these spotted <br>DNA sequences in two DNA or RNA samples may be <br>assessed by monitoring the differential hybridization of <br>the two samples to the sequences on the array. For <br>mRNA samples, the two samples are reverse-transcribed <br>into cDNA, labeled using different fluorescent dyes <br>mixed (red-fluorescent dye Cy5 and green-fluorescent <br>dye Cy3). After the hybridization of these samples with <br>the arrayed DNA probes, the slides are imaged using <br>scanner that makes fluorescence measurements for each <br>dye. The log ratio between the two intensities of each dye <br>is used as the gene expression data (Lashkari et al. 1997, <br>Derisi et al. 1997, Eisen et al. 1998). </span></nobr></DIV>
<DIV style="position:absolute;top:393;left:705"><nobr><span class="ft12">)</span></nobr></DIV>
<DIV style="position:absolute;top:393;left:698"><nobr><span class="ft12">3</span></nobr></DIV>
<DIV style="position:absolute;top:393;left:681"><nobr><span class="ft12">Cy</span></nobr></DIV>
<DIV style="position:absolute;top:393;left:676"><nobr><span class="ft12">(</span></nobr></DIV>
<DIV style="position:absolute;top:393;left:660"><nobr><span class="ft12">Int</span></nobr></DIV>
<DIV style="position:absolute;top:372;left:705"><nobr><span class="ft12">)</span></nobr></DIV>
<DIV style="position:absolute;top:372;left:698"><nobr><span class="ft12">5</span></nobr></DIV>
<DIV style="position:absolute;top:372;left:681"><nobr><span class="ft12">Cy</span></nobr></DIV>
<DIV style="position:absolute;top:372;left:676"><nobr><span class="ft12">(</span></nobr></DIV>
<DIV style="position:absolute;top:372;left:659"><nobr><span class="ft12">Int</span></nobr></DIV>
<DIV style="position:absolute;top:381;left:631"><nobr><span class="ft12">log</span></nobr></DIV>
<DIV style="position:absolute;top:381;left:544"><nobr><span class="ft12">_</span></nobr></DIV>
<DIV style="position:absolute;top:391;left:650"><nobr><span class="ft13">2</span></nobr></DIV>
<DIV style="position:absolute;top:380;left:619"><nobr><span class="ft12">=</span></nobr></DIV>
<DIV style="position:absolute;top:381;left:554"><nobr><span class="ft12">expression</span></nobr></DIV>
<DIV style="position:absolute;top:381;left:515"><nobr><span class="ft12">gene</span></nobr></DIV>
<DIV style="position:absolute;top:377;left:713"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:383;left:786"><nobr><span class="ft2">(1)</span></nobr></DIV>
<DIV style="position:absolute;top:421;left:457"><nobr><span class="ft9"> where Int(Cy5) and Int(Cy3) are the intensities of red <br>and green colors. Since at least hundreds of genes are put <br>on the DNA microarray, it is so helpful that we can </span></nobr></DIV>
<DIV style="position:absolute;top:490;left:297"><nobr><span class="ft2">Table  . Relevant works on cancer classification</span></nobr></DIV>
<DIV style="position:absolute;top:513;left:495"><nobr><span class="ft4">Method</span></nobr></DIV>
<DIV style="position:absolute;top:512;left:540"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:523;left:107"><nobr><span class="ft4">Authors</span></nobr></DIV>
<DIV style="position:absolute;top:521;left:154"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:523;left:214"><nobr><span class="ft4">Dataset </span></nobr></DIV>
<DIV style="position:absolute;top:534;left:372"><nobr><span class="ft4">Feature</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:417"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:534;left:596"><nobr><span class="ft4">Classifier</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:651"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:517;left:755"><nobr><span class="ft4">Accuracy </span></nobr></DIV>
<DIV style="position:absolute;top:528;left:772"><nobr><span class="ft4">[%]</span></nobr></DIV>
<DIV style="position:absolute;top:527;left:794"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:555;left:206"><nobr><span class="ft4">Leukemia </span></nobr></DIV>
<DIV style="position:absolute;top:555;left:771"><nobr><span class="ft4">94.1</span></nobr></DIV>
<DIV style="position:absolute;top:553;left:795"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:555;left:98"><nobr><span class="ft4">Furey et al.</span></nobr></DIV>
<DIV style="position:absolute;top:553;left:163"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:576;left:218"><nobr><span class="ft4">Colon </span></nobr></DIV>
<DIV style="position:absolute;top:555;left:338"><nobr><span class="ft4">Signal to noise ratio</span></nobr></DIV>
<DIV style="position:absolute;top:553;left:452"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:555;left:608"><nobr><span class="ft4">SVM</span></nobr></DIV>
<DIV style="position:absolute;top:553;left:638"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:576;left:771"><nobr><span class="ft4">90.3 </span></nobr></DIV>
<DIV style="position:absolute;top:598;left:94"><nobr><span class="ft4">Li et al. 2000</span></nobr></DIV>
<DIV style="position:absolute;top:597;left:167"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:598;left:206"><nobr><span class="ft4">Leukemia </span></nobr></DIV>
<DIV style="position:absolute;top:598;left:296"><nobr><span class="ft4">Model selection with Akaike information criterion and Bayesian information </span></nobr></DIV>
<DIV style="position:absolute;top:608;left:424"><nobr><span class="ft4">criterion with logistic regression</span></nobr></DIV>
<DIV style="position:absolute;top:607;left:610"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:598;left:771"><nobr><span class="ft4">94.1</span></nobr></DIV>
<DIV style="position:absolute;top:597;left:795"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:635;left:202"><nobr><span class="ft4">Lymphoma </span></nobr></DIV>
<DIV style="position:absolute;top:635;left:764"><nobr><span class="ft4"> 84.6~ </span></nobr></DIV>
<DIV style="position:absolute;top:635;left:94"><nobr><span class="ft4">Li et al. 2001 </span></nobr></DIV>
<DIV style="position:absolute;top:656;left:218"><nobr><span class="ft4">Colon </span></nobr></DIV>
<DIV style="position:absolute;top:635;left:341"><nobr><span class="ft4">Genetic Algorithm </span></nobr></DIV>
<DIV style="position:absolute;top:635;left:608"><nobr><span class="ft4">KNN   </span></nobr></DIV>
<DIV style="position:absolute;top:656;left:764"><nobr><span class="ft4"> 94.1~ </span></nobr></DIV>
<DIV style="position:absolute;top:678;left:206"><nobr><span class="ft4">Leukemia </span></nobr></DIV>
<DIV style="position:absolute;top:678;left:771"><nobr><span class="ft4">91.6</span></nobr></DIV>
<DIV style="position:absolute;top:677;left:795"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:698;left:218"><nobr><span class="ft4">Colon </span></nobr></DIV>
<DIV style="position:absolute;top:678;left:574"><nobr><span class="ft4">Nearest neighbor</span></nobr></DIV>
<DIV style="position:absolute;top:677;left:673"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:698;left:771"><nobr><span class="ft4">80.6 </span></nobr></DIV>
<DIV style="position:absolute;top:717;left:206"><nobr><span class="ft4">Leukemia </span></nobr></DIV>
<DIV style="position:absolute;top:717;left:771"><nobr><span class="ft4">94.4</span></nobr></DIV>
<DIV style="position:absolute;top:716;left:795"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:737;left:218"><nobr><span class="ft4">Colon </span></nobr></DIV>
<DIV style="position:absolute;top:717;left:544"><nobr><span class="ft4">SVM with quadratic kernel</span></nobr></DIV>
<DIV style="position:absolute;top:716;left:703"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:737;left:771"><nobr><span class="ft4">74.2 </span></nobr></DIV>
<DIV style="position:absolute;top:756;left:206"><nobr><span class="ft4">Leukemia </span></nobr></DIV>
<DIV style="position:absolute;top:756;left:771"><nobr><span class="ft4">95.8</span></nobr></DIV>
<DIV style="position:absolute;top:755;left:795"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:678;left:91"><nobr><span class="ft4">Ben-Dor et al.</span></nobr></DIV>
<DIV style="position:absolute;top:677;left:170"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:776;left:218"><nobr><span class="ft4">Colon </span></nobr></DIV>
<DIV style="position:absolute;top:678;left:330"><nobr><span class="ft4">All genes, TNoM score </span></nobr></DIV>
<DIV style="position:absolute;top:696;left:395"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:756;left:595"><nobr><span class="ft4">AdaBoost</span></nobr></DIV>
<DIV style="position:absolute;top:755;left:651"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:776;left:771"><nobr><span class="ft4">72.6 </span></nobr></DIV>
<DIV style="position:absolute;top:796;left:206"><nobr><span class="ft4">Leukemia </span></nobr></DIV>
<DIV style="position:absolute;top:796;left:764"><nobr><span class="ft4"> 95.0~</span></nobr></DIV>
<DIV style="position:absolute;top:795;left:801"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:817;left:202"><nobr><span class="ft4">Lymphoma </span></nobr></DIV>
<DIV style="position:absolute;top:796;left:574"><nobr><span class="ft4">Nearest neighbor</span></nobr></DIV>
<DIV style="position:absolute;top:795;left:673"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:817;left:764"><nobr><span class="ft4"> 95.0~ </span></nobr></DIV>
<DIV style="position:absolute;top:838;left:206"><nobr><span class="ft4">Leukemia </span></nobr></DIV>
<DIV style="position:absolute;top:838;left:764"><nobr><span class="ft4"> 95.0~</span></nobr></DIV>
<DIV style="position:absolute;top:837;left:801"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:859;left:202"><nobr><span class="ft4">Lymphoma </span></nobr></DIV>
<DIV style="position:absolute;top:838;left:516"><nobr><span class="ft4">Diagonal linear discriminant analysis</span></nobr></DIV>
<DIV style="position:absolute;top:837;left:731"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:859;left:764"><nobr><span class="ft4"> 95.0~ </span></nobr></DIV>
<DIV style="position:absolute;top:880;left:206"><nobr><span class="ft4">Leukemia </span></nobr></DIV>
<DIV style="position:absolute;top:880;left:764"><nobr><span class="ft4"> 95.0~</span></nobr></DIV>
<DIV style="position:absolute;top:879;left:801"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:796;left:95"><nobr><span class="ft4">Dudoit et al.</span></nobr></DIV>
<DIV style="position:absolute;top:795;left:166"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:902;left:202"><nobr><span class="ft4">Lymphoma </span></nobr></DIV>
<DIV style="position:absolute;top:796;left:306"><nobr><span class="ft4">The ratio of between-groups to </span></nobr></DIV>
<DIV style="position:absolute;top:807;left:310"><nobr><span class="ft4">within-groups sum of squares</span></nobr></DIV>
<DIV style="position:absolute;top:805;left:480"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:880;left:588"><nobr><span class="ft4">BoostCART</span></nobr></DIV>
<DIV style="position:absolute;top:879;left:659"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:902;left:764"><nobr><span class="ft4"> 90.0~ </span></nobr></DIV>
<DIV style="position:absolute;top:924;left:206"><nobr><span class="ft4">Leukemia </span></nobr></DIV>
<DIV style="position:absolute;top:924;left:771"><nobr><span class="ft4">94.2</span></nobr></DIV>
<DIV style="position:absolute;top:922;left:795"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:943;left:202"><nobr><span class="ft4">Lymphoma </span></nobr></DIV>
<DIV style="position:absolute;top:943;left:771"><nobr><span class="ft4">98.1 </span></nobr></DIV>
<DIV style="position:absolute;top:963;left:218"><nobr><span class="ft4">Colon </span></nobr></DIV>
<DIV style="position:absolute;top:924;left:562"><nobr><span class="ft4">Logistic discriminant</span></nobr></DIV>
<DIV style="position:absolute;top:922;left:685"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:963;left:771"><nobr><span class="ft4">87.1 </span></nobr></DIV>
<DIV style="position:absolute;top:982;left:206"><nobr><span class="ft4">Leukemia </span></nobr></DIV>
<DIV style="position:absolute;top:982;left:771"><nobr><span class="ft4">95.4</span></nobr></DIV>
<DIV style="position:absolute;top:981;left:795"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:1002;left:202"><nobr><span class="ft4">Lymphoma </span></nobr></DIV>
<DIV style="position:absolute;top:1002;left:771"><nobr><span class="ft4">97.6 </span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:218"><nobr><span class="ft4">Colon </span></nobr></DIV>
<DIV style="position:absolute;top:924;left:310"><nobr><span class="ft4">Principal component analysis</span></nobr></DIV>
<DIV style="position:absolute;top:922;left:480"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:982;left:531"><nobr><span class="ft4">Quadratic discriminant analysis</span></nobr></DIV>
<DIV style="position:absolute;top:981;left:716"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:771"><nobr><span class="ft4">87.1 </span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:206"><nobr><span class="ft4">Leukemia </span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:771"><nobr><span class="ft4">95.9</span></nobr></DIV>
<DIV style="position:absolute;top:1039;left:795"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:1060;left:202"><nobr><span class="ft4">Lymphoma </span></nobr></DIV>
<DIV style="position:absolute;top:1060;left:771"><nobr><span class="ft4">96.9 </span></nobr></DIV>
<DIV style="position:absolute;top:1080;left:218"><nobr><span class="ft4">Colon </span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:562"><nobr><span class="ft4">Logistic discriminant</span></nobr></DIV>
<DIV style="position:absolute;top:1039;left:685"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:1080;left:771"><nobr><span class="ft4">93.5 </span></nobr></DIV>
<DIV style="position:absolute;top:1099;left:206"><nobr><span class="ft4">Leukemia </span></nobr></DIV>
<DIV style="position:absolute;top:1099;left:771"><nobr><span class="ft4">96.4</span></nobr></DIV>
<DIV style="position:absolute;top:1098;left:795"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:1119;left:202"><nobr><span class="ft4">Lymphoma </span></nobr></DIV>
<DIV style="position:absolute;top:1119;left:771"><nobr><span class="ft4">97.4 </span></nobr></DIV>
<DIV style="position:absolute;top:924;left:93"><nobr><span class="ft4">Nguyen et al.</span></nobr></DIV>
<DIV style="position:absolute;top:922;left:168"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:1138;left:218"><nobr><span class="ft4">Colon </span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:339"><nobr><span class="ft4">Partial least square</span></nobr></DIV>
<DIV style="position:absolute;top:1039;left:451"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:1099;left:531"><nobr><span class="ft4">Quadratic discriminant analysis</span></nobr></DIV>
<DIV style="position:absolute;top:1098;left:716"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:1138;left:771"><nobr><span class="ft4">91.9 </span></nobr></DIV>
</DIV>
<!-- Page 3 -->
<a name="3"></a>
<DIV style="position:relative;width:892;height:1263;">
<STYLE type="text/css">
<!--
	.ft15{font-size:8px;font-family:Times;color:#000000;}
	.ft16{font-size:20px;font-family:Times;color:#000000;}
	.ft17{font-size:19px;font-family:Times;color:#000000;}
	.ft18{font-size:8px;line-height:12px;font-family:Times;color:#000000;}
	.ft19{font-size:12px;line-height:-13px;font-family:Times;color:#000000;}
	.ft20{font-size:12px;line-height:24px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="892" height="1263" src="133003.png" alt="background image">
<DIV style="position:absolute;top:87;left:86"><nobr><span class="ft2">investigate the genome-wide information in short time. </span></nobr></DIV>
<DIV style="position:absolute;top:122;left:86"><nobr><span class="ft6"><b>2.2  Related Works </b></span></nobr></DIV>
<DIV style="position:absolute;top:150;left:86"><nobr><span class="ft9">It is essential to efficiently analyze DNA microarray data <br>because the amount of DNA microarray data is usually <br>very large. The analysis of DNA microarray data is <br>divided into four branches: clustering, classification, gene <br>identification, and gene regulatory network modeling. <br>Many machine learning and data mining methods have <br>been applied to solve them. </span></nobr></DIV>
<DIV style="position:absolute;top:280;left:86"><nobr><span class="ft9">Information theory (Fuhrman et al. 2000) has been <br>applied to gene identification problem. Also, boolean <br>network (Thieffry et al. 1998), Bayesian network <br>(Friedman  et al. 2000), and reverse engineering method <br>(Arkin et al. 1997) have been applied to gene regulatory <br>network modeling problem. </span></nobr></DIV>
<DIV style="position:absolute;top:392;left:86"><nobr><span class="ft9">Several machine learning techniques have been <br>previously used in classifying gene expression data, <br>including Fisher linear discriminant analysis (Dudoit et al. <br>2000), k nearest neighbour (Li et al. 2001), decision tree, <br>multi-layer perceptron (Khan et al. 2001, Xu et al. 2002), <br>support vector machine (Furey et al. 2000, Brown et al. <br>2000), boosting, and self-organizing map (Golub et al. <br>1999). Also, many machine learning techniques were <br>have been used in clustering gene expression data <br>(Shamir 2001). They include hierarchical clustering <br>(Eisen  et al. 1998), self-organizing map (Tamayo et al. <br>1999), and graph theoretic approaches (Hartuv et al. 2000, <br>Ben-Dor et al. 1999, Sharan et al. 2000) </span></nobr></DIV>
<DIV style="position:absolute;top:625;left:86"><nobr><span class="ft10">The first approach, classification method, is called <br>supervised method while the second approach, clustering <br>method, is called unsupervised method. Clustering <br>methods do not use any tissue annotation (e.g., tumor vs. <br>normal) in the partitioning step. In contrast, classification <br>methods attempt to predict the classification of new <br>tissues, based on their gene expression profiles after <br>training on examples (training data) that have been <br>classified by an external "supervision" (Ben-Dor et al. <br>2000). Table  shows relevant works on cancer <br>classification. </span></nobr></DIV>
<DIV style="position:absolute;top:835;left:86"><nobr><span class="ft6"><b>3 </b></span></nobr></DIV>
<DIV style="position:absolute;top:835;left:119"><nobr><span class="ft6"><b>Machine Learning for DNA Microarray </b></span></nobr></DIV>
<DIV style="position:absolute;top:863;left:86"><nobr><span class="ft9">We define machine learning for DNA microarray that <br>selects discriminative genes related with classification <br>from gene expression data, trains classifier and then <br>classifies new data using learned classifier. The system is <br>as shown in Fig. 2. After acquiring the gene expression <br>data calculated from the DNA microarray, our prediction <br>system has 2 stages: feature selection and pattern <br>classification stages. </span></nobr></DIV>
<DIV style="position:absolute;top:1010;left:86"><nobr><span class="ft9">The feature selection can be thought of as the gene <br>selection, which is to get the list of genes that might be <br>informative for the prediction by statistical, information <br>theoretical methods, etc. Since it is highly unlikely that <br>all the 7,129 genes have the information related to the <br>cancer and using all the genes results in too big <br>dimensionality, it is necessary to explore the efficient <br>way to get the best feature. We have extracted 25 genes <br>using seven methods described in Section 3.1, and the </span></nobr></DIV>
<DIV style="position:absolute;top:87;left:457"><nobr><span class="ft9">cancer predictor classifies the category only with these <br>genes. </span></nobr></DIV>
<DIV style="position:absolute;top:130;left:457"><nobr><span class="ft9">Given the gene list, a classifier makes decision to which <br>category the gene pattern belongs at prediction stage. We <br>have adopted four most widely used classification <br>methods and an ensemble classifier as shown in Fig. 2. </span></nobr></DIV>
<DIV style="position:absolute;top:208;left:457"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:337;left:517"><nobr><span class="ft15">Feature selection</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:482"><nobr><span class="ft15">Tumor</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:592"><nobr><span class="ft15">Normal</span></nobr></DIV>
<DIV style="position:absolute;top:384;left:517"><nobr><span class="ft15">Cancer predictor</span></nobr></DIV>
<DIV style="position:absolute;top:262;left:634"><nobr><span class="ft18">Pearson's correlation coefficient<br>Spearman's correlation coefficient<br>Euclidean distance<br>Cosine coefficient<br>Information gain<br>Mutual information<br>Signal to noise ratio</span></nobr></DIV>
<DIV style="position:absolute;top:363;left:634"><nobr><span class="ft18">3-layered MLP with backpropagation<br>k-nearest neighbor<br>Support vector machine<br>Structure adaptive self-organizing map<br>Ensemble classifier</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:529"><nobr><span class="ft15">Microarray</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:519"><nobr><span class="ft15">Expression data</span></nobr></DIV>
<DIV style="position:absolute;top:453;left:806"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:476;left:525"><nobr><span class="ft2">Fig. 2. Cancer classification system </span></nobr></DIV>
<DIV style="position:absolute;top:511;left:457"><nobr><span class="ft6"><b>3.1  Gene Selection </b></span></nobr></DIV>
<DIV style="position:absolute;top:539;left:457"><nobr><span class="ft9">Among thousands of genes whose expression levels are <br>measured, not all are needed for classification. <br>Microarray data consist of large number of genes in small <br>samples. We need to select some genes highly related <br>with particular classes for classification, which is called <br>informative genes (Golub et al. 1999). This process is <br>referred to as gene selection. It is also called feature <br>selection in machine learning. </span></nobr></DIV>
<DIV style="position:absolute;top:686;left:457"><nobr><span class="ft9">Using the statistical correlation analysis, we can see the <br>linear relationship and the direction of relation between <br>two variables. Correlation coefficient r varies from ­1 to <br>+1, so that the data distributed near the line biased to (+) <br>direction will have positive coefficients, and the data near <br>the line biased to (-) direction will have negative <br>coefficients. </span></nobr></DIV>
<DIV style="position:absolute;top:816;left:457"><nobr><span class="ft2">Suppose that we have a gene expression pattern g</span></nobr></DIV>
<DIV style="position:absolute;top:822;left:755"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:816;left:758"><nobr><span class="ft2"> (i = 1 ~ </span></nobr></DIV>
<DIV style="position:absolute;top:833;left:457"><nobr><span class="ft9">7,129 in Leukemia data, i = 1 ~ 2,000 in Colon data, i = 1 <br>~ 4,026 in Lymphoma data)</span></nobr></DIV>
<DIV style="position:absolute;top:857;left:628"><nobr><span class="ft5">. </span></nobr></DIV>
<DIV style="position:absolute;top:850;left:636"><nobr><span class="ft2"> Each g</span></nobr></DIV>
<DIV style="position:absolute;top:857;left:686"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:850;left:688"><nobr><span class="ft2"> is a vector of gene </span></nobr></DIV>
<DIV style="position:absolute;top:867;left:457"><nobr><span class="ft2">expression levels from N samples, g</span></nobr></DIV>
<DIV style="position:absolute;top:874;left:677"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:867;left:680"><nobr><span class="ft2"> = (e</span></nobr></DIV>
<DIV style="position:absolute;top:874;left:709"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:867;left:714"><nobr><span class="ft2">, e</span></nobr></DIV>
<DIV style="position:absolute;top:874;left:729"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:867;left:733"><nobr><span class="ft2">, e</span></nobr></DIV>
<DIV style="position:absolute;top:874;left:748"><nobr><span class="ft5">3</span></nobr></DIV>
<DIV style="position:absolute;top:867;left:753"><nobr><span class="ft2">, ..., e</span></nobr></DIV>
<DIV style="position:absolute;top:874;left:791"><nobr><span class="ft5">N</span></nobr></DIV>
<DIV style="position:absolute;top:867;left:798"><nobr><span class="ft2">). </span></nobr></DIV>
<DIV style="position:absolute;top:884;left:457"><nobr><span class="ft2">The first M elements (e</span></nobr></DIV>
<DIV style="position:absolute;top:891;left:612"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:884;left:617"><nobr><span class="ft2">,  e</span></nobr></DIV>
<DIV style="position:absolute;top:891;left:635"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:884;left:639"><nobr><span class="ft2">, ..., e</span></nobr></DIV>
<DIV style="position:absolute;top:891;left:684"><nobr><span class="ft5">M</span></nobr></DIV>
<DIV style="position:absolute;top:884;left:692"><nobr><span class="ft2">) are examples of </span></nobr></DIV>
<DIV style="position:absolute;top:902;left:457"><nobr><span class="ft2">tumor samples, and the other N-M (e</span></nobr></DIV>
<DIV style="position:absolute;top:909;left:682"><nobr><span class="ft5">M+1</span></nobr></DIV>
<DIV style="position:absolute;top:902;left:701"><nobr><span class="ft2">, e</span></nobr></DIV>
<DIV style="position:absolute;top:909;left:716"><nobr><span class="ft5">M+2</span></nobr></DIV>
<DIV style="position:absolute;top:902;left:734"><nobr><span class="ft2">, ..., e</span></nobr></DIV>
<DIV style="position:absolute;top:909;left:772"><nobr><span class="ft5">N</span></nobr></DIV>
<DIV style="position:absolute;top:902;left:779"><nobr><span class="ft2">) are </span></nobr></DIV>
<DIV style="position:absolute;top:919;left:457"><nobr><span class="ft9">those from normal samples. An ideal gene pattern that <br>belongs to tumor class is defined by g</span></nobr></DIV>
<DIV style="position:absolute;top:943;left:689"><nobr><span class="ft5">ideal_tumor </span></nobr></DIV>
<DIV style="position:absolute;top:936;left:739"><nobr><span class="ft2">= (1, 1, ..., </span></nobr></DIV>
<DIV style="position:absolute;top:953;left:457"><nobr><span class="ft9">1, 0, ..., 0), so that all the elements from tumor samples <br>are 1 and the others are 0. In this paper, we have <br>calculated the correlation coefficient between this g</span></nobr></DIV>
<DIV style="position:absolute;top:995;left:787"><nobr><span class="ft5">ideal</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:806"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:1005;left:457"><nobr><span class="ft9">and the expression pattern of each gene. When we have <br>two vectors X and Y that contain N elements, r</span></nobr></DIV>
<DIV style="position:absolute;top:1029;left:747"><nobr><span class="ft5">Pearson</span></nobr></DIV>
<DIV style="position:absolute;top:1022;left:780"><nobr><span class="ft2"> and </span></nobr></DIV>
<DIV style="position:absolute;top:1040;left:457"><nobr><span class="ft2">r</span></nobr></DIV>
<DIV style="position:absolute;top:1046;left:463"><nobr><span class="ft5">Spearman</span></nobr></DIV>
<DIV style="position:absolute;top:1040;left:502"><nobr><span class="ft2"> are calculated as follows:   </span></nobr></DIV>
<DIV style="position:absolute;top:1105;left:593"><nobr><span class="ft16">(</span></nobr></DIV>
<DIV style="position:absolute;top:1105;left:627"><nobr><span class="ft16">)</span></nobr></DIV>
<DIV style="position:absolute;top:1105;left:701"><nobr><span class="ft16">( )</span></nobr></DIV>
<DIV style="position:absolute;top:1133;left:744"><nobr><span class="ft20"><br><br></span></nobr></DIV>
<DIV style="position:absolute;top:1110;left:744"><nobr><span class="ft12"></span></nobr></DIV>
<DIV style="position:absolute;top:1133;left:645"><nobr><span class="ft20"><br><br></span></nobr></DIV>
<DIV style="position:absolute;top:1110;left:645"><nobr><span class="ft12"></span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:689"><nobr><span class="ft12">-</span></nobr></DIV>
<DIV style="position:absolute;top:1133;left:640"><nobr><span class="ft20"><br><br></span></nobr></DIV>
<DIV style="position:absolute;top:1110;left:640"><nobr><span class="ft12"></span></nobr></DIV>
<DIV style="position:absolute;top:1133;left:535"><nobr><span class="ft20"><br><br></span></nobr></DIV>
<DIV style="position:absolute;top:1110;left:535"><nobr><span class="ft12"></span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:582"><nobr><span class="ft12">-</span></nobr></DIV>
<DIV style="position:absolute;top:1078;left:623"><nobr><span class="ft12">-</span></nobr></DIV>
<DIV style="position:absolute;top:1095;left:513"><nobr><span class="ft12">=</span></nobr></DIV>
<DIV style="position:absolute;top:1121;left:653"><nobr><span class="ft17"></span></nobr></DIV>
<DIV style="position:absolute;top:1110;left:704"><nobr><span class="ft17"></span></nobr></DIV>
<DIV style="position:absolute;top:1121;left:542"><nobr><span class="ft17"></span></nobr></DIV>
<DIV style="position:absolute;top:1110;left:597"><nobr><span class="ft17"></span></nobr></DIV>
<DIV style="position:absolute;top:1063;left:665"><nobr><span class="ft17"></span></nobr></DIV>
<DIV style="position:absolute;top:1063;left:635"><nobr><span class="ft17"></span></nobr></DIV>
<DIV style="position:absolute;top:1074;left:584"><nobr><span class="ft17"></span></nobr></DIV>
<DIV style="position:absolute;top:1138;left:716"><nobr><span class="ft12">N</span></nobr></DIV>
<DIV style="position:absolute;top:1115;left:721"><nobr><span class="ft12">Y</span></nobr></DIV>
<DIV style="position:absolute;top:1126;left:669"><nobr><span class="ft12">Y</span></nobr></DIV>
<DIV style="position:absolute;top:1138;left:610"><nobr><span class="ft12">N</span></nobr></DIV>
<DIV style="position:absolute;top:1115;left:616"><nobr><span class="ft12">X</span></nobr></DIV>
<DIV style="position:absolute;top:1126;left:560"><nobr><span class="ft12">X</span></nobr></DIV>
<DIV style="position:absolute;top:1091;left:658"><nobr><span class="ft12">N</span></nobr></DIV>
<DIV style="position:absolute;top:1069;left:681"><nobr><span class="ft12">Y</span></nobr></DIV>
<DIV style="position:absolute;top:1069;left:654"><nobr><span class="ft12">X</span></nobr></DIV>
<DIV style="position:absolute;top:1080;left:602"><nobr><span class="ft12">XY</span></nobr></DIV>
<DIV style="position:absolute;top:1097;left:474"><nobr><span class="ft12">r</span></nobr></DIV>
<DIV style="position:absolute;top:1106;left:479"><nobr><span class="ft13">Pearson</span></nobr></DIV>
<DIV style="position:absolute;top:1112;left:735"><nobr><span class="ft13">2</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:680"><nobr><span class="ft13">2</span></nobr></DIV>
<DIV style="position:absolute;top:1112;left:632"><nobr><span class="ft13">2</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:573"><nobr><span class="ft13">2</span></nobr></DIV>
<DIV style="position:absolute;top:1083;left:754"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:1106;left:786"><nobr><span class="ft2">(2)</span></nobr></DIV>
</DIV>
<!-- Page 4 -->
<a name="4"></a>
<DIV style="position:relative;width:892;height:1263;">
<STYLE type="text/css">
<!--
	.ft21{font-size:23px;font-family:Times;color:#000000;}
	.ft22{font-size:21px;font-family:Times;color:#000000;}
	.ft23{font-size:18px;font-family:Times;color:#000000;}
	.ft24{font-size:15px;font-family:Times;color:#000000;}
	.ft25{font-size:4px;font-family:Times;color:#000000;}
	.ft26{font-size:13px;line-height:23px;font-family:Times;color:#000000;}
	.ft27{font-size:13px;line-height:21px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="892" height="1263" src="133004.png" alt="background image">
<DIV style="position:absolute;top:84;left:261"><nobr><span class="ft0"><b>(</b></span></nobr></DIV>
<DIV style="position:absolute;top:84;left:321"><nobr><span class="ft0"><b>)</b></span></nobr></DIV>
<DIV style="position:absolute;top:108;left:265"><nobr><span class="ft21">(</span></nobr></DIV>
<DIV style="position:absolute;top:108;left:312"><nobr><span class="ft21">)</span></nobr></DIV>
<DIV style="position:absolute;top:120;left:305"><nobr><span class="ft2">1</span></nobr></DIV>
<DIV style="position:absolute;top:95;left:234"><nobr><span class="ft2">6</span></nobr></DIV>
<DIV style="position:absolute;top:107;left:211"><nobr><span class="ft2">1</span></nobr></DIV>
<DIV style="position:absolute;top:119;left:284"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:92;left:326"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:118;left:294"><nobr><span class="ft2">-</span></nobr></DIV>
<DIV style="position:absolute;top:93;left:288"><nobr><span class="ft2">-</span></nobr></DIV>
<DIV style="position:absolute;top:105;left:221"><nobr><span class="ft2">-</span></nobr></DIV>
<DIV style="position:absolute;top:105;left:199"><nobr><span class="ft2">=</span></nobr></DIV>
<DIV style="position:absolute;top:89;left:242"><nobr><span class="ft22"></span></nobr></DIV>
<DIV style="position:absolute;top:120;left:270"><nobr><span class="ft2">N</span></nobr></DIV>
<DIV style="position:absolute;top:120;left:253"><nobr><span class="ft2">N</span></nobr></DIV>
<DIV style="position:absolute;top:95;left:301"><nobr><span class="ft2">D</span></nobr></DIV>
<DIV style="position:absolute;top:95;left:266"><nobr><span class="ft2">D</span></nobr></DIV>
<DIV style="position:absolute;top:107;left:149"><nobr><span class="ft2">r</span></nobr></DIV>
<DIV style="position:absolute;top:105;left:314"><nobr><span class="ft5">y</span></nobr></DIV>
<DIV style="position:absolute;top:105;left:279"><nobr><span class="ft5">x</span></nobr></DIV>
<DIV style="position:absolute;top:117;left:155"><nobr><span class="ft5">Spearman</span></nobr></DIV>
<DIV style="position:absolute;top:105;left:337"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:108;left:415"><nobr><span class="ft2">(3)</span></nobr></DIV>
<DIV style="position:absolute;top:150;left:86"><nobr><span class="ft2">where,  D</span></nobr></DIV>
<DIV style="position:absolute;top:157;left:146"><nobr><span class="ft5">x</span></nobr></DIV>
<DIV style="position:absolute;top:150;left:150"><nobr><span class="ft2"> and D</span></nobr></DIV>
<DIV style="position:absolute;top:157;left:198"><nobr><span class="ft5">y</span></nobr></DIV>
<DIV style="position:absolute;top:150;left:202"><nobr><span class="ft2"> are the rank matrices of X and Y, </span></nobr></DIV>
<DIV style="position:absolute;top:168;left:86"><nobr><span class="ft2">respectively. </span></nobr></DIV>
<DIV style="position:absolute;top:194;left:86"><nobr><span class="ft9">The similarity between two input vectors X and Y can be <br>thought of as distance. Distance is a measure on how far <br>the two vectors are located, and the distance between <br>g</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:94"><nobr><span class="ft5">ideal_tumor</span></nobr></DIV>
<DIV style="position:absolute;top:246;left:141"><nobr><span class="ft2"> and g</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:181"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:246;left:184"><nobr><span class="ft2"> tells us how much the g</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:338"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:246;left:341"><nobr><span class="ft2"> is likely to the </span></nobr></DIV>
<DIV style="position:absolute;top:263;left:86"><nobr><span class="ft9">tumor class. Calculating the distance between them, if it <br>is bigger than certain threshold, the gene g</span></nobr></DIV>
<DIV style="position:absolute;top:287;left:346"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:280;left:349"><nobr><span class="ft2"> would belong </span></nobr></DIV>
<DIV style="position:absolute;top:297;left:86"><nobr><span class="ft2">to tumor class, otherwise g</span></nobr></DIV>
<DIV style="position:absolute;top:304;left:257"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:297;left:259"><nobr><span class="ft2"> belongs to normal class. In </span></nobr></DIV>
<DIV style="position:absolute;top:315;left:86"><nobr><span class="ft2">this paper, we have adopted Euclidean distance (r</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:396"><nobr><span class="ft5">Eclidean</span></nobr></DIV>
<DIV style="position:absolute;top:315;left:431"><nobr><span class="ft2">) </span></nobr></DIV>
<DIV style="position:absolute;top:332;left:86"><nobr><span class="ft2">and cosine coefficient (r</span></nobr></DIV>
<DIV style="position:absolute;top:339;left:261"><nobr><span class="ft5">Cosine</span></nobr></DIV>
<DIV style="position:absolute;top:332;left:288"><nobr><span class="ft2">) represented by the </span></nobr></DIV>
<DIV style="position:absolute;top:349;left:86"><nobr><span class="ft2">following equations: </span></nobr></DIV>
<DIV style="position:absolute;top:376;left:256"><nobr><span class="ft23">(</span></nobr></DIV>
<DIV style="position:absolute;top:376;left:298"><nobr><span class="ft23">)</span></nobr></DIV>
<DIV style="position:absolute;top:377;left:238"><nobr><span class="ft16"></span></nobr></DIV>
<DIV style="position:absolute;top:381;left:276"><nobr><span class="ft2">-</span></nobr></DIV>
<DIV style="position:absolute;top:381;left:216"><nobr><span class="ft2">=</span></nobr></DIV>
<DIV style="position:absolute;top:381;left:302"><nobr><span class="ft13">2</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:287"><nobr><span class="ft2">Y</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:262"><nobr><span class="ft2">X</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:173"><nobr><span class="ft2">r</span></nobr></DIV>
<DIV style="position:absolute;top:392;left:179"><nobr><span class="ft13">Eclidean</span></nobr></DIV>
<DIV style="position:absolute;top:381;left:313"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:383;left:415"><nobr><span class="ft2">(4)</span></nobr></DIV>
<DIV style="position:absolute;top:440;left:233"><nobr><span class="ft22"> </span></nobr></DIV>
<DIV style="position:absolute;top:412;left:246"><nobr><span class="ft22"></span></nobr></DIV>
<DIV style="position:absolute;top:429;left:209"><nobr><span class="ft2">=</span></nobr></DIV>
<DIV style="position:absolute;top:445;left:301"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:445;left:265"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:289"><nobr><span class="ft2">Y</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:252"><nobr><span class="ft2">X</span></nobr></DIV>
<DIV style="position:absolute;top:418;left:265"><nobr><span class="ft2">XY</span></nobr></DIV>
<DIV style="position:absolute;top:431;left:173"><nobr><span class="ft2">r</span></nobr></DIV>
<DIV style="position:absolute;top:440;left:178"><nobr><span class="ft5">Cosine</span></nobr></DIV>
<DIV style="position:absolute;top:428;left:313"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:435;left:415"><nobr><span class="ft2">(5)</span></nobr></DIV>
<DIV style="position:absolute;top:481;left:86"><nobr><span class="ft26">We have utilized the information gain and mutual <br>information that are widely used in many fields such as <br>text categorization and data mining. If we count the <br>number of genes excited (</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:279"><nobr><span class="ft12">)</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:261"><nobr><span class="ft12">(</span></nobr></DIV>
<DIV style="position:absolute;top:550;left:275"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:267"><nobr><span class="ft12">g</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:251"><nobr><span class="ft12">P</span></nobr></DIV>
<DIV style="position:absolute;top:539;left:286"><nobr><span class="ft2">) or not excited (</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:423"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:404"><nobr><span class="ft4">(</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:412"><nobr><span class="ft13">_</span></nobr></DIV>
<DIV style="position:absolute;top:550;left:419"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:410"><nobr><span class="ft4">g</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:395"><nobr><span class="ft4">P</span></nobr></DIV>
<DIV style="position:absolute;top:539;left:431"><nobr><span class="ft2">) </span></nobr></DIV>
<DIV style="position:absolute;top:562;left:86"><nobr><span class="ft2">in category c</span></nobr></DIV>
<DIV style="position:absolute;top:569;left:165"><nobr><span class="ft5">j</span></nobr></DIV>
<DIV style="position:absolute;top:562;left:168"><nobr><span class="ft2"> (</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:207"><nobr><span class="ft12">)</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:189"><nobr><span class="ft12">(</span></nobr></DIV>
<DIV style="position:absolute;top:573;left:202"><nobr><span class="ft13">j</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:194"><nobr><span class="ft12">c</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:180"><nobr><span class="ft12">P</span></nobr></DIV>
<DIV style="position:absolute;top:562;left:215"><nobr><span class="ft2">), the coefficients of the information </span></nobr></DIV>
<DIV style="position:absolute;top:586;left:86"><nobr><span class="ft2">gain and mutual information become as follows: </span></nobr></DIV>
<DIV style="position:absolute;top:684;left:367"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:348"><nobr><span class="ft2">(</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:324"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:305"><nobr><span class="ft2">(</span></nobr></DIV>
<DIV style="position:absolute;top:661;left:355"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:661;left:336"><nobr><span class="ft2">,</span></nobr></DIV>
<DIV style="position:absolute;top:661;left:317"><nobr><span class="ft2">(</span></nobr></DIV>
<DIV style="position:absolute;top:672;left:273"><nobr><span class="ft2">log</span></nobr></DIV>
<DIV style="position:absolute;top:672;left:264"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:672;left:247"><nobr><span class="ft2">,</span></nobr></DIV>
<DIV style="position:absolute;top:672;left:229"><nobr><span class="ft2">(</span></nobr></DIV>
<DIV style="position:absolute;top:636;left:338"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:636;left:319"><nobr><span class="ft2">(</span></nobr></DIV>
<DIV style="position:absolute;top:636;left:295"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:636;left:277"><nobr><span class="ft2">(</span></nobr></DIV>
<DIV style="position:absolute;top:613;left:326"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:613;left:308"><nobr><span class="ft2">,</span></nobr></DIV>
<DIV style="position:absolute;top:613;left:289"><nobr><span class="ft2">(</span></nobr></DIV>
<DIV style="position:absolute;top:624;left:244"><nobr><span class="ft2">log</span></nobr></DIV>
<DIV style="position:absolute;top:624;left:236"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:624;left:217"><nobr><span class="ft2">,</span></nobr></DIV>
<DIV style="position:absolute;top:624;left:198"><nobr><span class="ft2">(</span></nobr></DIV>
<DIV style="position:absolute;top:624;left:167"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:624;left:146"><nobr><span class="ft2">,</span></nobr></DIV>
<DIV style="position:absolute;top:624;left:127"><nobr><span class="ft2">(</span></nobr></DIV>
<DIV style="position:absolute;top:693;left:362"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:693;left:319"><nobr><span class="ft5">j</span></nobr></DIV>
<DIV style="position:absolute;top:670;left:350"><nobr><span class="ft5">j</span></nobr></DIV>
<DIV style="position:absolute;top:670;left:332"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:681;left:259"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:681;left:243"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:645;left:334"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:645;left:291"><nobr><span class="ft5">j</span></nobr></DIV>
<DIV style="position:absolute;top:622;left:321"><nobr><span class="ft5">j</span></nobr></DIV>
<DIV style="position:absolute;top:622;left:303"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:633;left:231"><nobr><span class="ft5">j</span></nobr></DIV>
<DIV style="position:absolute;top:633;left:213"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:633;left:162"><nobr><span class="ft5">j</span></nobr></DIV>
<DIV style="position:absolute;top:633;left:141"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:354"><nobr><span class="ft2">g</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:338"><nobr><span class="ft2">P</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:310"><nobr><span class="ft2">c</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:295"><nobr><span class="ft2">P</span></nobr></DIV>
<DIV style="position:absolute;top:661;left:341"><nobr><span class="ft2">c</span></nobr></DIV>
<DIV style="position:absolute;top:661;left:323"><nobr><span class="ft2">g</span></nobr></DIV>
<DIV style="position:absolute;top:661;left:308"><nobr><span class="ft2">P</span></nobr></DIV>
<DIV style="position:absolute;top:672;left:252"><nobr><span class="ft2">c</span></nobr></DIV>
<DIV style="position:absolute;top:672;left:235"><nobr><span class="ft2">g</span></nobr></DIV>
<DIV style="position:absolute;top:672;left:219"><nobr><span class="ft2">P</span></nobr></DIV>
<DIV style="position:absolute;top:636;left:325"><nobr><span class="ft2">g</span></nobr></DIV>
<DIV style="position:absolute;top:636;left:310"><nobr><span class="ft2">P</span></nobr></DIV>
<DIV style="position:absolute;top:636;left:282"><nobr><span class="ft2">c</span></nobr></DIV>
<DIV style="position:absolute;top:636;left:267"><nobr><span class="ft2">P</span></nobr></DIV>
<DIV style="position:absolute;top:613;left:313"><nobr><span class="ft2">c</span></nobr></DIV>
<DIV style="position:absolute;top:613;left:295"><nobr><span class="ft2">g</span></nobr></DIV>
<DIV style="position:absolute;top:613;left:279"><nobr><span class="ft2">P</span></nobr></DIV>
<DIV style="position:absolute;top:624;left:222"><nobr><span class="ft2">c</span></nobr></DIV>
<DIV style="position:absolute;top:624;left:204"><nobr><span class="ft2">g</span></nobr></DIV>
<DIV style="position:absolute;top:624;left:189"><nobr><span class="ft2">P</span></nobr></DIV>
<DIV style="position:absolute;top:624;left:153"><nobr><span class="ft2">c</span></nobr></DIV>
<DIV style="position:absolute;top:624;left:133"><nobr><span class="ft2">g</span></nobr></DIV>
<DIV style="position:absolute;top:624;left:111"><nobr><span class="ft2">IG</span></nobr></DIV>
<DIV style="position:absolute;top:682;left:331"><nobr><span class="ft2"></span></nobr></DIV>
<DIV style="position:absolute;top:671;left:206"><nobr><span class="ft2">+</span></nobr></DIV>
<DIV style="position:absolute;top:634;left:303"><nobr><span class="ft2"></span></nobr></DIV>
<DIV style="position:absolute;top:623;left:176"><nobr><span class="ft2">=</span></nobr></DIV>
<DIV style="position:absolute;top:649;left:376"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:651;left:415"><nobr><span class="ft2">(6)</span></nobr></DIV>
<DIV style="position:absolute;top:739;left:320"><nobr><span class="ft12">)</span></nobr></DIV>
<DIV style="position:absolute;top:739;left:303"><nobr><span class="ft12">(</span></nobr></DIV>
<DIV style="position:absolute;top:739;left:282"><nobr><span class="ft12">)</span></nobr></DIV>
<DIV style="position:absolute;top:739;left:265"><nobr><span class="ft12">(</span></nobr></DIV>
<DIV style="position:absolute;top:717;left:310"><nobr><span class="ft12">)</span></nobr></DIV>
<DIV style="position:absolute;top:717;left:293"><nobr><span class="ft12">,</span></nobr></DIV>
<DIV style="position:absolute;top:717;left:276"><nobr><span class="ft12">(</span></nobr></DIV>
<DIV style="position:absolute;top:727;left:236"><nobr><span class="ft12">log</span></nobr></DIV>
<DIV style="position:absolute;top:727;left:211"><nobr><span class="ft12">)</span></nobr></DIV>
<DIV style="position:absolute;top:727;left:192"><nobr><span class="ft12">,</span></nobr></DIV>
<DIV style="position:absolute;top:727;left:175"><nobr><span class="ft12">(</span></nobr></DIV>
<DIV style="position:absolute;top:747;left:316"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:747;left:278"><nobr><span class="ft13">j</span></nobr></DIV>
<DIV style="position:absolute;top:725;left:305"><nobr><span class="ft13">j</span></nobr></DIV>
<DIV style="position:absolute;top:725;left:289"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:736;left:206"><nobr><span class="ft13">j</span></nobr></DIV>
<DIV style="position:absolute;top:736;left:188"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:739;left:308"><nobr><span class="ft12">g</span></nobr></DIV>
<DIV style="position:absolute;top:739;left:294"><nobr><span class="ft12">P</span></nobr></DIV>
<DIV style="position:absolute;top:739;left:270"><nobr><span class="ft12">c</span></nobr></DIV>
<DIV style="position:absolute;top:739;left:257"><nobr><span class="ft12">P</span></nobr></DIV>
<DIV style="position:absolute;top:717;left:298"><nobr><span class="ft12">c</span></nobr></DIV>
<DIV style="position:absolute;top:717;left:281"><nobr><span class="ft12">g</span></nobr></DIV>
<DIV style="position:absolute;top:717;left:267"><nobr><span class="ft12">P</span></nobr></DIV>
<DIV style="position:absolute;top:727;left:198"><nobr><span class="ft12">c</span></nobr></DIV>
<DIV style="position:absolute;top:727;left:181"><nobr><span class="ft12">g</span></nobr></DIV>
<DIV style="position:absolute;top:727;left:157"><nobr><span class="ft12">MI</span></nobr></DIV>
<DIV style="position:absolute;top:737;left:288"><nobr><span class="ft12"></span></nobr></DIV>
<DIV style="position:absolute;top:726;left:222"><nobr><span class="ft12">=</span></nobr></DIV>
<DIV style="position:absolute;top:722;left:328"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:729;left:415"><nobr><span class="ft2">(7)</span></nobr></DIV>
<DIV style="position:absolute;top:764;left:86"><nobr><span class="ft27">Mutual information tells us the dependency relationship <br>between two probabilistic variables of events. If two <br>events are completely independent, the mutual <br>information is 0. The more they are related, the higher the <br>mutual information gets. Information gain is used when <br>the features of samples are extracted by inducing the <br>relationship between gene and class by the presence <br>frequency of the gene in the sample. Information gain <br>measures the goodness of gene using the presence and <br>absence within the corresponding class. <br>For each gene g</span></nobr></DIV>
<DIV style="position:absolute;top:948;left:182"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:185"><nobr><span class="ft2">, some are from tumor samples, and some </span></nobr></DIV>
<DIV style="position:absolute;top:958;left:86"><nobr><span class="ft2">are from normal samples. If we calculate the mean </span></nobr></DIV>
<DIV style="position:absolute;top:956;left:422"><nobr><span class="ft2">µ  </span></nobr></DIV>
<DIV style="position:absolute;top:980;left:86"><nobr><span class="ft2">and standard deviation </span></nobr></DIV>
<DIV style="position:absolute;top:977;left:234"><nobr><span class="ft2">   from the distribution of gene </span></nobr></DIV>
<DIV style="position:absolute;top:998;left:86"><nobr><span class="ft9">expressions within their classes, the signal to noise ratio <br>of gene g</span></nobr></DIV>
<DIV style="position:absolute;top:1022;left:142"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:145"><nobr><span class="ft2">, SN(g</span></nobr></DIV>
<DIV style="position:absolute;top:1022;left:183"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:185"><nobr><span class="ft2">), is defined by: </span></nobr></DIV>
<DIV style="position:absolute;top:1063;left:329"><nobr><span class="ft12">)</span></nobr></DIV>
<DIV style="position:absolute;top:1063;left:311"><nobr><span class="ft12">(</span></nobr></DIV>
<DIV style="position:absolute;top:1063;left:256"><nobr><span class="ft12">)</span></nobr></DIV>
<DIV style="position:absolute;top:1063;left:238"><nobr><span class="ft12">(</span></nobr></DIV>
<DIV style="position:absolute;top:1043;left:329"><nobr><span class="ft12">)</span></nobr></DIV>
<DIV style="position:absolute;top:1043;left:311"><nobr><span class="ft12">(</span></nobr></DIV>
<DIV style="position:absolute;top:1043;left:256"><nobr><span class="ft12">)</span></nobr></DIV>
<DIV style="position:absolute;top:1043;left:238"><nobr><span class="ft12">(</span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:185"><nobr><span class="ft12">)</span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:166"><nobr><span class="ft12">(</span></nobr></DIV>
<DIV style="position:absolute;top:1072;left:325"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:1072;left:284"><nobr><span class="ft13">normal</span></nobr></DIV>
<DIV style="position:absolute;top:1072;left:252"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:1072;left:216"><nobr><span class="ft13">tumor</span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:325"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:284"><nobr><span class="ft13">normal</span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:252"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:216"><nobr><span class="ft13">tumor</span></nobr></DIV>
<DIV style="position:absolute;top:1061;left:180"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:1063;left:317"><nobr><span class="ft12">g</span></nobr></DIV>
<DIV style="position:absolute;top:1063;left:244"><nobr><span class="ft12">g</span></nobr></DIV>
<DIV style="position:absolute;top:1043;left:316"><nobr><span class="ft12">g</span></nobr></DIV>
<DIV style="position:absolute;top:1043;left:244"><nobr><span class="ft12">g</span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:172"><nobr><span class="ft12">g</span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:148"><nobr><span class="ft12">SN</span></nobr></DIV>
<DIV style="position:absolute;top:1061;left:274"><nobr><span class="ft2"></span></nobr></DIV>
<DIV style="position:absolute;top:1061;left:205"><nobr><span class="ft2"></span></nobr></DIV>
<DIV style="position:absolute;top:1040;left:275"><nobr><span class="ft2">µ</span></nobr></DIV>
<DIV style="position:absolute;top:1040;left:207"><nobr><span class="ft2">µ</span></nobr></DIV>
<DIV style="position:absolute;top:1062;left:264"><nobr><span class="ft12">-</span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:264"><nobr><span class="ft12">-</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:193"><nobr><span class="ft12">=</span></nobr></DIV>
<DIV style="position:absolute;top:1047;left:338"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:1054;left:415"><nobr><span class="ft2">(8)</span></nobr></DIV>
<DIV style="position:absolute;top:1101;left:86"><nobr><span class="ft6"><b>3.2  Classification </b></span></nobr></DIV>
<DIV style="position:absolute;top:1129;left:86"><nobr><span class="ft9">Many algorithms designed for solving classification <br>problems in machine learning have been applied to recent </span></nobr></DIV>
<DIV style="position:absolute;top:87;left:457"><nobr><span class="ft9">research of prediction and classification of cancer with <br>gene expression data. General process of classification in <br>machine learning is to train classifier to accurately <br>recognize patterns from given training samples and to <br>classify test samples with the trained classifier. <br>Representative classification algorithms such as <br>multi-layer perceptron, k-nearest neighbour, support <br>vector machine, and structure-adaptive self-organizing <br>map are applied to the classification. </span></nobr></DIV>
<DIV style="position:absolute;top:260;left:457"><nobr><span class="ft9"><b>1) MLP </b></span></nobr></DIV>
<DIV style="position:absolute;top:288;left:457"><nobr><span class="ft9">Error backpropagation neural network is a feed-forward <br>multilayer perceptron (MLP) that is applied in many <br>fields due to its powerful and stable learning algorithm <br>(Lippman  et al. 1987). The neural network learns the <br>training examples by adjusting the synaptic weight of <br>neurons according to the error occurred on the output <br>layer. The power of the backpropagation algorithm lies in <br>two main aspects: local for updating the synaptic weights <br>and biases, and efficient for computing all the partial <br>derivatives of the cost function with respect to these free <br>parameters (Beale 1996). The weight-update rule in <br>backpropagation algorithm is defined as follows: </span></nobr></DIV>
<DIV style="position:absolute;top:505;left:715"><nobr><span class="ft24">)</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:708"><nobr><span class="ft24">1</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:678"><nobr><span class="ft24">(</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:551"><nobr><span class="ft24">)</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:536"><nobr><span class="ft24">(</span></nobr></DIV>
<DIV style="position:absolute;top:503;left:697"><nobr><span class="ft24">-</span></nobr></DIV>
<DIV style="position:absolute;top:503;left:646"><nobr><span class="ft24"></span></nobr></DIV>
<DIV style="position:absolute;top:503;left:623"><nobr><span class="ft24">+</span></nobr></DIV>
<DIV style="position:absolute;top:503;left:562"><nobr><span class="ft24">=</span></nobr></DIV>
<DIV style="position:absolute;top:503;left:504"><nobr><span class="ft24"></span></nobr></DIV>
<DIV style="position:absolute;top:505;left:684"><nobr><span class="ft24">n</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:657"><nobr><span class="ft24">w</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:601"><nobr><span class="ft24">x</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:542"><nobr><span class="ft24">n</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:515"><nobr><span class="ft24">w</span></nobr></DIV>
<DIV style="position:absolute;top:516;left:670"><nobr><span class="ft15">ji</span></nobr></DIV>
<DIV style="position:absolute;top:516;left:611"><nobr><span class="ft15">ji</span></nobr></DIV>
<DIV style="position:absolute;top:516;left:596"><nobr><span class="ft15">j</span></nobr></DIV>
<DIV style="position:absolute;top:516;left:528"><nobr><span class="ft15">ji</span></nobr></DIV>
<DIV style="position:absolute;top:502;left:635"><nobr><span class="ft1"><b></b></span></nobr></DIV>
<DIV style="position:absolute;top:502;left:573"><nobr><span class="ft1"><b></b></span></nobr></DIV>
<DIV style="position:absolute;top:507;left:724"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:509;left:786"><nobr><span class="ft2">(9)</span></nobr></DIV>
<DIV style="position:absolute;top:540;left:457"><nobr><span class="ft2">where </span></nobr></DIV>
<DIV style="position:absolute;top:543;left:544"><nobr><span class="ft12">)</span></nobr></DIV>
<DIV style="position:absolute;top:543;left:531"><nobr><span class="ft12">(n</span></nobr></DIV>
<DIV style="position:absolute;top:543;left:513"><nobr><span class="ft12">w</span></nobr></DIV>
<DIV style="position:absolute;top:552;left:524"><nobr><span class="ft13">ji</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:504"><nobr><span class="ft12"></span></nobr></DIV>
<DIV style="position:absolute;top:540;left:551"><nobr><span class="ft2"> is the weight update performed during </span></nobr></DIV>
<DIV style="position:absolute;top:565;left:457"><nobr><span class="ft2">the nth iteration through the main loop of the algorithm, </span></nobr></DIV>
<DIV style="position:absolute;top:580;left:458"><nobr><span class="ft6"><b></b></span></nobr></DIV>
<DIV style="position:absolute;top:582;left:470"><nobr><span class="ft2"> is a positive constant called the learning rate, </span></nobr></DIV>
<DIV style="position:absolute;top:594;left:783"><nobr><span class="ft13">j</span></nobr></DIV>
<DIV style="position:absolute;top:582;left:773"><nobr><span class="ft2">  is </span></nobr></DIV>
<DIV style="position:absolute;top:606;left:457"><nobr><span class="ft2">the error term associated with j, x</span></nobr></DIV>
<DIV style="position:absolute;top:613;left:662"><nobr><span class="ft5">ji</span></nobr></DIV>
<DIV style="position:absolute;top:606;left:667"><nobr><span class="ft2"> is the input from node </span></nobr></DIV>
<DIV style="position:absolute;top:625;left:457"><nobr><span class="ft2">i to unit j, and 0</span></nobr></DIV>
<DIV style="position:absolute;top:620;left:601"><nobr><span class="ft1"><b></b></span></nobr></DIV>
<DIV style="position:absolute;top:625;left:620"><nobr><span class="ft2">&lt;1 is a constant called the </span></nobr></DIV>
<DIV style="position:absolute;top:643;left:457"><nobr><span class="ft2">momentum. </span></nobr></DIV>
<DIV style="position:absolute;top:679;left:457"><nobr><span class="ft9"><b>2) KNN </b></span></nobr></DIV>
<DIV style="position:absolute;top:706;left:457"><nobr><span class="ft9">k-nearest neighbor (KNN) is one of the most common <br>methods among memory based induction. Given an input <br>vector, KNN extracts k closest vectors in the reference set <br>based on similarity measures, and makes decision for the <br>label of input vector using the labels of the k nearest <br>neighbors. </span></nobr></DIV>
<DIV style="position:absolute;top:819;left:457"><nobr><span class="ft10">Pearson's coefficient correlation and Euclidean distance <br>have been used as the similarity measure. When we have <br>an input X and a reference set D = {d</span></nobr></DIV>
<DIV style="position:absolute;top:862;left:696"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:855;left:700"><nobr><span class="ft2">, d</span></nobr></DIV>
<DIV style="position:absolute;top:862;left:717"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:855;left:722"><nobr><span class="ft2">,  ...,  d</span></nobr></DIV>
<DIV style="position:absolute;top:862;left:765"><nobr><span class="ft5">N</span></nobr></DIV>
<DIV style="position:absolute;top:855;left:772"><nobr><span class="ft2">}, the </span></nobr></DIV>
<DIV style="position:absolute;top:873;left:457"><nobr><span class="ft2">probability that X may belong to class c</span></nobr></DIV>
<DIV style="position:absolute;top:880;left:725"><nobr><span class="ft5">j</span></nobr></DIV>
<DIV style="position:absolute;top:873;left:727"><nobr><span class="ft2">,  P(X,  c</span></nobr></DIV>
<DIV style="position:absolute;top:880;left:781"><nobr><span class="ft5">j</span></nobr></DIV>
<DIV style="position:absolute;top:873;left:783"><nobr><span class="ft2">) is </span></nobr></DIV>
<DIV style="position:absolute;top:890;left:457"><nobr><span class="ft2">defined as follows: </span></nobr></DIV>
<DIV style="position:absolute;top:928;left:723"><nobr><span class="ft13">j</span></nobr></DIV>
<DIV style="position:absolute;top:928;left:690"><nobr><span class="ft13">j</span></nobr></DIV>
<DIV style="position:absolute;top:928;left:671"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:938;left:570"><nobr><span class="ft13">kNN</span></nobr></DIV>
<DIV style="position:absolute;top:938;left:557"><nobr><span class="ft13">d</span></nobr></DIV>
<DIV style="position:absolute;top:928;left:639"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:928;left:531"><nobr><span class="ft13">j</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:714"><nobr><span class="ft12">b</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:682"><nobr><span class="ft12">c</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:663"><nobr><span class="ft12">d</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:648"><nobr><span class="ft12">P</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:630"><nobr><span class="ft12">d</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:613"><nobr><span class="ft12">X</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:523"><nobr><span class="ft12">c</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:505"><nobr><span class="ft12">X</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:489"><nobr><span class="ft12">P</span></nobr></DIV>
<DIV style="position:absolute;top:943;left:562"><nobr><span class="ft25"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:917;left:703"><nobr><span class="ft12">-</span></nobr></DIV>
<DIV style="position:absolute;top:917;left:545"><nobr><span class="ft12">=</span></nobr></DIV>
<DIV style="position:absolute;top:913;left:564"><nobr><span class="ft16"></span></nobr></DIV>
<DIV style="position:absolute;top:937;left:564"><nobr><span class="ft13"></span></nobr></DIV>
<DIV style="position:absolute;top:919;left:695"><nobr><span class="ft12">)</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:676"><nobr><span class="ft12">,</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:658"><nobr><span class="ft12">(</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:643"><nobr><span class="ft12">)</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:624"><nobr><span class="ft12">,</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:582"><nobr><span class="ft12">Sim(</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:536"><nobr><span class="ft12">)</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:517"><nobr><span class="ft12">,</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:499"><nobr><span class="ft12">(</span></nobr></DIV>
<DIV style="position:absolute;top:914;left:728"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:925;left:777"><nobr><span class="ft2">(10)</span></nobr></DIV>
<DIV style="position:absolute;top:961;left:457"><nobr><span class="ft2">where Sim(X, d</span></nobr></DIV>
<DIV style="position:absolute;top:968;left:552"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:961;left:554"><nobr><span class="ft2">) is the similarity between X and d</span></nobr></DIV>
<DIV style="position:absolute;top:968;left:764"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:961;left:766"><nobr><span class="ft2"> and b</span></nobr></DIV>
<DIV style="position:absolute;top:968;left:804"><nobr><span class="ft5">j</span></nobr></DIV>
<DIV style="position:absolute;top:961;left:806"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:978;left:457"><nobr><span class="ft2">is a bias term. </span></nobr></DIV>
<DIV style="position:absolute;top:1014;left:457"><nobr><span class="ft9"><b>3) SASOM </b></span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:457"><nobr><span class="ft9">Self-organizing map (SOM) defines a mapping from the <br>input space onto an output layer by unsupervised learning <br>algorithm. SOM has an output layer consisting of N nodes, <br>each of which represents a vector that has the same <br>dimension as the input pattern. For a given input vector X, <br>the winner node m</span></nobr></DIV>
<DIV style="position:absolute;top:1135;left:577"><nobr><span class="ft5">c</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:581"><nobr><span class="ft2"> is chosen using Euclidean distance </span></nobr></DIV>
<DIV style="position:absolute;top:1145;left:457"><nobr><span class="ft2">between x and its neighbors, m</span></nobr></DIV>
<DIV style="position:absolute;top:1152;left:644"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:1145;left:647"><nobr><span class="ft2">. </span></nobr></DIV>
</DIV>
<!-- Page 5 -->
<a name="5"></a>
<DIV style="position:relative;width:892;height:1263;">
<STYLE type="text/css">
<!--
	.ft28{font-size:10px;font-family:Times;color:#000000;}
	.ft29{font-size:8px;line-height:6px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="892" height="1263" src="133005.png" alt="background image">
<DIV style="position:absolute;top:103;left:292"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:108;left:243"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:103;left:208"><nobr><span class="ft13">c</span></nobr></DIV>
<DIV style="position:absolute;top:94;left:281"><nobr><span class="ft2">m</span></nobr></DIV>
<DIV style="position:absolute;top:94;left:261"><nobr><span class="ft2">x</span></nobr></DIV>
<DIV style="position:absolute;top:94;left:197"><nobr><span class="ft2">m</span></nobr></DIV>
<DIV style="position:absolute;top:94;left:176"><nobr><span class="ft2">x</span></nobr></DIV>
<DIV style="position:absolute;top:92;left:271"><nobr><span class="ft2">-</span></nobr></DIV>
<DIV style="position:absolute;top:92;left:221"><nobr><span class="ft2">=</span></nobr></DIV>
<DIV style="position:absolute;top:92;left:186"><nobr><span class="ft2">-</span></nobr></DIV>
<DIV style="position:absolute;top:94;left:233"><nobr><span class="ft2">min</span></nobr></DIV>
<DIV style="position:absolute;top:92;left:304"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:97;left:406"><nobr><span class="ft2">(11)</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:363"><nobr><span class="ft2">)}</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:353"><nobr><span class="ft2">(</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:317"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:307"><nobr><span class="ft2">(</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:292"><nobr><span class="ft2">{</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:276"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:266"><nobr><span class="ft2">(</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:231"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:221"><nobr><span class="ft2">(</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:192"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:181"><nobr><span class="ft2">(</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:144"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:138"><nobr><span class="ft2">1</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:115"><nobr><span class="ft2">(</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:357"><nobr><span class="ft2">t</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:337"><nobr><span class="ft2">m</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:312"><nobr><span class="ft2">t</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:300"><nobr><span class="ft2">x</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:271"><nobr><span class="ft2">t</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:249"><nobr><span class="ft2">n</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:226"><nobr><span class="ft2">t</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:186"><nobr><span class="ft2">t</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:165"><nobr><span class="ft2">m</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:120"><nobr><span class="ft2">t</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:99"><nobr><span class="ft2">m</span></nobr></DIV>
<DIV style="position:absolute;top:140;left:348"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:140;left:257"><nobr><span class="ft13">ci</span></nobr></DIV>
<DIV style="position:absolute;top:140;left:176"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:140;left:110"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:129;left:325"><nobr><span class="ft2">-</span></nobr></DIV>
<DIV style="position:absolute;top:129;left:283"><nobr><span class="ft2">×</span></nobr></DIV>
<DIV style="position:absolute;top:129;left:238"><nobr><span class="ft2">×</span></nobr></DIV>
<DIV style="position:absolute;top:129;left:200"><nobr><span class="ft2">+</span></nobr></DIV>
<DIV style="position:absolute;top:129;left:153"><nobr><span class="ft2">=</span></nobr></DIV>
<DIV style="position:absolute;top:129;left:128"><nobr><span class="ft2">+</span></nobr></DIV>
<DIV style="position:absolute;top:128;left:210"><nobr><span class="ft6"><b></b></span></nobr></DIV>
<DIV style="position:absolute;top:130;left:376"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:132;left:406"><nobr><span class="ft2">(12)</span></nobr></DIV>
<DIV style="position:absolute;top:162;left:86"><nobr><span class="ft9">Even though SOM is well known for its good <br>performance of topology preserving, it is difficult to <br>apply it to practical classification since the topology <br>should be fixed before training. A structure adaptive <br>self-organizing map (SASOM) is proposed to overcome <br>this shortcoming (Kim et al. 2000). SASOM starts with <br>4×4 map, and dynamically splits the output nodes of the <br>map, where the data from different classes are mixed, <br>trained with the LVQ learning algorithm. Fig. 3 illustrates <br>the algorithm of SASOM. </span></nobr></DIV>
<DIV style="position:absolute;top:345;left:86"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:375;left:201"><nobr><span class="ft28">Input data</span></nobr></DIV>
<DIV style="position:absolute;top:640;left:373"><nobr><span class="ft28">No</span></nobr></DIV>
<DIV style="position:absolute;top:669;left:232"><nobr><span class="ft28">Yes</span></nobr></DIV>
<DIV style="position:absolute;top:694;left:188"><nobr><span class="ft28">Map generated</span></nobr></DIV>
<DIV style="position:absolute;top:417;left:172"><nobr><span class="ft28">Initialize map as 4X4</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:145"><nobr><span class="ft28">Train with Kohonen's algorithm</span></nobr></DIV>
<DIV style="position:absolute;top:497;left:110"><nobr><span class="ft28">Find nodes whose hit_ratio is less than 95.0%</span></nobr></DIV>
<DIV style="position:absolute;top:530;left:149"><nobr><span class="ft28">Split the nodes to 2X2 submap</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:121"><nobr><span class="ft28">Train the split nodes with LVQ algorithm</span></nobr></DIV>
<DIV style="position:absolute;top:597;left:122"><nobr><span class="ft28">Remove nodes not participted in learning</span></nobr></DIV>
<DIV style="position:absolute;top:646;left:163"><nobr><span class="ft28">Stop condition satisfied?</span></nobr></DIV>
<DIV style="position:absolute;top:469;left:302"><nobr><span class="ft28">Structure adaptation</span></nobr></DIV>
<DIV style="position:absolute;top:701;left:431"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:723;left:174"><nobr><span class="ft2">Fig. 3. Overview of SASOM </span></nobr></DIV>
<DIV style="position:absolute;top:759;left:86"><nobr><span class="ft9"><b>4) SVM </b></span></nobr></DIV>
<DIV style="position:absolute;top:787;left:86"><nobr><span class="ft9">Support vector machine (SVM) estimates the function <br>classifying the data into two classes (Vapnik 1995, <br>Moghaddam et al. 2000). SVM builds up a hyperplane as <br>the decision surface in such a way to maximize the <br>margin of separation between positive and negative <br>examples. SVM achieves this by the structural risk <br>minimization principle that the error rate of a learning <br>machine on the test data is bounded by the sum of the <br>training-error rate and a term that depends on the <br>Vapnik-Chervonenkis (VC) dimension. Given a labeled <br>set of M training samples (X</span></nobr></DIV>
<DIV style="position:absolute;top:966;left:261"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:959;left:264"><nobr><span class="ft2">, Y</span></nobr></DIV>
<DIV style="position:absolute;top:966;left:282"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:959;left:284"><nobr><span class="ft2">), where X</span></nobr></DIV>
<DIV style="position:absolute;top:966;left:349"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:960;left:353"><nobr><span class="ft12"></span></nobr></DIV>
<DIV style="position:absolute;top:959;left:365"><nobr><span class="ft2">R</span></nobr></DIV>
<DIV style="position:absolute;top:957;left:374"><nobr><span class="ft5">N</span></nobr></DIV>
<DIV style="position:absolute;top:959;left:381"><nobr><span class="ft2"> and Y</span></nobr></DIV>
<DIV style="position:absolute;top:966;left:421"><nobr><span class="ft5">i </span></nobr></DIV>
<DIV style="position:absolute;top:959;left:426"><nobr><span class="ft2">is </span></nobr></DIV>
<DIV style="position:absolute;top:976;left:86"><nobr><span class="ft2">the associated label,  Y</span></nobr></DIV>
<DIV style="position:absolute;top:983;left:248"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:977;left:255"><nobr><span class="ft12"></span></nobr></DIV>
<DIV style="position:absolute;top:976;left:270"><nobr><span class="ft2">{-1, 1}, the discriminant </span></nobr></DIV>
<DIV style="position:absolute;top:993;left:86"><nobr><span class="ft2">hyperplane is defined by: </span></nobr></DIV>
<DIV style="position:absolute;top:1025;left:204"><nobr><span class="ft17"></span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:209"><nobr><span class="ft13">=</span></nobr></DIV>
<DIV style="position:absolute;top:1029;left:298"><nobr><span class="ft12">+</span></nobr></DIV>
<DIV style="position:absolute;top:1029;left:193"><nobr><span class="ft12">=</span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:208"><nobr><span class="ft13">M</span></nobr></DIV>
<DIV style="position:absolute;top:1049;left:206"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:1039;left:286"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:1039;left:241"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:1039;left:228"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:309"><nobr><span class="ft12">b</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:275"><nobr><span class="ft12">X</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:258"><nobr><span class="ft12">X</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:244"><nobr><span class="ft12">k</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:220"><nobr><span class="ft12">Y</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:173"><nobr><span class="ft12">X</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:160"><nobr><span class="ft12">f</span></nobr></DIV>
<DIV style="position:absolute;top:1049;left:213"><nobr><span class="ft13">1</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:291"><nobr><span class="ft12">)</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:269"><nobr><span class="ft12">,</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:252"><nobr><span class="ft12">(</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:184"><nobr><span class="ft12">)</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:167"><nobr><span class="ft12">(</span></nobr></DIV>
<DIV style="position:absolute;top:1028;left:230"><nobr><span class="ft2"></span></nobr></DIV>
<DIV style="position:absolute;top:1025;left:318"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:1031;left:406"><nobr><span class="ft2">(13)</span></nobr></DIV>
<DIV style="position:absolute;top:1069;left:86"><nobr><span class="ft10">where  k(  .) is a kernel function and the sign of f(X) <br>determines the membership of X. Constructing an optimal <br>hyperplane is equivalent to finding all the nonzero </span></nobr></DIV>
<DIV style="position:absolute;top:1114;left:430"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:1102;left:419"><nobr><span class="ft2">  </span></nobr></DIV>
<DIV style="position:absolute;top:1126;left:86"><nobr><span class="ft2">(support vectors) and a bias b. We have used SVM</span></nobr></DIV>
<DIV style="position:absolute;top:1124;left:418"><nobr><span class="ft5">light</span></nobr></DIV>
<DIV style="position:absolute;top:1126;left:436"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:1143;left:86"><nobr><span class="ft2">module and SVM</span></nobr></DIV>
<DIV style="position:absolute;top:1141;left:193"><nobr><span class="ft5">RBF</span></nobr></DIV>
<DIV style="position:absolute;top:1143;left:212"><nobr><span class="ft2"> in this paper. </span></nobr></DIV>
<DIV style="position:absolute;top:87;left:457"><nobr><span class="ft9"><b>5) Ensemble classifier </b></span></nobr></DIV>
<DIV style="position:absolute;top:115;left:457"><nobr><span class="ft9">Classification can be defined as the process to <br>approximate I/O mapping from the given observation to <br>the optimal solution. Generally, classification tasks <br>consist of two parts: feature selection and classification. <br>Feature selection is a transformation process of <br>observations to obtain the best pathway to get to the <br>optimal solution. Therefore, considering multiple features <br>encourages obtaining various candidate solutions, so that <br>we can estimate more accurate solution to the optimal <br>than any other local optima. </span></nobr></DIV>
<DIV style="position:absolute;top:296;left:457"><nobr><span class="ft9">When we have multiple features available, it is important <br>to know which of features should be used. Theoretically, <br>as many features we may concern, it may be more <br>effective for the classifier to solve the problems. But <br>features that have overlapped feature spaces may cause <br>the redundancy of irrelevant information and result in the <br>counter effect such as overfitting. Therefore, it is more <br>important to explore and utilize independent features to <br>train classifiers, rather than increase the number of <br>features we use. Correlation between feature sets can be <br>induced from the distribution of feature numbers, or using <br>mathematical analysis using statistics. </span></nobr></DIV>
<DIV style="position:absolute;top:512;left:457"><nobr><span class="ft9">Meanwhile, there are many algorithms for the <br>classification from machine learning approach, but none <br>of them is perfect. However, it is always difficult to <br>decide what to use and how to set up its parameters. <br>According to the environments the classifier is embedded, <br>some algorithm works well and others not. It is because, <br>depending on the algorithms, features and parameters <br>used, the classifier searches in different solution space. <br>These sets of classifiers produce their own outputs, and <br>enable the ensemble classifier to explore more wide <br>solution space. </span></nobr></DIV>
<DIV style="position:absolute;top:710;left:457"><nobr><span class="ft10">We have applied this idea to a classification framework <br>as shown in Fig. 4. If there are k features and n classifiers, <br>there are k×n feature-classifier combinations. There are </span></nobr></DIV>
<DIV style="position:absolute;top:773;left:457"><nobr><span class="ft5">k×n</span></nobr></DIV>
<DIV style="position:absolute;top:766;left:474"><nobr><span class="ft2">C</span></nobr></DIV>
<DIV style="position:absolute;top:773;left:484"><nobr><span class="ft5">m</span></nobr></DIV>
<DIV style="position:absolute;top:766;left:491"><nobr><span class="ft2"> possible ensemble classifiers when m </span></nobr></DIV>
<DIV style="position:absolute;top:784;left:457"><nobr><span class="ft9">feature-classifier combinations are selected for ensemble <br>classifier. Then classifiers are trained using the features <br>selected, finally a majority voting is accompanied to <br>combine the outputs of these classifiers. After classifiers <br>with some features are trained independently produce <br>their own outputs, final answer will be judged by a <br>combining module, where the majority voting method is <br>adopted. </span></nobr></DIV>
<DIV style="position:absolute;top:1026;left:797"><nobr><span class="ft15">Class</span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:819"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:996;left:796"><nobr><span class="ft15">Class</span></nobr></DIV>
<DIV style="position:absolute;top:1003;left:818"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:1005;left:531"><nobr><span class="ft15">Feature</span></nobr></DIV>
<DIV style="position:absolute;top:1017;left:528"><nobr><span class="ft15">extractor</span></nobr></DIV>
<DIV style="position:absolute;top:1005;left:720"><nobr><span class="ft15">Majority</span></nobr></DIV>
<DIV style="position:absolute;top:1017;left:724"><nobr><span class="ft15">Voting</span></nobr></DIV>
<DIV style="position:absolute;top:1001;left:470"><nobr><span class="ft15">Input</span></nobr></DIV>
<DIV style="position:absolute;top:1014;left:467"><nobr><span class="ft15">pattern</span></nobr></DIV>
<DIV style="position:absolute;top:981;left:704"><nobr><span class="ft15">...</span></nobr></DIV>
<DIV style="position:absolute;top:1045;left:704"><nobr><span class="ft15">...</span></nobr></DIV>
<DIV style="position:absolute;top:1023;left:646"><nobr><span class="ft15">Classifier</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:686"><nobr><span class="ft11">n1</span></nobr></DIV>
<DIV style="position:absolute;top:1065;left:646"><nobr><span class="ft15">Classifier</span></nobr></DIV>
<DIV style="position:absolute;top:1072;left:686"><nobr><span class="ft11">nk</span></nobr></DIV>
<DIV style="position:absolute;top:1046;left:676"><nobr><span class="ft15">...</span></nobr></DIV>
<DIV style="position:absolute;top:957;left:646"><nobr><span class="ft15">Classifier</span></nobr></DIV>
<DIV style="position:absolute;top:963;left:686"><nobr><span class="ft11">a1</span></nobr></DIV>
<DIV style="position:absolute;top:1000;left:646"><nobr><span class="ft15">Classifier</span></nobr></DIV>
<DIV style="position:absolute;top:1006;left:686"><nobr><span class="ft11">ak</span></nobr></DIV>
<DIV style="position:absolute;top:980;left:676"><nobr><span class="ft15">...</span></nobr></DIV>
<DIV style="position:absolute;top:976;left:646"><nobr><span class="ft15">Classifier</span></nobr></DIV>
<DIV style="position:absolute;top:982;left:686"><nobr><span class="ft11">a2</span></nobr></DIV>
<DIV style="position:absolute;top:1042;left:646"><nobr><span class="ft15">Classifier</span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:686"><nobr><span class="ft11">n2</span></nobr></DIV>
<DIV style="position:absolute;top:967;left:575"><nobr><span class="ft15">Feature 1</span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:576"><nobr><span class="ft15">Feature k</span></nobr></DIV>
<DIV style="position:absolute;top:987;left:575"><nobr><span class="ft15">Feature 2</span></nobr></DIV>
<DIV style="position:absolute;top:1012;left:595"><nobr><span class="ft15">...</span></nobr></DIV>
<DIV style="position:absolute;top:1003;left:790"><nobr><span class="ft15">...</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:705"><nobr><span class="ft15">...</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:677"><nobr><span class="ft29">..<br>.</span></nobr></DIV>
<DIV style="position:absolute;top:1083;left:504"><nobr><span class="ft2">Fig 4. Overview of the ensemble classifier </span></nobr></DIV>
</DIV>
<!-- Page 6 -->
<a name="6"></a>
<DIV style="position:relative;width:892;height:1263;">
<STYLE type="text/css">
<!--
	.ft30{font-size:0px;font-family:Times;color:#000000;}
	.ft31{font-size:11px;line-height:20px;font-family:Times;color:#000000;}
	.ft32{font-size:11px;line-height:21px;font-family:Times;color:#000000;}
	.ft33{font-size:11px;line-height:22px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="892" height="1263" src="133006.png" alt="background image">
<DIV style="position:absolute;top:87;left:86"><nobr><span class="ft6"><b>4 </b></span></nobr></DIV>
<DIV style="position:absolute;top:87;left:119"><nobr><span class="ft6"><b>Experimental Results </b></span></nobr></DIV>
<DIV style="position:absolute;top:124;left:86"><nobr><span class="ft6"><b>4.1  Datasets </b></span></nobr></DIV>
<DIV style="position:absolute;top:152;left:86"><nobr><span class="ft9">There are several microarray datasets from published <br>cancer gene expression studies, including leukemia <br>cancer dataset, colon cancer dataset, lymphoma dataset, <br>breast cancer dataset, NCI60 dataset, and ovarian cancer <br>dataset. Among them three datasets are used in this paper. <br>The first dataset and third dataset involve samples from <br>two variants of the same disease and second dataset <br>involves tumor and normal samples of the same tissue. <br>Because the benchmark data have been studied in many <br>papers, we can compare the results of this paper with <br>others. </span></nobr></DIV>
<DIV style="position:absolute;top:360;left:86"><nobr><span class="ft6"><b>1) Leukemia cancer dataset </b></span></nobr></DIV>
<DIV style="position:absolute;top:387;left:86"><nobr><span class="ft9">Leukemia dataset consists of 72 samples: 25 samples of <br>acute myeloid leukemia (AML) and 47 samples of acute <br>lymphoblastic leukemia (ALL). The source of the gene <br>expression measurements was taken form 63 bone <br>marrow samples and 9 peripheral blood samples. Gene <br>expression levels in these 72 samples were measured <br>using high density oligonucleotide microarrays (Ben-Dor <br>et al. 2000). </span></nobr></DIV>
<DIV style="position:absolute;top:534;left:86"><nobr><span class="ft9">38 out of 72 samples were used as training data and the <br>remaining were used as test data in this paper. Each <br>sample contains 7129 gene expression levels. </span></nobr></DIV>
<DIV style="position:absolute;top:604;left:86"><nobr><span class="ft6"><b>2) Colon cancer dataset </b></span></nobr></DIV>
<DIV style="position:absolute;top:632;left:86"><nobr><span class="ft9">Colon dataset consists of 62 samples of colon epithelial <br>cells taken from colon-cancer patients. Each sample <br>contains 2000 gene expression levels. Although original <br>data consists of 6000 gene expression levels, 4000 out of <br>6000 were removed based on the confidence in the <br>measured expression levels. 40 of 62 samples are colon <br>cancer samples and the remaining are normal samples. <br>Each sample was taken from tumors and normal healthy <br>parts of the colons of the same patients and measured <br>using high density oligonucleotide arrays (Ben-Dor et al. <br>2000). </span></nobr></DIV>
<DIV style="position:absolute;top:830;left:86"><nobr><span class="ft9">31 out of 62 samples were used as training data and the <br>remaining were used as test data in this paper. </span></nobr></DIV>
<DIV style="position:absolute;top:883;left:86"><nobr><span class="ft6"><b>3) Lymphoma cancer dataset </b></span></nobr></DIV>
<DIV style="position:absolute;top:911;left:86"><nobr><span class="ft9">B cell diffuse large cell lymphoma (B-DLCL) is a <br>heterogeneous group of tumors, based on significant <br>variations in morphology, clinical presentation, and <br>response to treatment. Gene expression profiling has <br>revealed two distinct tumor subtypes of B-DLCL: <br>germinal center B cell-like DLCL and activated B <br>cell-like DLCL (Lossos et al. 2000). Lymphoma dataset <br>consists of 24 samples of GC B-like and 23 samples of <br>activated B-like. </span></nobr></DIV>
<DIV style="position:absolute;top:1075;left:86"><nobr><span class="ft9">22 out of 47 samples were used as training data and the <br>remaining were used as test data in this paper. </span></nobr></DIV>
<DIV style="position:absolute;top:87;left:457"><nobr><span class="ft6"><b>4.2  Environments </b></span></nobr></DIV>
<DIV style="position:absolute;top:115;left:457"><nobr><span class="ft9">For feature selection, each gene is scored based on the <br>feature selection methods described in Section 3.1, and <br>the 25 top-ranked genes are chosen as the feature of the <br>input pattern. </span></nobr></DIV>
<DIV style="position:absolute;top:193;left:457"><nobr><span class="ft9">For classification, we have used 3-layered MLP with <br>5~15 hidden nodes, 2 output nodes, 0.01~0.50 of learning <br>rate and 0.9 of momentum. KNN has been used with <br>k=1~8. Similarity measures used in KNN are Pearson's <br>correlation coefficient and Euclidean distance. SASOM <br>has been used by 4×4 map with rectangular topology, <br>0.05 of initial learning rate, 1000 of initial learning length, <br>10 of initial radius, 0.02 of final learning rate, 10000 of <br>final learning length and 3 of final radius. We have used <br>SVM with linear function and RBF function as kernel <br>function. In RBF, we have changed 0.1~0.5 gamma <br>variable. </span></nobr></DIV>
<DIV style="position:absolute;top:420;left:457"><nobr><span class="ft6"><b>4.3  Analysis of results </b></span></nobr></DIV>
<DIV style="position:absolute;top:449;left:457"><nobr><span class="ft9">Table    shows the IDs of genes overlapped by <br>Pearson's correlation coefficient, cosine coefficient, <br>Euclidean distance in each dataset. Among these genes <br>there are some genes overlapped by other feature <br>selection methods. For example, gene 2288 of leukemia <br>has been third-ranked in information gain. The number of <br>overlapped genes of leukemia dataset is 17. The number <br>of overlapped genes of colon dataset is 9. The number of <br>overlapped genes of lymphoma dataset is 19. These <br>overlapped genes are very informative. In particular, <br>Zyxin, gene 4847 of leukemia, has been reported as <br>informative (Golub et al. 1999), but there are no genes <br>appeared commonly in every method. </span></nobr></DIV>
<DIV style="position:absolute;top:683;left:457"><nobr><span class="ft30"> </span></nobr></DIV>
<DIV style="position:absolute;top:697;left:472"><nobr><span class="ft2">Table  . The IDs of genes overlapped by Pearson's </span></nobr></DIV>
<DIV style="position:absolute;top:715;left:462"><nobr><span class="ft2">correlation coefficient, cosine coefficient, and Euclidean </span></nobr></DIV>
<DIV style="position:absolute;top:732;left:607"><nobr><span class="ft2">distance </span></nobr></DIV>
<DIV style="position:absolute;top:758;left:548"><nobr><span class="ft32">461 1249 1745 1834 2020 <br>2043 2242 2288 3258 3320 <br>4196 4847 5039 6200 6201 </span></nobr></DIV>
<DIV style="position:absolute;top:758;left:457"><nobr><span class="ft4">Leukemia </span></nobr></DIV>
<DIV style="position:absolute;top:821;left:548"><nobr><span class="ft4">6373 6803  </span></nobr></DIV>
<DIV style="position:absolute;top:821;left:713"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:821;left:768"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:843;left:548"><nobr><span class="ft4">187 </span></nobr></DIV>
<DIV style="position:absolute;top:843;left:603"><nobr><span class="ft4">619 </span></nobr></DIV>
<DIV style="position:absolute;top:843;left:658"><nobr><span class="ft4">704 </span></nobr></DIV>
<DIV style="position:absolute;top:843;left:713"><nobr><span class="ft4">767     1060 </span></nobr></DIV>
<DIV style="position:absolute;top:843;left:457"><nobr><span class="ft4">Colon </span></nobr></DIV>
<DIV style="position:absolute;top:864;left:548"><nobr><span class="ft31">1208 1546 1771 1772  <br>36 75 76 77 86 <br>86 678 680 1636 </span></nobr></DIV>
<DIV style="position:absolute;top:907;left:768"><nobr><span class="ft4">1637 </span></nobr></DIV>
<DIV style="position:absolute;top:928;left:548"><nobr><span class="ft4">2225 2243 2263 2412 2417 </span></nobr></DIV>
<DIV style="position:absolute;top:886;left:457"><nobr><span class="ft4">Lymphoma </span></nobr></DIV>
<DIV style="position:absolute;top:949;left:548"><nobr><span class="ft4">2467 3890 3893 3934  </span></nobr></DIV>
<DIV style="position:absolute;top:975;left:457"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:1001;left:457"><nobr><span class="ft9">Fig. 5 shows the expression level of genes chosen by <br>Pearson's correlation coefficient method in Leukemia <br>dataset. 1~27 samples are ALL and 28~38 samples are <br>AML. The differences of brightness between AML and <br>ALL represent that genes chosen by Pearson's correlation <br>coefficient method divide samples into AML and ALL. </span></nobr></DIV>
<DIV style="position:absolute;top:1114;left:457"><nobr><span class="ft10">The results of recognition rate on the test data are as <br>shown in Tables  , , and . Column is the list of <br>feature selection methods: Pearson's correlation </span></nobr></DIV>
</DIV>
<!-- Page 7 -->
<a name="7"></a>
<DIV style="position:relative;width:892;height:1263;">
<STYLE type="text/css">
<!--
	.ft34{font-size:5px;line-height:-3px;font-family:Times;color:#000000;}
	.ft35{font-size:11px;line-height:17px;font-family:Times;color:#000000;}
	.ft36{font-size:10px;line-height:-7px;font-family:Times;color:#000000;}
	.ft37{font-size:10px;line-height:-6px;font-family:Times;color:#000000;}
	.ft38{font-size:10px;line-height:-11px;font-family:Times;color:#000000;}
	.ft39{font-size:10px;line-height:-4px;font-family:Times;color:#000000;}
	.ft40{font-size:10px;line-height:-3px;font-family:Times;color:#000000;}
	.ft41{font-size:10px;line-height:-8px;font-family:Times;color:#000000;}
	.ft42{font-size:10px;line-height:-10px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="892" height="1263" src="133007.png" alt="background image">
<DIV style="position:absolute;top:87;left:86"><nobr><span class="ft9">coefficient (PC), Spearman's correlation coefficient (SC), <br>Euclidean distance (ED), cosine coefficient (CC), <br>information gain (IG), mutual information (MI), and <br>signal to noise ratio (SN). KNN</span></nobr></DIV>
<DIV style="position:absolute;top:146;left:287"><nobr><span class="ft5">Pearson</span></nobr></DIV>
<DIV style="position:absolute;top:139;left:318"><nobr><span class="ft2"> and MLP seem to </span></nobr></DIV>
<DIV style="position:absolute;top:156;left:86"><nobr><span class="ft9">produce the best recognition rate among the classifiers on <br>the average. KNN</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:199"><nobr><span class="ft5">Pearson</span></nobr></DIV>
<DIV style="position:absolute;top:173;left:229"><nobr><span class="ft2"> is better than KNN</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:354"><nobr><span class="ft5">cosine</span></nobr></DIV>
<DIV style="position:absolute;top:173;left:378"><nobr><span class="ft2">. SVM is </span></nobr></DIV>
<DIV style="position:absolute;top:190;left:86"><nobr><span class="ft2">poorer than any other classifiers. </span></nobr></DIV>
<DIV style="position:absolute;top:360;left:425"><nobr><span class="ft11">0</span></nobr></DIV>
<DIV style="position:absolute;top:331;left:425"><nobr><span class="ft11">0.2</span></nobr></DIV>
<DIV style="position:absolute;top:302;left:425"><nobr><span class="ft11">0.4</span></nobr></DIV>
<DIV style="position:absolute;top:274;left:425"><nobr><span class="ft11">0.6</span></nobr></DIV>
<DIV style="position:absolute;top:245;left:425"><nobr><span class="ft11">0.8</span></nobr></DIV>
<DIV style="position:absolute;top:216;left:425"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:376;left:248"><nobr><span class="ft11">Sample</span></nobr></DIV>
<DIV style="position:absolute;top:295;left:121"><nobr><span class="ft11">Ge</span></nobr></DIV>
<DIV style="position:absolute;top:286;left:121"><nobr><span class="ft34">n<br>e</span></nobr></DIV>
<DIV style="position:absolute;top:366;left:306"><nobr><span class="ft11">27</span></nobr></DIV>
<DIV style="position:absolute;top:366;left:379"><nobr><span class="ft11">38</span></nobr></DIV>
<DIV style="position:absolute;top:242;left:129"><nobr><span class="ft11">5</span></nobr></DIV>
<DIV style="position:absolute;top:271;left:125"><nobr><span class="ft11">10</span></nobr></DIV>
<DIV style="position:absolute;top:299;left:125"><nobr><span class="ft11">15</span></nobr></DIV>
<DIV style="position:absolute;top:328;left:125"><nobr><span class="ft11">20</span></nobr></DIV>
<DIV style="position:absolute;top:357;left:125"><nobr><span class="ft11">25</span></nobr></DIV>
<DIV style="position:absolute;top:370;left:465"><nobr><span class="ft6"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:395;left:100"><nobr><span class="ft2">Fig. 5. Expression level of genes chosen by </span></nobr></DIV>
<DIV style="position:absolute;top:394;left:365"><nobr><span class="ft6"><b>r</b></span></nobr></DIV>
<DIV style="position:absolute;top:401;left:371"><nobr><span class="ft15">Pearson</span></nobr></DIV>
<DIV style="position:absolute;top:395;left:407"><nobr><span class="ft2"> in </span></nobr></DIV>
<DIV style="position:absolute;top:413;left:208"><nobr><span class="ft2">Leukemia dataset </span></nobr></DIV>
<DIV style="position:absolute;top:439;left:86"><nobr><span class="ft30"> </span></nobr></DIV>
<DIV style="position:absolute;top:453;left:93"><nobr><span class="ft2">Table  . Recognition rate with features and classifiers </span></nobr></DIV>
<DIV style="position:absolute;top:471;left:187"><nobr><span class="ft2">(%) in Leukemia dataset </span></nobr></DIV>
<DIV style="position:absolute;top:494;left:259"><nobr><span class="ft4">SVM KNN </span></nobr></DIV>
<DIV style="position:absolute;top:494;left:90"><nobr><span class="ft4"> MLP </span></nobr></DIV>
<DIV style="position:absolute;top:494;left:169"><nobr><span class="ft4">SASOM </span></nobr></DIV>
<DIV style="position:absolute;top:513;left:233"><nobr><span class="ft4">Linear</span></nobr></DIV>
<DIV style="position:absolute;top:513;left:288"><nobr><span class="ft4">RBF Cosine</span></nobr></DIV>
<DIV style="position:absolute;top:513;left:387"><nobr><span class="ft4">Pearson</span></nobr></DIV>
<DIV style="position:absolute;top:532;left:81"><nobr><span class="ft4">PC 97.1  76.5  79.4 79.4 97.1  94.1 </span></nobr></DIV>
<DIV style="position:absolute;top:550;left:81"><nobr><span class="ft4">SC  82.4  61.8  58.8 58.8 76.5  82.4 </span></nobr></DIV>
<DIV style="position:absolute;top:568;left:80"><nobr><span class="ft35">ED 91.2  73.5  70.6 70.6 85.3  82.4 <br>CC 94.1  88.2  85.3 85.3 91.2  94.1 </span></nobr></DIV>
<DIV style="position:absolute;top:604;left:82"><nobr><span class="ft4">IG  97.1  91.2  97.1 97.1 94.1  97.1 </span></nobr></DIV>
<DIV style="position:absolute;top:622;left:81"><nobr><span class="ft4">MI 58.8  58.8  58.8 58.8 73.5  73.5 </span></nobr></DIV>
<DIV style="position:absolute;top:640;left:81"><nobr><span class="ft4">SN  76.5  67.7  58.8 58.8 73.5  73.5 </span></nobr></DIV>
<DIV style="position:absolute;top:659;left:73"><nobr><span class="ft4">Mean 85.3  74.0  72.7 72.7 84.5  85.3 </span></nobr></DIV>
<DIV style="position:absolute;top:685;left:86"><nobr><span class="ft30"> </span></nobr></DIV>
<DIV style="position:absolute;top:699;left:95"><nobr><span class="ft2">Table . Recognition rate with features and classifiers </span></nobr></DIV>
<DIV style="position:absolute;top:717;left:199"><nobr><span class="ft2">(%) in Colon dataset </span></nobr></DIV>
<DIV style="position:absolute;top:740;left:259"><nobr><span class="ft4">SVM KNN </span></nobr></DIV>
<DIV style="position:absolute;top:740;left:90"><nobr><span class="ft4"> MLP </span></nobr></DIV>
<DIV style="position:absolute;top:740;left:169"><nobr><span class="ft4">SASOM </span></nobr></DIV>
<DIV style="position:absolute;top:759;left:233"><nobr><span class="ft4">Linear</span></nobr></DIV>
<DIV style="position:absolute;top:759;left:288"><nobr><span class="ft4">RBF Cosine</span></nobr></DIV>
<DIV style="position:absolute;top:759;left:387"><nobr><span class="ft4">Pearson</span></nobr></DIV>
<DIV style="position:absolute;top:778;left:81"><nobr><span class="ft4">PC 74.2  74.2  64.5 64.5 71.0  77.4 </span></nobr></DIV>
<DIV style="position:absolute;top:796;left:81"><nobr><span class="ft4">SC  58.1  45.2  64.5 64.5 61.3  67.7 </span></nobr></DIV>
<DIV style="position:absolute;top:814;left:80"><nobr><span class="ft35">ED 67.8  67.6  64.5 64.5 83.9  83.9 <br>CC 83.9  64.5  64.5 64.5 80.7  80.7 </span></nobr></DIV>
<DIV style="position:absolute;top:850;left:82"><nobr><span class="ft4">IG  71.0  71.0  71.0 71.0 74.2  80.7 </span></nobr></DIV>
<DIV style="position:absolute;top:868;left:81"><nobr><span class="ft4">MI 71.0  71.0  71.0 71.0 74.2  80.7 </span></nobr></DIV>
<DIV style="position:absolute;top:886;left:81"><nobr><span class="ft4">SN  64.5  45.2  64.5 64.5 64.5  71.0 </span></nobr></DIV>
<DIV style="position:absolute;top:906;left:73"><nobr><span class="ft4">Mean 70.1  62.7  66.4 66.4 72.7  77.4 </span></nobr></DIV>
<DIV style="position:absolute;top:931;left:86"><nobr><span class="ft30"> </span></nobr></DIV>
<DIV style="position:absolute;top:945;left:95"><nobr><span class="ft2">Table . Recognition rate with features and classifiers </span></nobr></DIV>
<DIV style="position:absolute;top:963;left:183"><nobr><span class="ft2">(%) in Lymphoma dataset </span></nobr></DIV>
<DIV style="position:absolute;top:986;left:259"><nobr><span class="ft4">SVM KNN </span></nobr></DIV>
<DIV style="position:absolute;top:986;left:90"><nobr><span class="ft4"> MLP </span></nobr></DIV>
<DIV style="position:absolute;top:986;left:169"><nobr><span class="ft4">SASOM </span></nobr></DIV>
<DIV style="position:absolute;top:1005;left:233"><nobr><span class="ft4">Linear</span></nobr></DIV>
<DIV style="position:absolute;top:1005;left:288"><nobr><span class="ft4">RBF Cosine</span></nobr></DIV>
<DIV style="position:absolute;top:1005;left:387"><nobr><span class="ft4">Pearson</span></nobr></DIV>
<DIV style="position:absolute;top:1025;left:81"><nobr><span class="ft4">PC 64.0  48.0  56.0 60.0 60.0  76.0 </span></nobr></DIV>
<DIV style="position:absolute;top:1042;left:81"><nobr><span class="ft4">SC  60.0  68.0  44.0 44.0 60.0  60.0 </span></nobr></DIV>
<DIV style="position:absolute;top:1060;left:80"><nobr><span class="ft35">ED 56.0  52.0  56.0 56.0 56.0  68.0 <br>CC 68.0  52.0  56.0 56.0 60.0  72.0 </span></nobr></DIV>
<DIV style="position:absolute;top:1096;left:82"><nobr><span class="ft4">IG  92.0  84.0  92.0 92.0 92.0  92.0 </span></nobr></DIV>
<DIV style="position:absolute;top:1114;left:81"><nobr><span class="ft4">MI 72.0  64.0  64.0 64.0 80.0  64.0 </span></nobr></DIV>
<DIV style="position:absolute;top:1132;left:81"><nobr><span class="ft4">SN  76.0  76.0  72.0 76.0 76.0  80.0 </span></nobr></DIV>
<DIV style="position:absolute;top:1152;left:73"><nobr><span class="ft4">Mean 69.7  63.4  62.9 63.4 69.1  73.1 </span></nobr></DIV>
<DIV style="position:absolute;top:87;left:457"><nobr><span class="ft9">Fig. 6 shows the comparison of the average performance <br>of features. Although the results are different between <br>datasets, information gain is the best, and Pearson's <br>correlation coefficient is the second. Mutual information <br>and Spearman's correlation coefficient are poor. The <br>difference of performance in datasets might be caused by <br>the characteristics of data. </span></nobr></DIV>
<DIV style="position:absolute;top:216;left:457"><nobr><span class="ft30"> </span></nobr></DIV>
<DIV style="position:absolute;top:397;left:512"><nobr><span class="ft28">0</span></nobr></DIV>
<DIV style="position:absolute;top:372;left:506"><nobr><span class="ft28">20</span></nobr></DIV>
<DIV style="position:absolute;top:349;left:506"><nobr><span class="ft28">40</span></nobr></DIV>
<DIV style="position:absolute;top:324;left:506"><nobr><span class="ft28">60</span></nobr></DIV>
<DIV style="position:absolute;top:301;left:506"><nobr><span class="ft28">80</span></nobr></DIV>
<DIV style="position:absolute;top:276;left:499"><nobr><span class="ft28">100</span></nobr></DIV>
<DIV style="position:absolute;top:414;left:545"><nobr><span class="ft28">Leukemia</span></nobr></DIV>
<DIV style="position:absolute;top:414;left:648"><nobr><span class="ft28">Colon</span></nobr></DIV>
<DIV style="position:absolute;top:414;left:725"><nobr><span class="ft28">Ly mphoma</span></nobr></DIV>
<DIV style="position:absolute;top:392;left:488"><nobr><span class="ft38">R<br>e<br>c<br>o<br>g<br>n<br>it<br>io<br>n<br> <br>ra<br>t<br>e<br> <br>[<br>%<br>]</span></nobr></DIV>
<DIV style="position:absolute;top:242;left:562"><nobr><span class="ft28">PC</span></nobr></DIV>
<DIV style="position:absolute;top:242;left:597"><nobr><span class="ft28">SC</span></nobr></DIV>
<DIV style="position:absolute;top:242;left:632"><nobr><span class="ft28">ED</span></nobr></DIV>
<DIV style="position:absolute;top:242;left:665"><nobr><span class="ft28">CC</span></nobr></DIV>
<DIV style="position:absolute;top:242;left:700"><nobr><span class="ft28">IG</span></nobr></DIV>
<DIV style="position:absolute;top:242;left:731"><nobr><span class="ft28">MI</span></nobr></DIV>
<DIV style="position:absolute;top:242;left:761"><nobr><span class="ft28">SN</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:458"><nobr><span class="ft2">Fig. 6. Average performance of feature selection methods </span></nobr></DIV>
<DIV style="position:absolute;top:473;left:457"><nobr><span class="ft30"> </span></nobr></DIV>
<DIV style="position:absolute;top:486;left:457"><nobr><span class="ft9">Recognition rates by ensemble classifiers are shown in <br>Table  . Majority voting-3 means the ensemble <br>classifier using majority voting with 3 classifiers, and <br>majority voting-all means the ensemble classifier using <br>majority voting with all 42 feature-classifier <br>combinations. Fig. 7 shows the comparison of the <br>performance of the best classifier of all possible </span></nobr></DIV>
<DIV style="position:absolute;top:598;left:782"><nobr><span class="ft5">42</span></nobr></DIV>
<DIV style="position:absolute;top:591;left:792"><nobr><span class="ft2">C</span></nobr></DIV>
<DIV style="position:absolute;top:598;left:802"><nobr><span class="ft5">3</span></nobr></DIV>
<DIV style="position:absolute;top:591;left:806"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:609;left:457"><nobr><span class="ft9">ensemble classifiers, ensemble classifier-3 and ensemble <br>classifier-all. The best result of Leukemia is obtained by <br>all classifier except SASOM. The result of the best <br>classifier is the same as that of the best ensemble <br>classifier using majority voting with 3 classifiers. In other <br>datasets, the performance of ensemble classifier surpasses <br>the best classifier. In all datasets, ensemble classifier <br>using majority voting with all classifiers are the worst. </span></nobr></DIV>
<DIV style="position:absolute;top:755;left:457"><nobr><span class="ft30"> </span></nobr></DIV>
<DIV style="position:absolute;top:769;left:482"><nobr><span class="ft2">Table . Recognition rate by ensemble classifier </span></nobr></DIV>
<DIV style="position:absolute;top:793;left:494"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:793;left:548"><nobr><span class="ft2">Majority voting-3  Majority voting-all</span></nobr></DIV>
<DIV style="position:absolute;top:814;left:462"><nobr><span class="ft2">Leukemia</span></nobr></DIV>
<DIV style="position:absolute;top:814;left:591"><nobr><span class="ft2">97.1 91.2 </span></nobr></DIV>
<DIV style="position:absolute;top:834;left:475"><nobr><span class="ft2">Colon 93.6 </span></nobr></DIV>
<DIV style="position:absolute;top:834;left:729"><nobr><span class="ft2">71.0 </span></nobr></DIV>
<DIV style="position:absolute;top:853;left:457"><nobr><span class="ft2">Lymphoma</span></nobr></DIV>
<DIV style="position:absolute;top:853;left:591"><nobr><span class="ft2">96.0 80.0 </span></nobr></DIV>
<DIV style="position:absolute;top:880;left:632"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:1075;left:505"><nobr><span class="ft28">60</span></nobr></DIV>
<DIV style="position:absolute;top:1046;left:505"><nobr><span class="ft28">70</span></nobr></DIV>
<DIV style="position:absolute;top:1018;left:505"><nobr><span class="ft28">80</span></nobr></DIV>
<DIV style="position:absolute;top:989;left:505"><nobr><span class="ft28">90</span></nobr></DIV>
<DIV style="position:absolute;top:960;left:498"><nobr><span class="ft28">100</span></nobr></DIV>
<DIV style="position:absolute;top:1092;left:546"><nobr><span class="ft28">Leukemia</span></nobr></DIV>
<DIV style="position:absolute;top:1092;left:644"><nobr><span class="ft28">Colon</span></nobr></DIV>
<DIV style="position:absolute;top:1092;left:718"><nobr><span class="ft28">Lymphoma</span></nobr></DIV>
<DIV style="position:absolute;top:1086;left:490"><nobr><span class="ft41">R<br>ecognit</span></nobr></DIV>
<DIV style="position:absolute;top:1037;left:490"><nobr><span class="ft28">ion rat</span></nobr></DIV>
<DIV style="position:absolute;top:1001;left:490"><nobr><span class="ft42">e<br> [<br>%]</span></nobr></DIV>
<DIV style="position:absolute;top:911;left:513"><nobr><span class="ft28">The best classifier</span></nobr></DIV>
<DIV style="position:absolute;top:911;left:632"><nobr><span class="ft28">Majority voting-3</span></nobr></DIV>
<DIV style="position:absolute;top:929;left:513"><nobr><span class="ft28">Majority voting-all</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:481"><nobr><span class="ft2">Fig. 7. Comparison of the performance of the best </span></nobr></DIV>
<DIV style="position:absolute;top:1142;left:468"><nobr><span class="ft2">classifier, the best ensemble classifier-3, and ensemble </span></nobr></DIV>
<DIV style="position:absolute;top:1159;left:595"><nobr><span class="ft2">classifier-all </span></nobr></DIV>
</DIV>
<!-- Page 8 -->
<a name="8"></a>
<DIV style="position:relative;width:892;height:1263;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="892" height="1263" src="133008.png" alt="background image">
<DIV style="position:absolute;top:88;left:88"><nobr><span class="ft2">Table . Classifiers of the best ensemble classifier of all </span></nobr></DIV>
<DIV style="position:absolute;top:106;left:110"><nobr><span class="ft2">possible </span></nobr></DIV>
<DIV style="position:absolute;top:113;left:163"><nobr><span class="ft5">42</span></nobr></DIV>
<DIV style="position:absolute;top:106;left:172"><nobr><span class="ft2">C</span></nobr></DIV>
<DIV style="position:absolute;top:113;left:182"><nobr><span class="ft5">3</span></nobr></DIV>
<DIV style="position:absolute;top:106;left:187"><nobr><span class="ft2"> ensemble classifiers in Colon dataset </span></nobr></DIV>
<DIV style="position:absolute;top:128;left:105"><nobr><span class="ft2">Classifier </span></nobr></DIV>
<DIV style="position:absolute;top:128;left:201"><nobr><span class="ft2">Feature selection method </span></nobr></DIV>
<DIV style="position:absolute;top:147;left:105"><nobr><span class="ft9">MLP <br>KNN</span></nobr></DIV>
<DIV style="position:absolute;top:172;left:139"><nobr><span class="ft5">cosine</span></nobr></DIV>
<DIV style="position:absolute;top:165;left:164"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:183;left:105"><nobr><span class="ft2">KNN</span></nobr></DIV>
<DIV style="position:absolute;top:190;left:139"><nobr><span class="ft5">cosine</span></nobr></DIV>
<DIV style="position:absolute;top:183;left:164"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:147;left:201"><nobr><span class="ft9">Cosine coefficient <br>Euclidean distance <br>Pearson's correlation coefficient </span></nobr></DIV>
<DIV style="position:absolute;top:203;left:105"><nobr><span class="ft9">MLP <br>KNN</span></nobr></DIV>
<DIV style="position:absolute;top:227;left:139"><nobr><span class="ft5">cosine</span></nobr></DIV>
<DIV style="position:absolute;top:221;left:164"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:239;left:105"><nobr><span class="ft2">KNN</span></nobr></DIV>
<DIV style="position:absolute;top:245;left:139"><nobr><span class="ft5">Pearson</span></nobr></DIV>
<DIV style="position:absolute;top:239;left:172"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:203;left:201"><nobr><span class="ft9">Cosine coefficient <br>Euclidean distance <br>Pearson's correlation coefficient </span></nobr></DIV>
<DIV style="position:absolute;top:258;left:105"><nobr><span class="ft9">MLP <br>KNN</span></nobr></DIV>
<DIV style="position:absolute;top:283;left:139"><nobr><span class="ft5">cosine</span></nobr></DIV>
<DIV style="position:absolute;top:276;left:164"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:294;left:105"><nobr><span class="ft2">SASOM </span></nobr></DIV>
<DIV style="position:absolute;top:258;left:201"><nobr><span class="ft9">Cosine coefficient <br>Euclidean distance <br>Pearson's correlation coefficient </span></nobr></DIV>
<DIV style="position:absolute;top:313;left:105"><nobr><span class="ft9">MLP <br>KNN</span></nobr></DIV>
<DIV style="position:absolute;top:338;left:139"><nobr><span class="ft5">cosine</span></nobr></DIV>
<DIV style="position:absolute;top:331;left:164"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:349;left:105"><nobr><span class="ft2">KNN</span></nobr></DIV>
<DIV style="position:absolute;top:356;left:139"><nobr><span class="ft5">pearson</span></nobr></DIV>
<DIV style="position:absolute;top:349;left:171"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:313;left:201"><nobr><span class="ft9">Mutual information <br>Euclidean distance <br>Pearson's correlation coefficient </span></nobr></DIV>
<DIV style="position:absolute;top:368;left:105"><nobr><span class="ft9">MLP <br>KNN</span></nobr></DIV>
<DIV style="position:absolute;top:393;left:139"><nobr><span class="ft5">cosine</span></nobr></DIV>
<DIV style="position:absolute;top:386;left:164"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:404;left:105"><nobr><span class="ft2">KNN</span></nobr></DIV>
<DIV style="position:absolute;top:411;left:139"><nobr><span class="ft5">pearson</span></nobr></DIV>
<DIV style="position:absolute;top:404;left:171"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:368;left:201"><nobr><span class="ft9">Information gain <br>Euclidean distance <br>Pearson's correlation coefficient </span></nobr></DIV>
<DIV style="position:absolute;top:423;left:105"><nobr><span class="ft9">MLP <br>MLP <br>KNN</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:139"><nobr><span class="ft5">pearson</span></nobr></DIV>
<DIV style="position:absolute;top:459;left:171"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:423;left:201"><nobr><span class="ft9">Cosine coefficient <br>Pearson's correlation coefficient <br>Euclidean distance </span></nobr></DIV>
<DIV style="position:absolute;top:478;left:105"><nobr><span class="ft2">KNN</span></nobr></DIV>
<DIV style="position:absolute;top:485;left:139"><nobr><span class="ft5">pearson</span></nobr></DIV>
<DIV style="position:absolute;top:478;left:171"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:496;left:105"><nobr><span class="ft2">KNN</span></nobr></DIV>
<DIV style="position:absolute;top:503;left:139"><nobr><span class="ft5">pearson</span></nobr></DIV>
<DIV style="position:absolute;top:496;left:171"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:514;left:105"><nobr><span class="ft2">SASOM </span></nobr></DIV>
<DIV style="position:absolute;top:478;left:201"><nobr><span class="ft9">Euclidean distance <br>Mutual information <br>Pearson's correlation coefficient </span></nobr></DIV>
<DIV style="position:absolute;top:533;left:105"><nobr><span class="ft2">KNN</span></nobr></DIV>
<DIV style="position:absolute;top:540;left:139"><nobr><span class="ft5">pearson</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:171"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:551;left:105"><nobr><span class="ft2">KNN</span></nobr></DIV>
<DIV style="position:absolute;top:558;left:139"><nobr><span class="ft5">pearson</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:171"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:569;left:105"><nobr><span class="ft2">SASOM </span></nobr></DIV>
<DIV style="position:absolute;top:533;left:201"><nobr><span class="ft9">Euclidean distance <br>Information gain <br>Pearson's correlation coefficient </span></nobr></DIV>
<DIV style="position:absolute;top:596;left:86"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:624;left:86"><nobr><span class="ft10">Table   shows the classifiers of the best ensemble <br>classifier of all possible </span></nobr></DIV>
<DIV style="position:absolute;top:649;left:255"><nobr><span class="ft5">42</span></nobr></DIV>
<DIV style="position:absolute;top:642;left:264"><nobr><span class="ft2">C</span></nobr></DIV>
<DIV style="position:absolute;top:649;left:274"><nobr><span class="ft5">3</span></nobr></DIV>
<DIV style="position:absolute;top:642;left:279"><nobr><span class="ft2"> ensemble classifiers in </span></nobr></DIV>
<DIV style="position:absolute;top:659;left:86"><nobr><span class="ft9">Colon dataset where its recognition rate is 93.6%. If we <br>observe the classifiers of the best ensemble classifier in <br>Fig. 10, we find features more important to affect the <br>result than classifiers. In other words, in ensemble <br>classifiers there must be classifiers with Euclidean <br>distance and Pearson's correlation coefficient. The other <br>classifier is the one with cosine coefficient, mutual <br>information or information gain. </span></nobr></DIV>
<DIV style="position:absolute;top:806;left:86"><nobr><span class="ft9">This fact is also prominent in Lymphoma dataset. Most of <br>the classifiers of the best ensemble classifiers are <br>classifiers with information gain, signal to noise ratio and <br>Euclidean distance, or the classifiers with information <br>gain, signal to noise ratio and Pearson's correlation <br>coefficient. </span></nobr></DIV>
<DIV style="position:absolute;top:918;left:86"><nobr><span class="ft9">As shown in Fig. 8~11, Euclidean distance, Pearson's <br>correlation coefficient and cosine coefficient are highly <br>correlated in Colon dataset. Table  shows genes ranked <br>by Euclidean distance, Pearson's correlation coefficient <br>and cosine coefficient and the value of genes by each <br>method. The bold faced figures mean the overlapped <br>genes of those features. There are some overlapped genes <br>among them as shown in Table .  This indicates <br>overlapped genes of highly correlated features can <br>discriminate classes and the other genes not overlapped <br>among combined features can supplement to search the <br>solution spaces. For example, gene 1659 and gene 550 <br>are high-ranked in both of Pearson's correlation <br>coefficient and cosine coefficient, and gene 440 is </span></nobr></DIV>
<DIV style="position:absolute;top:87;left:457"><nobr><span class="ft9">high-ranked in both of Euclidean distance and cosine <br>coefficient. This subset of two features might paly an <br>important role in classification. </span></nobr></DIV>
<DIV style="position:absolute;top:148;left:457"><nobr><span class="ft9">This paper shows that the ensemble classifier works and <br>we can improve the classification performance by <br>combining complementary common sets of classifiers <br>learned from three independent features, even when we <br>use simple combination method like majority voting. </span></nobr></DIV>
<DIV style="position:absolute;top:491;left:806"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:513;left:466"><nobr><span class="ft2">Fig. 8. Correlation of Euclidean distance and Pearson's </span></nobr></DIV>
<DIV style="position:absolute;top:531;left:515"><nobr><span class="ft2">correlation coefficient in Colon dataset</span></nobr></DIV>
<DIV style="position:absolute;top:537;left:749"><nobr><span class="ft11"> </span></nobr></DIV>
<DIV style="position:absolute;top:805;left:806"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:828;left:476"><nobr><span class="ft2">Fig. 9. Correlation of Euclidean distance and cosine </span></nobr></DIV>
<DIV style="position:absolute;top:845;left:549"><nobr><span class="ft2">coefficient in Colon dataset </span></nobr></DIV>
<DIV style="position:absolute;top:1119;left:806"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:1142;left:465"><nobr><span class="ft2">Fig. 10. Correlation of Pearson's correlation coefficient </span></nobr></DIV>
<DIV style="position:absolute;top:1159;left:515"><nobr><span class="ft2">and cosine coefficient in Colon dataset </span></nobr></DIV>
</DIV>
<!-- Page 9 -->
<a name="9"></a>
<DIV style="position:relative;width:892;height:1263;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="892" height="1263" src="133009.png" alt="background image">
<DIV style="position:absolute;top:335;left:435"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:358;left:102"><nobr><span class="ft2">Fig. 11. Correlation of Euclidean distance, Pearson's </span></nobr></DIV>
<DIV style="position:absolute;top:375;left:99"><nobr><span class="ft2">correlation coefficient and cosine coefficient in Colon </span></nobr></DIV>
<DIV style="position:absolute;top:392;left:240"><nobr><span class="ft2">dataset </span></nobr></DIV>
<DIV style="position:absolute;top:418;left:86"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:446;left:88"><nobr><span class="ft2">Table . Genes ranked by Euclidean distance, Pearson's </span></nobr></DIV>
<DIV style="position:absolute;top:464;left:127"><nobr><span class="ft2">correlation coefficient and cosine coefficient </span></nobr></DIV>
<DIV style="position:absolute;top:493;left:86"><nobr><span class="ft4">Rank   Euclidean </span></nobr></DIV>
<DIV style="position:absolute;top:493;left:245"><nobr><span class="ft4">Pearson </span></nobr></DIV>
<DIV style="position:absolute;top:493;left:352"><nobr><span class="ft4">Cosine </span></nobr></DIV>
<DIV style="position:absolute;top:518;left:93"><nobr><span class="ft4">1    619(2.262385) </span></nobr></DIV>
<DIV style="position:absolute;top:542;left:93"><nobr><span class="ft4">2    767(2.335303) </span></nobr></DIV>
<DIV style="position:absolute;top:567;left:93"><nobr><span class="ft4">3    704(2.374358) </span></nobr></DIV>
<DIV style="position:absolute;top:592;left:93"><nobr><span class="ft4">4    187(2.388404) </span></nobr></DIV>
<DIV style="position:absolute;top:616;left:93"><nobr><span class="ft4">5    207(2.410640) </span></nobr></DIV>
<DIV style="position:absolute;top:641;left:93"><nobr><span class="ft4">6    887(2.473033) </span></nobr></DIV>
<DIV style="position:absolute;top:665;left:93"><nobr><span class="ft4">7    635(2.474971) </span></nobr></DIV>
<DIV style="position:absolute;top:690;left:93"><nobr><span class="ft4">8    1915(2.498611) </span></nobr></DIV>
<DIV style="position:absolute;top:714;left:93"><nobr><span class="ft4">9    1046(2.506833) </span></nobr></DIV>
<DIV style="position:absolute;top:739;left:93"><nobr><span class="ft4">10   1208(2.512257) </span></nobr></DIV>
<DIV style="position:absolute;top:763;left:93"><nobr><span class="ft4">11   482(2.520699) </span></nobr></DIV>
<DIV style="position:absolute;top:788;left:93"><nobr><span class="ft4">12   1771(2.525080) </span></nobr></DIV>
<DIV style="position:absolute;top:812;left:93"><nobr><span class="ft4">13   1993(2.529032) </span></nobr></DIV>
<DIV style="position:absolute;top:837;left:93"><nobr><span class="ft4">14   62(2.546894) </span></nobr></DIV>
<DIV style="position:absolute;top:861;left:93"><nobr><span class="ft4">15   1772(2.547455) </span></nobr></DIV>
<DIV style="position:absolute;top:886;left:93"><nobr><span class="ft4">16   1194(2.549244) </span></nobr></DIV>
<DIV style="position:absolute;top:910;left:93"><nobr><span class="ft4">17   1594(2.551892) </span></nobr></DIV>
<DIV style="position:absolute;top:935;left:93"><nobr><span class="ft4">18   199(2.557360) </span></nobr></DIV>
<DIV style="position:absolute;top:959;left:93"><nobr><span class="ft4">19   1867(2.587469) </span></nobr></DIV>
<DIV style="position:absolute;top:984;left:93"><nobr><span class="ft4">20   959(2.589989) </span></nobr></DIV>
<DIV style="position:absolute;top:1008;left:93"><nobr><span class="ft4">21   440(2.593881) </span></nobr></DIV>
<DIV style="position:absolute;top:1033;left:93"><nobr><span class="ft4">22   480(2.594514) </span></nobr></DIV>
<DIV style="position:absolute;top:1057;left:93"><nobr><span class="ft4">23   1546(2.604907) </span></nobr></DIV>
<DIV style="position:absolute;top:1082;left:93"><nobr><span class="ft4">24   399(2.613609) </span></nobr></DIV>
<DIV style="position:absolute;top:1106;left:93"><nobr><span class="ft4">25   1060(2.614100) </span></nobr></DIV>
<DIV style="position:absolute;top:518;left:232"><nobr><span class="ft4">619(0.681038) </span></nobr></DIV>
<DIV style="position:absolute;top:542;left:232"><nobr><span class="ft4">1771(0.664378) </span></nobr></DIV>
<DIV style="position:absolute;top:567;left:232"><nobr><span class="ft4">1659(0.634084) </span></nobr></DIV>
<DIV style="position:absolute;top:592;left:232"><nobr><span class="ft4">550(0.631655) </span></nobr></DIV>
<DIV style="position:absolute;top:616;left:232"><nobr><span class="ft4">187(0.626262) </span></nobr></DIV>
<DIV style="position:absolute;top:641;left:232"><nobr><span class="ft4">1772(0.621581) </span></nobr></DIV>
<DIV style="position:absolute;top:665;left:232"><nobr><span class="ft4">1730( 0.615566) </span></nobr></DIV>
<DIV style="position:absolute;top:690;left:232"><nobr><span class="ft4">1648(0.614949) </span></nobr></DIV>
<DIV style="position:absolute;top:714;left:232"><nobr><span class="ft4">365(0.614591) </span></nobr></DIV>
<DIV style="position:absolute;top:739;left:232"><nobr><span class="ft4">1208(0.603313) </span></nobr></DIV>
<DIV style="position:absolute;top:763;left:232"><nobr><span class="ft4">1042(0.602160) </span></nobr></DIV>
<DIV style="position:absolute;top:788;left:232"><nobr><span class="ft4">1060(0.601712) </span></nobr></DIV>
<DIV style="position:absolute;top:812;left:232"><nobr><span class="ft4">513(0.596444) </span></nobr></DIV>
<DIV style="position:absolute;top:837;left:232"><nobr><span class="ft4">767(0.594119) </span></nobr></DIV>
<DIV style="position:absolute;top:861;left:232"><nobr><span class="ft4">1263(0.591725) </span></nobr></DIV>
<DIV style="position:absolute;top:886;left:232"><nobr><span class="ft4">138(0.587851) </span></nobr></DIV>
<DIV style="position:absolute;top:910;left:232"><nobr><span class="ft4">1826(0.584774) </span></nobr></DIV>
<DIV style="position:absolute;top:935;left:232"><nobr><span class="ft4">1546(0.582293) </span></nobr></DIV>
<DIV style="position:absolute;top:959;left:232"><nobr><span class="ft4">141(0.579073) </span></nobr></DIV>
<DIV style="position:absolute;top:984;left:232"><nobr><span class="ft4">1227(0.574537) </span></nobr></DIV>
<DIV style="position:absolute;top:1008;left:232"><nobr><span class="ft4">704(0.569022) </span></nobr></DIV>
<DIV style="position:absolute;top:1033;left:232"><nobr><span class="ft4">1549(0.562828) </span></nobr></DIV>
<DIV style="position:absolute;top:1057;left:232"><nobr><span class="ft4">1489(0.561003) </span></nobr></DIV>
<DIV style="position:absolute;top:1082;left:232"><nobr><span class="ft4">1724(0.559919) </span></nobr></DIV>
<DIV style="position:absolute;top:1106;left:232"><nobr><span class="ft4">1209(0.559778) </span></nobr></DIV>
<DIV style="position:absolute;top:518;left:338"><nobr><span class="ft4">619(0.895971) </span></nobr></DIV>
<DIV style="position:absolute;top:542;left:338"><nobr><span class="ft4">1772(0.875472) </span></nobr></DIV>
<DIV style="position:absolute;top:567;left:338"><nobr><span class="ft4">767(0.874914) </span></nobr></DIV>
<DIV style="position:absolute;top:591;left:338"><nobr><span class="ft4">1771(0.873892) </span></nobr></DIV>
<DIV style="position:absolute;top:616;left:338"><nobr><span class="ft4">1659(0.870115) </span></nobr></DIV>
<DIV style="position:absolute;top:641;left:338"><nobr><span class="ft4">187(0.867285) </span></nobr></DIV>
<DIV style="position:absolute;top:665;left:338"><nobr><span class="ft4">704(0.866679) </span></nobr></DIV>
<DIV style="position:absolute;top:690;left:338"><nobr><span class="ft4">1208(0.866029) </span></nobr></DIV>
<DIV style="position:absolute;top:714;left:338"><nobr><span class="ft4">550(0.864547) </span></nobr></DIV>
<DIV style="position:absolute;top:739;left:338"><nobr><span class="ft4">1546(0.856904) </span></nobr></DIV>
<DIV style="position:absolute;top:763;left:338"><nobr><span class="ft4">251(0.855841) </span></nobr></DIV>
<DIV style="position:absolute;top:788;left:338"><nobr><span class="ft4">1915(0.855784) </span></nobr></DIV>
<DIV style="position:absolute;top:812;left:338"><nobr><span class="ft4">440(0.855453) </span></nobr></DIV>
<DIV style="position:absolute;top:837;left:338"><nobr><span class="ft4">1263(0.854854) </span></nobr></DIV>
<DIV style="position:absolute;top:861;left:338"><nobr><span class="ft4">1060(0.854829) </span></nobr></DIV>
<DIV style="position:absolute;top:886;left:338"><nobr><span class="ft4">965(0.854137) </span></nobr></DIV>
<DIV style="position:absolute;top:910;left:338"><nobr><span class="ft4">1648(0.854119) </span></nobr></DIV>
<DIV style="position:absolute;top:935;left:338"><nobr><span class="ft4">1942(0.853586) </span></nobr></DIV>
<DIV style="position:absolute;top:959;left:338"><nobr><span class="ft4">513(0.852270) </span></nobr></DIV>
<DIV style="position:absolute;top:984;left:338"><nobr><span class="ft4">1042(0.851993) </span></nobr></DIV>
<DIV style="position:absolute;top:1008;left:338"><nobr><span class="ft4">1993(0.851753) </span></nobr></DIV>
<DIV style="position:absolute;top:1033;left:338"><nobr><span class="ft4">365(0.851205) </span></nobr></DIV>
<DIV style="position:absolute;top:1057;left:338"><nobr><span class="ft4">1400(0.849531) </span></nobr></DIV>
<DIV style="position:absolute;top:1082;left:338"><nobr><span class="ft4">207(0.849084) </span></nobr></DIV>
<DIV style="position:absolute;top:1106;left:338"><nobr><span class="ft4">271(0.848481) </span></nobr></DIV>
<DIV style="position:absolute;top:87;left:457"><nobr><span class="ft6"><b>5 </b></span></nobr></DIV>
<DIV style="position:absolute;top:87;left:490"><nobr><span class="ft6"><b>Concluding Remarks </b></span></nobr></DIV>
<DIV style="position:absolute;top:115;left:457"><nobr><span class="ft9">We have conducted a thorough quantitative comparison <br>among the 42 combinations of features and classifiers for <br>three benchmark dataset. Information gain and Pearson's <br>correlation coefficient are the top feature selection <br>methods, and MLP and KNN are the best classifiers. The <br>experimental results also imply some correlations <br>between features and classifiers, which might guide the <br>researchers to choose or devise the best classification <br>method for their problems in bioinformatics. Based on the <br>results, we have developed the optimal feature-classifier <br>combination to produce the best performance on the <br>classification. </span></nobr></DIV>
<DIV style="position:absolute;top:331;left:457"><nobr><span class="ft9">We have combined 3 classifiers among 42 classifiers <br>using majority voting. We could confirm that ensemble <br>classifier of highly correlated features works better than <br>ensemble of uncorrelated features. In particular, we <br>analyzed the improvement of the classification <br>performance for Colon dataset. </span></nobr></DIV>
<DIV style="position:absolute;top:443;left:457"><nobr><span class="ft9">Moreover, our method of combining classifiers is very <br>simple, and there are many methods of combining <br>classifiers in machine learning and data mining fields. We <br>will have to apply more sophisticated methods of <br>combining classifiers to the same dataset to confirm the <br>results obtained and get better results. </span></nobr></DIV>
<DIV style="position:absolute;top:556;left:457"><nobr><span class="ft2">Acknowledgements </span></nobr></DIV>
<DIV style="position:absolute;top:582;left:457"><nobr><span class="ft9">This paper was supported by Brain Science and <br>Engineering Research Program sponsored by Korean <br>Ministry of Science and Technology. </span></nobr></DIV>
<DIV style="position:absolute;top:652;left:457"><nobr><span class="ft6"><b>6 </b></span></nobr></DIV>
<DIV style="position:absolute;top:652;left:490"><nobr><span class="ft6"><b>References </b></span></nobr></DIV>
<DIV style="position:absolute;top:679;left:457"><nobr><span class="ft2">Alon, U., Barkai, N., et al. (1999): Broad patterns of gene </span></nobr></DIV>
<DIV style="position:absolute;top:697;left:471"><nobr><span class="ft9">expression revealed by clustering analysis of tumor and <br>normal colon tissues probed by oligonucleotide arrays. <br>Proc. of the Natl. Acad. of Sci. USA, 96:6745-6750. </span></nobr></DIV>
<DIV style="position:absolute;top:757;left:457"><nobr><span class="ft2">Arkin, A., Shen, P. and Ross, J. (1997): A test case of </span></nobr></DIV>
<DIV style="position:absolute;top:774;left:471"><nobr><span class="ft9">correlation metric construction of a reaction pathway <br>from measurements. Science, 277:1275-1279. </span></nobr></DIV>
<DIV style="position:absolute;top:818;left:457"><nobr><span class="ft2">Beale, H. D. (1996): Neural Network Design. 1-47, PWS </span></nobr></DIV>
<DIV style="position:absolute;top:835;left:471"><nobr><span class="ft2">Publish Company. </span></nobr></DIV>
<DIV style="position:absolute;top:861;left:457"><nobr><span class="ft2">Ben-Dor, A., Shamir, R. and Yakhini, Z. (1999): </span></nobr></DIV>
<DIV style="position:absolute;top:879;left:471"><nobr><span class="ft9">Clustering gene expression patterns. Journal of <br>Computational Biology, 6:281-297. </span></nobr></DIV>
<DIV style="position:absolute;top:922;left:457"><nobr><span class="ft2">Ben-Dor, A., Bruhn, L., Friedman, N., Nachman, I., </span></nobr></DIV>
<DIV style="position:absolute;top:939;left:471"><nobr><span class="ft9">Schummer, M. and Yakhini, N. (2000): Tissue <br>classification with gene expression profiles. Journal of <br>Computational Biology, 7:559-584. </span></nobr></DIV>
<DIV style="position:absolute;top:1000;left:457"><nobr><span class="ft2">Brown, M. P. S., Grundy, W. N., Lin, D., Cristianini, N., </span></nobr></DIV>
<DIV style="position:absolute;top:1017;left:471"><nobr><span class="ft9">Sugnet, C. W., Furey, T. S., Ares, M. Jr. and Haussler, <br>D. (2000): Knowledge-based analysis of microarray <br>gene expression data by using support vector machines. <br>Proc. of the Natl. Acad. of Sci. USA, 97:262-267, 2000. </span></nobr></DIV>
<DIV style="position:absolute;top:1095;left:457"><nobr><span class="ft2">Derisi, J., Iyer, V. and Brosn, P. (1997): Exploring the </span></nobr></DIV>
<DIV style="position:absolute;top:1112;left:471"><nobr><span class="ft9">metabolic and genetic control of gene expression on a <br>genomic scale. Science, 278:680-686. </span></nobr></DIV>
</DIV>
<!-- Page 10 -->
<a name="10"></a>
<DIV style="position:relative;width:892;height:1263;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="892" height="1263" src="133010.png" alt="background image">
<DIV style="position:absolute;top:87;left:86"><nobr><span class="ft2">Dudoit, S., Fridlyand, J. and Speed, T. P. (2000): </span></nobr></DIV>
<DIV style="position:absolute;top:104;left:100"><nobr><span class="ft9">Comparison of discrimination methods for the <br>classification of tumors using gene expression data. <br>Technical Report 576, Department of Statistics, <br>University of California, Berkeley. </span></nobr></DIV>
<DIV style="position:absolute;top:182;left:86"><nobr><span class="ft2">Eisen, M. B., Spellman, P. T., Brown, P. O. and Bostein, </span></nobr></DIV>
<DIV style="position:absolute;top:199;left:100"><nobr><span class="ft9">D. (1998): Cluster analysis and display of <br>genome-wide expression patterns. Proc. of the Natl. <br>Acad. of Sci. USA, 95:14863-14868. </span></nobr></DIV>
<DIV style="position:absolute;top:260;left:86"><nobr><span class="ft2">Eisen, M. B. and Brown, P. O. (1999): DNA arrays for </span></nobr></DIV>
<DIV style="position:absolute;top:277;left:100"><nobr><span class="ft9">analysis of gene expression. Methods Enzymbol,  303: <br>179-205. </span></nobr></DIV>
<DIV style="position:absolute;top:321;left:86"><nobr><span class="ft2">Friedman, N., Linial, M., Nachman, I. and Pe'er, D. </span></nobr></DIV>
<DIV style="position:absolute;top:338;left:100"><nobr><span class="ft9">(2000): Using Bayesian networks to analyze expression <br>data. Journal of Computational Biology, 7:601-620. </span></nobr></DIV>
<DIV style="position:absolute;top:381;left:86"><nobr><span class="ft2">Fuhrman, S., Cunningham, M. J., Wen, X., Zweiger, G., </span></nobr></DIV>
<DIV style="position:absolute;top:399;left:100"><nobr><span class="ft9">Seilhamer, J. and Somogyi, R. (2000): The application <br>of Shannon entropy in the identification of putative <br>drug targets. Biosystems, 55:5-14. </span></nobr></DIV>
<DIV style="position:absolute;top:459;left:86"><nobr><span class="ft2">Furey, T. S., Cristianini, N., Duffy, N., Bednarski, D. W., </span></nobr></DIV>
<DIV style="position:absolute;top:476;left:100"><nobr><span class="ft9">Schummer, M. and Haussler, D. (2000): Support vector <br>machine classification and validation of cancer tissue <br>samples using microarray expression data. <br>Bioinformatics, 16(10):906-914. </span></nobr></DIV>
<DIV style="position:absolute;top:554;left:86"><nobr><span class="ft2">Golub, T. R., Slonim, D. K., Tamayo, P., Huard, C., </span></nobr></DIV>
<DIV style="position:absolute;top:572;left:100"><nobr><span class="ft9">GaasenBeek, M., Mesirov, J. P., Coller, H., Loh, M. L., <br>Downing, J. R., Caligiuri, M. A., Blomfield, C. D., and <br>Lander, E. S. (1999): Molecular classification of <br>cancer:  Class discovery and class prediction by <br>gene-expression monitoring. Science, 286:531-537. </span></nobr></DIV>
<DIV style="position:absolute;top:667;left:86"><nobr><span class="ft2">Harrington, C. A., Rosenow, C., and Retief, J. (2000): </span></nobr></DIV>
<DIV style="position:absolute;top:684;left:100"><nobr><span class="ft9">Monitoring gene expression using DNA microarrays. <br>Curr. Opin. Microbiol., 3:285-291. </span></nobr></DIV>
<DIV style="position:absolute;top:727;left:86"><nobr><span class="ft2">Hartuv, E., Schmitt, A., Lange, J., Meier-Ewert, S., </span></nobr></DIV>
<DIV style="position:absolute;top:745;left:100"><nobr><span class="ft9">Lehrach, H. and Shamir, R. (2000): An algorithm for <br>clustering cDNA fingerprints. Genomics, <br>66(3):249-256. </span></nobr></DIV>
<DIV style="position:absolute;top:805;left:86"><nobr><span class="ft2">Khan, J., Wei, J. S., Ringner, M., Saal, L. H., Ladanyi, M., </span></nobr></DIV>
<DIV style="position:absolute;top:823;left:100"><nobr><span class="ft9">Westermann, F., Berthold, F., Schwab, M., Antonescu, <br>C. R., Peterson, C. And Meltzer, P. S. (2001): <br>Classification and diagnostic prediction of cancers <br>using gene expression profiling and artificial neural <br>networks. Nature Medicine, 7(6):673-679. </span></nobr></DIV>
<DIV style="position:absolute;top:918;left:86"><nobr><span class="ft2">Kim, H. D. and Cho, S.-B. (2000): Genetic optimization </span></nobr></DIV>
<DIV style="position:absolute;top:935;left:100"><nobr><span class="ft9">of structure-adaptive self-organizing map for efficient <br>classification.  Proc. of International Conference on <br>Soft Computing, 34-39, World-Scientific Publishing. </span></nobr></DIV>
<DIV style="position:absolute;top:996;left:86"><nobr><span class="ft2">Lashkari, D., Derisi, J., McCusker, J., Namath, A., </span></nobr></DIV>
<DIV style="position:absolute;top:1013;left:100"><nobr><span class="ft9">Gentile, C., Hwang, S., Brown, P., and Davis, R. <br>(1997): Yeast microarrays for genome wide parallel <br>genetic and gene expression analysis. Proc. of the Natl. <br>Acad. of Sci. USA, 94:13057-13062. </span></nobr></DIV>
<DIV style="position:absolute;top:1091;left:86"><nobr><span class="ft2">Lippman, R. P. (1987): An introduction to computing </span></nobr></DIV>
<DIV style="position:absolute;top:1108;left:100"><nobr><span class="ft2">with neural nets. IEEE ASSP Magazine, 4-22. </span></nobr></DIV>
<DIV style="position:absolute;top:1134;left:86"><nobr><span class="ft2">Li, L., Weinberg, C. R., Darden, T. A. and Pedersen, L. G. </span></nobr></DIV>
<DIV style="position:absolute;top:1152;left:100"><nobr><span class="ft2">(2001): Gene selection for sample classification based </span></nobr></DIV>
<DIV style="position:absolute;top:87;left:471"><nobr><span class="ft9">on gene expression data: study of sensitivity to choice <br>of parameters of the GA/KNN method. Bioinformatics, <br>17(12):1131-1142. </span></nobr></DIV>
<DIV style="position:absolute;top:148;left:457"><nobr><span class="ft2">Li, W. and Yang, Y. (2000): How many genes are needed </span></nobr></DIV>
<DIV style="position:absolute;top:165;left:471"><nobr><span class="ft9">for a discriminant microarray data analysis. Critical <br>Assessment of Techniques for Microarray Data Mining <br>Workshop. </span></nobr></DIV>
<DIV style="position:absolute;top:225;left:457"><nobr><span class="ft2">Lossos, I. S., Alizadeh, A. A., Eisen, M. B., Chan, W. C., </span></nobr></DIV>
<DIV style="position:absolute;top:243;left:471"><nobr><span class="ft9">Brown, P. O., Bostein, D., Staudt, L. M., and Levy, R. <br>(2000): Ongoing immunoglobulin somatic mutation in <br>germinal center B cell-like but not in activated B <br>cell-like diffuse large cell lymphomas. Proc. of the Natl. <br>Acad. of Sci. USA, 97(18):10209-10213. </span></nobr></DIV>
<DIV style="position:absolute;top:338;left:457"><nobr><span class="ft2">Moghaddam, B. and Yang, M.-H. (2000): Gender </span></nobr></DIV>
<DIV style="position:absolute;top:355;left:471"><nobr><span class="ft9">classification with support vector machines. Proc. of <br>4th IEEE Intl. Conf. on Automatic Face and Gesture <br>Recognition, 306-311. </span></nobr></DIV>
<DIV style="position:absolute;top:416;left:457"><nobr><span class="ft2">Nguyen, D. V. and Rocke, D. M. (2002): Tumor </span></nobr></DIV>
<DIV style="position:absolute;top:433;left:471"><nobr><span class="ft9">classification by partial least squares using microarray <br>gene expression data. Bioinformatics, 18(1):39-50. </span></nobr></DIV>
<DIV style="position:absolute;top:476;left:457"><nobr><span class="ft2">Quinlan, J. R. (1986): The effect of noise on concept </span></nobr></DIV>
<DIV style="position:absolute;top:494;left:471"><nobr><span class="ft9">learning.  Machine Learning: An Artificial Intelligence <br>Approach, Michalski, R. S., Carbonell, J. G. and <br>Mitchell, T. M. (eds). San Mateo, CA: Morgan <br>Kauffmann, 2:149-166. </span></nobr></DIV>
<DIV style="position:absolute;top:572;left:457"><nobr><span class="ft2">Ryu, J. and Cho, S. B. (2002): Towards optimal feature </span></nobr></DIV>
<DIV style="position:absolute;top:589;left:471"><nobr><span class="ft9">and classifier for gene expression classification of <br>cancer.  Lecture Note in Artificial Intelligence, <br>2275:310-317. </span></nobr></DIV>
<DIV style="position:absolute;top:650;left:457"><nobr><span class="ft2">Shamir, R. and Sharan, R. (2001): Algorithmic </span></nobr></DIV>
<DIV style="position:absolute;top:667;left:471"><nobr><span class="ft9">approaches to clustering gene expression data. Current <br>Topics in Computational Biology. In Jiang, T., Smith, <br>T., Xu, Y. and Zhang, M. Q. (eds), MIT press. </span></nobr></DIV>
<DIV style="position:absolute;top:727;left:457"><nobr><span class="ft2">Sharan, R. and Shamir, R. (2000): CLICK: A clustering </span></nobr></DIV>
<DIV style="position:absolute;top:745;left:471"><nobr><span class="ft9">with applications to gene expression analysis. Proc. Of <br>the Eighth International Conference in Computational <br>Molecular Biology (ISBM), 307-316. </span></nobr></DIV>
<DIV style="position:absolute;top:805;left:457"><nobr><span class="ft2">Tamayo, P. (1999): Interpreting patterns of gene </span></nobr></DIV>
<DIV style="position:absolute;top:823;left:471"><nobr><span class="ft9">expression with self-organizing map: Methods and <br>application to hematopoietic differentiation. Proc. of <br>the National Academy of Sciences of the United States <br>of America, 96: 2907-2912. </span></nobr></DIV>
<DIV style="position:absolute;top:901;left:457"><nobr><span class="ft2">Thieffry, D. and Thomas, R. (1998): Qualitative analysis </span></nobr></DIV>
<DIV style="position:absolute;top:918;left:471"><nobr><span class="ft9">of gene networks. Pacific Symposium on Biocomputing, <br>3:66-76. </span></nobr></DIV>
<DIV style="position:absolute;top:961;left:457"><nobr><span class="ft2">Vapnik, V. N. (1995): The Nature of Statistical Learning </span></nobr></DIV>
<DIV style="position:absolute;top:979;left:471"><nobr><span class="ft2">Theory, New York: Springer. </span></nobr></DIV>
<DIV style="position:absolute;top:1005;left:457"><nobr><span class="ft2">Xu, Y., Selaru, M., Yin, J., Zou, T. T., Shustova, V., Mori, </span></nobr></DIV>
<DIV style="position:absolute;top:1022;left:471"><nobr><span class="ft9">Y., Sato, F., Liu, T. C., Olaru, A., Wang, S., Kimos, M. <br>C., Perry, K., Desai, K., Greenwood, B. D., Krasna, M. <br>J., Shibata, D., Abraham, J. M. and Meltzer, S. J. <br>(2002): Artificial neural networks and gene filtering <br>distinguish between global gene expression profiles of <br>Barrett's esophagus and esophageal cancer. Cancer <br>Research, 62:3493-3497. </span></nobr></DIV>
<DIV style="position:absolute;top:1152;left:457"><nobr><span class="ft2"> </span></nobr></DIV>
</DIV>
</BODY>
</HTML>
