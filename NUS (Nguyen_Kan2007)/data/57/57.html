<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
<HEAD>
<TITLE>Contour-based Partial Object Recognition Using Symmetry in Image Databases</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<META name="generator" content="pdftohtml 0.35beta">
<META name="author" content="June-Suh Cho, Joonsoo Choi">
<META name="date" content="2005-05-27T11:45:01+00:00">
</HEAD>
<BODY bgcolor="#A0A0A0" vlink="blue" link="blue">
<!-- Page 1 -->
<a name="1"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft0{font-size:22px;font-family:Helvetica;color:#000000;}
	.ft1{font-size:14px;font-family:Helvetica;color:#000000;}
	.ft2{font-size:11px;font-family:Helvetica;color:#000000;}
	.ft3{font-size:14px;font-family:Times;color:#000000;}
	.ft4{font-size:10px;font-family:Times;color:#000000;}
	.ft5{font-size:14px;font-family:Helvetica;color:#000000;}
	.ft6{font-size:10px;font-family:Times;color:#000000;}
	.ft7{font-size:7px;font-family:Times;color:#000000;}
	.ft8{font-size:9px;font-family:Times;color:#000000;}
	.ft9{font-size:9px;font-family:Times;color:#000000;}
	.ft10{font-size:13px;font-family:Helvetica;color:#000000;}
	.ft11{font-size:10px;line-height:14px;font-family:Times;color:#000000;}
	.ft12{font-size:10px;line-height:19px;font-family:Times;color:#000000;}
	.ft13{font-size:9px;line-height:12px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="57001.png" alt="background image">
<DIV style="position:absolute;top:106;left:99"><nobr><span class="ft0"><b>Contour-based Partial Object Recognition using Symmetry in </b></span></nobr></DIV>
<DIV style="position:absolute;top:135;left:357"><nobr><span class="ft0"><b>Image Databases </b></span></nobr></DIV>
<DIV style="position:absolute;top:169;left:224"><nobr><span class="ft1">June-Suh Cho </span></nobr></DIV>
<DIV style="position:absolute;top:188;left:220"><nobr><span class="ft2">Department of MIS </span></nobr></DIV>
<DIV style="position:absolute;top:203;left:167"><nobr><span class="ft2">Hankuk University of Foreign Studies </span></nobr></DIV>
<DIV style="position:absolute;top:219;left:236"><nobr><span class="ft2">Seoul, Korea. </span></nobr></DIV>
<DIV style="position:absolute;top:235;left:220"><nobr><span class="ft2">Tel:822-2173-3015 </span></nobr></DIV>
<DIV style="position:absolute;top:250;left:214"><nobr><span class="ft1">jscho@hufs.ac.kr</span></nobr></DIV>
<DIV style="position:absolute;top:169;left:591"><nobr><span class="ft1">Joonsoo Choi</span></nobr></DIV>
<DIV style="position:absolute;top:172;left:690"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:188;left:542"><nobr><span class="ft2">Department of Computer Science </span></nobr></DIV>
<DIV style="position:absolute;top:203;left:584"><nobr><span class="ft2">Kookmin University </span></nobr></DIV>
<DIV style="position:absolute;top:219;left:600"><nobr><span class="ft2">Seoul, Korea. </span></nobr></DIV>
<DIV style="position:absolute;top:235;left:588"><nobr><span class="ft2">Tel:822-910-4798 </span></nobr></DIV>
<DIV style="position:absolute;top:250;left:562"><nobr><span class="ft1">jschoi@kookmin.ac.kr </span></nobr></DIV>
<DIV style="position:absolute;top:269;left:640"><nobr><span class="ft1"> </span></nobr></DIV>
<DIV style="position:absolute;top:288;left:458"><nobr><span class="ft1"> </span></nobr></DIV>
<DIV style="position:absolute;top:312;left:94"><nobr><span class="ft3"><b>ABSTRACT </b></span></nobr></DIV>
<DIV style="position:absolute;top:336;left:94"><nobr><span class="ft12">This paper discusses the problem of partial object recognition in <br>image databases. We propose the method to reconstruct and estimate <br>partially occluded shapes and regions of objects in images from <br>overlapping and cutting.  We present the robust method for <br>recognizing partially occluded objects based on symmetry properties, <br>which is based on the contours of objects. Our method provides <br>simple techniques to reconstruct occluded regions via a region copy <br>using the symmetry axis within an object.  Based on the estimated <br>parameters for partially occluded objects, we perform object <br>recognition on the classification tree. Since our method relies on <br>reconstruction of the object based on the symmetry rather than <br>statistical estimates, it has proven to be remarkably robust in <br>recognizing partially occluded objects in the presence of scale <br>changes, rotation, and viewpoint changes. <br> </span></nobr></DIV>
<DIV style="position:absolute;top:564;left:94"><nobr><span class="ft3"><b>Keywords </b></span></nobr></DIV>
<DIV style="position:absolute;top:589;left:94"><nobr><span class="ft12">Object, Image, Contour, Recognition, Symmetry <br> </span></nobr></DIV>
<DIV style="position:absolute;top:632;left:94"><nobr><span class="ft3"><b>1.</b></span></nobr></DIV>
<DIV style="position:absolute;top:632;left:106"><nobr><span class="ft5"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:632;left:116"><nobr><span class="ft3"><b>INTRODUCTION </b></span></nobr></DIV>
<DIV style="position:absolute;top:651;left:94"><nobr><span class="ft11">Most existing methods for object recognition are based on full objects. <br>However, many images in electronic catalogs contain multiple objects <br>with occluded shapes and regions. Due to the occlusion of objects, <br>image retrieval can provide incomplete, uncertain, and inaccurate <br>results. To resolve this problem, we propose new method to <br>reconstruct objects using symmetry properties since most objects in a <br>given image database are represented by symmetrical figures. <br>Even though there have been several efforts in object recognition with <br>occlusion, currents methods have been highly sensitive to object pose, <br>rotation, scaling, and visible portion of occluded objects [12] [9] [17] <br>[3] [15]. In addition, many appearance-based and model-based object <br>recognition methods assumed that they have known occluded regions <br>of objects or images through extensive training processes with <br>statistical approach. However, our approach is not limited to <br>recognizing occluded objects by pose and scale changes, and does not </span></nobr></DIV>
<DIV style="position:absolute;top:311;left:475"><nobr><span class="ft12">need extensive training processes. <br>Unlike existing methods, our method finds shapes and regions to <br>reconstruct occluded shapes and regions <i>within objects</i>. Our approach <br>can handle object rotation and scaling for dealing with occlusion, and <br>does not require extensive training processes. The main advantage of <br>our approach is that it becomes simple to reconstruct objects from <br>occlusions. We present the robust method, which is based on the <br>contours of objects, for recognizing partially occluded objects based <br>on symmetry properties. The contour-based approach finds a <br>symmetry axis using the maximum diameter from the occluded object.  <br>In experiments, we demonstrate how our method reconstruct and <br>recognize occluded shapes and regions using symmetry. Experiments <br>use rotated and scaled objects for dealing with occlusion. We also <br>evaluate the recognition rate of the reconstructed objects using <br>symmetry and the visible portion of the occluded objects for <br>recognition. <br>The rest of this paper is organized as follows. In Section 2, we briefly <br>review work related to this study. In Section 3, we describe a method <br>to recognize partial objects from given classes. In Section 4, we <br>describe experimental results for partial object recognition. Finally, <br>we summarize this paper in Section 5. <br> </span></nobr></DIV>
<DIV style="position:absolute;top:660;left:475"><nobr><span class="ft3"><b>2.</b></span></nobr></DIV>
<DIV style="position:absolute;top:660;left:487"><nobr><span class="ft5"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:660;left:497"><nobr><span class="ft3"><b>RELATED WORK </b></span></nobr></DIV>
<DIV style="position:absolute;top:679;left:475"><nobr><span class="ft11">There have been several research efforts in object recognition for <br>dealing with occlusion. Krumm [13] proposed a new algorithm for <br>detecting objects in images which uses models based on training <br>images of the object, with each model representing one pose. <br>Williams [23] proposed a method for the reconstruction of solid-<br>shape from image contour using the Huffman labeling scheme. For <br>object recognition, Chang and Krumm [3] used the color <br>cooccurrence histogram based on pairs of pixels. Schiele et al. [20] <br>proposed a method to perform partial object recognition using <br>statistical methods, which are based on multidimensional receptive <br>field histograms. In addition, Rajpal et al. [17] introduced a method <br>for partial object recognition using neural network based indexing.  <br>In appearance-based object recognition, Edwards and Murase [6] <br>addressed the occlusion problem inherent in appearance-based <br>methods using a mask to block out part of the basic eigenimages and <br>the input image. Leonardis and Bischof [14] handled occlusion, <br>scaling, and translation by randomly selecting image points from the <br>scene and their corresponding points in the basis eigenvectors. Rao <br>[18] applied the adaptive learning of eigenspace basis vectors in <br>appearance-based methods. Ohba and Ikeuchi [16] were able to <br>handle translation and occlusion of an object using eigenwindows. </span></nobr></DIV>
<DIV style="position:absolute;top:889;left:103"><nobr><span class="ft7"> </span></nobr></DIV>
<DIV style="position:absolute;top:908;left:103"><nobr><span class="ft13">Permission to make digital or hard copies of all or part of this work for <br>personal or classroom use is granted without fee provided that copies are <br>not made or distributed for profit or commercial advantage and that copies <br>bear this notice and the full citation on the first page. To copy otherwise, <br>or republish, to post on servers or to redistribute to lists, requires prior <br>specific permission and/or a fee. <br><i>SAC'05</i>, March 13-17, 2005, Santa Fe, New Mexico, USA. <br>Copyright 2005 ACM 1-58113-964-0/05/0003...$5.00. </span></nobr></DIV>
<DIV style="position:absolute;top:1012;left:103"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:1095;left:442"><nobr><span class="ft10">1190</span></nobr></DIV>
<DIV style="position:absolute;top:79;left:562"><nobr><span class="ft2">2005 ACM Symposium on Applied Computing</span></nobr></DIV>
</DIV>
<!-- Page 2 -->
<a name="2"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft14{font-size:10px;font-family:Times;color:#000000;}
	.ft15{font-size:10px;font-family:Helvetica;color:#000000;}
	.ft16{font-size:10px;font-family:Times;color:#000000;}
	.ft17{font-size:10px;line-height:14px;font-family:Times;color:#000000;}
	.ft18{font-size:10px;line-height:19px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="57002.png" alt="background image">
<DIV style="position:absolute;top:87;left:94"><nobr><span class="ft12">Current methods for dealing with occlusion have been based on <br>template matching, statistical approaches using localized invariants, <br>and recognition of occluded regions based on local features. In <br>addition, there are many efforts in ellipse construction and detection <br>[7][9][22]. In this paper, we propose unique methodologies in object <br>recognition for dealing with occlusion based on symmetry properties <br>through the ellipse reconstruction. <br>Even though there have been several efforts in object recognition with <br>occlusion, current methods have been highly sensitive to object pose <br>and scaling. In addition, many appearance-based and model-based <br>object recognition methods assumed that they have known occluded <br>regions of objects or images through extensive training processes. <br>However, our method is not limited to recognizing occluded objects <br>by pose and scale changes, and do not require extensive training <br>processes. <br> </span></nobr></DIV>
<DIV style="position:absolute;top:338;left:94"><nobr><span class="ft3"><b>3.</b></span></nobr></DIV>
<DIV style="position:absolute;top:338;left:106"><nobr><span class="ft5"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:338;left:116"><nobr><span class="ft3"><b>THE PROPOSED METHOD </b></span></nobr></DIV>
<DIV style="position:absolute;top:357;left:94"><nobr><span class="ft11">We discuss the object reconstruction and the parameter estimation <br>method to find the best matching class of input objects using the <br>classification tree method [4]. We extracted shape parameters from <br>reconstructed objects using RLC lines, such as roundness, aspect ratio, <br>form factor, surface regularity [5]. <br>The approach tries to find occluded shapes within partially occluded <br>objects. The basic assumption is that most objects are represented by <br>symmetrical figures. When a symmetric object is partially occluded, <br>we use the symmetry measure to evaluate the symmetric shape. We <br>estimate the most similar parameters of occluded shape and region of <br>objects, and we retrieve objects that have the estimated parameters of <br>occluded objects. <br>A basic idea of reconstruction and estimation of occluded objects is to <br>use symmetry properties within objects and use to the contour of <br>objects. Fortunately, most products in electronic catalogs have <br>symmetry in their shapes and they are represented by symmetrical <br>figures. Symmetrical descriptions of shape or detection of <br>symmetrical features of objects can be useful for shape matching, <br>model-based object matching, and object recognition [2] [1]. <br>In the given database, we have elliptical and roughly-rounded objects <br>such as plates, cups, pans, and pots, depending on their poses and <br>shapes. First, we consider elliptical objects in which the occlusion <br>changes values of measurements and parameters related to diameters. <br>We assume that we can get diameters from elliptical objects, which <br>are partially occluded. </span></nobr></DIV>
<DIV style="position:absolute;top:810;left:311"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:827;left:156"><nobr><span class="ft14"><b>Figure 3.1 Three-Spoke from the Triangle. </b></span></nobr></DIV>
<DIV style="position:absolute;top:847;left:94"><nobr><span class="ft11"> <br>However, the elliptical objects are limited to the shape of objects. <br>Therefore, it may not be applied to other types of shape such as <br>irregular shapes. In this case, since we cannot easily detect the <br>symmetry axes, we introduce the three-spoke type symmetry method <br>as shown in Figure 3.1. We apply this approach to roughly-rounded <br>objects such as cups. </span></nobr></DIV>
<DIV style="position:absolute;top:87;left:475"><nobr><span class="ft12">For roughly-rounded objects, we use the three-spoke type method, <br>which is derived from the triangle. The triangle is a basic model to <br>represent figures such as circle, rectangle, and polygon. We use <br>extended lines of the triangle to make axes as shown in Figure 3.1. <br>The three-spoke type symmetry axes, which are equally assigned by <br>120 degrees, provide the possibility to detect proper symmetry axes <br>on roughly-rounded objects. Therefore, this method can detect <br>symmetry axes in roughly-rounded objects. <br>In order to perform the following procedures, we assume that objects <br>are represented by symmetrical figures. <br>1.</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:484"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:243;left:499"><nobr><span class="ft11">We have an occluded elliptical object in Figure 3.2 and roughly-<br>rounded object in Figure 3.6, we can get cutting points of the <br>occlusion  <i>(x,y)'</i> and <i>(x,y)''</i>, that are given by overlapping or <br>cutting. </span></nobr></DIV>
<DIV style="position:absolute;top:301;left:475"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:437;left:823"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:455;left:475"><nobr><span class="ft18"><b>Figure 3.2 The Occlusion Area <br>Estimation using Symmetry: Get <br>cutting points <i>(x,y)'</i> and <i>(x,y)''</i> <br>and get a distance <i>l'</i>. <br></b> </span></nobr></DIV>
<DIV style="position:absolute;top:455;left:677"><nobr><span class="ft17"><b>Figure 3.3 The Occlusion Area <br>Estimation using Symmetry: <br>Get the maximum diameter <br>and the symmetry axis. </b></span></nobr></DIV>
<DIV style="position:absolute;top:518;left:665"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:668;left:823"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:686;left:475"><nobr><span class="ft17"><b>Figure 3.4 The Occlusion <br>Area Estimation using <br>Symmetry: Get the estimated <br>region  <i>a'</i> using a line <i>l'</i> and <br>the symmetry axis. </b></span></nobr></DIV>
<DIV style="position:absolute;top:764;left:470"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:686;left:668"><nobr><span class="ft17"><b>Figure 3.5 The Occlusion Area <br>Estimation using Symmetry: <br>Add region a' to occluded shape <br>and region and re-captured the <br>estimated shape of an object. </b></span></nobr></DIV>
<DIV style="position:absolute;top:764;left:643"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:784;left:475"><nobr><span class="ft4">2.</span></nobr></DIV>
<DIV style="position:absolute;top:784;left:484"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:784;left:499"><nobr><span class="ft11">Compute a distance between two cutting points from <i>(x,y)'</i> and <br><i>(x,y)''</i>, which is called a line <i>l'</i> as in Figure 3.2 and 3.6. </span></nobr></DIV>
<DIV style="position:absolute;top:813;left:475"><nobr><span class="ft4">3.</span></nobr></DIV>
<DIV style="position:absolute;top:813;left:484"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:813;left:499"><nobr><span class="ft11">Based on a line l', make a connection between two points, fill the <br>concave region and re-captured the shape. It is important to <br>compute a centroid in an object. </span></nobr></DIV>
<DIV style="position:absolute;top:857;left:475"><nobr><span class="ft4">4.</span></nobr></DIV>
<DIV style="position:absolute;top:856;left:484"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:857;left:499"><nobr><span class="ft11">Get the maximum diameter from re-captured shape using <br>extremal points as shown in Figure 3.4 and 3.7. Two extremal <br>points <i>(r, l)</i> and <i>(r, l)'</i> from re-captured shape as in Figure 3.7. <br>The distance between two extreme boundary points are <br>represented by the maximum diameter. </span></nobr></DIV>
<DIV style="position:absolute;top:929;left:475"><nobr><span class="ft4">5.</span></nobr></DIV>
<DIV style="position:absolute;top:929;left:484"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:929;left:499"><nobr><span class="ft11">In elliptical objects, one of the maximum and minimum <br>diameters can be a symmetry axis. In roughly-rounded objects, <br>we use the three-spoke type symmetry, one spoke can be a </span></nobr></DIV>
<DIV style="position:absolute;top:1095;left:442"><nobr><span class="ft10">1191</span></nobr></DIV>
</DIV>
<!-- Page 3 -->
<a name="3"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft19{font-size:7px;font-family:Times;color:#000000;}
	.ft20{font-size:14px;font-family:Times;color:#000000;}
	.ft21{font-size:4px;font-family:Times;color:#000000;}
	.ft22{font-size:14px;font-family:Times;color:#000000;}
	.ft23{font-size:4px;font-family:Symbol;color:#000000;}
	.ft24{font-size:9px;font-family:Symbol;color:#000000;}
	.ft25{font-size:4px;font-family:Times;color:#000000;}
	.ft26{font-size:15px;font-family:Times;color:#000000;}
	.ft27{font-size:10px;font-family:Times;color:#000000;}
	.ft28{font-size:5px;font-family:Times;color:#000000;}
	.ft29{font-size:11px;font-family:Times;color:#000000;}
	.ft30{font-size:11px;font-family:Times;color:#000000;}
	.ft31{font-size:11px;font-family:Symbol;color:#000000;}
	.ft32{font-size:10px;line-height:15px;font-family:Times;color:#000000;}
	.ft33{font-size:11px;line-height:11px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="57003.png" alt="background image">
<DIV style="position:absolute;top:87;left:118"><nobr><span class="ft4">symmetry axis to find occluded region within an object. </span></nobr></DIV>
<DIV style="position:absolute;top:102;left:94"><nobr><span class="ft4">6.</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:103"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:102;left:118"><nobr><span class="ft12">Centroid Detection: In case of elliptical objects, we find a <br>centroid based on the maximum diameter and a line <br>perpendicular to the maximum diameter, which is located in the <br>center of the length of the maximum diameter. We select <br>symmetry axes based on one of these lines as in Figure 3.3. In <br>roughly-rounded objects, we get a centroid, based on whole <br>region of an object. Equation 2 is adapted from Russ [19]. If the <br>centroid is calculated by equation 1 using the boundary pixels <br>only, the results may not be correct. The calculated points will be <br>biased toward whichever part of the boundary is most complex <br>and contains the most pixels. The correct centroid location uses <br>the pairs of coordinates </span></nobr></DIV>
<DIV style="position:absolute;top:272;left:259"><nobr><span class="ft19"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:262;left:251"><nobr><span class="ft20"><i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:266;left:266"><nobr><span class="ft4">, </span></nobr></DIV>
<DIV style="position:absolute;top:272;left:285"><nobr><span class="ft19"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:262;left:277"><nobr><span class="ft20"><i>y</i></span></nobr></DIV>
<DIV style="position:absolute;top:266;left:292"><nobr><span class="ft4"> for each point in the shape </span></nobr></DIV>
<DIV style="position:absolute;top:286;left:118"><nobr><span class="ft11">boundary. The centroid of an irregular shape is calculated <br>correctly using all of the pixels in an object. </span></nobr></DIV>
<DIV style="position:absolute;top:314;left:94"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:360;left:291"><nobr><span class="ft9"><i>Area</i></span></nobr></DIV>
<DIV style="position:absolute;top:337;left:304"><nobr><span class="ft9"><i>y</i></span></nobr></DIV>
<DIV style="position:absolute;top:352;left:264"><nobr><span class="ft9"><i>C</i></span></nobr></DIV>
<DIV style="position:absolute;top:360;left:236"><nobr><span class="ft9"><i>Area</i></span></nobr></DIV>
<DIV style="position:absolute;top:337;left:249"><nobr><span class="ft9"><i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:352;left:210"><nobr><span class="ft9"><i>C</i></span></nobr></DIV>
<DIV style="position:absolute;top:329;left:294"><nobr><span class="ft21"><i>k</i></span></nobr></DIV>
<DIV style="position:absolute;top:351;left:291"><nobr><span class="ft21"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:343;left:309"><nobr><span class="ft21"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:359;left:272"><nobr><span class="ft21"><i>y</i></span></nobr></DIV>
<DIV style="position:absolute;top:329;left:240"><nobr><span class="ft21"><i>k</i></span></nobr></DIV>
<DIV style="position:absolute;top:351;left:236"><nobr><span class="ft21"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:343;left:254"><nobr><span class="ft21"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:359;left:218"><nobr><span class="ft21"><i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:333;left:290"><nobr><span class="ft22"></span></nobr></DIV>
<DIV style="position:absolute;top:333;left:235"><nobr><span class="ft22"></span></nobr></DIV>
<DIV style="position:absolute;top:350;left:293"><nobr><span class="ft23">=</span></nobr></DIV>
<DIV style="position:absolute;top:350;left:239"><nobr><span class="ft23">=</span></nobr></DIV>
<DIV style="position:absolute;top:350;left:280"><nobr><span class="ft24">=</span></nobr></DIV>
<DIV style="position:absolute;top:350;left:225"><nobr><span class="ft24">=</span></nobr></DIV>
<DIV style="position:absolute;top:351;left:297"><nobr><span class="ft25">0</span></nobr></DIV>
<DIV style="position:absolute;top:351;left:243"><nobr><span class="ft25">0</span></nobr></DIV>
<DIV style="position:absolute;top:352;left:260"><nobr><span class="ft8">,</span></nobr></DIV>
<DIV style="position:absolute;top:345;left:316"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:345;left:356"><nobr><span class="ft4">    </span></nobr></DIV>
<DIV style="position:absolute;top:345;left:406"><nobr><span class="ft4">        (1) </span></nobr></DIV>
<DIV style="position:absolute;top:411;left:342"><nobr><span class="ft9"><i>Area</i></span></nobr></DIV>
<DIV style="position:absolute;top:386;left:387"><nobr><span class="ft9"><i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:386;left:366"><nobr><span class="ft9"><i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:386;left:335"><nobr><span class="ft9"><i>y</i></span></nobr></DIV>
<DIV style="position:absolute;top:386;left:314"><nobr><span class="ft9"><i>y</i></span></nobr></DIV>
<DIV style="position:absolute;top:402;left:267"><nobr><span class="ft9"><i>C</i></span></nobr></DIV>
<DIV style="position:absolute;top:411;left:191"><nobr><span class="ft9"><i>Area</i></span></nobr></DIV>
<DIV style="position:absolute;top:386;left:235"><nobr><span class="ft9"><i>y</i></span></nobr></DIV>
<DIV style="position:absolute;top:386;left:213"><nobr><span class="ft9"><i>y</i></span></nobr></DIV>
<DIV style="position:absolute;top:386;left:182"><nobr><span class="ft9"><i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:386;left:162"><nobr><span class="ft9"><i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:402;left:116"><nobr><span class="ft9"><i>C</i></span></nobr></DIV>
<DIV style="position:absolute;top:379;left:299"><nobr><span class="ft21"><i>k</i></span></nobr></DIV>
<DIV style="position:absolute;top:402;left:296"><nobr><span class="ft21"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:394;left:392"><nobr><span class="ft21"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:394;left:371"><nobr><span class="ft21"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:394;left:341"><nobr><span class="ft21"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:394;left:319"><nobr><span class="ft21"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:409;left:276"><nobr><span class="ft21"><i>y</i></span></nobr></DIV>
<DIV style="position:absolute;top:379;left:147"><nobr><span class="ft21"><i>k</i></span></nobr></DIV>
<DIV style="position:absolute;top:402;left:144"><nobr><span class="ft21"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:394;left:241"><nobr><span class="ft21"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:394;left:219"><nobr><span class="ft21"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:394;left:188"><nobr><span class="ft21"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:394;left:167"><nobr><span class="ft21"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:409;left:125"><nobr><span class="ft21"><i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:383;left:294"><nobr><span class="ft26"></span></nobr></DIV>
<DIV style="position:absolute;top:383;left:143"><nobr><span class="ft26"></span></nobr></DIV>
<DIV style="position:absolute;top:401;left:298"><nobr><span class="ft23">-</span></nobr></DIV>
<DIV style="position:absolute;top:393;left:395"><nobr><span class="ft23">-</span></nobr></DIV>
<DIV style="position:absolute;top:393;left:343"><nobr><span class="ft23">-</span></nobr></DIV>
<DIV style="position:absolute;top:401;left:147"><nobr><span class="ft23">-</span></nobr></DIV>
<DIV style="position:absolute;top:393;left:243"><nobr><span class="ft23">-</span></nobr></DIV>
<DIV style="position:absolute;top:393;left:190"><nobr><span class="ft23">-</span></nobr></DIV>
<DIV style="position:absolute;top:385;left:377"><nobr><span class="ft24">-</span></nobr></DIV>
<DIV style="position:absolute;top:385;left:325"><nobr><span class="ft24">+</span></nobr></DIV>
<DIV style="position:absolute;top:401;left:284"><nobr><span class="ft24">=</span></nobr></DIV>
<DIV style="position:absolute;top:385;left:225"><nobr><span class="ft24">-</span></nobr></DIV>
<DIV style="position:absolute;top:385;left:173"><nobr><span class="ft24">+</span></nobr></DIV>
<DIV style="position:absolute;top:401;left:132"><nobr><span class="ft24">=</span></nobr></DIV>
<DIV style="position:absolute;top:402;left:302"><nobr><span class="ft25">0</span></nobr></DIV>
<DIV style="position:absolute;top:386;left:407"><nobr><span class="ft25">2</span></nobr></DIV>
<DIV style="position:absolute;top:394;left:398"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:386;left:356"><nobr><span class="ft25">2</span></nobr></DIV>
<DIV style="position:absolute;top:394;left:347"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:402;left:151"><nobr><span class="ft25">0</span></nobr></DIV>
<DIV style="position:absolute;top:386;left:256"><nobr><span class="ft25">2</span></nobr></DIV>
<DIV style="position:absolute;top:394;left:246"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:386;left:203"><nobr><span class="ft25">2</span></nobr></DIV>
<DIV style="position:absolute;top:394;left:194"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:386;left:402"><nobr><span class="ft8">)</span></nobr></DIV>
<DIV style="position:absolute;top:386;left:361"><nobr><span class="ft8">(</span></nobr></DIV>
<DIV style="position:absolute;top:386;left:351"><nobr><span class="ft8">)</span></nobr></DIV>
<DIV style="position:absolute;top:386;left:308"><nobr><span class="ft8">(</span></nobr></DIV>
<DIV style="position:absolute;top:402;left:263"><nobr><span class="ft8">,</span></nobr></DIV>
<DIV style="position:absolute;top:386;left:251"><nobr><span class="ft8">)</span></nobr></DIV>
<DIV style="position:absolute;top:386;left:208"><nobr><span class="ft8">(</span></nobr></DIV>
<DIV style="position:absolute;top:386;left:198"><nobr><span class="ft8">)</span></nobr></DIV>
<DIV style="position:absolute;top:386;left:157"><nobr><span class="ft8">(</span></nobr></DIV>
<DIV style="position:absolute;top:397;left:415"><nobr><span class="ft4">     (2) </span></nobr></DIV>
<DIV style="position:absolute;top:430;left:94"><nobr><span class="ft12"> <br>7.</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:103"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:450;left:118"><nobr><span class="ft11">In roughly-rounded objects, a centroid is put at the same position <br>at the center of the three-spoke type symmetry axes. </span></nobr></DIV>
<DIV style="position:absolute;top:629;left:447"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:647;left:94"><nobr><span class="ft17"><b>Figure 3.6 The occlusion of a <br>cup: Get a centroid after re-<br>captured a shape. </b></span></nobr></DIV>
<DIV style="position:absolute;top:647;left:287"><nobr><span class="ft17"><b>Figure 3.7 Get extremal points <br><i>(r,l), (r,l)'</i> and <i>(r,l)'',(r,l)'''</i> and <br>the maximum diameter of an <br>object. </b></span></nobr></DIV>
<DIV style="position:absolute;top:873;left:459"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:891;left:94"><nobr><span class="ft17"><b>Figure 3.8 Use the three spoke <br>type symmetry: Match a center of <br>the spoke to a centroid and <br>parallel one of axes to the <br>maximum diameter. </b></span></nobr></DIV>
<DIV style="position:absolute;top:891;left:301"><nobr><span class="ft17"><b>Figure 3.9 Extend axes and <br>make symmetry axes. </b></span></nobr></DIV>
<DIV style="position:absolute;top:259;left:820"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:277;left:475"><nobr><span class="ft17"><b>Figure 3.10 Select a symmetry <br>axis based on two regions, <br>which are A and B. </b></span></nobr></DIV>
<DIV style="position:absolute;top:277;left:665"><nobr><span class="ft17"><b>Figure 3.11 Find a region <i>a'</i> <br>of occluded shape using a <br>symmetry axis and add to a <br>occluded shape. </b></span></nobr></DIV>
<DIV style="position:absolute;top:340;left:441"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:360;left:475"><nobr><span class="ft4">8.</span></nobr></DIV>
<DIV style="position:absolute;top:360;left:484"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:360;left:499"><nobr><span class="ft11">Axis Detection: The midpoint of the major axis is called the <br>center of the ellipse. The minor axis is the line segment <br>perpendicular to the major axis which also goes through the <br>center and touches the ellipse at two points. In elliptical objects, <br>we detect a symmetry axis based on the maximum diameter or <br>the minimum diameter. To find a symmetry axis in roughly-<br>rounded objects, one of axes of the three-spoke type symmetry <br>axes is in parallel with the maximum diameter of an object as <br>shown in Figure 3.8. <br>Based on occluded shape and region, we select a symmetry axis <br>to estimate this region within an object. Figures 3.9 and 3.10 <br>show how to select a symmetry axis. When we select an axis in <br>roughly-rounded objects, we consider conditions as follows: </span></nobr></DIV>
<DIV style="position:absolute;top:554;left:505"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:554;left:524"><nobr><span class="ft4">Select axes, which don't intersect the occluded region. </span></nobr></DIV>
<DIV style="position:absolute;top:568;left:505"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:568;left:524"><nobr><span class="ft32">3.9 and 3.10 show how to select a symmetry axis. Select <br>axes, which have a region with the maximum diameter   <i>l'</i>. </span></nobr></DIV>
<DIV style="position:absolute;top:598;left:505"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:599;left:524"><nobr><span class="ft11">Area and perimeter are invariants as in equation 3, compare <br>the proportion of region A and B. </span></nobr></DIV>
<DIV style="position:absolute;top:629;left:739"><nobr><span class="ft28"><i>B</i></span></nobr></DIV>
<DIV style="position:absolute;top:629;left:646"><nobr><span class="ft28"><i>A</i></span></nobr></DIV>
<DIV style="position:absolute;top:652;left:690"><nobr><span class="ft29"><i>Area</i></span></nobr></DIV>
<DIV style="position:absolute;top:632;left:675"><nobr><span class="ft29"><i>Perimeter</i></span></nobr></DIV>
<DIV style="position:absolute;top:652;left:596"><nobr><span class="ft29"><i>Area</i></span></nobr></DIV>
<DIV style="position:absolute;top:632;left:581"><nobr><span class="ft29"><i>Perimeter</i></span></nobr></DIV>
<DIV style="position:absolute;top:641;left:733"><nobr><span class="ft33"><br></span></nobr></DIV>
<DIV style="position:absolute;top:633;left:733"><nobr><span class="ft30"></span></nobr></DIV>
<DIV style="position:absolute;top:641;left:667"><nobr><span class="ft33"><br></span></nobr></DIV>
<DIV style="position:absolute;top:633;left:667"><nobr><span class="ft30"></span></nobr></DIV>
<DIV style="position:absolute;top:639;left:656"><nobr><span class="ft31"></span></nobr></DIV>
<DIV style="position:absolute;top:641;left:639"><nobr><span class="ft33"><br></span></nobr></DIV>
<DIV style="position:absolute;top:633;left:639"><nobr><span class="ft30"></span></nobr></DIV>
<DIV style="position:absolute;top:641;left:573"><nobr><span class="ft33"><br></span></nobr></DIV>
<DIV style="position:absolute;top:633;left:573"><nobr><span class="ft30"></span></nobr></DIV>
<DIV style="position:absolute;top:639;left:747"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:639;left:793"><nobr><span class="ft4">     (3) </span></nobr></DIV>
<DIV style="position:absolute;top:675;left:475"><nobr><span class="ft4">9.</span></nobr></DIV>
<DIV style="position:absolute;top:675;left:484"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:675;left:499"><nobr><span class="ft11">Using mirror symmetry, we can get points across an axis. We <br>find points on the contour across an axis which have the same <br>length  <i>l'</i> and the same angle corresponding to the axis that is <br>perpendicular to a symmetry axis, but the distance between axis <br>and points may or may not be the same. </span></nobr></DIV>
<DIV style="position:absolute;top:747;left:475"><nobr><span class="ft4">10.</span></nobr></DIV>
<DIV style="position:absolute;top:747;left:490"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:747;left:499"><nobr><span class="ft11">Capture a region <i>a'</i>, move the captured region to the occluded <br>shape using the mirror symmetry, and add to these regions as <br>shown in Figure 3.4, 3.5, and 3.11. </span></nobr></DIV>
<DIV style="position:absolute;top:791;left:475"><nobr><span class="ft4">11.</span></nobr></DIV>
<DIV style="position:absolute;top:791;left:490"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:791;left:499"><nobr><span class="ft11">Re-compute shape measurements such as area, diameters, and <br>perimeter using RLC lines from re-captured shape of an object. <br>Then, re-compute shape parameters based on measurements. </span></nobr></DIV>
<DIV style="position:absolute;top:834;left:475"><nobr><span class="ft4">12.</span></nobr></DIV>
<DIV style="position:absolute;top:834;left:490"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:834;left:499"><nobr><span class="ft4">Apply to a classifier. </span></nobr></DIV>
<DIV style="position:absolute;top:849;left:475"><nobr><span class="ft12"> <br>From the above discussions, we described how to reconstruct and <br>estimate the partially occluded shape and region of an object and how <br>to find the best matching class of partially occluded objects after the <br>estimation. <br> </span></nobr></DIV>
<DIV style="position:absolute;top:1095;left:442"><nobr><span class="ft10">1192</span></nobr></DIV>
</DIV>
<!-- Page 4 -->
<a name="4"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft34{font-size:9px;font-family:Times;color:#000000;}
	.ft35{font-size:10px;line-height:20px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="57004.png" alt="background image">
<DIV style="position:absolute;top:88;left:94"><nobr><span class="ft3"><b>4.</b></span></nobr></DIV>
<DIV style="position:absolute;top:88;left:106"><nobr><span class="ft5"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:88;left:116"><nobr><span class="ft3"><b>EXPERIMENTAL RESULTS </b></span></nobr></DIV>
<DIV style="position:absolute;top:107;left:94"><nobr><span class="ft11">In the sections, we evaluate and describe the results of partial object <br>recognition by our proposed a method. We have selected 190 partially <br>occluded objects of images from electronic catalogs on the Internet as <br>well as manipulated images. We assume that occluded objects have <br>more than 50% visibility of objects, and images of catalogs contain <br>partially occluded objects. The objects are categorized by semantic <br>meanings such as cup and plate. In addition, our approaches and <br>experiments are limited to cups and plates since we use roughly-<br>rounded or elliptical objects. More precisely, the database contains 32 <br>objects from different viewpoints and images of 97 objects <br>comprising image plane rotations and scale changes. <br>In sample images, we have extracted image features of partially <br>occluded objects such as shape and texture. We experimented with <br>shape reconstruction based on the contour of objects using symmetry <br>properties. We assumed that inputs are not correctly classified and <br>have occlusion. <br>We experimented with samples such as plates and cups to reconstruct <br>the occluded shape of objects as shown in Figure 4.1 and 4.2. In <br>Figure 4.2, it is correctly classified after the reconstruction with an <br>occlusion about 30%. On the other hand, Figure 4.1 is not correctly <br>classified after the reconstruction since the width of plate is too <br>narrow. This experiment shows that our method heavily relies on <br>shape of objects. </span></nobr></DIV>
<DIV style="position:absolute;top:581;left:394"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:598;left:140"><nobr><span class="ft14"><b>Figure 4.1 Example of the occlusion with a Plate. </b></span></nobr></DIV>
<DIV style="position:absolute;top:617;left:94"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:738;left:407"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:756;left:108"><nobr><span class="ft14"><b>Figure 4.2 Example of the manipulated occlusion with a Cup. </b></span></nobr></DIV>
<DIV style="position:absolute;top:775;left:94"><nobr><span class="ft12"> <br>Finally, we performed an experiment for the relationships between <br>visible portion of objects and recognition rates. In order to evaluate <br>the visibility of objects, we used manipulated images of cups and <br>plates. Figure 4.3 shows the pattern of object recognition in the <br>presence of partial occlusion of objects and the results obtained by the <br>symmetric recognition. A visible portion of approximately 67% is <br>sufficient for the recognition of objects based on the contour. <br> </span></nobr></DIV>
<DIV style="position:absolute;top:242;left:779"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:259;left:475"><nobr><span class="ft17"><b>Figure 4.3 Object recognition in the presence of the occlusion of <br>objects based on the contour. <br></b> <br>There are many efforts in object recognition for dealing with <br>occlusion. The visible portion of objects required to recognize <br>occluded objects are shown in Table 4.1. Table 4.1 shows a simple <br>comparison between our method and other existing methods. The <br>probabilistic method based on local measurements requires small <br>portions of objects to recognize the whole objects, but it required <br>extensive training processes to recognize occluded objects [21] [20]. <br>Our method shows good visibility of partial object recognition and do <br>not need extensive training processes. <br> <br><b>Table 4.1 The visibility of object recognition in the presence of <br>partial occlusion. </b></span></nobr></DIV>
<DIV style="position:absolute;top:503;left:550"><nobr><span class="ft34"><b>Methods Visibility </b></span></nobr></DIV>
<DIV style="position:absolute;top:503;left:760"><nobr><span class="ft34"><b>Training </b></span></nobr></DIV>
<DIV style="position:absolute;top:516;left:759"><nobr><span class="ft34"><b>processes </b></span></nobr></DIV>
<DIV style="position:absolute;top:535;left:472"><nobr><span class="ft13">Appearance matching techniques  using <br>adaptive masks </span></nobr></DIV>
<DIV style="position:absolute;top:535;left:700"><nobr><span class="ft8">90% not </span></nobr></DIV>
<DIV style="position:absolute;top:535;left:771"><nobr><span class="ft8">required </span></nobr></DIV>
<DIV style="position:absolute;top:567;left:472"><nobr><span class="ft8">Probabilistic technique using Chi-square </span></nobr></DIV>
<DIV style="position:absolute;top:567;left:700"><nobr><span class="ft8">72% </span></nobr></DIV>
<DIV style="position:absolute;top:567;left:763"><nobr><span class="ft8">required </span></nobr></DIV>
<DIV style="position:absolute;top:586;left:472"><nobr><span class="ft13">Probabilistic technique using local <br>measurements </span></nobr></DIV>
<DIV style="position:absolute;top:586;left:700"><nobr><span class="ft8">34% required </span></nobr></DIV>
<DIV style="position:absolute;top:618;left:472"><nobr><span class="ft8">Contour-based approach using symmetry </span></nobr></DIV>
<DIV style="position:absolute;top:618;left:700"><nobr><span class="ft8">67% </span></nobr></DIV>
<DIV style="position:absolute;top:618;left:755"><nobr><span class="ft8">not required </span></nobr></DIV>
<DIV style="position:absolute;top:638;left:475"><nobr><span class="ft12"> <br>In order to measure the influence of occlusion and compare its impact <br>on the recognition performance of the different methods, we <br>performed an experiment as follows. <br>Figure 4.4 summarizes the recognition results for different visible <br>object portions. For each test object, we varied the visible object <br>portion from 20% to 100% and recorded the recognition results using <br>Chi-square divergence and our method. <br> </span></nobr></DIV>
<DIV style="position:absolute;top:948;left:787"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:965;left:525"><nobr><span class="ft14"><b>Figure 4.4 Experimental results with occlusion. </b></span></nobr></DIV>
<DIV style="position:absolute;top:1095;left:442"><nobr><span class="ft10">1193</span></nobr></DIV>
</DIV>
<!-- Page 5 -->
<a name="5"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft36{font-size:10px;line-height:14px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="57005.png" alt="background image">
<DIV style="position:absolute;top:87;left:94"><nobr><span class="ft17"> <br>The results show that our method clearly obtains better results than <br>Chi-square divergence. Using only 60% of the object area, almost <br>80% of the objects are still recognized. This confirms that our method <br>is capable of reliable recognition in the presence of occlusion.  <br> <br><b>Table 4.2 Summary of Object Recognition Methods for dealing <br>with Occlusion. </b></span></nobr></DIV>
<DIV style="position:absolute;top:226;left:83"><nobr><span class="ft34"><b>Methods </b></span></nobr></DIV>
<DIV style="position:absolute;top:226;left:162"><nobr><span class="ft34"><b>Occlusion </b></span></nobr></DIV>
<DIV style="position:absolute;top:226;left:227"><nobr><span class="ft34"><b>Scale changes</b></span></nobr></DIV>
<DIV style="position:absolute;top:226;left:310"><nobr><span class="ft34"><b>Object Pose </b></span></nobr></DIV>
<DIV style="position:absolute;top:226;left:385"><nobr><span class="ft34"><b>Rotation </b></span></nobr></DIV>
<DIV style="position:absolute;top:245;left:62"><nobr><span class="ft8">Bischof et al. [1] </span></nobr></DIV>
<DIV style="position:absolute;top:245;left:177"><nobr><span class="ft8">Yes </span></nobr></DIV>
<DIV style="position:absolute;top:245;left:251"><nobr><span class="ft8">Yes </span></nobr></DIV>
<DIV style="position:absolute;top:245;left:332"><nobr><span class="ft8">No </span></nobr></DIV>
<DIV style="position:absolute;top:245;left:408"><nobr><span class="ft8">No </span></nobr></DIV>
<DIV style="position:absolute;top:264;left:62"><nobr><span class="ft8">Edwards et al. [6] </span></nobr></DIV>
<DIV style="position:absolute;top:264;left:177"><nobr><span class="ft8">Yes </span></nobr></DIV>
<DIV style="position:absolute;top:264;left:251"><nobr><span class="ft8">Yes </span></nobr></DIV>
<DIV style="position:absolute;top:264;left:332"><nobr><span class="ft8">No </span></nobr></DIV>
<DIV style="position:absolute;top:264;left:387"><nobr><span class="ft8">Yes(limited)</span></nobr></DIV>
<DIV style="position:absolute;top:283;left:62"><nobr><span class="ft8">Ohba et al. [16] </span></nobr></DIV>
<DIV style="position:absolute;top:283;left:177"><nobr><span class="ft8">Yes </span></nobr></DIV>
<DIV style="position:absolute;top:283;left:253"><nobr><span class="ft8">No </span></nobr></DIV>
<DIV style="position:absolute;top:283;left:330"><nobr><span class="ft8">Yes </span></nobr></DIV>
<DIV style="position:absolute;top:283;left:408"><nobr><span class="ft8">No </span></nobr></DIV>
<DIV style="position:absolute;top:302;left:62"><nobr><span class="ft8">Rao [18] </span></nobr></DIV>
<DIV style="position:absolute;top:302;left:177"><nobr><span class="ft8">Yes </span></nobr></DIV>
<DIV style="position:absolute;top:302;left:253"><nobr><span class="ft8">No </span></nobr></DIV>
<DIV style="position:absolute;top:302;left:330"><nobr><span class="ft8">Yes </span></nobr></DIV>
<DIV style="position:absolute;top:302;left:408"><nobr><span class="ft8">No </span></nobr></DIV>
<DIV style="position:absolute;top:321;left:62"><nobr><span class="ft8">Jacob et al. [11] </span></nobr></DIV>
<DIV style="position:absolute;top:321;left:177"><nobr><span class="ft8">Yes </span></nobr></DIV>
<DIV style="position:absolute;top:321;left:253"><nobr><span class="ft8">No </span></nobr></DIV>
<DIV style="position:absolute;top:321;left:330"><nobr><span class="ft8">Yes </span></nobr></DIV>
<DIV style="position:absolute;top:321;left:408"><nobr><span class="ft8">No </span></nobr></DIV>
<DIV style="position:absolute;top:340;left:62"><nobr><span class="ft8">Krumm [13] </span></nobr></DIV>
<DIV style="position:absolute;top:340;left:177"><nobr><span class="ft8">Yes </span></nobr></DIV>
<DIV style="position:absolute;top:340;left:253"><nobr><span class="ft8">No </span></nobr></DIV>
<DIV style="position:absolute;top:340;left:332"><nobr><span class="ft8">No </span></nobr></DIV>
<DIV style="position:absolute;top:340;left:407"><nobr><span class="ft8">NO </span></nobr></DIV>
<DIV style="position:absolute;top:359;left:62"><nobr><span class="ft13">Contour-based <br>using symmetry </span></nobr></DIV>
<DIV style="position:absolute;top:359;left:177"><nobr><span class="ft8">Yes Yes </span></nobr></DIV>
<DIV style="position:absolute;top:359;left:311"><nobr><span class="ft8">Yes(limited) </span></nobr></DIV>
<DIV style="position:absolute;top:359;left:406"><nobr><span class="ft8">Yes </span></nobr></DIV>
<DIV style="position:absolute;top:391;left:94"><nobr><span class="ft12"> <br>Table 4.2 summarizes the various object recognition methods. The <br>table indicates whether the methods can handle occlusion, rotation, <br>pose, and changes in the size of objects in the database. Unlike the <br>other methods, our method can handle scale change, object pose, and <br>rotated objects with occlusion, even though our method has minor <br>limitations of object poses. <br> </span></nobr></DIV>
<DIV style="position:absolute;top:526;left:94"><nobr><span class="ft3"><b>5.</b></span></nobr></DIV>
<DIV style="position:absolute;top:526;left:106"><nobr><span class="ft5"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:526;left:116"><nobr><span class="ft3"><b>CONCLUSION </b></span></nobr></DIV>
<DIV style="position:absolute;top:545;left:94"><nobr><span class="ft12">In this paper, we have discussed how to estimate parameters and to <br>reconstruct the occluded shape of partial objects in image databases. <br>In order to reconstruct occluded shapes, we used symmetry, which <br>provides powerful method for the partial object recognition. Unlike <br>the existing methods, our method tried to reconstruct occluded shapes <br>and regions within objects, since most objects in our domain have <br>symmetrical figures. However, we have limitations in the shape of <br>objects and the occluded region of objects. For example, if a pan has <br>an occlusion in handle, it cannot correctly reconstruct and be <br>recognized.  <br>Another minor limitation of our method is that a method is sensitive <br>to the pose of an object. For example, if we cannot see an ellipse due <br>to the object's pose, we cannot recognize the object. After estimation, <br>we have applied inputs, which include estimated parameters, to the <br>existing classification trees, to get to the best matching class. <br>All experiments are performed based on the classifier in earlier work. <br>In experiments, the results show that the recognition of the occluded <br>object is properly reconstructed, estimated, and classified, even <br>though we have limited to the size of samples. In addition, we have <br>experienced the power of the symmetry through experiments.  <br> </span></nobr></DIV>
<DIV style="position:absolute;top:874;left:94"><nobr><span class="ft3"><b>6.</b></span></nobr></DIV>
<DIV style="position:absolute;top:874;left:106"><nobr><span class="ft5"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:874;left:116"><nobr><span class="ft3"><b>REFERENCES </b></span></nobr></DIV>
<DIV style="position:absolute;top:893;left:94"><nobr><span class="ft4">[1]</span></nobr></DIV>
<DIV style="position:absolute;top:892;left:108"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:893;left:118"><nobr><span class="ft36">H. Bischof and A. Leonardis. Robust recognition of scaled <br>eigenimages through a hierachical approach. <i>In IEEE Conference <br>on Computer Vision and Pattern Recognition</i>, 1998. </span></nobr></DIV>
<DIV style="position:absolute;top:87;left:475"><nobr><span class="ft4">[2]</span></nobr></DIV>
<DIV style="position:absolute;top:87;left:489"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:87;left:499"><nobr><span class="ft11">H. Blum and R.N. Nagel. Shape description using weighted <br>symmetric axis features. <i>Pattern Recognition</i>, 1978. </span></nobr></DIV>
<DIV style="position:absolute;top:116;left:475"><nobr><span class="ft4">[3]</span></nobr></DIV>
<DIV style="position:absolute;top:116;left:489"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:116;left:499"><nobr><span class="ft36">P. Chang and J. Krumm. Object Recognition with Color <br>Cooccurrence Histograms. <i>In IEEE Conference on Computer <br>Vision and Pattern Recognition</i>, 1999. </span></nobr></DIV>
<DIV style="position:absolute;top:160;left:475"><nobr><span class="ft4">[4]</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:489"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:160;left:499"><nobr><span class="ft36">J. Cho and N. Adam. Efficient Splitting Rules based on the <br>Probabilities of Pre-Assigned Intervals. <i>In IEEE Conference on <br>Data Mining, </i>2001. </span></nobr></DIV>
<DIV style="position:absolute;top:203;left:475"><nobr><span class="ft4">[5]</span></nobr></DIV>
<DIV style="position:absolute;top:203;left:489"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:203;left:499"><nobr><span class="ft36">J. Cho, A. Gangopadhyay and N. Adam. Feature Extraction for <br>Content-based Image search in Electronic Commerce. <i>In MIS/OA <br>International Conference,</i> 2000. </span></nobr></DIV>
<DIV style="position:absolute;top:246;left:475"><nobr><span class="ft4">[6]</span></nobr></DIV>
<DIV style="position:absolute;top:246;left:489"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:246;left:499"><nobr><span class="ft36">J. Edwards and H. Murase. Appearance matching of occluded <br>objects using coarse-to-fine adaptive masks. <i>In IEEE Conference <br>on Computer Vision and Pattern Recognition</i>, 1997. </span></nobr></DIV>
<DIV style="position:absolute;top:290;left:475"><nobr><span class="ft4">[7]</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:489"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:290;left:499"><nobr><span class="ft36">A. W. Fitzgibbon, M. Pilu, and R. B. Fisher. Direct least squares <br>fitting of ellipses. <i>In International Conference on Pattern <br>Recognition</i>, 1996. </span></nobr></DIV>
<DIV style="position:absolute;top:333;left:475"><nobr><span class="ft4">[8]</span></nobr></DIV>
<DIV style="position:absolute;top:333;left:489"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:333;left:499"><nobr><span class="ft36">M. Fleck. Local Rotational Symmetries. <i>In IEEE Conference on <br>Computer Vision and Pattern Recognition</i>, 1986. </span></nobr></DIV>
<DIV style="position:absolute;top:362;left:475"><nobr><span class="ft4">[9]</span></nobr></DIV>
<DIV style="position:absolute;top:362;left:489"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:362;left:499"><nobr><span class="ft11">C. Ho and L. Chan. A fast ellipse/circle detector using geometric <br>symmetry<i>. Pattern Recognition,</i> 1995. </span></nobr></DIV>
<DIV style="position:absolute;top:391;left:475"><nobr><span class="ft4">[10]</span></nobr></DIV>
<DIV style="position:absolute;top:391;left:496"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:391;left:499"><nobr><span class="ft11">Joachim Hornegger, Heinrich Niemann, and Robert Risack. <br>Appearance-based object recognition using optimal feature <br>transforms. <i>Pattern Recognition</i>, 2000. </span></nobr></DIV>
<DIV style="position:absolute;top:434;left:475"><nobr><span class="ft4">[11]</span></nobr></DIV>
<DIV style="position:absolute;top:434;left:496"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:434;left:499"><nobr><span class="ft36">David W. Jacobs and Ronen Basri. 3D to 2D recognition with <br>regions.  <i>In IEEE Conference on Computer Vision and Pattern <br>Recognition</i>, 1997. </span></nobr></DIV>
<DIV style="position:absolute;top:478;left:475"><nobr><span class="ft4">[12]</span></nobr></DIV>
<DIV style="position:absolute;top:478;left:496"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:478;left:499"><nobr><span class="ft36">Grinnell Jones and Bir Bhanu. Recognition of articulated and <br>occluded objects. <i>IEEE Transaction on Pattern Analysis and <br>Machine Intelligence</i>, 1999. </span></nobr></DIV>
<DIV style="position:absolute;top:521;left:475"><nobr><span class="ft4">[13]</span></nobr></DIV>
<DIV style="position:absolute;top:521;left:496"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:521;left:499"><nobr><span class="ft36">John Krumm. Object detection with vector quantized binary <br>features.  <i>In IEEE Conference on Computer Vision and Pattern <br>Recognition</i>, 1997. </span></nobr></DIV>
<DIV style="position:absolute;top:565;left:475"><nobr><span class="ft4">[14]</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:496"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:565;left:499"><nobr><span class="ft36">Ales Leonardis and Horst Bishof. Dealing with Occlusions in the <br>Eigenspace Approach. <i>In IEEE Conference on Computer Vision <br>and Pattern Recognition</i>, 1996. </span></nobr></DIV>
<DIV style="position:absolute;top:608;left:475"><nobr><span class="ft4">[15]</span></nobr></DIV>
<DIV style="position:absolute;top:608;left:496"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:608;left:499"><nobr><span class="ft11">David G. Lowe. Object Recognition from Local Scale-Invariant <br>Features. <i>In International Conference on Computer Vision, </i>1999. </span></nobr></DIV>
<DIV style="position:absolute;top:637;left:475"><nobr><span class="ft4">[16]</span></nobr></DIV>
<DIV style="position:absolute;top:637;left:496"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:637;left:499"><nobr><span class="ft11">K. Ohba and K. Ikeuchi. Detectability, uniqueness, and <br>reliability of eigen windows for stable verification of partially <br>occluded objects<i>. IEEE Trans. Pattern Anal</i>. Mach, 1997. </span></nobr></DIV>
<DIV style="position:absolute;top:680;left:475"><nobr><span class="ft4">[17]</span></nobr></DIV>
<DIV style="position:absolute;top:680;left:496"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:680;left:499"><nobr><span class="ft11">N. Rajpal, S. Chaudhury, and S. Banerjee. Recognition of <br>partially occluded objects using neural network based indexing. <br><i>Pattern Recognition</i>, 1999. </span></nobr></DIV>
<DIV style="position:absolute;top:724;left:475"><nobr><span class="ft4">[18]</span></nobr></DIV>
<DIV style="position:absolute;top:723;left:496"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:724;left:499"><nobr><span class="ft36">R. Rao. Dynamic appearance-based recognition. <i>In IEEE <br>Conference on Computer Vision and Pattern Recognition</i>, 1997. </span></nobr></DIV>
<DIV style="position:absolute;top:753;left:475"><nobr><span class="ft4">[19]</span></nobr></DIV>
<DIV style="position:absolute;top:752;left:496"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:753;left:499"><nobr><span class="ft11">John C. Russ. <i>The Image Processing Handboo</i>k. CRC Press, 3rd <br>edition, 1998.  </span></nobr></DIV>
<DIV style="position:absolute;top:781;left:475"><nobr><span class="ft4">[20]</span></nobr></DIV>
<DIV style="position:absolute;top:781;left:496"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:781;left:499"><nobr><span class="ft36">Bernt Schiele and Alex Pentland. Probabilistic Object <br>Recognition and Localization. <i>In International Conference on <br>Computer Vision</i>, 1999. </span></nobr></DIV>
<DIV style="position:absolute;top:825;left:475"><nobr><span class="ft4">[21]</span></nobr></DIV>
<DIV style="position:absolute;top:825;left:496"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:825;left:499"><nobr><span class="ft11">H. Schneiderman and T. Kanade. Probabilistic modeling of local <br>appearance and spatial relationships for object recognition. <i>In <br>IEEE Conference on Computer Vision and Pattern Recognition</i>, <br>1998 </span></nobr></DIV>
<DIV style="position:absolute;top:883;left:475"><nobr><span class="ft4">[22]</span></nobr></DIV>
<DIV style="position:absolute;top:882;left:496"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:883;left:499"><nobr><span class="ft11">W. Wu and M. J. Wang. Elliptical object detection by using its <br>geometrical properties. <i>Pattern Recognition</i> 1993. </span></nobr></DIV>
<DIV style="position:absolute;top:912;left:475"><nobr><span class="ft4">[23]</span></nobr></DIV>
<DIV style="position:absolute;top:911;left:496"><nobr><span class="ft15"> </span></nobr></DIV>
<DIV style="position:absolute;top:912;left:499"><nobr><span class="ft36">Lance R. Williams. Topological reconstruction of a smooth <br>manifold-solid from its occluding contour. <i>Journal of Computer <br>Vision,</i> 1997.</span></nobr></DIV>
<DIV style="position:absolute;top:956;left:94"><nobr><span class="ft0"><b> </b></span></nobr></DIV>
<DIV style="position:absolute;top:1095;left:442"><nobr><span class="ft10">1194</span></nobr></DIV>
</DIV>
</BODY>
</HTML>
