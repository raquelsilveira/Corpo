<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
<HEAD>
<TITLE>disperserproceed.dvi</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<META name="generator" content="pdftohtml 0.35beta">
<META name="date" content="2006-05-11T08:40:29+00:00">
</HEAD>
<BODY bgcolor="#A0A0A0" vlink="blue" link="blue">
<!-- Page 1 -->
<a name="1"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft0{font-size:24px;font-family:Helvetica;color:#000000;}
	.ft1{font-size:15px;font-family:Helvetica;color:#000000;}
	.ft2{font-size:11px;font-family:Times;color:#000000;}
	.ft3{font-size:12px;font-family:Helvetica;color:#000000;}
	.ft4{font-size:15px;font-family:Times;color:#000000;}
	.ft5{font-size:6px;font-family:Times;color:#000000;}
	.ft6{font-size:9px;font-family:Times;color:#000000;}
	.ft7{font-size:9px;font-family:Times;color:#000000;}
	.ft8{font-size:16px;font-family:Courier;color:#000000;}
	.ft9{font-size:11px;font-family:Times;color:#000000;}
	.ft10{font-size:11px;line-height:15px;font-family:Times;color:#000000;}
	.ft11{font-size:11px;line-height:17px;font-family:Times;color:#000000;}
	.ft12{font-size:11px;line-height:13px;font-family:Times;color:#000000;}
	.ft13{font-size:11px;line-height:14px;font-family:Times;color:#000000;}
	.ft14{font-size:9px;line-height:13px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="1001.png" alt="background image">
<DIV style="position:absolute;top:108;left:119"><nobr><span class="ft0"><b>2-Source Dispersers for Sub-Polynomial Entropy and</b></span></nobr></DIV>
<DIV style="position:absolute;top:138;left:98"><nobr><span class="ft0"><b>Ramsey Graphs Beating the Frankl-Wilson Construction</b></span></nobr></DIV>
<DIV style="position:absolute;top:220;left:233"><nobr><span class="ft1">Boaz Barak</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:331"><nobr><span class="ft2"></span></nobr></DIV>
<DIV style="position:absolute;top:238;left:177"><nobr><span class="ft3">Department of Computer Science</span></nobr></DIV>
<DIV style="position:absolute;top:254;left:221"><nobr><span class="ft3">Princeton University</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:194"><nobr><span class="ft1">boaz@cs.princeton.edu</span></nobr></DIV>
<DIV style="position:absolute;top:220;left:579"><nobr><span class="ft1">Anup Rao</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:664"><nobr><span class="ft2"></span></nobr></DIV>
<DIV style="position:absolute;top:238;left:516"><nobr><span class="ft3">Department of Computer Science</span></nobr></DIV>
<DIV style="position:absolute;top:254;left:534"><nobr><span class="ft3">University of Texas at Austin</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:545"><nobr><span class="ft1">arao@cs.utexas.edu</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:221"><nobr><span class="ft1">Ronen Shaltiel</span></nobr></DIV>
<DIV style="position:absolute;top:301;left:343"><nobr><span class="ft2"></span></nobr></DIV>
<DIV style="position:absolute;top:330;left:228"><nobr><span class="ft3">University of Haifa</span></nobr></DIV>
<DIV style="position:absolute;top:345;left:241"><nobr><span class="ft3">Mount Carmel</span></nobr></DIV>
<DIV style="position:absolute;top:361;left:248"><nobr><span class="ft3">Haifa, Israel</span></nobr></DIV>
<DIV style="position:absolute;top:381;left:207"><nobr><span class="ft1">ronen@cs.haifa.ac.il</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:561"><nobr><span class="ft1">Avi Wigderson</span></nobr></DIV>
<DIV style="position:absolute;top:301;left:681"><nobr><span class="ft2">§</span></nobr></DIV>
<DIV style="position:absolute;top:330;left:534"><nobr><span class="ft3">Institute for Advanced Study</span></nobr></DIV>
<DIV style="position:absolute;top:345;left:595"><nobr><span class="ft3">Princeton</span></nobr></DIV>
<DIV style="position:absolute;top:361;left:588"><nobr><span class="ft3">New Jersey</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:555"><nobr><span class="ft1">avi@math.ias.edu</span></nobr></DIV>
<DIV style="position:absolute;top:424;left:81"><nobr><span class="ft4"><b>ABSTRACT</b></span></nobr></DIV>
<DIV style="position:absolute;top:448;left:81"><nobr><span class="ft10">The main result of this paper is an explicit disperser for two<br>independent sources on n bits, each of entropy k = n</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:415"><nobr><span class="ft5">o(1)</span></nobr></DIV>
<DIV style="position:absolute;top:463;left:436"><nobr><span class="ft2">.</span></nobr></DIV>
<DIV style="position:absolute;top:479;left:81"><nobr><span class="ft2">Put differently, setting N = 2</span></nobr></DIV>
<DIV style="position:absolute;top:477;left:264"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:479;left:278"><nobr><span class="ft2">and K = 2</span></nobr></DIV>
<DIV style="position:absolute;top:477;left:346"><nobr><span class="ft5">k</span></nobr></DIV>
<DIV style="position:absolute;top:479;left:353"><nobr><span class="ft2">, we construct</span></nobr></DIV>
<DIV style="position:absolute;top:495;left:81"><nobr><span class="ft2">explicit N × N Boolean matrices for which no K × K sub-</span></nobr></DIV>
<DIV style="position:absolute;top:511;left:81"><nobr><span class="ft10">matrix is monochromatic. Viewed as adjacency matrices of<br>bipartite graphs, this gives an explicit construction of K-<br>Ramsey bipartite graphs of size N .</span></nobr></DIV>
<DIV style="position:absolute;top:558;left:94"><nobr><span class="ft2">This greatly improves the previous bound of k = o(n) of</span></nobr></DIV>
<DIV style="position:absolute;top:573;left:81"><nobr><span class="ft11">Barak, Kindler, Shaltiel, Sudakov and Wigderson [4]. It also<br>significantly improves the 25-year record of k = ~</span></nobr></DIV>
<DIV style="position:absolute;top:591;left:378"><nobr><span class="ft2">O(n) on</span></nobr></DIV>
<DIV style="position:absolute;top:606;left:81"><nobr><span class="ft10">the special case of Ramsey graphs, due to Frankl and Wilson<br>[9].</span></nobr></DIV>
<DIV style="position:absolute;top:638;left:94"><nobr><span class="ft2">The construction uses (besides "classical" extractor ideas)</span></nobr></DIV>
<DIV style="position:absolute;top:653;left:81"><nobr><span class="ft10">almost all of the machinery developed in the last couple of<br>years for extraction from independent sources, including:</span></nobr></DIV>
<DIV style="position:absolute;top:699;left:101"><nobr><span class="ft2">· Bourgain's extractor for 2 independent sources of some</span></nobr></DIV>
<DIV style="position:absolute;top:715;left:114"><nobr><span class="ft2">entropy rate &lt; 1/2 [5]</span></nobr></DIV>
<DIV style="position:absolute;top:748;left:101"><nobr><span class="ft2">· Raz's extractor for 2 independent sources, one of which</span></nobr></DIV>
<DIV style="position:absolute;top:763;left:114"><nobr><span class="ft2">has any entropy rate &gt; 1/2 [18]</span></nobr></DIV>
<DIV style="position:absolute;top:792;left:81"><nobr><span class="ft2">Supported by a Princeton University startup grant.</span></nobr></DIV>
<DIV style="position:absolute;top:811;left:81"><nobr><span class="ft2">Most of this work was done while the author was visiting</span></nobr></DIV>
<DIV style="position:absolute;top:831;left:81"><nobr><span class="ft12">Princeton University and the Institute for Advanced Study.<br>Supported in part by an MCD fellowship from UT Austin<br>and NSF Grant CCR-0310960.</span></nobr></DIV>
<DIV style="position:absolute;top:868;left:81"><nobr><span class="ft2">This research was supported by the United States-Israel</span></nobr></DIV>
<DIV style="position:absolute;top:890;left:81"><nobr><span class="ft13">Binational Science Foundation (BSF) grant 2004329.<br>§This research was supported by NSF Grant CCR-0324906.</span></nobr></DIV>
<DIV style="position:absolute;top:977;left:81"><nobr><span class="ft14">Permission to make digital or hard copies of all or part of this work for<br>personal or classroom use is granted without fee provided that copies are<br>not made or distributed for profit or commercial advantage and that copies<br>bear this notice and the full citation on the first page. To copy otherwise, to<br>republish, to post on servers or to redistribute to lists, requires prior specific<br>permission and/or a fee.<br><i>STOC'06, </i>May</span></nobr></DIV>
<DIV style="position:absolute;top:1054;left:153"><nobr><span class="ft6"> 21­23, 2006, Seattle, Washington, USA.</span></nobr></DIV>
<DIV style="position:absolute;top:1071;left:81"><nobr><span class="ft6">Copyright 2006 ACM 1-59593-134-1/06/0005 ...</span></nobr></DIV>
<DIV style="position:absolute;top:1069;left:315"><nobr><span class="ft2">$</span></nobr></DIV>
<DIV style="position:absolute;top:1071;left:322"><nobr><span class="ft6">5.00.</span></nobr></DIV>
<DIV style="position:absolute;top:426;left:495"><nobr><span class="ft2">· Rao's extractor for 2 independent block-sources of en-</span></nobr></DIV>
<DIV style="position:absolute;top:442;left:509"><nobr><span class="ft2">tropy n</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:554"><nobr><span class="ft5">(1)</span></nobr></DIV>
<DIV style="position:absolute;top:442;left:581"><nobr><span class="ft2">[17]</span></nobr></DIV>
<DIV style="position:absolute;top:471;left:495"><nobr><span class="ft2">· The "Challenge-Response" mechanism for detecting</span></nobr></DIV>
<DIV style="position:absolute;top:486;left:509"><nobr><span class="ft2">"entropy concentration" of [4].</span></nobr></DIV>
<DIV style="position:absolute;top:514;left:489"><nobr><span class="ft2">The main novelty comes in a bootstrap procedure which</span></nobr></DIV>
<DIV style="position:absolute;top:530;left:475"><nobr><span class="ft10">allows the Challenge-Response mechanism of [4] to be used<br>with sources of less and less entropy, using recursive calls<br>to itself. Subtleties arise since the success of this mecha-<br>nism depends on restricting the given sources, and so re-<br>cursion constantly changes the original sources. These are<br>resolved via a new construct, in between a disperser and<br>an extractor, which behaves like an extractor on sufficiently<br>large subsources of the given ones.</span></nobr></DIV>
<DIV style="position:absolute;top:655;left:489"><nobr><span class="ft2">This version is only an extended abstract, please see the</span></nobr></DIV>
<DIV style="position:absolute;top:671;left:475"><nobr><span class="ft10">full version, available on the authors' homepages, for more<br>details.</span></nobr></DIV>
<DIV style="position:absolute;top:723;left:475"><nobr><span class="ft4"><b>Categories and Subject Descriptors</b></span></nobr></DIV>
<DIV style="position:absolute;top:747;left:475"><nobr><span class="ft10">G.2.2 [Mathematics of Computing]: Discrete Mathe-<br>matics--Graph algorithms</span></nobr></DIV>
<DIV style="position:absolute;top:799;left:475"><nobr><span class="ft4"><b>General Terms</b></span></nobr></DIV>
<DIV style="position:absolute;top:823;left:475"><nobr><span class="ft2">Theory, Algorithms</span></nobr></DIV>
<DIV style="position:absolute;top:859;left:475"><nobr><span class="ft4"><b>Keywords</b></span></nobr></DIV>
<DIV style="position:absolute;top:883;left:475"><nobr><span class="ft10">Dispersers, Ramsey Graphs, Independent Sources, Extrac-<br>tors</span></nobr></DIV>
<DIV style="position:absolute;top:935;left:475"><nobr><span class="ft4"><b>1.</b></span></nobr></DIV>
<DIV style="position:absolute;top:935;left:507"><nobr><span class="ft4"><b>INTRODUCTION</b></span></nobr></DIV>
<DIV style="position:absolute;top:956;left:489"><nobr><span class="ft2">This paper deals with randomness extraction from weak</span></nobr></DIV>
<DIV style="position:absolute;top:972;left:475"><nobr><span class="ft10">random sources. Here a weak random source is a distribu-<br>tion which contains some entropy. The extraction task is to<br>design efficient algorithms (called extractors) to convert this<br>entropy into useful form, namely a sequence of independent<br>unbiased bits. Beyond the obvious motivations (potential<br>use of physical sources in pseudorandom generators and in<br>derandomization), extractors have found applications in a</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft9">671</span></nobr></DIV>
</DIV>
<!-- Page 2 -->
<a name="2"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft15{font-size:5px;font-family:Times;color:#000000;}
	.ft16{font-size:11px;line-height:18px;font-family:Times;color:#000000;}
	.ft17{font-size:15px;line-height:17px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="1002.png" alt="background image">
<DIV style="position:absolute;top:85;left:81"><nobr><span class="ft10">variety of areas in theoretical computer science where ran-<br>domness does not seem an issue, such as in efficient con-<br>structions of communication networks [24, 7], error correct-<br>ing codes [22, 12], data structures [14] and more.</span></nobr></DIV>
<DIV style="position:absolute;top:148;left:94"><nobr><span class="ft2">Most work in this subject over the last 20 years has fo-</span></nobr></DIV>
<DIV style="position:absolute;top:164;left:81"><nobr><span class="ft10">cused on what is now called seeded extraction, in which the<br>extractor is given as input not only the (sample from the)<br>defective random source, but also a few truly random bits<br>(called the seed). A comprehensive survey of much of this<br>body of work is [21].</span></nobr></DIV>
<DIV style="position:absolute;top:242;left:94"><nobr><span class="ft2">Another direction, which has been mostly dormant till</span></nobr></DIV>
<DIV style="position:absolute;top:258;left:81"><nobr><span class="ft10">about two years ago, is (seedless, deterministic) extraction<br>from a few independent weak sources. This kind of extrac-<br>tion is important in several applications where it is unrealis-<br>tic to have a short random seed or deterministically enumer-<br>ate over its possible values. However, it is easily shown to be<br>impossible when only one weak source is available. When at<br>least 2 independent sources are available extraction becomes<br>possible in principle. The 2-source case is the one we will<br>focus on in this work.</span></nobr></DIV>
<DIV style="position:absolute;top:399;left:94"><nobr><span class="ft2">The rest of the introduction is structured as follows. We'll</span></nobr></DIV>
<DIV style="position:absolute;top:415;left:81"><nobr><span class="ft10">start by describing our main result in the context of Ramsey<br>graphs. We then move to the context of extractors and dis-<br>perser, describing the relevant background and stating our<br>result in this language. Then we give an overview of the<br>construction of our dispersers, describing the main building<br>blocks we construct along the way. As the construction is<br>quite complex and its analysis quite subtle, in this proceed-<br>ings version we try to abstract away many of the technical<br>difficulties so that the main ideas, structure and tools used<br>are highlighted. For that reason we also often state defini-<br>tions and theorems somewhat informally.</span></nobr></DIV>
<DIV style="position:absolute;top:600;left:81"><nobr><span class="ft4"><b>1.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:600;left:121"><nobr><span class="ft4"><b>Ramsey Graphs</b></span></nobr></DIV>
<DIV style="position:absolute;top:638;left:96"><nobr><span class="ft2">Definition 1.1. A graph on N vertices is called a K-</span></nobr></DIV>
<DIV style="position:absolute;top:654;left:81"><nobr><span class="ft10">Ramsey Graph if it contains no clique or independent set of<br>size K.</span></nobr></DIV>
<DIV style="position:absolute;top:702;left:94"><nobr><span class="ft2">In 1947 Erd</span></nobr></DIV>
<DIV style="position:absolute;top:702;left:165"><nobr><span class="ft2">os published his paper inaugurating the Prob-</span></nobr></DIV>
<DIV style="position:absolute;top:718;left:81"><nobr><span class="ft10">abilistic Method with a few examples, including a proof that<br>most graphs on N = 2</span></nobr></DIV>
<DIV style="position:absolute;top:731;left:216"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:734;left:229"><nobr><span class="ft2">vertices are 2n-Ramsey. The quest</span></nobr></DIV>
<DIV style="position:absolute;top:750;left:81"><nobr><span class="ft10">for constructing such graphs explicitly has existed ever since<br>and lead to some beautiful mathematics.</span></nobr></DIV>
<DIV style="position:absolute;top:781;left:94"><nobr><span class="ft2">The best record to date was obtained in 1981 by Frankl</span></nobr></DIV>
<DIV style="position:absolute;top:796;left:81"><nobr><span class="ft16">and Wilson [9], who used intersection theorems for set sys-<br>tems to construct N -vertex graphs which are 2</span></nobr></DIV>
<DIV style="position:absolute;top:807;left:354"><nobr><span class="ft5">n log n</span></nobr></DIV>
<DIV style="position:absolute;top:815;left:395"><nobr><span class="ft2">-Ramsey.</span></nobr></DIV>
<DIV style="position:absolute;top:831;left:81"><nobr><span class="ft10">This bound was matched by Alon [1] using the Polynomial<br>Method, by Grolmusz [11] using low rank matrices over rings,<br>and also by Barak [2] boosting Abbot's method with almost<br>k-wise independent random variables (a construction that<br>was independently discovered by others as well). Remark-<br>ably all of these different approaches got stuck at essentially<br>the same bound. In recent work, Gopalan [10] showed that<br>other than the last construction, all of these can be viewed<br>as coming from low-degree symmetric representations of the<br>OR function. He also shows that any such symmetric rep-<br>resentation cannot be used to give a better Ramsey graph,<br>which gives a good indication of why these constructions<br>had similar performance. Indeed, as we will discuss in a<br>later section, the n entropy bound initially looked like a<br>natural obstacle even for our techniques, though eventually<br>we were able to surpass it.</span></nobr></DIV>
<DIV style="position:absolute;top:85;left:489"><nobr><span class="ft2">The analogous question for bipartite graphs seemed much</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:475"><nobr><span class="ft2">harder.</span></nobr></DIV>
<DIV style="position:absolute;top:132;left:490"><nobr><span class="ft2">Definition 1.2. A bipartite graph on two sets of N ver-</span></nobr></DIV>
<DIV style="position:absolute;top:147;left:475"><nobr><span class="ft2">tices is a K-Ramsey Bipartite Graph if it has no K × K</span></nobr></DIV>
<DIV style="position:absolute;top:163;left:475"><nobr><span class="ft2">complete or empty bipartite subgraph.</span></nobr></DIV>
<DIV style="position:absolute;top:194;left:489"><nobr><span class="ft2">While Erd</span></nobr></DIV>
<DIV style="position:absolute;top:194;left:550"><nobr><span class="ft2">os' result on the abundance of 2n-Ramsey graphs</span></nobr></DIV>
<DIV style="position:absolute;top:209;left:475"><nobr><span class="ft10">holds as is for bipartite graphs, until recently the best ex-<br>plicit construction of bipartite Ramsey graphs was 2</span></nobr></DIV>
<DIV style="position:absolute;top:223;left:810"><nobr><span class="ft5">n/2</span></nobr></DIV>
<DIV style="position:absolute;top:225;left:829"><nobr><span class="ft2">-</span></nobr></DIV>
<DIV style="position:absolute;top:241;left:475"><nobr><span class="ft10">Ramsey, using the Hadamard matrix. This was improved<br>last year, first to o(2</span></nobr></DIV>
<DIV style="position:absolute;top:254;left:599"><nobr><span class="ft5">n/2</span></nobr></DIV>
<DIV style="position:absolute;top:256;left:618"><nobr><span class="ft2">) by Pudlak and R</span></nobr></DIV>
<DIV style="position:absolute;top:256;left:731"><nobr><span class="ft2">odl [16] and then</span></nobr></DIV>
<DIV style="position:absolute;top:274;left:475"><nobr><span class="ft2">to 2</span></nobr></DIV>
<DIV style="position:absolute;top:271;left:498"><nobr><span class="ft5">o(n)</span></nobr></DIV>
<DIV style="position:absolute;top:274;left:523"><nobr><span class="ft2">by Barak, Kindler, Shaltiel, Sudakov and Wigderson</span></nobr></DIV>
<DIV style="position:absolute;top:289;left:475"><nobr><span class="ft2">[4].</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:489"><nobr><span class="ft2">It is convenient to view such graphs as functions f :</span></nobr></DIV>
<DIV style="position:absolute;top:321;left:475"><nobr><span class="ft2">({0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:318;left:514"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:321;left:522"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:318;left:527"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:321;left:539"><nobr><span class="ft2"> {0, 1}. This then gives exactly the definition</span></nobr></DIV>
<DIV style="position:absolute;top:336;left:475"><nobr><span class="ft2">of a disperser.</span></nobr></DIV>
<DIV style="position:absolute;top:367;left:490"><nobr><span class="ft2">Definition 1.3. A function f : ({0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:365;left:736"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:367;left:744"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:365;left:749"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:367;left:762"><nobr><span class="ft2"> {0, 1} is</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:475"><nobr><span class="ft10">called a 2-source disperser for entropy k if for any two sets<br>X, Y  {0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:396;left:556"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:398;left:569"><nobr><span class="ft2">with |X| = |Y | = 2</span></nobr></DIV>
<DIV style="position:absolute;top:396;left:681"><nobr><span class="ft5">k</span></nobr></DIV>
<DIV style="position:absolute;top:398;left:688"><nobr><span class="ft2">, we have that the image</span></nobr></DIV>
<DIV style="position:absolute;top:414;left:475"><nobr><span class="ft2">f (X, Y ) is {0, 1}.</span></nobr></DIV>
<DIV style="position:absolute;top:444;left:489"><nobr><span class="ft2">This allows for a more formal definition of explicitness: we</span></nobr></DIV>
<DIV style="position:absolute;top:460;left:475"><nobr><span class="ft10">simply demand that the function f is computable in polyno-<br>mial time. Most of the constructions mentioned above are<br>explicit in this sense.</span></nobr></DIV>
<DIV style="position:absolute;top:489;left:602"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:507;left:489"><nobr><span class="ft2">Our main result (stated informally) significantly improves</span></nobr></DIV>
<DIV style="position:absolute;top:523;left:475"><nobr><span class="ft2">the bounds in both the bipartite and non-bipartite settings:</span></nobr></DIV>
<DIV style="position:absolute;top:553;left:490"><nobr><span class="ft2">Theorem 1.4. For every N we construct polynomial time</span></nobr></DIV>
<DIV style="position:absolute;top:573;left:475"><nobr><span class="ft2">computable bipartite graphs which are 2</span></nobr></DIV>
<DIV style="position:absolute;top:570;left:706"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:570;left:713"><nobr><span class="ft15">o</span></nobr></DIV>
<DIV style="position:absolute;top:568;left:718"><nobr><span class="ft15">(1)</span></nobr></DIV>
<DIV style="position:absolute;top:573;left:733"><nobr><span class="ft2">-Ramsey. A stan-</span></nobr></DIV>
<DIV style="position:absolute;top:588;left:475"><nobr><span class="ft10">dard transformation of these graphs also yields polynomial<br>time computable ordinary Ramsey Graphs with the same pa-<br>rameters.</span></nobr></DIV>
<DIV style="position:absolute;top:648;left:475"><nobr><span class="ft4"><b>1.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:648;left:516"><nobr><span class="ft17"><b>Extractors and Dispersers from indepen-<br>dent sources</b></span></nobr></DIV>
<DIV style="position:absolute;top:687;left:489"><nobr><span class="ft2">Now we give a brief review of past relevant work (with the</span></nobr></DIV>
<DIV style="position:absolute;top:703;left:475"><nobr><span class="ft10">goal of putting this paper in proper context) and describe<br>some of the tools from these past works that we will use.<br>We start with the basic definitions of k-sources by Nisan<br>and Zuckerman [15] and of extractors and dispersers for in-<br>dependent sources by Santha and Vazirani [20].</span></nobr></DIV>
<DIV style="position:absolute;top:796;left:490"><nobr><span class="ft2">Definition 1.5</span></nobr></DIV>
<DIV style="position:absolute;top:796;left:603"><nobr><span class="ft2">([15], see also [8]). The min-entropy</span></nobr></DIV>
<DIV style="position:absolute;top:812;left:475"><nobr><span class="ft10">of a distribution X is the maximum k such that for every<br>element x in its support, Pr[X = x]  2</span></nobr></DIV>
<DIV style="position:absolute;top:827;left:723"><nobr><span class="ft5">-k</span></nobr></DIV>
<DIV style="position:absolute;top:827;left:738"><nobr><span class="ft2">. If X is a dis-</span></nobr></DIV>
<DIV style="position:absolute;top:843;left:475"><nobr><span class="ft10">tribution on strings with min-entropy at least k, we will call<br>X a k-source</span></nobr></DIV>
<DIV style="position:absolute;top:856;left:559"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:859;left:566"><nobr><span class="ft2">.</span></nobr></DIV>
<DIV style="position:absolute;top:889;left:489"><nobr><span class="ft2">To simplify the presentation, in this version of the paper</span></nobr></DIV>
<DIV style="position:absolute;top:905;left:475"><nobr><span class="ft10">we will assume that we are working with entropy as opposed<br>to min-entropy.</span></nobr></DIV>
<DIV style="position:absolute;top:951;left:490"><nobr><span class="ft2">Definition 1.6</span></nobr></DIV>
<DIV style="position:absolute;top:951;left:603"><nobr><span class="ft2">([20]). A function f : ({0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:949;left:793"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:951;left:800"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:949;left:806"><nobr><span class="ft5">c</span></nobr></DIV>
<DIV style="position:absolute;top:951;left:820"><nobr><span class="ft2"></span></nobr></DIV>
<DIV style="position:absolute;top:967;left:475"><nobr><span class="ft2">{0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:964;left:509"><nobr><span class="ft5">m</span></nobr></DIV>
<DIV style="position:absolute;top:967;left:524"><nobr><span class="ft2">is a c-source (k, ) extractor if for every family of c</span></nobr></DIV>
<DIV style="position:absolute;top:982;left:475"><nobr><span class="ft2">independent k-sources X</span></nobr></DIV>
<DIV style="position:absolute;top:987;left:621"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:982;left:627"><nobr><span class="ft2">,</span></nobr></DIV>
<DIV style="position:absolute;top:982;left:654"><nobr><span class="ft2">, X</span></nobr></DIV>
<DIV style="position:absolute;top:987;left:671"><nobr><span class="ft5">c</span></nobr></DIV>
<DIV style="position:absolute;top:982;left:677"><nobr><span class="ft2">, the output f (X</span></nobr></DIV>
<DIV style="position:absolute;top:987;left:773"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:982;left:780"><nobr><span class="ft2">,</span></nobr></DIV>
<DIV style="position:absolute;top:982;left:806"><nobr><span class="ft2">, X</span></nobr></DIV>
<DIV style="position:absolute;top:987;left:824"><nobr><span class="ft5">c</span></nobr></DIV>
<DIV style="position:absolute;top:982;left:830"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:1005;left:476"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:1007;left:482"><nobr><span class="ft2">The Abbot's product based Ramsey-graph construction of</span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:475"><nobr><span class="ft12">[3] and the bipartite Ramsey construction of [16] only satisfy<br>a weaker notion of explicitness.</span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:476"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:1050;left:482"><nobr><span class="ft2">It is no loss of generality to imagine that X is uniformly</span></nobr></DIV>
<DIV style="position:absolute;top:1066;left:475"><nobr><span class="ft2">distributed over some (unknown) set of size 2</span></nobr></DIV>
<DIV style="position:absolute;top:1064;left:750"><nobr><span class="ft5">k</span></nobr></DIV>
<DIV style="position:absolute;top:1066;left:757"><nobr><span class="ft2">.</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft9">672</span></nobr></DIV>
</DIV>
<!-- Page 3 -->
<a name="3"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft18{font-size:11px;line-height:16px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="1003.png" alt="background image">
<DIV style="position:absolute;top:85;left:81"><nobr><span class="ft2">is a -close</span></nobr></DIV>
<DIV style="position:absolute;top:83;left:152"><nobr><span class="ft5">3</span></nobr></DIV>
<DIV style="position:absolute;top:85;left:163"><nobr><span class="ft2">to uniformly distributed on m bits. f is a dis-</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:81"><nobr><span class="ft10">perser for the same parameters if the output is simply re-<br>quired to have a support of relative size (1 - ).</span></nobr></DIV>
<DIV style="position:absolute;top:141;left:94"><nobr><span class="ft2">To simplify the presentation, in this version of the paper,</span></nobr></DIV>
<DIV style="position:absolute;top:157;left:81"><nobr><span class="ft2">we will assume that  = 0 for all of our constructions.</span></nobr></DIV>
<DIV style="position:absolute;top:173;left:94"><nobr><span class="ft2">In this language, Erd</span></nobr></DIV>
<DIV style="position:absolute;top:173;left:220"><nobr><span class="ft2">os' theorem says that most functions</span></nobr></DIV>
<DIV style="position:absolute;top:188;left:81"><nobr><span class="ft2">f : ({0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:186;left:142"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:188;left:150"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:186;left:155"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:188;left:166"><nobr><span class="ft2"> {0,1} are dispersers for entropy 1 + log n</span></nobr></DIV>
<DIV style="position:absolute;top:204;left:81"><nobr><span class="ft10">(treating f as the characteristic function for the set of edges<br>of the graph). The proof easily extends to show that indeed<br>most such functions are in fact extractors. This naturally<br>challenges us to find explicit functions f that are 2-source<br>extractors.</span></nobr></DIV>
<DIV style="position:absolute;top:283;left:94"><nobr><span class="ft2">Until one year ago, essentially the only known explicit</span></nobr></DIV>
<DIV style="position:absolute;top:298;left:81"><nobr><span class="ft18">construction was the Hadamard extractor Had defined by<br>Had</span></nobr></DIV>
<DIV style="position:absolute;top:314;left:104"><nobr><span class="ft2">(x, y) = x, y ( mod 2). It is an extractor for entropy</span></nobr></DIV>
<DIV style="position:absolute;top:330;left:81"><nobr><span class="ft10">k &gt; n/2 as observed by Chor and Goldreich [8] and can<br>be extended to give m = (n) output bits as observed by<br>Vazirani [23]. Over 20 years later, a recent breakthrough<br>of Bourgain [5] broke this "1/2 barrier" and can handle 2<br>sources of entropy .4999n, again with linear output length<br>m = (n). This seemingly minor improvement will be cru-<br>cial for our work!</span></nobr></DIV>
<DIV style="position:absolute;top:448;left:96"><nobr><span class="ft2">Theorem 1.7</span></nobr></DIV>
<DIV style="position:absolute;top:448;left:198"><nobr><span class="ft2">([5]). There is a polynomial time com-</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:81"><nobr><span class="ft2">putable 2-source extractor f : ({0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:304"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:312"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:317"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:328"><nobr><span class="ft2"> {0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:381"><nobr><span class="ft5">m</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:397"><nobr><span class="ft2">for en-</span></nobr></DIV>
<DIV style="position:absolute;top:480;left:81"><nobr><span class="ft2">tropy .4999n and m = (n).</span></nobr></DIV>
<DIV style="position:absolute;top:504;left:94"><nobr><span class="ft2">No better bounds are known for 2-source extractors. Now</span></nobr></DIV>
<DIV style="position:absolute;top:520;left:81"><nobr><span class="ft10">we turn our attention to 2-source dispersers. It turned out<br>that progress for building good 2-source dispersers came via<br>progress on extractors for more than 2 sources, all happening<br>in fast pace in the last 2 years. The seminal paper of Bour-<br>gain, Katz and Tao [6] proved the so-called "sum-product<br>theorem" in prime fields, a result in arithmetic combina-<br>torics. This result has already found applications in diverse<br>areas of mathematics, including analysis, number theory,<br>group theory and ... extractor theory. Their work implic-<br>itly contained dispersers for c = O(log(n/k)) independent<br>sources of entropy k (with output m = (k)). The use of<br>the "sum-product" theorem was then extended by Barak et<br>al. [3] to give extractors with similar parameters. Note that<br>for linear entropy k = (n), the number of sources needed<br>for extraction c is a constant!</span></nobr></DIV>
<DIV style="position:absolute;top:755;left:94"><nobr><span class="ft2">Relaxing the independence assumptions via the idea of</span></nobr></DIV>
<DIV style="position:absolute;top:771;left:81"><nobr><span class="ft10">repeated condensing, allowed the reduction of the number<br>of independent sources to c = 3, for extraction from sources<br>of any linear entropy k = (n), by Barak et al. [4] and<br>independently by Raz [18].</span></nobr></DIV>
<DIV style="position:absolute;top:834;left:94"><nobr><span class="ft2">For 2 sources Barak et al. [4] were able to construct dis-</span></nobr></DIV>
<DIV style="position:absolute;top:849;left:81"><nobr><span class="ft10">persers for sources of entropy o(n). To do this, they first<br>showed that if the sources have extra structure (block-source<br>structure, defined below), even extraction is possible from 2<br>sources. The notion of block-sources, capturing "semi inde-<br>pendence" of parts of the source, was introduced by Chor<br>and Goldreich [8]. It has been fundamental in the develop-<br>ment of seeded extractors and as we shall see, is essential<br>for us as well.</span></nobr></DIV>
<DIV style="position:absolute;top:984;left:96"><nobr><span class="ft2">Definition 1.8</span></nobr></DIV>
<DIV style="position:absolute;top:984;left:209"><nobr><span class="ft2">([8]). A distribution X = X</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:385"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:984;left:392"><nobr><span class="ft2">, . . . , X</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:433"><nobr><span class="ft5">c</span></nobr></DIV>
<DIV style="position:absolute;top:999;left:81"><nobr><span class="ft2">is a c-block-source of (block) entropy k if every block X</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:435"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:81"><nobr><span class="ft10">has entropy k even conditioned on fixing the previous blocks<br>X</span></nobr></DIV>
<DIV style="position:absolute;top:1036;left:92"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:1031;left:98"><nobr><span class="ft2">,</span></nobr></DIV>
<DIV style="position:absolute;top:1031;left:125"><nobr><span class="ft2">, X</span></nobr></DIV>
<DIV style="position:absolute;top:1036;left:143"><nobr><span class="ft5">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:1031;left:166"><nobr><span class="ft2">to arbitrary constants.</span></nobr></DIV>
<DIV style="position:absolute;top:1050;left:81"><nobr><span class="ft5">3</span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:88"><nobr><span class="ft2">The error is usually measured in terms of </span></nobr></DIV>
<DIV style="position:absolute;top:1057;left:360"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:372"><nobr><span class="ft2">distance or</span></nobr></DIV>
<DIV style="position:absolute;top:1066;left:81"><nobr><span class="ft2">variation distance.</span></nobr></DIV>
<DIV style="position:absolute;top:85;left:489"><nobr><span class="ft2">This definition allowed Barak et al. [4] to show that their</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:475"><nobr><span class="ft10">extractor for 4 independent sources, actually performs as<br>well with only 2 independent sources, as long as both are<br>2-block-sources.</span></nobr></DIV>
<DIV style="position:absolute;top:161;left:490"><nobr><span class="ft2">Theorem 1.9</span></nobr></DIV>
<DIV style="position:absolute;top:161;left:593"><nobr><span class="ft2">([4]). There exists a polynomial time com-</span></nobr></DIV>
<DIV style="position:absolute;top:177;left:475"><nobr><span class="ft2">putable extractor f : ({0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:174;left:644"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:177;left:651"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:174;left:657"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:177;left:668"><nobr><span class="ft2"> {0, 1} for 2 independent</span></nobr></DIV>
<DIV style="position:absolute;top:192;left:475"><nobr><span class="ft2">2-block-sources with entropy o(n).</span></nobr></DIV>
<DIV style="position:absolute;top:221;left:489"><nobr><span class="ft2">There is no reason to assume that the given sources are</span></nobr></DIV>
<DIV style="position:absolute;top:237;left:475"><nobr><span class="ft10">block-sources, but it is natural to try and reduce to this<br>case. This approach has been one of the most successful in<br>the extractor literature. Namely try to partition a source<br>X into two blocks X = X</span></nobr></DIV>
<DIV style="position:absolute;top:288;left:644"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:284;left:650"><nobr><span class="ft2">, X</span></nobr></DIV>
<DIV style="position:absolute;top:288;left:667"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:284;left:680"><nobr><span class="ft2">such that X</span></nobr></DIV>
<DIV style="position:absolute;top:288;left:756"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:284;left:762"><nobr><span class="ft2">, X</span></nobr></DIV>
<DIV style="position:absolute;top:288;left:780"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:284;left:793"><nobr><span class="ft2">form a</span></nobr></DIV>
<DIV style="position:absolute;top:299;left:475"><nobr><span class="ft10">2-block-source. Barak et al. introduced a new technique to<br>do this reduction called the Challenge-Response mechanism,<br>which is crucial for this paper. This method gives a way to<br>"find" how entropy is distributed in a source X, guiding the<br>choice of such a partition. This method succeeds only with<br>small probability, dashing the hope for an extractor, but still<br>yielding a disperser.</span></nobr></DIV>
<DIV style="position:absolute;top:422;left:490"><nobr><span class="ft2">Theorem 1.10</span></nobr></DIV>
<DIV style="position:absolute;top:422;left:600"><nobr><span class="ft2">([4]). There exists a polynomial time</span></nobr></DIV>
<DIV style="position:absolute;top:438;left:475"><nobr><span class="ft2">computable 2-source disperser f : ({0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:435;left:729"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:438;left:737"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:435;left:742"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:438;left:755"><nobr><span class="ft2"> {0, 1} for</span></nobr></DIV>
<DIV style="position:absolute;top:453;left:475"><nobr><span class="ft2">entropy o(n).</span></nobr></DIV>
<DIV style="position:absolute;top:482;left:489"><nobr><span class="ft2">Reducing the entropy requirement of the above 2-source</span></nobr></DIV>
<DIV style="position:absolute;top:498;left:475"><nobr><span class="ft10">disperser, which is what we achieve in this paper, again<br>needed progress on achieving a similar reduction for extrac-<br>tors with more independent sources. A few months ago Rao<br>[?] was able to significantly improve all the above results<br>for c  3 sources. Interestingly, his techniques do not use</span></nobr></DIV>
<DIV style="position:absolute;top:576;left:475"><nobr><span class="ft10">arithmetic combinatorics, which seemed essential to all the<br>papers above. He improves the results of Barak et al. [3] to<br>give c = O((log n)/(log k))-source extractors for entropy k.<br>Note that now the number c of sources needed for extraction<br>is constant, even when the entropy is as low as n</span></nobr></DIV>
<DIV style="position:absolute;top:636;left:779"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:639;left:791"><nobr><span class="ft2">for any</span></nobr></DIV>
<DIV style="position:absolute;top:654;left:475"><nobr><span class="ft2">constant !</span></nobr></DIV>
<DIV style="position:absolute;top:670;left:489"><nobr><span class="ft2">Again, when the input sources are block-sources with suf-</span></nobr></DIV>
<DIV style="position:absolute;top:686;left:475"><nobr><span class="ft10">ficiently many blocks, Rao proves that 2 independent sources<br>suffice (though this result does rely on arithmetic combina-<br>torics, in particular, on Bourgain's extractor).</span></nobr></DIV>
<DIV style="position:absolute;top:746;left:490"><nobr><span class="ft2">Theorem 1.11</span></nobr></DIV>
<DIV style="position:absolute;top:746;left:600"><nobr><span class="ft2">([?]). There is a polynomial time com-</span></nobr></DIV>
<DIV style="position:absolute;top:761;left:475"><nobr><span class="ft2">putable extractor f : ({0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:759;left:639"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:761;left:647"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:759;left:652"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:761;left:662"><nobr><span class="ft2"> {0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:759;left:714"><nobr><span class="ft5">m</span></nobr></DIV>
<DIV style="position:absolute;top:761;left:729"><nobr><span class="ft2">for 2 independent</span></nobr></DIV>
<DIV style="position:absolute;top:777;left:475"><nobr><span class="ft10">c-block-sources with block entropy k and m = (k), as long<br>as c = O((log n)/(log k)).</span></nobr></DIV>
<DIV style="position:absolute;top:821;left:489"><nobr><span class="ft2">In this paper (see Theorem 2.7 below) we improve this</span></nobr></DIV>
<DIV style="position:absolute;top:837;left:475"><nobr><span class="ft10">result to hold even when only one of the 2 sources is a c-<br>block-source. The other source can be an arbitrary source<br>with sufficient entropy. This is a central building block in<br>our construction. This extractor, like Rao's above, critically<br>uses Bourgain's extractor mentioned above. In addition it<br>uses a theorem of Raz [18] allowing seeded extractors to have<br>"weak" seeds, namely instead of being completely random<br>they work as long as the seed has entropy rate &gt; 1/2.</span></nobr></DIV>
<DIV style="position:absolute;top:980;left:475"><nobr><span class="ft4"><b>2.</b></span></nobr></DIV>
<DIV style="position:absolute;top:980;left:507"><nobr><span class="ft4"><b>MAIN NOTIONS AND NEW RESULTS</b></span></nobr></DIV>
<DIV style="position:absolute;top:1002;left:489"><nobr><span class="ft2">The main result of this paper is a polynomial time com-</span></nobr></DIV>
<DIV style="position:absolute;top:1017;left:475"><nobr><span class="ft2">putable disperser for 2 sources of entropy n</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:733"><nobr><span class="ft5">o(1)</span></nobr></DIV>
<DIV style="position:absolute;top:1017;left:754"><nobr><span class="ft2">, significantly</span></nobr></DIV>
<DIV style="position:absolute;top:1033;left:475"><nobr><span class="ft11">improving both the results of Barak et al. [4] (o(n) entropy).<br>It also improves on Frankl and Wilson [9], who only built<br>Ramsey Graphs and only for entropy ~</span></nobr></DIV>
<DIV style="position:absolute;top:1066;left:705"><nobr><span class="ft2">O(n).</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft9">673</span></nobr></DIV>
</DIV>
<!-- Page 4 -->
<a name="4"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft19{font-size:15px;line-height:20px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="1004.png" alt="background image">
<DIV style="position:absolute;top:85;left:96"><nobr><span class="ft2">Theorem 2.1</span></nobr></DIV>
<DIV style="position:absolute;top:85;left:198"><nobr><span class="ft2">(Main theorem, restated). There ex-</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:81"><nobr><span class="ft10">ists a polynomial time computable 2-source disperser D :<br>({0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:115;left:120"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:117;left:127"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:115;left:133"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:117;left:143"><nobr><span class="ft2"> {0, 1} for entropy n</span></nobr></DIV>
<DIV style="position:absolute;top:115;left:279"><nobr><span class="ft5">o(1)</span></nobr></DIV>
<DIV style="position:absolute;top:117;left:300"><nobr><span class="ft2">.</span></nobr></DIV>
<DIV style="position:absolute;top:146;left:94"><nobr><span class="ft2">The construction of this disperser will involve the con-</span></nobr></DIV>
<DIV style="position:absolute;top:162;left:81"><nobr><span class="ft10">struction of an object which in some sense is stronger and<br>in another weaker than a disperser: a subsource somewhere<br>extractor. We first define a related object: a somewhere ex-<br>tractor, which is a function producing several outputs, one of<br>which must be uniform. Again we will ignore many technical<br>issues such as error, min-entropy vs. entropy and more, in<br>definitions and results, which are deferred to the full version<br>of this paper.</span></nobr></DIV>
<DIV style="position:absolute;top:301;left:96"><nobr><span class="ft2">Definition 2.2. A function f : ({0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:299;left:335"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:301;left:343"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:299;left:348"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:301;left:360"><nobr><span class="ft2"> ({0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:299;left:418"><nobr><span class="ft5">m</span></nobr></DIV>
<DIV style="position:absolute;top:301;left:429"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:299;left:434"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:317;left:81"><nobr><span class="ft10">is a 2-source somewhere extractor with  outputs, for entropy<br>k, if for every 2 independent k-sources X, Y there exists an<br>i  [] such the ith output f(X,Y )</span></nobr></DIV>
<DIV style="position:absolute;top:353;left:282"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:290"><nobr><span class="ft2">is a uniformly distributed</span></nobr></DIV>
<DIV style="position:absolute;top:364;left:81"><nobr><span class="ft2">string of m bits.</span></nobr></DIV>
<DIV style="position:absolute;top:393;left:94"><nobr><span class="ft2">Here is a simple construction of such a somewhere extrac-</span></nobr></DIV>
<DIV style="position:absolute;top:409;left:81"><nobr><span class="ft18">tor with  as large as poly(n) (and the p in its name will<br>stress the fact that indeed the number of outputs is that<br>large). It will nevertheless be useful to us (though its de-<br>scription in the next sentence may be safely skipped). Define<br>pSE</span></nobr></DIV>
<DIV style="position:absolute;top:472;left:104"><nobr><span class="ft2">(x, y)</span></nobr></DIV>
<DIV style="position:absolute;top:477;left:136"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:472;left:146"><nobr><span class="ft2">= V(E(x, i), E(y, i)) where E is a "strong" loga-</span></nobr></DIV>
<DIV style="position:absolute;top:488;left:81"><nobr><span class="ft10">rithmic seed extractor, and V is the Hadamard/Vazirani 2-<br>source extractor. Using this construction, it is easy to see<br>that:</span></nobr></DIV>
<DIV style="position:absolute;top:548;left:96"><nobr><span class="ft2">Proposition 2.3. For every n, k there is a polynomial</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:81"><nobr><span class="ft2">time computable somewhere extractor pSE : ({0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:562;left:399"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:407"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:562;left:412"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:426"><nobr><span class="ft2"></span></nobr></DIV>
<DIV style="position:absolute;top:580;left:81"><nobr><span class="ft2">({0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:578;left:120"><nobr><span class="ft5">m</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:131"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:578;left:136"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:580;left:145"><nobr><span class="ft2">with  = poly(n) outputs, for entropy k, and m =</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:81"><nobr><span class="ft2">(k).</span></nobr></DIV>
<DIV style="position:absolute;top:625;left:94"><nobr><span class="ft2">Before we define subsource somewhere extractor, we must</span></nobr></DIV>
<DIV style="position:absolute;top:641;left:81"><nobr><span class="ft2">first define a subsource.</span></nobr></DIV>
<DIV style="position:absolute;top:670;left:96"><nobr><span class="ft2">Definition 2.4</span></nobr></DIV>
<DIV style="position:absolute;top:670;left:209"><nobr><span class="ft2">(Subsources). Given random variables</span></nobr></DIV>
<DIV style="position:absolute;top:688;left:81"><nobr><span class="ft2">Z and ^</span></nobr></DIV>
<DIV style="position:absolute;top:688;left:121"><nobr><span class="ft2">Z on {0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:685;left:187"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:688;left:199"><nobr><span class="ft2">we say that ^</span></nobr></DIV>
<DIV style="position:absolute;top:688;left:268"><nobr><span class="ft2">Z is a deficiency d subsource</span></nobr></DIV>
<DIV style="position:absolute;top:705;left:81"><nobr><span class="ft2">of Z and write ^</span></nobr></DIV>
<DIV style="position:absolute;top:705;left:175"><nobr><span class="ft2">Z  Z if there exists a set A  {0,1}</span></nobr></DIV>
<DIV style="position:absolute;top:703;left:400"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:705;left:413"><nobr><span class="ft2">such</span></nobr></DIV>
<DIV style="position:absolute;top:723;left:81"><nobr><span class="ft2">that (Z|Z  A) = ^Z and Pr[Z  A]  2</span></nobr></DIV>
<DIV style="position:absolute;top:722;left:318"><nobr><span class="ft5">-d</span></nobr></DIV>
<DIV style="position:absolute;top:723;left:333"><nobr><span class="ft2">.</span></nobr></DIV>
<DIV style="position:absolute;top:752;left:94"><nobr><span class="ft2">A subsource somewhere extractor guarantees the "some-</span></nobr></DIV>
<DIV style="position:absolute;top:768;left:81"><nobr><span class="ft2">where extractor" property only on subsources X</span></nobr></DIV>
<DIV style="position:absolute;top:768;left:374"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:768;left:379"><nobr><span class="ft2">, Y</span></nobr></DIV>
<DIV style="position:absolute;top:768;left:396"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:768;left:404"><nobr><span class="ft2">of the</span></nobr></DIV>
<DIV style="position:absolute;top:784;left:81"><nobr><span class="ft10">original input distributions X, Y (respectively). It will be<br>extremely important for us to make these subsources as large<br>as possible (i.e. we have to lose as little entropy as possible).<br>Controlling these entropy deficiencies is a major technical<br>complication we have to deal with. However we will be in-<br>formal with it here, mentioning it only qualitatively when<br>needed. We discuss this issue a little more in Section 6.</span></nobr></DIV>
<DIV style="position:absolute;top:907;left:96"><nobr><span class="ft2">Definition 2.5. A function f : ({0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:905;left:335"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:907;left:343"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:905;left:348"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:907;left:360"><nobr><span class="ft2"> ({0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:905;left:418"><nobr><span class="ft5">m</span></nobr></DIV>
<DIV style="position:absolute;top:907;left:429"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:905;left:434"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:923;left:81"><nobr><span class="ft10">is a 2-source subsource somewhere extractor with  outputs<br>for entropy k, if for every 2 independent k-sources X, Y there<br>exists a subsource ^</span></nobr></DIV>
<DIV style="position:absolute;top:955;left:189"><nobr><span class="ft2">X of X, a subsource ^</span></nobr></DIV>
<DIV style="position:absolute;top:955;left:314"><nobr><span class="ft2">Y of Y and an i  []</span></nobr></DIV>
<DIV style="position:absolute;top:972;left:81"><nobr><span class="ft2">such the i</span></nobr></DIV>
<DIV style="position:absolute;top:970;left:138"><nobr><span class="ft5">th</span></nobr></DIV>
<DIV style="position:absolute;top:972;left:153"><nobr><span class="ft2">output f ( ^</span></nobr></DIV>
<DIV style="position:absolute;top:972;left:208"><nobr><span class="ft2">X, ^</span></nobr></DIV>
<DIV style="position:absolute;top:972;left:227"><nobr><span class="ft2">Y )</span></nobr></DIV>
<DIV style="position:absolute;top:977;left:244"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:972;left:252"><nobr><span class="ft2">is a uniformly distributed string</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:81"><nobr><span class="ft2">of m bits.</span></nobr></DIV>
<DIV style="position:absolute;top:1017;left:94"><nobr><span class="ft2">A central technical result for us is that with this "sub-</span></nobr></DIV>
<DIV style="position:absolute;top:1033;left:81"><nobr><span class="ft11">source" relaxation, we can have much fewer outputs ­ in-<br>deed we'll replace poly(n) outputs in our first construction<br>above with n</span></nobr></DIV>
<DIV style="position:absolute;top:1064;left:160"><nobr><span class="ft5">o(1)</span></nobr></DIV>
<DIV style="position:absolute;top:1066;left:185"><nobr><span class="ft2">outputs.</span></nobr></DIV>
<DIV style="position:absolute;top:85;left:490"><nobr><span class="ft2">Theorem 2.6</span></nobr></DIV>
<DIV style="position:absolute;top:85;left:593"><nobr><span class="ft2">(Subsource somewhere extractor).</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:475"><nobr><span class="ft10">For every  &gt; 0 there is a polynomial time computable sub-<br>source somewhere extractor SSE : ({0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:115;left:728"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:117;left:735"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:115;left:741"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:117;left:753"><nobr><span class="ft2"> ({0,1}</span></nobr></DIV>
<DIV style="position:absolute;top:115;left:812"><nobr><span class="ft5">m</span></nobr></DIV>
<DIV style="position:absolute;top:117;left:823"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:115;left:829"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:134;left:475"><nobr><span class="ft2">with  = n</span></nobr></DIV>
<DIV style="position:absolute;top:132;left:547"><nobr><span class="ft5">o(1)</span></nobr></DIV>
<DIV style="position:absolute;top:134;left:574"><nobr><span class="ft2">outputs, for entropy k = n</span></nobr></DIV>
<DIV style="position:absolute;top:132;left:746"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:134;left:752"><nobr><span class="ft2">, with output</span></nobr></DIV>
<DIV style="position:absolute;top:150;left:475"><nobr><span class="ft2">m = k.</span></nobr></DIV>
<DIV style="position:absolute;top:177;left:489"><nobr><span class="ft2">We will describe the ideas used for constructing this im-</span></nobr></DIV>
<DIV style="position:absolute;top:193;left:475"><nobr><span class="ft10">portant object and analyzing it in the next section, where<br>we will also indicate how it is used in the construction of<br>the final disperser. Here we state a central building block,<br>mentioned in the previous section (as an improvement of the<br>work of Rao [?]). We construct an extractor for 2 indepen-<br>dent sources one of which is a block-sources with sufficient<br>number of blocks.</span></nobr></DIV>
<DIV style="position:absolute;top:314;left:490"><nobr><span class="ft2">Theorem 2.7</span></nobr></DIV>
<DIV style="position:absolute;top:314;left:593"><nobr><span class="ft2">(Block Source Extractor). There is</span></nobr></DIV>
<DIV style="position:absolute;top:329;left:475"><nobr><span class="ft2">a polynomial time computable extractor B : ({0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:327;left:793"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:329;left:801"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:327;left:807"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:329;left:820"><nobr><span class="ft2"></span></nobr></DIV>
<DIV style="position:absolute;top:345;left:475"><nobr><span class="ft2">{0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:343;left:509"><nobr><span class="ft5">m</span></nobr></DIV>
<DIV style="position:absolute;top:345;left:524"><nobr><span class="ft2">for 2 independent sources, one of which is a c-block-</span></nobr></DIV>
<DIV style="position:absolute;top:361;left:475"><nobr><span class="ft10">sources with block entropy k and the other a source of en-<br>tropy k, with m = (k), and c = O((log n)/(log k)).</span></nobr></DIV>
<DIV style="position:absolute;top:403;left:489"><nobr><span class="ft2">A simple corollary of this block-source extractor B, is the</span></nobr></DIV>
<DIV style="position:absolute;top:419;left:475"><nobr><span class="ft10">following weaker (though useful) somewhere block-source<br>extractor SB. A source Z = Z</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:662"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:435;left:669"><nobr><span class="ft2">, Z</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:684"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:435;left:690"><nobr><span class="ft2">,</span></nobr></DIV>
<DIV style="position:absolute;top:435;left:717"><nobr><span class="ft2">, Z</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:733"><nobr><span class="ft5">t</span></nobr></DIV>
<DIV style="position:absolute;top:435;left:743"><nobr><span class="ft2">is a somewhere</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:475"><nobr><span class="ft2">c-block-source of block entropy k if for some c indices i</span></nobr></DIV>
<DIV style="position:absolute;top:455;left:812"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:823"><nobr><span class="ft2">&lt;</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:475"><nobr><span class="ft2">i</span></nobr></DIV>
<DIV style="position:absolute;top:471;left:480"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:490"><nobr><span class="ft2">&lt;</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:525"><nobr><span class="ft2">&lt; i</span></nobr></DIV>
<DIV style="position:absolute;top:471;left:544"><nobr><span class="ft5">c</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:554"><nobr><span class="ft2">the source Z</span></nobr></DIV>
<DIV style="position:absolute;top:471;left:628"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:474;left:632"><nobr><span class="ft15">1</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:638"><nobr><span class="ft2">, Z</span></nobr></DIV>
<DIV style="position:absolute;top:471;left:654"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:474;left:658"><nobr><span class="ft15">2</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:665"><nobr><span class="ft2">,</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:691"><nobr><span class="ft2">, Z</span></nobr></DIV>
<DIV style="position:absolute;top:471;left:707"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:476;left:711"><nobr><span class="ft15">c</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:721"><nobr><span class="ft2">is a c-block-source.</span></nobr></DIV>
<DIV style="position:absolute;top:482;left:475"><nobr><span class="ft10">Collecting the outputs of B on every c-subset of blocks re-<br>sults in that somewhere extractor.</span></nobr></DIV>
<DIV style="position:absolute;top:524;left:490"><nobr><span class="ft2">Corollary 2.8. There is a polynomial time computable</span></nobr></DIV>
<DIV style="position:absolute;top:540;left:475"><nobr><span class="ft2">somewhere extractor SB : ({0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:538;left:667"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:540;left:675"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:538;left:681"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:540;left:691"><nobr><span class="ft2"> ({0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:538;left:747"><nobr><span class="ft5">m</span></nobr></DIV>
<DIV style="position:absolute;top:540;left:758"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:538;left:764"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:540;left:772"><nobr><span class="ft2">for 2 inde-</span></nobr></DIV>
<DIV style="position:absolute;top:556;left:475"><nobr><span class="ft10">pendent sources, one of which is a somewhere c-block-sources<br>with block entropy k and t blocks total and the other a source<br>of entropy k, with m = (k), c = O((log n)/(log k)), and<br>  t</span></nobr></DIV>
<DIV style="position:absolute;top:600;left:504"><nobr><span class="ft5">c</span></nobr></DIV>
<DIV style="position:absolute;top:603;left:510"><nobr><span class="ft2">.</span></nobr></DIV>
<DIV style="position:absolute;top:630;left:489"><nobr><span class="ft2">In both the theorem and corollary above, the values of</span></nobr></DIV>
<DIV style="position:absolute;top:645;left:475"><nobr><span class="ft2">entropy k we will be interested in are k = n</span></nobr></DIV>
<DIV style="position:absolute;top:643;left:744"><nobr><span class="ft5">(1)</span></nobr></DIV>
<DIV style="position:absolute;top:645;left:767"><nobr><span class="ft2">. It follows</span></nobr></DIV>
<DIV style="position:absolute;top:661;left:475"><nobr><span class="ft2">that a block-source with a constant c = O(1) suffices.</span></nobr></DIV>
<DIV style="position:absolute;top:694;left:475"><nobr><span class="ft4"><b>3.</b></span></nobr></DIV>
<DIV style="position:absolute;top:694;left:507"><nobr><span class="ft19"><b>THE CHALLENGE-RESPONSE MECH-<br>ANISM</b></span></nobr></DIV>
<DIV style="position:absolute;top:736;left:489"><nobr><span class="ft2">We now describe abstractly a mechanism which will be</span></nobr></DIV>
<DIV style="position:absolute;top:752;left:475"><nobr><span class="ft10">used in the construction of the disperser as well as the sub-<br>source somewhere extractor. Intuitively, this mechanism al-<br>lows us to identify parts of a source which contain large<br>amounts of entropy. One can hope that using such a mech-<br>anism one can partition a given source into blocks in a way<br>which make it a block-source, or alternatively focus on a part<br>of the source which is unusually condensed with entropy -<br>two cases which may simplify the extraction problem.</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:489"><nobr><span class="ft2">The reader may decide, now or in the middle of this</span></nobr></DIV>
<DIV style="position:absolute;top:893;left:475"><nobr><span class="ft10">section, to skip ahead to the next section which describes<br>the construction of the subsource somewhere extractor SSE,<br>which extensively uses this mechanism. Then this section<br>may seem less abstract, as it will be clearer where this mech-<br>anism is used.</span></nobr></DIV>
<DIV style="position:absolute;top:972;left:489"><nobr><span class="ft2">This mechanism was introduced by Barak et al. [4], and</span></nobr></DIV>
<DIV style="position:absolute;top:987;left:475"><nobr><span class="ft10">was essential in their 2-source disperser. Its use in this paper<br>is far more involved (in particular it calls itself recursively,<br>a fact which creates many subtleties). However, at a high<br>level, the basic idea behind the mechanism is the same:</span></nobr></DIV>
<DIV style="position:absolute;top:1050;left:489"><nobr><span class="ft2">Let Z be a source and Z</span></nobr></DIV>
<DIV style="position:absolute;top:1050;left:641"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:1050;left:651"><nobr><span class="ft2">a part of Z (Z projected on a</span></nobr></DIV>
<DIV style="position:absolute;top:1066;left:475"><nobr><span class="ft2">subset of the coordinates). We know that Z has entropy k,</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft9">674</span></nobr></DIV>
</DIV>
<!-- Page 5 -->
<a name="5"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="1005.png" alt="background image">
<DIV style="position:absolute;top:85;left:81"><nobr><span class="ft2">and want to distinguish two possibilities: Z</span></nobr></DIV>
<DIV style="position:absolute;top:85;left:342"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:85;left:351"><nobr><span class="ft2">has no entropy</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:81"><nobr><span class="ft2">(it is fixed) or it has at least k</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:268"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:101;left:278"><nobr><span class="ft2">entropy. Z</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:344"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:101;left:353"><nobr><span class="ft2">will get a pass</span></nobr></DIV>
<DIV style="position:absolute;top:117;left:81"><nobr><span class="ft10">or fail grade, hopefully corresponding to the cases of high or<br>no entropy in Z</span></nobr></DIV>
<DIV style="position:absolute;top:132;left:177"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:133;left:181"><nobr><span class="ft2">.</span></nobr></DIV>
<DIV style="position:absolute;top:148;left:94"><nobr><span class="ft2">Anticipating the use of this mechanism, it is a good idea</span></nobr></DIV>
<DIV style="position:absolute;top:164;left:81"><nobr><span class="ft2">to think of Z as a "parent" of Z</span></nobr></DIV>
<DIV style="position:absolute;top:163;left:282"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:164;left:286"><nobr><span class="ft2">, which wants to check if</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:81"><nobr><span class="ft10">this "child" has sufficient entropy. Moreover, in the context<br>of the initial 2 sources X, Y we will operate on, think of Z<br>as a part of X, and thus that Y is independent of Z and Z</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:431"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:211;left:436"><nobr><span class="ft2">.</span></nobr></DIV>
<DIV style="position:absolute;top:227;left:94"><nobr><span class="ft2">To execute this "test" we will compute two sets of strings</span></nobr></DIV>
<DIV style="position:absolute;top:242;left:81"><nobr><span class="ft2">(all of length m, say): the Challenge C = C(Z</span></nobr></DIV>
<DIV style="position:absolute;top:242;left:384"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:242;left:388"><nobr><span class="ft2">, Y ) and</span></nobr></DIV>
<DIV style="position:absolute;top:258;left:81"><nobr><span class="ft2">the Response R = R(Z, Y ). Z</span></nobr></DIV>
<DIV style="position:absolute;top:258;left:270"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:258;left:280"><nobr><span class="ft2">fails if C  R and passes</span></nobr></DIV>
<DIV style="position:absolute;top:274;left:81"><nobr><span class="ft2">otherwise.</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:94"><nobr><span class="ft2">The key to the usefulness of this mechanism is the follow-</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:81"><nobr><span class="ft10">ing lemma, which states that what "should" happen, indeed<br>happens after some restriction of the 2 sources Z and Y .<br>We state it and then explain how the functions C and R are<br>defined to accommodate its proof.</span></nobr></DIV>
<DIV style="position:absolute;top:381;left:96"><nobr><span class="ft2">Lemma 3.1. Assume Z, Y are sources of entropy k.</span></nobr></DIV>
<DIV style="position:absolute;top:408;left:96"><nobr><span class="ft2">1. If Z</span></nobr></DIV>
<DIV style="position:absolute;top:407;left:139"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:408;left:147"><nobr><span class="ft2">has entropy k</span></nobr></DIV>
<DIV style="position:absolute;top:407;left:228"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:408;left:234"><nobr><span class="ft2">+ O(m), then there are subsources</span></nobr></DIV>
<DIV style="position:absolute;top:422;left:117"><nobr><span class="ft2">^</span></nobr></DIV>
<DIV style="position:absolute;top:425;left:114"><nobr><span class="ft2">Z of Z and ^</span></nobr></DIV>
<DIV style="position:absolute;top:425;left:188"><nobr><span class="ft2">Y of Y , such that</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:114"><nobr><span class="ft2">Pr[ ^</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:133"><nobr><span class="ft2">Z</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:143"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:451;left:152"><nobr><span class="ft2">passes] = Pr[C( ^</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:244"><nobr><span class="ft2">Z</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:254"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:451;left:258"><nobr><span class="ft2">, ^</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:265"><nobr><span class="ft2">Y )</span></nobr></DIV>
<DIV style="position:absolute;top:452;left:300"><nobr><span class="ft2">R</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:309"><nobr><span class="ft2">( ^</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:314"><nobr><span class="ft2">Z, ^</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:330"><nobr><span class="ft2">Y )]  1-n</span></nobr></DIV>
<DIV style="position:absolute;top:448;left:395"><nobr><span class="ft5">O(1)</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:419"><nobr><span class="ft2">2</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:426"><nobr><span class="ft5">-m</span></nobr></DIV>
<DIV style="position:absolute;top:481;left:96"><nobr><span class="ft2">2. If Z</span></nobr></DIV>
<DIV style="position:absolute;top:481;left:138"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:481;left:146"><nobr><span class="ft2">is fixed (namely, has zero entropy), then for some</span></nobr></DIV>
<DIV style="position:absolute;top:499;left:114"><nobr><span class="ft2">subsources ^</span></nobr></DIV>
<DIV style="position:absolute;top:499;left:182"><nobr><span class="ft2">Z of Z and ^</span></nobr></DIV>
<DIV style="position:absolute;top:499;left:255"><nobr><span class="ft2">Y of Y , we have</span></nobr></DIV>
<DIV style="position:absolute;top:523;left:152"><nobr><span class="ft2">Pr[Z</span></nobr></DIV>
<DIV style="position:absolute;top:522;left:181"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:523;left:190"><nobr><span class="ft2">fails] = Pr[C( ^</span></nobr></DIV>
<DIV style="position:absolute;top:523;left:270"><nobr><span class="ft2">Z</span></nobr></DIV>
<DIV style="position:absolute;top:522;left:280"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:523;left:284"><nobr><span class="ft2">, ^</span></nobr></DIV>
<DIV style="position:absolute;top:523;left:290"><nobr><span class="ft2">Y )  R( ^Z, ^Y)] = 1</span></nobr></DIV>
<DIV style="position:absolute;top:553;left:94"><nobr><span class="ft2">Once we have such a mechanism, we will design our dis-</span></nobr></DIV>
<DIV style="position:absolute;top:569;left:81"><nobr><span class="ft10">perser algorithm assuming that the challenge response mech-<br>anism correctly identifies parts of the source with high or<br>low levels of entropy. Then in the analysis, we will ensure<br>that our algorithm succeeds in making the right decisions,<br>at least on subsources of the original input sources.</span></nobr></DIV>
<DIV style="position:absolute;top:647;left:94"><nobr><span class="ft2">Now let us explain how to compute the sets C and R. We</span></nobr></DIV>
<DIV style="position:absolute;top:663;left:81"><nobr><span class="ft10">will use some of the constructs above with parameters which<br>don't quite fit.</span></nobr></DIV>
<DIV style="position:absolute;top:694;left:94"><nobr><span class="ft2">The response set R(Z, Y ) = pSE(Z, Y ) is chosen to be the</span></nobr></DIV>
<DIV style="position:absolute;top:710;left:81"><nobr><span class="ft10">output of the somewhere extractor of Proposition 2.3. The<br>challenge set C(Z</span></nobr></DIV>
<DIV style="position:absolute;top:725;left:185"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:726;left:189"><nobr><span class="ft2">, Y ) = SSE(Z</span></nobr></DIV>
<DIV style="position:absolute;top:725;left:269"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:726;left:274"><nobr><span class="ft2">, Y ) is chosen to be the out-</span></nobr></DIV>
<DIV style="position:absolute;top:742;left:81"><nobr><span class="ft2">put of the subsource somewhere extractor of Theorem 2.6.</span></nobr></DIV>
<DIV style="position:absolute;top:757;left:94"><nobr><span class="ft2">Why does it work? We explain each of the two claims</span></nobr></DIV>
<DIV style="position:absolute;top:773;left:81"><nobr><span class="ft10">in the lemma in turn (and after each comment on the im-<br>portant parameters and how they differ from Barak et al.<br>[4]).</span></nobr></DIV>
<DIV style="position:absolute;top:831;left:97"><nobr><span class="ft2">1. Z</span></nobr></DIV>
<DIV style="position:absolute;top:830;left:125"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:831;left:134"><nobr><span class="ft2">has entropy. We need to show that Z</span></nobr></DIV>
<DIV style="position:absolute;top:830;left:368"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:831;left:378"><nobr><span class="ft2">passes the</span></nobr></DIV>
<DIV style="position:absolute;top:846;left:114"><nobr><span class="ft10">test with high probability. We will point to the out-<br>put string in C( ^</span></nobr></DIV>
<DIV style="position:absolute;top:862;left:207"><nobr><span class="ft2">Z</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:217"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:862;left:221"><nobr><span class="ft2">, ^</span></nobr></DIV>
<DIV style="position:absolute;top:862;left:227"><nobr><span class="ft2">Y</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:239"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:862;left:242"><nobr><span class="ft2">) which avoids R( ^</span></nobr></DIV>
<DIV style="position:absolute;top:862;left:346"><nobr><span class="ft2">Z, ^</span></nobr></DIV>
<DIV style="position:absolute;top:862;left:362"><nobr><span class="ft2">Y ) with high</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:114"><nobr><span class="ft10">probability as follows. In the analysis we will use the<br>union bound on several events, one associated with<br>each (poly(n) many) string in pSE( ^</span></nobr></DIV>
<DIV style="position:absolute;top:909;left:338"><nobr><span class="ft2">Z, ^</span></nobr></DIV>
<DIV style="position:absolute;top:909;left:355"><nobr><span class="ft2">Y ). We note</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:114"><nobr><span class="ft18">that by the definition of the response function, if we<br>want to fix a particular element in the response set to<br>a particular value, we can do this by fixing E(Z, i) and<br>E</span></nobr></DIV>
<DIV style="position:absolute;top:972;left:123"><nobr><span class="ft2">(Y, i). This fixing keeps the restricted sources inde-</span></nobr></DIV>
<DIV style="position:absolute;top:987;left:114"><nobr><span class="ft10">pendent and loses only O(m) entropy. In the subsource<br>of Z</span></nobr></DIV>
<DIV style="position:absolute;top:1002;left:139"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:1003;left:147"><nobr><span class="ft2">guaranteed to exist by Theorem 2.6 we can afford</span></nobr></DIV>
<DIV style="position:absolute;top:1019;left:114"><nobr><span class="ft2">to lose this entropy in Z</span></nobr></DIV>
<DIV style="position:absolute;top:1018;left:262"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:1019;left:266"><nobr><span class="ft2">. Thus we conclude that one</span></nobr></DIV>
<DIV style="position:absolute;top:1034;left:114"><nobr><span class="ft10">of its outputs is uniform. The probability that this<br>output will equal any fixed value is thus 2</span></nobr></DIV>
<DIV style="position:absolute;top:1050;left:381"><nobr><span class="ft5">-m</span></nobr></DIV>
<DIV style="position:absolute;top:1050;left:400"><nobr><span class="ft2">, com-</span></nobr></DIV>
<DIV style="position:absolute;top:1066;left:114"><nobr><span class="ft2">pleting the argument. We note that we can handle</span></nobr></DIV>
<DIV style="position:absolute;top:85;left:509"><nobr><span class="ft10">the polynomial output size of pSE, since the uniform<br>string has length m = n</span></nobr></DIV>
<DIV style="position:absolute;top:99;left:660"><nobr><span class="ft5">(1)</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:689"><nobr><span class="ft2">(something which could</span></nobr></DIV>
<DIV style="position:absolute;top:117;left:509"><nobr><span class="ft10">not be done with the technology available to Barak et<br>al. [4]).</span></nobr></DIV>
<DIV style="position:absolute;top:158;left:491"><nobr><span class="ft2">2. Z</span></nobr></DIV>
<DIV style="position:absolute;top:157;left:519"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:158;left:529"><nobr><span class="ft2">has no entropy. We now need to guarantee that</span></nobr></DIV>
<DIV style="position:absolute;top:174;left:509"><nobr><span class="ft2">in the chosen subsources (which we choose) ^</span></nobr></DIV>
<DIV style="position:absolute;top:174;left:782"><nobr><span class="ft2">Z, ^</span></nobr></DIV>
<DIV style="position:absolute;top:174;left:799"><nobr><span class="ft2">Y , all</span></nobr></DIV>
<DIV style="position:absolute;top:191;left:509"><nobr><span class="ft2">strings in C = C( ^</span></nobr></DIV>
<DIV style="position:absolute;top:191;left:619"><nobr><span class="ft2">Z</span></nobr></DIV>
<DIV style="position:absolute;top:191;left:629"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:191;left:633"><nobr><span class="ft2">, ^</span></nobr></DIV>
<DIV style="position:absolute;top:191;left:639"><nobr><span class="ft2">Y ) are in R( ^</span></nobr></DIV>
<DIV style="position:absolute;top:191;left:717"><nobr><span class="ft2">Z, ^</span></nobr></DIV>
<DIV style="position:absolute;top:191;left:734"><nobr><span class="ft2">Y ). First notice</span></nobr></DIV>
<DIV style="position:absolute;top:207;left:509"><nobr><span class="ft2">that as Z</span></nobr></DIV>
<DIV style="position:absolute;top:206;left:570"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:207;left:580"><nobr><span class="ft2">is fixed, C is only a function of Y . We</span></nobr></DIV>
<DIV style="position:absolute;top:223;left:509"><nobr><span class="ft2">set ~</span></nobr></DIV>
<DIV style="position:absolute;top:223;left:532"><nobr><span class="ft2">Y to be the subsource of Y that fixes all strings</span></nobr></DIV>
<DIV style="position:absolute;top:238;left:509"><nobr><span class="ft11">in C = C(Y ) to their most popular values (losing<br>only m entropy from Y ). We take care of includ-<br>ing these fixed strings in R(Z, ~</span></nobr></DIV>
<DIV style="position:absolute;top:271;left:700"><nobr><span class="ft2">Y ) one at a time, by</span></nobr></DIV>
<DIV style="position:absolute;top:287;left:509"><nobr><span class="ft10">restricting to subsources assuring that. Let  be any<br>m-bit string we want to appear in R(Z, ~</span></nobr></DIV>
<DIV style="position:absolute;top:303;left:742"><nobr><span class="ft2">Y ). Recall that</span></nobr></DIV>
<DIV style="position:absolute;top:319;left:509"><nobr><span class="ft2">R</span></nobr></DIV>
<DIV style="position:absolute;top:318;left:518"><nobr><span class="ft2">(z, y) = V(E(z, i), E(y, i)). We pick a "good" seed i,</span></nobr></DIV>
<DIV style="position:absolute;top:336;left:509"><nobr><span class="ft2">and restrict Z, ~</span></nobr></DIV>
<DIV style="position:absolute;top:336;left:606"><nobr><span class="ft2">Y to subsources with only O(m) less</span></nobr></DIV>
<DIV style="position:absolute;top:353;left:509"><nobr><span class="ft2">entropy by fixing E(Z, i) = a and E( ~</span></nobr></DIV>
<DIV style="position:absolute;top:353;left:725"><nobr><span class="ft2">Y , i) = b to values</span></nobr></DIV>
<DIV style="position:absolute;top:369;left:509"><nobr><span class="ft10">(a, b) for which V(a, b) = . This is repeated suc-<br>cessively  times, and results in the final subsources</span></nobr></DIV>
<DIV style="position:absolute;top:397;left:512"><nobr><span class="ft2">^</span></nobr></DIV>
<DIV style="position:absolute;top:400;left:509"><nobr><span class="ft2">Z, ^</span></nobr></DIV>
<DIV style="position:absolute;top:400;left:525"><nobr><span class="ft2">Y on which ^</span></nobr></DIV>
<DIV style="position:absolute;top:400;left:602"><nobr><span class="ft2">Z</span></nobr></DIV>
<DIV style="position:absolute;top:399;left:612"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:400;left:622"><nobr><span class="ft2">fails with probability 1. Note that</span></nobr></DIV>
<DIV style="position:absolute;top:416;left:509"><nobr><span class="ft11">we keep reducing the entropy of our sources  times,<br>which necessitates that this  be tiny (here we could<br>not tolerate poly(n), and indeed can guarantee n</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:810"><nobr><span class="ft5">o(1)</span></nobr></DIV>
<DIV style="position:absolute;top:449;left:830"><nobr><span class="ft2">,</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:509"><nobr><span class="ft10">at least on a subsource ­ this is one aspect of how cru-<br>cial the subsource somewhere extractor SSE is to the<br>construction.</span></nobr></DIV>
<DIV style="position:absolute;top:520;left:489"><nobr><span class="ft2">We note that initially it seemed like the Challenge-Response</span></nobr></DIV>
<DIV style="position:absolute;top:536;left:475"><nobr><span class="ft10">mechanism as used in [4] could not be used to handle en-<br>tropy that is significantly less than n (which is approxi-<br>mately the bound that many of the previous constructions<br>got stuck at). The techniques of [4] involved partitioning<br>the sources into t pieces of length n/t each, with the hope<br>that one of those parts would have a significant amount of<br>entropy, yet there'd be enough entropy left over in the rest<br>of the source (so that the source can be partitioned into a<br>block source).</span></nobr></DIV>
<DIV style="position:absolute;top:677;left:489"><nobr><span class="ft2">However it is not clear how to do this when the total</span></nobr></DIV>
<DIV style="position:absolute;top:693;left:475"><nobr><span class="ft10">entropy is less than n. On the one hand we will have<br>to partition our sources into blocks of length significantly<br>more than n (or the adversary could distribute a negligible<br>fraction of entropy in all blocks). On the other hand, if<br>our blocks are so large, a single block could contain all the<br>entropy. Thus it was not clear how to use the challenge<br>response mechanism to find a block source.</span></nobr></DIV>
<DIV style="position:absolute;top:820;left:475"><nobr><span class="ft4"><b>4.</b></span></nobr></DIV>
<DIV style="position:absolute;top:820;left:507"><nobr><span class="ft19"><b>THE SUBSOURCE SOMEWHERE<br>EXTRACTOR</b></span></nobr></DIV>
<DIV style="position:absolute;top:843;left:624"><nobr><span class="ft2">SSE</span></nobr></DIV>
<DIV style="position:absolute;top:862;left:489"><nobr><span class="ft2">We now explain some of the ideas behind the construction</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:475"><nobr><span class="ft10">of the subsource somewhere extractor SSE of Theorem 2.6.<br>Consider the source X. We are seeking to find in it a some-<br>where c-block-source, so that we can use it (together with Y )<br>in the block-source extractor of Theorem 2.8. Like in previ-<br>ous works in the extractor literature (e.g. [19, 13]) we use a<br>"win-win" analysis which shows that either X is already a<br>somewhere c-block-source, or it has a condensed part which<br>contains a lot of the entropy of the source. In this case we<br>proceed recursively on that part. Continuing this way we<br>eventually reach a source so condensed that it must be a<br>somewhere block source. Note that in [4], the challenge re-<br>sponse mechanism was used to find a block source also, but<br>there the entropy was so high that they could afford to use</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft9">675</span></nobr></DIV>
</DIV>
<!-- Page 6 -->
<a name="6"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft20{font-size:12px;font-family:Times;color:#000000;}
	.ft21{font-size:17px;font-family:Times;color:#000000;}
	.ft22{font-size:15px;font-family:Times;color:#000000;}
	.ft23{font-size:15px;font-family:Times;color:#000000;}
	.ft24{font-size:12px;line-height:13px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="1006.png" alt="background image">
<DIV style="position:absolute;top:112;left:459"><nobr><span class="ft20">t blocks</span></nobr></DIV>
<DIV style="position:absolute;top:154;left:286"><nobr><span class="ft20">low</span></nobr></DIV>
<DIV style="position:absolute;top:154;left:421"><nobr><span class="ft20">high</span></nobr></DIV>
<DIV style="position:absolute;top:154;left:348"><nobr><span class="ft20">med</span></nobr></DIV>
<DIV style="position:absolute;top:88;left:452"><nobr><span class="ft20">n bits total</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:500"><nobr><span class="ft20">t blocks</span></nobr></DIV>
<DIV style="position:absolute;top:310;left:272"><nobr><span class="ft20">med</span></nobr></DIV>
<DIV style="position:absolute;top:310;left:345"><nobr><span class="ft20">med</span></nobr></DIV>
<DIV style="position:absolute;top:310;left:414"><nobr><span class="ft20">low</span></nobr></DIV>
<DIV style="position:absolute;top:310;left:483"><nobr><span class="ft20">high</span></nobr></DIV>
<DIV style="position:absolute;top:244;left:196"><nobr><span class="ft20">responded</span></nobr></DIV>
<DIV style="position:absolute;top:230;left:196"><nobr><span class="ft20">Challenge</span></nobr></DIV>
<DIV style="position:absolute;top:230;left:279"><nobr><span class="ft24">Challenge<br>responded</span></nobr></DIV>
<DIV style="position:absolute;top:213;left:504"><nobr><span class="ft20">Challenge Unresponded</span></nobr></DIV>
<DIV style="position:absolute;top:310;left:552"><nobr><span class="ft20">med</span></nobr></DIV>
<DIV style="position:absolute;top:310;left:622"><nobr><span class="ft20">med</span></nobr></DIV>
<DIV style="position:absolute;top:258;left:497"><nobr><span class="ft20">n/t bits total</span></nobr></DIV>
<DIV style="position:absolute;top:136;left:687"><nobr><span class="ft20">SB</span></nobr></DIV>
<DIV style="position:absolute;top:292;left:687"><nobr><span class="ft20">SB</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:708"><nobr><span class="ft20">Outputs</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:168"><nobr><span class="ft20">Somewhere Block Source!</span></nobr></DIV>
<DIV style="position:absolute;top:84;left:120"><nobr><span class="ft20">Not Somewhere block source</span></nobr></DIV>
<DIV style="position:absolute;top:150;left:220"><nobr><span class="ft21">X</span></nobr></DIV>
<DIV style="position:absolute;top:356;left:580"><nobr><span class="ft22">Random Row</span></nobr></DIV>
<DIV style="position:absolute;top:181;left:189"><nobr><span class="ft20">&lt; k'</span></nobr></DIV>
<DIV style="position:absolute;top:393;left:424"><nobr><span class="ft20">0&lt; low &lt; k'/t</span></nobr></DIV>
<DIV style="position:absolute;top:434;left:421"><nobr><span class="ft20">k'/c &lt; high &lt; k'</span></nobr></DIV>
<DIV style="position:absolute;top:413;left:421"><nobr><span class="ft20">k'/t &lt; med &lt; k'/c</span></nobr></DIV>
<DIV style="position:absolute;top:473;left:256"><nobr><span class="ft2">Figure 1: Analysis of the subsource somewhere extractor.</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:81"><nobr><span class="ft10">a tree of depth 1. They did not need to recurse or condense<br>the sources.</span></nobr></DIV>
<DIV style="position:absolute;top:548;left:94"><nobr><span class="ft2">Consider the tree of parts of the source X evolved by</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:81"><nobr><span class="ft10">such recursion. Each node in the tree corresponds to some<br>interval of bit locations of the source, with the root node<br>corresponding to the entire source. A node is a child of an-<br>other if its interval is a subinterval of the parent. It can be<br>shown that some node in the tree is "good"; it corresponds<br>to a somewhere c-source, but we don't know which node is<br>good. Since we only want a somewhere extractor, we can<br>apply to each node the somewhere block-source extractor of<br>Corollary 2.8 ­ this will give us a random output in every<br>"good" node of the tree. The usual idea is output all these<br>values (and in seeded extractors, merge them using the ex-<br>ternally given random seed). However, we cannot afford to<br>do that here as there is no external seed and the number of<br>these outputs (the size of the tree) is far too large.</span></nobr></DIV>
<DIV style="position:absolute;top:784;left:94"><nobr><span class="ft2">Our aim then will be to significantly prune this number</span></nobr></DIV>
<DIV style="position:absolute;top:799;left:81"><nobr><span class="ft10">of candidates and in fact output only the candidates on one<br>path to a canonical "good" node. First we will give a very in-<br>formal description of how to do this (Figure 1). Before call-<br>ing SSE recursively on a subpart of a current part of X, we'll<br>use the "Challenge-Response" mechanism described above<br>to check if "it has entropy".</span></nobr></DIV>
<DIV style="position:absolute;top:876;left:249"><nobr><span class="ft5">4</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:262"><nobr><span class="ft2">We will recurse only with the</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:81"><nobr><span class="ft10">first (in left-to-right order) part which passes the "entropy<br>test". Thus note that we will follow a single path on this<br>tree. The algorithm SSE will output only the sets of strings<br>produced by applying the somewhere c-block-extractor SB<br>on the parts visited along this path.</span></nobr></DIV>
<DIV style="position:absolute;top:972;left:94"><nobr><span class="ft2">Now let us describe the algorithm for SSE. SSE will be</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:81"><nobr><span class="ft10">initially invoked as SSE(x, y), but will recursively call itself<br>with different inputs z which will always be substrings of x.</span></nobr></DIV>
<DIV style="position:absolute;top:1037;left:81"><nobr><span class="ft5">4</span></nobr></DIV>
<DIV style="position:absolute;top:1039;left:88"><nobr><span class="ft2">We note that we ignore the additional complication that</span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:81"><nobr><span class="ft2">SSE</span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:108"><nobr><span class="ft2">will actually use recursion also to compute the challenge</span></nobr></DIV>
<DIV style="position:absolute;top:1066;left:81"><nobr><span class="ft2">in the challenge-response mechanism.</span></nobr></DIV>
<DIV style="position:absolute;top:514;left:489"><nobr><span class="ft23">Algorithm: SSE</span></nobr></DIV>
<DIV style="position:absolute;top:514;left:624"><nobr><span class="ft23">(z, y)</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:489"><nobr><span class="ft2">Let pSE(., .) be the somewhere extractor with a polyno-</span></nobr></DIV>
<DIV style="position:absolute;top:548;left:475"><nobr><span class="ft2">mial number of outputs of Proposition 2.3.</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:489"><nobr><span class="ft2">Let SB be the somewhere block source extractor of Corol-</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:475"><nobr><span class="ft2">lary 2.8.</span></nobr></DIV>
<DIV style="position:absolute;top:595;left:489"><nobr><span class="ft2">Global Parameters: t, the branching factor of the tree. k</span></nobr></DIV>
<DIV style="position:absolute;top:611;left:475"><nobr><span class="ft2">the original entropy of the sources.</span></nobr></DIV>
<DIV style="position:absolute;top:627;left:489"><nobr><span class="ft2">Output will be a set of strings.</span></nobr></DIV>
<DIV style="position:absolute;top:656;left:491"><nobr><span class="ft2">1. If z is shorter than k, return the empty set, else</span></nobr></DIV>
<DIV style="position:absolute;top:671;left:509"><nobr><span class="ft2">continue.</span></nobr></DIV>
<DIV style="position:absolute;top:697;left:491"><nobr><span class="ft2">2. Partition z into t equal parts z = z</span></nobr></DIV>
<DIV style="position:absolute;top:702;left:721"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:697;left:727"><nobr><span class="ft2">, z</span></nobr></DIV>
<DIV style="position:absolute;top:702;left:740"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:697;left:746"><nobr><span class="ft2">, . . . , z</span></nobr></DIV>
<DIV style="position:absolute;top:702;left:783"><nobr><span class="ft5">t</span></nobr></DIV>
<DIV style="position:absolute;top:697;left:788"><nobr><span class="ft2">.</span></nobr></DIV>
<DIV style="position:absolute;top:723;left:491"><nobr><span class="ft2">3. Compute the response set R(z, y) which is the set of</span></nobr></DIV>
<DIV style="position:absolute;top:739;left:509"><nobr><span class="ft2">strings output by pSE(z, y).</span></nobr></DIV>
<DIV style="position:absolute;top:765;left:491"><nobr><span class="ft2">4. For i  [t], compute the challenge set C(z</span></nobr></DIV>
<DIV style="position:absolute;top:770;left:766"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:765;left:771"><nobr><span class="ft2">, y), which</span></nobr></DIV>
<DIV style="position:absolute;top:781;left:509"><nobr><span class="ft2">is the set of outputs of SSE(z</span></nobr></DIV>
<DIV style="position:absolute;top:786;left:686"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:781;left:691"><nobr><span class="ft2">, y).</span></nobr></DIV>
<DIV style="position:absolute;top:807;left:491"><nobr><span class="ft2">5. Let h be the smallest index for which the challenge set</span></nobr></DIV>
<DIV style="position:absolute;top:823;left:509"><nobr><span class="ft2">C</span></nobr></DIV>
<DIV style="position:absolute;top:823;left:518"><nobr><span class="ft2">(z</span></nobr></DIV>
<DIV style="position:absolute;top:828;left:530"><nobr><span class="ft5">h</span></nobr></DIV>
<DIV style="position:absolute;top:823;left:537"><nobr><span class="ft2">, y) is not contained in the response set (set h = t</span></nobr></DIV>
<DIV style="position:absolute;top:838;left:509"><nobr><span class="ft2">if no such index exists).</span></nobr></DIV>
<DIV style="position:absolute;top:865;left:491"><nobr><span class="ft2">6. Output SB(z, y) concatenated with SSE(z</span></nobr></DIV>
<DIV style="position:absolute;top:870;left:761"><nobr><span class="ft5">h</span></nobr></DIV>
<DIV style="position:absolute;top:865;left:769"><nobr><span class="ft2">, y).</span></nobr></DIV>
<DIV style="position:absolute;top:893;left:489"><nobr><span class="ft2">Proving that indeed there are subsources on which SSE</span></nobr></DIV>
<DIV style="position:absolute;top:909;left:475"><nobr><span class="ft10">will follow a path to a "good" (for these subsources) node,<br>is the heart of the analysis. It is especially complex due<br>to the fact that the recursive call to SSE on subparts of<br>the current part is used to generate the Challenges for the<br>Challenge-Response mechanism. Since SSE works only on<br>a subsources we have to guarantee that restriction to these<br>does not hamper the behavior of SSE in past and future calls<br>to it.</span></nobr></DIV>
<DIV style="position:absolute;top:1034;left:489"><nobr><span class="ft2">Let us turn to the highlights of the analysis, for the proof</span></nobr></DIV>
<DIV style="position:absolute;top:1050;left:475"><nobr><span class="ft2">of Theorem 2.6. Let k</span></nobr></DIV>
<DIV style="position:absolute;top:1050;left:615"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:1050;left:625"><nobr><span class="ft2">be the entropy of the source Z at</span></nobr></DIV>
<DIV style="position:absolute;top:1066;left:475"><nobr><span class="ft2">some place in this recursion. Either one of its blocks Z</span></nobr></DIV>
<DIV style="position:absolute;top:1071;left:805"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:1066;left:814"><nobr><span class="ft2">has</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft9">676</span></nobr></DIV>
</DIV>
<!-- Page 7 -->
<a name="7"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="1007.png" alt="background image">
<DIV style="position:absolute;top:85;left:81"><nobr><span class="ft2">entropy k</span></nobr></DIV>
<DIV style="position:absolute;top:85;left:140"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:85;left:144"><nobr><span class="ft2">/c, in which case it is very condensed, since its</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:81"><nobr><span class="ft2">size is n/t for t  c), or it must be that c of its blocks form</span></nobr></DIV>
<DIV style="position:absolute;top:117;left:81"><nobr><span class="ft2">a c-block source with block entropy k</span></nobr></DIV>
<DIV style="position:absolute;top:116;left:307"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:117;left:311"><nobr><span class="ft2">/t (which is sufficient</span></nobr></DIV>
<DIV style="position:absolute;top:133;left:81"><nobr><span class="ft10">for the extractor B used by SB). In the 2nd case the fact<br>that SB(z, y) is part of the output of of our SSE guarantees<br>that we are somewhere random. If the 2nd case doesn't hold,<br>let Z</span></nobr></DIV>
<DIV style="position:absolute;top:184;left:110"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:120"><nobr><span class="ft2">be the leftmost condensed block. We want to ensure</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:81"><nobr><span class="ft10">that (on appropriate subsources) SSE calls itself on that ith<br>subpart. To do so, we fix all Z</span></nobr></DIV>
<DIV style="position:absolute;top:216;left:259"><nobr><span class="ft5">j</span></nobr></DIV>
<DIV style="position:absolute;top:211;left:269"><nobr><span class="ft2">for j &lt; i to constants z</span></nobr></DIV>
<DIV style="position:absolute;top:216;left:405"><nobr><span class="ft5">j</span></nobr></DIV>
<DIV style="position:absolute;top:211;left:411"><nobr><span class="ft2">. We</span></nobr></DIV>
<DIV style="position:absolute;top:227;left:81"><nobr><span class="ft10">are now in the position described in the Challenge-Response<br>mechanism section, that (in each of the first i parts) there<br>is either no entropy or lots of entropy. We further restrict<br>to subsources as explained there which make all first i - 1</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:81"><nobr><span class="ft2">blocks fail the "entropy test", and the fact that Z</span></nobr></DIV>
<DIV style="position:absolute;top:294;left:383"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:392"><nobr><span class="ft2">still has</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:81"><nobr><span class="ft10">lots of entropy after these restrictions (which we need to<br>prove) ensures that indeed SSE will be recursively applied<br>to it.</span></nobr></DIV>
<DIV style="position:absolute;top:352;left:94"><nobr><span class="ft2">We note that while the procedure SSE can be described re-</span></nobr></DIV>
<DIV style="position:absolute;top:368;left:81"><nobr><span class="ft10">cursively, the formal analysis of fixing subsources is actually<br>done globally, to ensure that indeed all entropy requirements<br>are met along the various recursive calls.</span></nobr></DIV>
<DIV style="position:absolute;top:415;left:94"><nobr><span class="ft2">Let us remark on the choice of the branching parameter t.</span></nobr></DIV>
<DIV style="position:absolute;top:431;left:81"><nobr><span class="ft10">On the one hand, we'd like to keep it small, as it dominates<br>the number of outputs t</span></nobr></DIV>
<DIV style="position:absolute;top:444;left:222"><nobr><span class="ft5">c</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:231"><nobr><span class="ft2">of SB, and thus the total number of</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:81"><nobr><span class="ft2">outputs (which is t</span></nobr></DIV>
<DIV style="position:absolute;top:460;left:196"><nobr><span class="ft5">c</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:204"><nobr><span class="ft2">log</span></nobr></DIV>
<DIV style="position:absolute;top:469;left:222"><nobr><span class="ft5">t</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:229"><nobr><span class="ft2">n). For this purpose, any t = n</span></nobr></DIV>
<DIV style="position:absolute;top:460;left:419"><nobr><span class="ft5">o(1)</span></nobr></DIV>
<DIV style="position:absolute;top:478;left:81"><nobr><span class="ft10">will do. On the other hand, t should be large enough so that<br>condensing is faster than losing entropy. Here note that if<br>Z is of length n, its child has length n/t, while the entropy<br>shrinks only from k</span></nobr></DIV>
<DIV style="position:absolute;top:524;left:195"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:525;left:202"><nobr><span class="ft2">to k</span></nobr></DIV>
<DIV style="position:absolute;top:524;left:225"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:525;left:229"><nobr><span class="ft2">/c. A simple calculation shows that</span></nobr></DIV>
<DIV style="position:absolute;top:542;left:81"><nobr><span class="ft2">if k</span></nobr></DIV>
<DIV style="position:absolute;top:540;left:102"><nobr><span class="ft5">(log t)/ log c)</span></nobr></DIV>
<DIV style="position:absolute;top:542;left:169"><nobr><span class="ft2">&gt; n</span></nobr></DIV>
<DIV style="position:absolute;top:540;left:193"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:542;left:204"><nobr><span class="ft2">then a c block-source must exist along</span></nobr></DIV>
<DIV style="position:absolute;top:558;left:81"><nobr><span class="ft10">such a path before the length shrinks to k. Note that for<br>k = n</span></nobr></DIV>
<DIV style="position:absolute;top:571;left:117"><nobr><span class="ft5">(1)</span></nobr></DIV>
<DIV style="position:absolute;top:574;left:145"><nobr><span class="ft2">a (large enough) constant t suffices (resulting in</span></nobr></DIV>
<DIV style="position:absolute;top:589;left:81"><nobr><span class="ft10">only logarithmic number of outputs of SSE). This analysis<br>is depicted pictorially in Figure 1.</span></nobr></DIV>
<DIV style="position:absolute;top:644;left:81"><nobr><span class="ft4"><b>5.</b></span></nobr></DIV>
<DIV style="position:absolute;top:644;left:112"><nobr><span class="ft4"><b>THE FINAL DISPERSER</b></span></nobr></DIV>
<DIV style="position:absolute;top:646;left:319"><nobr><span class="ft2">D</span></nobr></DIV>
<DIV style="position:absolute;top:665;left:94"><nobr><span class="ft2">Following is a rough description of our disperser D proving</span></nobr></DIV>
<DIV style="position:absolute;top:681;left:81"><nobr><span class="ft10">Theorem 2.1. The high level structure of D will resemble the<br>structure of SSE - we will recursively split the source X and<br>look for entropy in the parts. However now we must output<br>a single value (rather than a set) which can take both values<br>0 and 1. This was problematic in SSE, even knowing where<br>the "good" part (containing a c-block-source) was! How can<br>we do so now?</span></nobr></DIV>
<DIV style="position:absolute;top:791;left:94"><nobr><span class="ft2">We now have at our disposal a much more powerful tool</span></nobr></DIV>
<DIV style="position:absolute;top:806;left:81"><nobr><span class="ft10">for generating challenges (and thus detecting entropy), namely<br>the subsource somewhere disperser SSE. Note that in con-<br>structing SSE we only had essentially the somewhere c-block-<br>source extractor SB to (recursively) generate the challenges,<br>but it depended on a structural property of the block it was<br>applied on. Now SSE does not assume any structure on its<br>input sources except sufficient entropy</span></nobr></DIV>
<DIV style="position:absolute;top:898;left:317"><nobr><span class="ft5">5</span></nobr></DIV>
<DIV style="position:absolute;top:901;left:323"><nobr><span class="ft2">.</span></nobr></DIV>
<DIV style="position:absolute;top:916;left:94"><nobr><span class="ft2">Let us now give a high level description of the disperser</span></nobr></DIV>
<DIV style="position:absolute;top:932;left:81"><nobr><span class="ft2">D</span></nobr></DIV>
<DIV style="position:absolute;top:932;left:91"><nobr><span class="ft2">. It too will be a recursive procedure. If when processing</span></nobr></DIV>
<DIV style="position:absolute;top:948;left:81"><nobr><span class="ft2">some part Z of X it "realizes" that a subpart Z</span></nobr></DIV>
<DIV style="position:absolute;top:952;left:377"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:948;left:387"><nobr><span class="ft2">of Z has</span></nobr></DIV>
<DIV style="position:absolute;top:963;left:81"><nobr><span class="ft2">entropy, but not all the entropy of Z (namely Z</span></nobr></DIV>
<DIV style="position:absolute;top:968;left:389"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:963;left:393"><nobr><span class="ft2">, Z is a</span></nobr></DIV>
<DIV style="position:absolute;top:979;left:81"><nobr><span class="ft10">2-block-source) then we will halt and produce the output<br>of D. Intuitively, thinking about the Challenge-Response<br>mechanism described above, the analysis implies that we</span></nobr></DIV>
<DIV style="position:absolute;top:1037;left:81"><nobr><span class="ft5">5</span></nobr></DIV>
<DIV style="position:absolute;top:1039;left:88"><nobr><span class="ft2">There is a catch ­ it only works on subsources of them!</span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:81"><nobr><span class="ft12">This will cause us a lot of head ache; we will elaborate on it<br>later.</span></nobr></DIV>
<DIV style="position:absolute;top:85;left:475"><nobr><span class="ft2">can either pass or fail Z</span></nobr></DIV>
<DIV style="position:absolute;top:90;left:620"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:85;left:630"><nobr><span class="ft2">(on appropriate subsources). But</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:475"><nobr><span class="ft10">this means that the outcome of this "entropy test" is a 1-bit<br>disperser!</span></nobr></DIV>
<DIV style="position:absolute;top:133;left:489"><nobr><span class="ft2">To capitalize on this idea, we want to use SSE to identify</span></nobr></DIV>
<DIV style="position:absolute;top:148;left:475"><nobr><span class="ft10">such a block-source in the recursion tree. As before, we scan<br>the blocks from left to right, and want to distinguish three<br>possibilities.</span></nobr></DIV>
<DIV style="position:absolute;top:207;left:475"><nobr><span class="ft2">low</span></nobr></DIV>
<DIV style="position:absolute;top:206;left:505"><nobr><span class="ft2">Z</span></nobr></DIV>
<DIV style="position:absolute;top:211;left:515"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:206;left:524"><nobr><span class="ft2">has low entropy. In this case we proceed to i + 1.</span></nobr></DIV>
<DIV style="position:absolute;top:233;left:475"><nobr><span class="ft2">medium</span></nobr></DIV>
<DIV style="position:absolute;top:233;left:538"><nobr><span class="ft2">Z</span></nobr></DIV>
<DIV style="position:absolute;top:238;left:547"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:233;left:555"><nobr><span class="ft2">has "medium" entropy (Z</span></nobr></DIV>
<DIV style="position:absolute;top:238;left:707"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:233;left:712"><nobr><span class="ft2">, Z is a block-source).</span></nobr></DIV>
<DIV style="position:absolute;top:248;left:509"><nobr><span class="ft10">In which case we halt and produce an output (zero or<br>one).</span></nobr></DIV>
<DIV style="position:absolute;top:291;left:475"><nobr><span class="ft2">high</span></nobr></DIV>
<DIV style="position:absolute;top:291;left:512"><nobr><span class="ft2">Z</span></nobr></DIV>
<DIV style="position:absolute;top:295;left:521"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:291;left:532"><nobr><span class="ft2">has essentially all entropy of Z. In this case we</span></nobr></DIV>
<DIV style="position:absolute;top:306;left:509"><nobr><span class="ft2">recurse on the condensed block Z</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:711"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:306;left:716"><nobr><span class="ft2">.</span></nobr></DIV>
<DIV style="position:absolute;top:333;left:489"><nobr><span class="ft2">As before, we use the Challenge-Response mechanism (with</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:475"><nobr><span class="ft2">a twist). We will compute challenges C(Z</span></nobr></DIV>
<DIV style="position:absolute;top:353;left:721"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:725"><nobr><span class="ft2">, Y ) and responses</span></nobr></DIV>
<DIV style="position:absolute;top:365;left:475"><nobr><span class="ft2">R</span></nobr></DIV>
<DIV style="position:absolute;top:364;left:484"><nobr><span class="ft2">(Z, Y ), all strings of length m. The responses are computed</span></nobr></DIV>
<DIV style="position:absolute;top:380;left:475"><nobr><span class="ft10">exactly as before, using the somewhere extractor pSE. The<br>Challenges are computed using our subsource somewhere<br>extractor SSE.</span></nobr></DIV>
<DIV style="position:absolute;top:427;left:489"><nobr><span class="ft2">We really have 4 possibilities to distinguish, since when we</span></nobr></DIV>
<DIV style="position:absolute;top:443;left:475"><nobr><span class="ft10">halt we also need to decide which output bit we give. We will<br>do so by deriving three tests from the above challenges and<br>responses: (C</span></nobr></DIV>
<DIV style="position:absolute;top:479;left:557"><nobr><span class="ft5">H</span></nobr></DIV>
<DIV style="position:absolute;top:474;left:567"><nobr><span class="ft2">, R</span></nobr></DIV>
<DIV style="position:absolute;top:479;left:584"><nobr><span class="ft5">H</span></nobr></DIV>
<DIV style="position:absolute;top:474;left:594"><nobr><span class="ft2">), (C</span></nobr></DIV>
<DIV style="position:absolute;top:479;left:621"><nobr><span class="ft5">M</span></nobr></DIV>
<DIV style="position:absolute;top:474;left:633"><nobr><span class="ft2">, R</span></nobr></DIV>
<DIV style="position:absolute;top:479;left:650"><nobr><span class="ft5">M</span></nobr></DIV>
<DIV style="position:absolute;top:474;left:662"><nobr><span class="ft2">), (C</span></nobr></DIV>
<DIV style="position:absolute;top:479;left:689"><nobr><span class="ft5">L</span></nobr></DIV>
<DIV style="position:absolute;top:474;left:697"><nobr><span class="ft2">, R</span></nobr></DIV>
<DIV style="position:absolute;top:479;left:714"><nobr><span class="ft5">L</span></nobr></DIV>
<DIV style="position:absolute;top:474;left:722"><nobr><span class="ft2">) for high, medium</span></nobr></DIV>
<DIV style="position:absolute;top:490;left:475"><nobr><span class="ft2">and low respectively, as follows. Let m  m</span></nobr></DIV>
<DIV style="position:absolute;top:495;left:743"><nobr><span class="ft5">H</span></nobr></DIV>
<DIV style="position:absolute;top:490;left:758"><nobr><span class="ft2">&gt;&gt; m</span></nobr></DIV>
<DIV style="position:absolute;top:495;left:796"><nobr><span class="ft5">M</span></nobr></DIV>
<DIV style="position:absolute;top:490;left:812"><nobr><span class="ft2">&gt;&gt;</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:475"><nobr><span class="ft2">m</span></nobr></DIV>
<DIV style="position:absolute;top:510;left:487"><nobr><span class="ft5">L</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:500"><nobr><span class="ft2">be appropriate integers: then in each of the tests above</span></nobr></DIV>
<DIV style="position:absolute;top:521;left:475"><nobr><span class="ft10">we restrict ourselves to prefixes of all strings of the appro-<br>priate lengths only. So every string in C</span></nobr></DIV>
<DIV style="position:absolute;top:542;left:724"><nobr><span class="ft5">M</span></nobr></DIV>
<DIV style="position:absolute;top:537;left:741"><nobr><span class="ft2">will be a prefix</span></nobr></DIV>
<DIV style="position:absolute;top:553;left:475"><nobr><span class="ft2">of length m</span></nobr></DIV>
<DIV style="position:absolute;top:557;left:546"><nobr><span class="ft5">M</span></nobr></DIV>
<DIV style="position:absolute;top:553;left:563"><nobr><span class="ft2">of some string in C</span></nobr></DIV>
<DIV style="position:absolute;top:557;left:680"><nobr><span class="ft5">H</span></nobr></DIV>
<DIV style="position:absolute;top:553;left:690"><nobr><span class="ft2">. Similarly, every string</span></nobr></DIV>
<DIV style="position:absolute;top:568;left:475"><nobr><span class="ft2">in R</span></nobr></DIV>
<DIV style="position:absolute;top:573;left:503"><nobr><span class="ft5">L</span></nobr></DIV>
<DIV style="position:absolute;top:568;left:516"><nobr><span class="ft2">is the length m</span></nobr></DIV>
<DIV style="position:absolute;top:573;left:611"><nobr><span class="ft5">L</span></nobr></DIV>
<DIV style="position:absolute;top:568;left:625"><nobr><span class="ft2">prefix of some string in R</span></nobr></DIV>
<DIV style="position:absolute;top:573;left:784"><nobr><span class="ft5">H</span></nobr></DIV>
<DIV style="position:absolute;top:568;left:795"><nobr><span class="ft2">. Now</span></nobr></DIV>
<DIV style="position:absolute;top:584;left:475"><nobr><span class="ft2">it is immediately clear that if C</span></nobr></DIV>
<DIV style="position:absolute;top:589;left:667"><nobr><span class="ft5">M</span></nobr></DIV>
<DIV style="position:absolute;top:584;left:684"><nobr><span class="ft2">is contained in R</span></nobr></DIV>
<DIV style="position:absolute;top:589;left:786"><nobr><span class="ft5">M</span></nobr></DIV>
<DIV style="position:absolute;top:584;left:799"><nobr><span class="ft2">, then</span></nobr></DIV>
<DIV style="position:absolute;top:600;left:475"><nobr><span class="ft2">C</span></nobr></DIV>
<DIV style="position:absolute;top:604;left:485"><nobr><span class="ft5">L</span></nobr></DIV>
<DIV style="position:absolute;top:600;left:499"><nobr><span class="ft2">is contained in R</span></nobr></DIV>
<DIV style="position:absolute;top:604;left:605"><nobr><span class="ft5">L</span></nobr></DIV>
<DIV style="position:absolute;top:600;left:614"><nobr><span class="ft2">. Thus these tests are monotone, if</span></nobr></DIV>
<DIV style="position:absolute;top:615;left:475"><nobr><span class="ft2">our sample fails the high test, it will definitely fail all tests.</span></nobr></DIV>
<DIV style="position:absolute;top:648;left:489"><nobr><span class="ft23">Algorithm: D</span></nobr></DIV>
<DIV style="position:absolute;top:648;left:607"><nobr><span class="ft23">(z, y)</span></nobr></DIV>
<DIV style="position:absolute;top:667;left:489"><nobr><span class="ft2">Let pSE(., .) be the somewhere extractor with a polyno-</span></nobr></DIV>
<DIV style="position:absolute;top:682;left:475"><nobr><span class="ft2">mial number of outputs of Proposition 2.3.</span></nobr></DIV>
<DIV style="position:absolute;top:698;left:489"><nobr><span class="ft2">Let SSE(., .) be the subsource somewhere extractor of The-</span></nobr></DIV>
<DIV style="position:absolute;top:714;left:475"><nobr><span class="ft2">orem 2.6.</span></nobr></DIV>
<DIV style="position:absolute;top:729;left:489"><nobr><span class="ft2">Global Parameters: t, the branching factor of the tree. k</span></nobr></DIV>
<DIV style="position:absolute;top:745;left:475"><nobr><span class="ft2">the original entropy of the sources.</span></nobr></DIV>
<DIV style="position:absolute;top:761;left:489"><nobr><span class="ft2">Local Parameters for recursive level: m</span></nobr></DIV>
<DIV style="position:absolute;top:765;left:727"><nobr><span class="ft5">L</span></nobr></DIV>
<DIV style="position:absolute;top:761;left:739"><nobr><span class="ft2"> m</span></nobr></DIV>
<DIV style="position:absolute;top:765;left:769"><nobr><span class="ft5">M</span></nobr></DIV>
<DIV style="position:absolute;top:761;left:785"><nobr><span class="ft2"> m</span></nobr></DIV>
<DIV style="position:absolute;top:765;left:815"><nobr><span class="ft5">H</span></nobr></DIV>
<DIV style="position:absolute;top:761;left:825"><nobr><span class="ft2">.</span></nobr></DIV>
<DIV style="position:absolute;top:776;left:489"><nobr><span class="ft2">Output will be an element of {0, 1}.</span></nobr></DIV>
<DIV style="position:absolute;top:808;left:491"><nobr><span class="ft2">1. If z is shorter than k, return 0.</span></nobr></DIV>
<DIV style="position:absolute;top:834;left:491"><nobr><span class="ft2">2. Partition z into t equal parts z = z</span></nobr></DIV>
<DIV style="position:absolute;top:839;left:721"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:834;left:727"><nobr><span class="ft2">, z</span></nobr></DIV>
<DIV style="position:absolute;top:839;left:740"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:834;left:746"><nobr><span class="ft2">, . . . , z</span></nobr></DIV>
<DIV style="position:absolute;top:839;left:783"><nobr><span class="ft5">t</span></nobr></DIV>
<DIV style="position:absolute;top:834;left:788"><nobr><span class="ft2">.</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:491"><nobr><span class="ft2">3. Compute three response sets R</span></nobr></DIV>
<DIV style="position:absolute;top:866;left:691"><nobr><span class="ft5">L</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:700"><nobr><span class="ft2">, R</span></nobr></DIV>
<DIV style="position:absolute;top:866;left:716"><nobr><span class="ft5">M</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:728"><nobr><span class="ft2">, R</span></nobr></DIV>
<DIV style="position:absolute;top:866;left:745"><nobr><span class="ft5">H</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:759"><nobr><span class="ft2">using pSE(z, y).</span></nobr></DIV>
<DIV style="position:absolute;top:876;left:509"><nobr><span class="ft2">R</span></nobr></DIV>
<DIV style="position:absolute;top:881;left:519"><nobr><span class="ft5">j</span></nobr></DIV>
<DIV style="position:absolute;top:876;left:530"><nobr><span class="ft2">will be the prefixes of length m</span></nobr></DIV>
<DIV style="position:absolute;top:881;left:724"><nobr><span class="ft5">j</span></nobr></DIV>
<DIV style="position:absolute;top:876;left:736"><nobr><span class="ft2">of the strings in</span></nobr></DIV>
<DIV style="position:absolute;top:893;left:509"><nobr><span class="ft2">pSE</span></nobr></DIV>
<DIV style="position:absolute;top:892;left:532"><nobr><span class="ft2">(z, y).</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:491"><nobr><span class="ft2">4. For each i  [t], compute three challenge sets C</span></nobr></DIV>
<DIV style="position:absolute;top:916;left:786"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:785"><nobr><span class="ft5">L</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:793"><nobr><span class="ft2">, C</span></nobr></DIV>
<DIV style="position:absolute;top:916;left:810"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:809"><nobr><span class="ft5">M</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:821"><nobr><span class="ft2">, C</span></nobr></DIV>
<DIV style="position:absolute;top:916;left:838"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:837"><nobr><span class="ft5">H</span></nobr></DIV>
<DIV style="position:absolute;top:934;left:509"><nobr><span class="ft2">using SSE(z</span></nobr></DIV>
<DIV style="position:absolute;top:939;left:581"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:934;left:586"><nobr><span class="ft2">, y). C</span></nobr></DIV>
<DIV style="position:absolute;top:932;left:626"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:940;left:625"><nobr><span class="ft5">j</span></nobr></DIV>
<DIV style="position:absolute;top:934;left:636"><nobr><span class="ft2">will be the prefixes of length m</span></nobr></DIV>
<DIV style="position:absolute;top:939;left:828"><nobr><span class="ft5">j</span></nobr></DIV>
<DIV style="position:absolute;top:950;left:509"><nobr><span class="ft2">of the strings in SSE(z</span></nobr></DIV>
<DIV style="position:absolute;top:955;left:645"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:950;left:649"><nobr><span class="ft2">, y).</span></nobr></DIV>
<DIV style="position:absolute;top:976;left:491"><nobr><span class="ft2">5. Let h be the smallest index for which the challenge set</span></nobr></DIV>
<DIV style="position:absolute;top:992;left:509"><nobr><span class="ft2">C</span></nobr></DIV>
<DIV style="position:absolute;top:997;left:519"><nobr><span class="ft5">L</span></nobr></DIV>
<DIV style="position:absolute;top:992;left:532"><nobr><span class="ft2">is not contained in the response set R</span></nobr></DIV>
<DIV style="position:absolute;top:997;left:760"><nobr><span class="ft5">L</span></nobr></DIV>
<DIV style="position:absolute;top:992;left:768"><nobr><span class="ft2">, if there is</span></nobr></DIV>
<DIV style="position:absolute;top:1008;left:509"><nobr><span class="ft2">no such index, output 0 and halt.</span></nobr></DIV>
<DIV style="position:absolute;top:1034;left:491"><nobr><span class="ft2">6. If C</span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:533"><nobr><span class="ft5">h</span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:532"><nobr><span class="ft5">H</span></nobr></DIV>
<DIV style="position:absolute;top:1034;left:547"><nobr><span class="ft2">is contained in R</span></nobr></DIV>
<DIV style="position:absolute;top:1039;left:649"><nobr><span class="ft5">H</span></nobr></DIV>
<DIV style="position:absolute;top:1034;left:664"><nobr><span class="ft2">and C</span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:702"><nobr><span class="ft5">h</span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:701"><nobr><span class="ft5">H</span></nobr></DIV>
<DIV style="position:absolute;top:1034;left:715"><nobr><span class="ft2">is contained in R</span></nobr></DIV>
<DIV style="position:absolute;top:1039;left:818"><nobr><span class="ft5">M</span></nobr></DIV>
<DIV style="position:absolute;top:1034;left:830"><nobr><span class="ft2">,</span></nobr></DIV>
<DIV style="position:absolute;top:1050;left:509"><nobr><span class="ft2">output 0 and halt. If C</span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:654"><nobr><span class="ft5">h</span></nobr></DIV>
<DIV style="position:absolute;top:1056;left:653"><nobr><span class="ft5">H</span></nobr></DIV>
<DIV style="position:absolute;top:1050;left:668"><nobr><span class="ft2">is contained in R</span></nobr></DIV>
<DIV style="position:absolute;top:1055;left:772"><nobr><span class="ft5">H</span></nobr></DIV>
<DIV style="position:absolute;top:1050;left:788"><nobr><span class="ft2">but C</span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:824"><nobr><span class="ft5">h</span></nobr></DIV>
<DIV style="position:absolute;top:1056;left:824"><nobr><span class="ft5">H</span></nobr></DIV>
<DIV style="position:absolute;top:1066;left:509"><nobr><span class="ft2">is not contained in R</span></nobr></DIV>
<DIV style="position:absolute;top:1071;left:636"><nobr><span class="ft5">M</span></nobr></DIV>
<DIV style="position:absolute;top:1066;left:649"><nobr><span class="ft2">, output 1 and halt.</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft9">677</span></nobr></DIV>
</DIV>
<!-- Page 8 -->
<a name="8"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft25{font-size:8px;font-family:Times;color:#000000;}
	.ft26{font-size:10px;font-family:Times;color:#000000;}
	.ft27{font-size:13px;font-family:Times;color:#000000;}
	.ft28{font-size:8px;line-height:13px;font-family:Times;color:#000000;}
	.ft29{font-size:10px;line-height:16px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="1008.png" alt="background image">
<DIV style="position:absolute;top:253;left:378"><nobr><span class="ft9">t blocks</span></nobr></DIV>
<DIV style="position:absolute;top:352;left:448"><nobr><span class="ft9">t blocks</span></nobr></DIV>
<DIV style="position:absolute;top:83;left:333"><nobr><span class="ft9">t blocks</span></nobr></DIV>
<DIV style="position:absolute;top:140;left:244"><nobr><span class="ft25">fail</span></nobr></DIV>
<DIV style="position:absolute;top:126;left:244"><nobr><span class="ft25">fail</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:244"><nobr><span class="ft25">fail</span></nobr></DIV>
<DIV style="position:absolute;top:113;left:299"><nobr><span class="ft28">pass<br>pass<br>pass</span></nobr></DIV>
<DIV style="position:absolute;top:233;left:178"><nobr><span class="ft25">fail</span></nobr></DIV>
<DIV style="position:absolute;top:219;left:178"><nobr><span class="ft25">fail</span></nobr></DIV>
<DIV style="position:absolute;top:205;left:178"><nobr><span class="ft25">fail</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:242"><nobr><span class="ft25">fail</span></nobr></DIV>
<DIV style="position:absolute;top:334;left:242"><nobr><span class="ft25">fail</span></nobr></DIV>
<DIV style="position:absolute;top:320;left:242"><nobr><span class="ft25">fail</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:292"><nobr><span class="ft25">fail</span></nobr></DIV>
<DIV style="position:absolute;top:433;left:292"><nobr><span class="ft25">fail</span></nobr></DIV>
<DIV style="position:absolute;top:419;left:292"><nobr><span class="ft25">fail</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:356"><nobr><span class="ft25">fail</span></nobr></DIV>
<DIV style="position:absolute;top:433;left:356"><nobr><span class="ft25">fail</span></nobr></DIV>
<DIV style="position:absolute;top:419;left:356"><nobr><span class="ft25">fail</span></nobr></DIV>
<DIV style="position:absolute;top:453;left:521"><nobr><span class="ft29">pass<br>pass<br>fail</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:447"><nobr><span class="ft29">pass<br>fail<br>fail</span></nobr></DIV>
<DIV style="position:absolute;top:173;left:183"><nobr><span class="ft9">low</span></nobr></DIV>
<DIV style="position:absolute;top:173;left:240"><nobr><span class="ft9">low</span></nobr></DIV>
<DIV style="position:absolute;top:173;left:307"><nobr><span class="ft9">high</span></nobr></DIV>
<DIV style="position:absolute;top:288;left:231"><nobr><span class="ft9">low</span></nobr></DIV>
<DIV style="position:absolute;top:285;left:298"><nobr><span class="ft9">low</span></nobr></DIV>
<DIV style="position:absolute;top:288;left:362"><nobr><span class="ft9">low</span></nobr></DIV>
<DIV style="position:absolute;top:288;left:426"><nobr><span class="ft9">high</span></nobr></DIV>
<DIV style="position:absolute;top:387;left:288"><nobr><span class="ft9">low</span></nobr></DIV>
<DIV style="position:absolute;top:384;left:483"><nobr><span class="ft9">med</span></nobr></DIV>
<DIV style="position:absolute;top:163;left:630"><nobr><span class="ft9">n bits total</span></nobr></DIV>
<DIV style="position:absolute;top:282;left:685"><nobr><span class="ft9">n/t bits total</span></nobr></DIV>
<DIV style="position:absolute;top:130;left:179"><nobr><span class="ft27">X</span></nobr></DIV>
<DIV style="position:absolute;top:387;left:355"><nobr><span class="ft9">low</span></nobr></DIV>
<DIV style="position:absolute;top:384;left:416"><nobr><span class="ft9">low</span></nobr></DIV>
<DIV style="position:absolute;top:515;left:422"><nobr><span class="ft9"> Output 0</span></nobr></DIV>
<DIV style="position:absolute;top:515;left:502"><nobr><span class="ft9">Output 1</span></nobr></DIV>
<DIV style="position:absolute;top:429;left:621"><nobr><span class="ft9">n/t^2 bits total</span></nobr></DIV>
<DIV style="position:absolute;top:283;left:170"><nobr><span class="ft27">X_3</span></nobr></DIV>
<DIV style="position:absolute;top:386;left:199"><nobr><span class="ft27">(X_3)_4</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:334"><nobr><span class="ft2">Figure 2: Analysis of the disperser.</span></nobr></DIV>
<DIV style="position:absolute;top:595;left:97"><nobr><span class="ft2">7. Output D(z</span></nobr></DIV>
<DIV style="position:absolute;top:600;left:185"><nobr><span class="ft5">h</span></nobr></DIV>
<DIV style="position:absolute;top:595;left:193"><nobr><span class="ft2">, y),</span></nobr></DIV>
<DIV style="position:absolute;top:625;left:94"><nobr><span class="ft2">First note the obvious monotonicity of the tests. If Z</span></nobr></DIV>
<DIV style="position:absolute;top:630;left:407"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:625;left:415"><nobr><span class="ft2">fails</span></nobr></DIV>
<DIV style="position:absolute;top:641;left:81"><nobr><span class="ft10">one of the tests it will certainly fail for shorter strings. Thus<br>there are only four outcomes to the three tests, written in the<br>order (low, medium, high): (pass, pass, pass), (pass, pass, fail),<br>(pass, fail, fail) and (fail, fail, fail).</span></nobr></DIV>
<DIV style="position:absolute;top:688;left:293"><nobr><span class="ft2">Conceptually, the algo-</span></nobr></DIV>
<DIV style="position:absolute;top:703;left:81"><nobr><span class="ft2">rithm is making the following decisions using the four tests:</span></nobr></DIV>
<DIV style="position:absolute;top:734;left:97"><nobr><span class="ft2">1. (fail, fail, fail): Assume Z</span></nobr></DIV>
<DIV style="position:absolute;top:738;left:260"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:734;left:268"><nobr><span class="ft2">has low entropy and proceed</span></nobr></DIV>
<DIV style="position:absolute;top:749;left:114"><nobr><span class="ft2">to block i + 1.</span></nobr></DIV>
<DIV style="position:absolute;top:777;left:97"><nobr><span class="ft2">2. (pass, fail, fail): Assume Z</span></nobr></DIV>
<DIV style="position:absolute;top:781;left:266"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:777;left:275"><nobr><span class="ft2">is medium, halt and output</span></nobr></DIV>
<DIV style="position:absolute;top:793;left:114"><nobr><span class="ft2">0.</span></nobr></DIV>
<DIV style="position:absolute;top:820;left:97"><nobr><span class="ft2">3. (pass, pass, fail): Assume Z</span></nobr></DIV>
<DIV style="position:absolute;top:825;left:276"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:820;left:286"><nobr><span class="ft2">is medium, halt and out-</span></nobr></DIV>
<DIV style="position:absolute;top:836;left:114"><nobr><span class="ft2">put 1.</span></nobr></DIV>
<DIV style="position:absolute;top:863;left:97"><nobr><span class="ft2">4. (pass, pass, pass): Assume Z</span></nobr></DIV>
<DIV style="position:absolute;top:868;left:280"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:863;left:288"><nobr><span class="ft2">is high and recurse on Z</span></nobr></DIV>
<DIV style="position:absolute;top:868;left:431"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:863;left:436"><nobr><span class="ft2">.</span></nobr></DIV>
<DIV style="position:absolute;top:893;left:94"><nobr><span class="ft2">The analysis of this idea (depicted in Figure 2).turns out</span></nobr></DIV>
<DIV style="position:absolute;top:909;left:81"><nobr><span class="ft10">to be more complex than it seems. There are two reasons for<br>that. Now we briefly explain them and the way to overcome<br>them in the construction and analysis.</span></nobr></DIV>
<DIV style="position:absolute;top:956;left:94"><nobr><span class="ft2">The first reason is the fact mentioned above, that SSE</span></nobr></DIV>
<DIV style="position:absolute;top:972;left:81"><nobr><span class="ft10">which generates the challenges, works only on a subsources<br>of the original sources. Restricting to these subsources at<br>some level of the recursion (as required by the analysis of of<br>the test) causes entropy loss which affects both definitions<br>(such as these entropy thresholds for decisions) and correct-<br>ness of SSE in higher levels of recursion. Controlling this en-<br>tropy loss is achieved by calling SSE recursively with smaller</span></nobr></DIV>
<DIV style="position:absolute;top:595;left:475"><nobr><span class="ft10">and smaller entropy requirements, which in turn limits the<br>entropy which will be lost by these restrictions. In order not<br>to lose all the entropy for this reason alone, we must work<br>with special parameters of SSE, essentially requiring that at<br>termination it has almost all the entropy it started with.</span></nobr></DIV>
<DIV style="position:absolute;top:673;left:489"><nobr><span class="ft2">The second reason is the analysis of the test when we are</span></nobr></DIV>
<DIV style="position:absolute;top:689;left:475"><nobr><span class="ft10">in a medium block. In contrast with the above situation, we<br>cannot consider the value of Z</span></nobr></DIV>
<DIV style="position:absolute;top:709;left:656"><nobr><span class="ft5">i</span></nobr></DIV>
<DIV style="position:absolute;top:705;left:665"><nobr><span class="ft2">fixed when we need it to fail</span></nobr></DIV>
<DIV style="position:absolute;top:720;left:475"><nobr><span class="ft10">on the Medium and Low tests. We need to show that for<br>these two tests (given a pass for High), they come up both<br>(pass, fail) and (fail, fail) each with positive probability.</span></nobr></DIV>
<DIV style="position:absolute;top:767;left:489"><nobr><span class="ft2">Since the length of Medium challenges and responses is</span></nobr></DIV>
<DIV style="position:absolute;top:783;left:475"><nobr><span class="ft2">m</span></nobr></DIV>
<DIV style="position:absolute;top:788;left:487"><nobr><span class="ft5">M</span></nobr></DIV>
<DIV style="position:absolute;top:783;left:499"><nobr><span class="ft2">, the probability of failure is at least exp(-(m</span></nobr></DIV>
<DIV style="position:absolute;top:788;left:780"><nobr><span class="ft5">M</span></nobr></DIV>
<DIV style="position:absolute;top:783;left:792"><nobr><span class="ft2">)) (this</span></nobr></DIV>
<DIV style="position:absolute;top:799;left:475"><nobr><span class="ft10">follows relatively easily from the fact that the responses are<br>somewhere random). If the Medium test fails so does the<br>Low test, and thus (fail, fail) has a positive probability and<br>our disperser D outputs 0 with positive probability.</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:489"><nobr><span class="ft2">To bound (pass, fail) we first observe (with a similar</span></nobr></DIV>
<DIV style="position:absolute;top:877;left:475"><nobr><span class="ft10">reasoning) that the low test fails with probability at least<br>exp(-(m</span></nobr></DIV>
<DIV style="position:absolute;top:898;left:540"><nobr><span class="ft5">L</span></nobr></DIV>
<DIV style="position:absolute;top:893;left:548"><nobr><span class="ft2">)). But we want the medium test to pass at the</span></nobr></DIV>
<DIV style="position:absolute;top:909;left:475"><nobr><span class="ft18">same time. This probability is at least the probability that<br>low</span></nobr></DIV>
<DIV style="position:absolute;top:924;left:498"><nobr><span class="ft2">fails minus the probability that medium fails. We already</span></nobr></DIV>
<DIV style="position:absolute;top:940;left:475"><nobr><span class="ft2">have a bound on the latter: it is at most poly(n)exp(-m</span></nobr></DIV>
<DIV style="position:absolute;top:945;left:813"><nobr><span class="ft5">M</span></nobr></DIV>
<DIV style="position:absolute;top:940;left:825"><nobr><span class="ft2">).</span></nobr></DIV>
<DIV style="position:absolute;top:956;left:475"><nobr><span class="ft10">Here comes our control of the different length into play - we<br>can make the m</span></nobr></DIV>
<DIV style="position:absolute;top:976;left:572"><nobr><span class="ft5">L</span></nobr></DIV>
<DIV style="position:absolute;top:971;left:585"><nobr><span class="ft2">sufficiently smaller than m</span></nobr></DIV>
<DIV style="position:absolute;top:976;left:745"><nobr><span class="ft5">M</span></nobr></DIV>
<DIV style="position:absolute;top:971;left:762"><nobr><span class="ft2">to yield this</span></nobr></DIV>
<DIV style="position:absolute;top:987;left:475"><nobr><span class="ft10">difference positive. We conclude that our disperser D out-<br>puts 1 with positive probability as well.</span></nobr></DIV>
<DIV style="position:absolute;top:1018;left:489"><nobr><span class="ft2">Finally, we need to take care of termination: we have to</span></nobr></DIV>
<DIV style="position:absolute;top:1034;left:475"><nobr><span class="ft10">ensure that the recurrence always arrives at a medium sub-<br>part, but it is easy to chose entropy thresholds for low, medium<br>and high to ensure that this happens.</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft9">678</span></nobr></DIV>
</DIV>
<!-- Page 9 -->
<a name="9"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="1009.png" alt="background image">
<DIV style="position:absolute;top:84;left:81"><nobr><span class="ft4"><b>6.</b></span></nobr></DIV>
<DIV style="position:absolute;top:84;left:112"><nobr><span class="ft4"><b>RESILIENCY AND DEFICIENCY</b></span></nobr></DIV>
<DIV style="position:absolute;top:105;left:94"><nobr><span class="ft2">In this section we will breifly discuss an issue which arises</span></nobr></DIV>
<DIV style="position:absolute;top:121;left:81"><nobr><span class="ft10">in our construction that we glossed over in the previous sec-<br>tions. Recall our definition of subsources:</span></nobr></DIV>
<DIV style="position:absolute;top:166;left:96"><nobr><span class="ft2">Definition 6.1</span></nobr></DIV>
<DIV style="position:absolute;top:166;left:209"><nobr><span class="ft2">(Subsources). Given random variables</span></nobr></DIV>
<DIV style="position:absolute;top:183;left:81"><nobr><span class="ft2">Z and ^</span></nobr></DIV>
<DIV style="position:absolute;top:183;left:121"><nobr><span class="ft2">Z on {0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:181;left:187"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:183;left:199"><nobr><span class="ft2">we say that ^</span></nobr></DIV>
<DIV style="position:absolute;top:183;left:268"><nobr><span class="ft2">Z is a deficiency d subsource</span></nobr></DIV>
<DIV style="position:absolute;top:201;left:81"><nobr><span class="ft2">of Z and write ^</span></nobr></DIV>
<DIV style="position:absolute;top:201;left:175"><nobr><span class="ft2">Z  Z if there exists a set A  {0,1}</span></nobr></DIV>
<DIV style="position:absolute;top:198;left:400"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:201;left:413"><nobr><span class="ft2">such</span></nobr></DIV>
<DIV style="position:absolute;top:219;left:81"><nobr><span class="ft2">that (Z|A) = ^Z and Pr[Z  A]  2</span></nobr></DIV>
<DIV style="position:absolute;top:218;left:290"><nobr><span class="ft5">-d</span></nobr></DIV>
<DIV style="position:absolute;top:219;left:305"><nobr><span class="ft2">.</span></nobr></DIV>
<DIV style="position:absolute;top:248;left:94"><nobr><span class="ft2">Recall that we were able to guarantee that our algorithms</span></nobr></DIV>
<DIV style="position:absolute;top:264;left:81"><nobr><span class="ft18">made the right decisions only on subsources of the original<br>source. For example, in the construction of our final dis-<br>perser, to ensure that our algorithms correctly identify the<br>right high block to recurse on, we were only able to guar-<br>antee that there are subsources of the original sources in<br>which our algorithm makes the correct decision with high<br>probability. Then, later in the analysis we had to further<br>restrict the source to even smaller subsources. This leads to<br>complications, since the original event of picking the correct<br>high</span></nobr></DIV>
<DIV style="position:absolute;top:405;left:111"><nobr><span class="ft2">block, which occurred with high probability, may be-</span></nobr></DIV>
<DIV style="position:absolute;top:420;left:81"><nobr><span class="ft10">come an event which does not occur with high probability<br>in the current subsource. To handle these kinds of issues,<br>we will need to be very careful in measuring how small our<br>subsources are.</span></nobr></DIV>
<DIV style="position:absolute;top:483;left:94"><nobr><span class="ft2">In the formal analysis we introduce the concept of re-</span></nobr></DIV>
<DIV style="position:absolute;top:499;left:81"><nobr><span class="ft10">siliency to deal with this. To give an idea of how this works,<br>here is the actual definition of somewhere subsource extrac-<br>tor that we use in the formal analysis.</span></nobr></DIV>
<DIV style="position:absolute;top:560;left:96"><nobr><span class="ft2">Definition 6.2</span></nobr></DIV>
<DIV style="position:absolute;top:560;left:209"><nobr><span class="ft2">(subsource somewhere extractor).</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:81"><nobr><span class="ft2">A function SSE : {0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:573;left:225"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:236"><nobr><span class="ft2">× {0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:573;left:285"><nobr><span class="ft5">n</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:298"><nobr><span class="ft2"> ({0, 1}</span></nobr></DIV>
<DIV style="position:absolute;top:573;left:357"><nobr><span class="ft5">m</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:367"><nobr><span class="ft2">)</span></nobr></DIV>
<DIV style="position:absolute;top:573;left:373"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:575;left:384"><nobr><span class="ft2">is a sub-</span></nobr></DIV>
<DIV style="position:absolute;top:591;left:81"><nobr><span class="ft10">source somewhere extractor with nrows output rows, entropy<br>threshold k, deficiency def, resiliency res and error  if for<br>every (n, k)-sources X, Y there exist a deficiency def sub-<br>source X</span></nobr></DIV>
<DIV style="position:absolute;top:637;left:137"><nobr><span class="ft15">good</span></nobr></DIV>
<DIV style="position:absolute;top:638;left:161"><nobr><span class="ft2">of X and a deficiency def subsource Y</span></nobr></DIV>
<DIV style="position:absolute;top:637;left:404"><nobr><span class="ft15">good</span></nobr></DIV>
<DIV style="position:absolute;top:638;left:428"><nobr><span class="ft2">of</span></nobr></DIV>
<DIV style="position:absolute;top:654;left:81"><nobr><span class="ft2">Y such that for every deficiency res subsource X</span></nobr></DIV>
<DIV style="position:absolute;top:653;left:382"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:654;left:392"><nobr><span class="ft2">of X</span></nobr></DIV>
<DIV style="position:absolute;top:653;left:422"><nobr><span class="ft15">good</span></nobr></DIV>
<DIV style="position:absolute;top:669;left:81"><nobr><span class="ft2">and deficiency res subsource Y</span></nobr></DIV>
<DIV style="position:absolute;top:669;left:269"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:669;left:280"><nobr><span class="ft2">of Y</span></nobr></DIV>
<DIV style="position:absolute;top:669;left:308"><nobr><span class="ft15">good</span></nobr></DIV>
<DIV style="position:absolute;top:669;left:325"><nobr><span class="ft2">, the random vari-</span></nobr></DIV>
<DIV style="position:absolute;top:685;left:81"><nobr><span class="ft2">able SSE(X</span></nobr></DIV>
<DIV style="position:absolute;top:685;left:152"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:685;left:156"><nobr><span class="ft2">, Y</span></nobr></DIV>
<DIV style="position:absolute;top:685;left:173"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:685;left:177"><nobr><span class="ft2">) is -close to a  × m somewhere random</span></nobr></DIV>
<DIV style="position:absolute;top:701;left:81"><nobr><span class="ft2">distribution.</span></nobr></DIV>
<DIV style="position:absolute;top:730;left:94"><nobr><span class="ft2">It turns out that our subsource somewhere extractor does</span></nobr></DIV>
<DIV style="position:absolute;top:746;left:81"><nobr><span class="ft10">satisfy this stronger definition. The advantage of this defi-<br>nition is that it says that once we restrict our attention to<br>the good subsources X</span></nobr></DIV>
<DIV style="position:absolute;top:777;left:217"><nobr><span class="ft15">good</span></nobr></DIV>
<DIV style="position:absolute;top:777;left:234"><nobr><span class="ft2">, Y</span></nobr></DIV>
<DIV style="position:absolute;top:777;left:251"><nobr><span class="ft15">good</span></nobr></DIV>
<DIV style="position:absolute;top:777;left:268"><nobr><span class="ft2">, we have the freedom to fur-</span></nobr></DIV>
<DIV style="position:absolute;top:793;left:81"><nobr><span class="ft10">ther restrict these subsources to smaller subsources, as long<br>as our final subsources do not lose more entropy than the<br>resiliency permits.</span></nobr></DIV>
<DIV style="position:absolute;top:840;left:94"><nobr><span class="ft2">This issue of managing the resiliency for the various ob-</span></nobr></DIV>
<DIV style="position:absolute;top:856;left:81"><nobr><span class="ft10">jects that we construct is one of the major technical chal-<br>lenges that we had to overcome in our construction.</span></nobr></DIV>
<DIV style="position:absolute;top:905;left:81"><nobr><span class="ft4"><b>7.</b></span></nobr></DIV>
<DIV style="position:absolute;top:905;left:112"><nobr><span class="ft4"><b>OPEN PROBLEMS</b></span></nobr></DIV>
<DIV style="position:absolute;top:941;left:81"><nobr><span class="ft2">Better Independent Source Extractors</span></nobr></DIV>
<DIV style="position:absolute;top:940;left:355"><nobr><span class="ft2">A bottleneck to</span></nobr></DIV>
<DIV style="position:absolute;top:956;left:114"><nobr><span class="ft10">improving our disperser is the block versus general<br>source extractor of Theorem 2.7. A good next step<br>would be to try to build an extractor for one block<br>source (with only a constant number of blocks) and<br>one other independent source which works for polylog-<br>arithmic entropy, or even an extractor for a constant<br>number of sources that works for sub-polynomial en-<br>tropy.</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft2">Simple Dispersers</span></nobr></DIV>
<DIV style="position:absolute;top:85;left:607"><nobr><span class="ft2">While our disperser is polynomial time</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:509"><nobr><span class="ft10">computable, it is not as explicit as one might have<br>hoped. For instance the Ramsey Graph construction<br>of Frankl-Wilson is extremely simple: For a prime p,<br>let the vertices of the graph be all subsets of [p</span></nobr></DIV>
<DIV style="position:absolute;top:146;left:807"><nobr><span class="ft5">3</span></nobr></DIV>
<DIV style="position:absolute;top:148;left:813"><nobr><span class="ft2">] of</span></nobr></DIV>
<DIV style="position:absolute;top:164;left:509"><nobr><span class="ft2">size p</span></nobr></DIV>
<DIV style="position:absolute;top:162;left:542"><nobr><span class="ft5">2</span></nobr></DIV>
<DIV style="position:absolute;top:164;left:551"><nobr><span class="ft2">- 1. Two vertices S,T are adjacent if and only</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:509"><nobr><span class="ft2">if |S  T|  -1 mod p. It would be nice to find a good</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:509"><nobr><span class="ft10">disperser that beats the Frankl-Wilson construction,<br>yet is comparable in simplicity.</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:475"><nobr><span class="ft4"><b>8.</b></span></nobr></DIV>
<DIV style="position:absolute;top:243;left:507"><nobr><span class="ft4"><b>REFERENCES</b></span></nobr></DIV>
<DIV style="position:absolute;top:260;left:482"><nobr><span class="ft2">[1] N. Alon. The shannon capacity of a union.</span></nobr></DIV>
<DIV style="position:absolute;top:276;left:503"><nobr><span class="ft2">Combinatorica, 18, 1998.</span></nobr></DIV>
<DIV style="position:absolute;top:293;left:482"><nobr><span class="ft2">[2] B. Barak. A simple explicit construction of an</span></nobr></DIV>
<DIV style="position:absolute;top:310;left:503"><nobr><span class="ft2">n</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:512"><nobr><span class="ft5">~</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:512"><nobr><span class="ft5">o(log n)</span></nobr></DIV>
<DIV style="position:absolute;top:310;left:550"><nobr><span class="ft2">-ramsey graph. Technical report, Arxiv, 2006.</span></nobr></DIV>
<DIV style="position:absolute;top:327;left:503"><nobr><span class="ft2">http://arxiv.org/abs/math.CO/0601651</span></nobr></DIV>
<DIV style="position:absolute;top:326;left:757"><nobr><span class="ft2">.</span></nobr></DIV>
<DIV style="position:absolute;top:343;left:482"><nobr><span class="ft2">[3] B. Barak, R. Impagliazzo, and A. Wigderson.</span></nobr></DIV>
<DIV style="position:absolute;top:359;left:503"><nobr><span class="ft10">Extracting randomness using few independent sources.<br>In Proceedings of the 45th Annual IEEE Symposium<br>on Foundations of Computer Science, pages 384­393,<br>2004.</span></nobr></DIV>
<DIV style="position:absolute;top:423;left:482"><nobr><span class="ft2">[4] B. Barak, G. Kindler, R. Shaltiel, B. Sudakov, and</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:503"><nobr><span class="ft10">A. Wigderson. Simulating independence: New<br>constructions of condensers, Ramsey graphs,<br>dispersers, and extractors. In Proceedings of the 37th<br>Annual ACM Symposium on Theory of Computing,<br>pages 1­10, 2005.</span></nobr></DIV>
<DIV style="position:absolute;top:519;left:482"><nobr><span class="ft2">[5] J. Bourgain. More on the sum-product phenomenon in</span></nobr></DIV>
<DIV style="position:absolute;top:535;left:503"><nobr><span class="ft10">prime fields and its applications. International Journal<br>of Number Theory, 1:1­32, 2005.</span></nobr></DIV>
<DIV style="position:absolute;top:568;left:482"><nobr><span class="ft2">[6] J. Bourgain, N. Katz, and T. Tao. A sum-product</span></nobr></DIV>
<DIV style="position:absolute;top:583;left:503"><nobr><span class="ft10">estimate in finite fields, and applications. Geometric<br>and Functional Analysis, 14:27­57, 2004.</span></nobr></DIV>
<DIV style="position:absolute;top:616;left:482"><nobr><span class="ft2">[7] M. Capalbo, O. Reingold, S. Vadhan, and</span></nobr></DIV>
<DIV style="position:absolute;top:632;left:503"><nobr><span class="ft10">A. Wigderson. Randomness conductors and<br>constant-degree lossless expanders. In Proceedings of<br>the 34th Annual ACM Symposium on Theory of<br>Computing, pages 659­668, 2002.</span></nobr></DIV>
<DIV style="position:absolute;top:696;left:482"><nobr><span class="ft2">[8] B. Chor and O. Goldreich. Unbiased bits from sources</span></nobr></DIV>
<DIV style="position:absolute;top:712;left:503"><nobr><span class="ft10">of weak randomness and probabilistic communication<br>complexity. SIAM Journal on Computing,<br>17(2):230­261, 1988.</span></nobr></DIV>
<DIV style="position:absolute;top:760;left:482"><nobr><span class="ft2">[9] P. Frankl and R. M. Wilson. Intersection theorems</span></nobr></DIV>
<DIV style="position:absolute;top:776;left:503"><nobr><span class="ft10">with geometric consequences. Combinatorica,<br>1(4):357­368, 1981.</span></nobr></DIV>
<DIV style="position:absolute;top:809;left:475"><nobr><span class="ft2">[10] P. Gopalan. Constructing ramsey graphs from boolean</span></nobr></DIV>
<DIV style="position:absolute;top:825;left:503"><nobr><span class="ft10">function representations. In Proceedings of the 21th<br>Annual IEEE Conference on Computational<br>Complexity, 2006.</span></nobr></DIV>
<DIV style="position:absolute;top:873;left:475"><nobr><span class="ft2">[11] V. Grolmusz. Low rank co-diagonal matrices and</span></nobr></DIV>
<DIV style="position:absolute;top:889;left:503"><nobr><span class="ft2">ramsey graphs. Electr. J. Comb, 7, 2000.</span></nobr></DIV>
<DIV style="position:absolute;top:906;left:475"><nobr><span class="ft2">[12] V. Guruswami. Better extractors for better codes?</span></nobr></DIV>
<DIV style="position:absolute;top:922;left:503"><nobr><span class="ft10">Electronic Colloquium on Computational Complexity<br>(ECCC), (080), 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:955;left:475"><nobr><span class="ft2">[13] C. J. Lu, O. Reingold, S. Vadhan, and A. Wigderson.</span></nobr></DIV>
<DIV style="position:absolute;top:970;left:503"><nobr><span class="ft10">Extractors: Optimal up to constant factors. In<br>Proceedings of the 35th Annual ACM Symposium on<br>Theory of Computing, pages 602­611, 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:1019;left:475"><nobr><span class="ft2">[14] P. Miltersen, N. Nisan, S. Safra, and A. Wigderson.</span></nobr></DIV>
<DIV style="position:absolute;top:1034;left:503"><nobr><span class="ft10">On data structures and asymmetric communication<br>complexity. Journal of Computer and System<br>Sciences, 57:37­49, 1 1998.</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft9">679</span></nobr></DIV>
</DIV>
<!-- Page 10 -->
<a name="10"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="1010.png" alt="background image">
<DIV style="position:absolute;top:85;left:81"><nobr><span class="ft2">[15] N. Nisan and D. Zuckerman. More deterministic</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:109"><nobr><span class="ft10">simulation in logspace. In Proceedings of the 25th<br>Annual ACM Symposium on Theory of Computing,<br>pages 235­244, 1993.</span></nobr></DIV>
<DIV style="position:absolute;top:150;left:81"><nobr><span class="ft2">[16] P. Pudlak and V. Rodl. Pseudorandom sets and</span></nobr></DIV>
<DIV style="position:absolute;top:166;left:109"><nobr><span class="ft10">explicit constructions of ramsey graphs. Submitted for<br>publication, 2004.</span></nobr></DIV>
<DIV style="position:absolute;top:198;left:81"><nobr><span class="ft2">[17] A. Rao. Extractors for a constant number of</span></nobr></DIV>
<DIV style="position:absolute;top:214;left:109"><nobr><span class="ft10">polynomially small min-entropy independent sources.<br>In Proceedings of the 38th Annual ACM Symposium<br>on Theory of Computing, 2006.</span></nobr></DIV>
<DIV style="position:absolute;top:263;left:81"><nobr><span class="ft2">[18] R. Raz. Extractors with weak random seeds. In</span></nobr></DIV>
<DIV style="position:absolute;top:278;left:109"><nobr><span class="ft10">Proceedings of the 37th Annual ACM Symposium on<br>Theory of Computing, pages 11­20, 2005.</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:81"><nobr><span class="ft2">[19] O. Reingold, R. Shaltiel, and A. Wigderson.</span></nobr></DIV>
<DIV style="position:absolute;top:327;left:109"><nobr><span class="ft10">Extracting randomness via repeated condensing. In<br>Proceedings of the 41st Annual IEEE Symposium on<br>Foundations of Computer Science, pages 22­31, 2000.</span></nobr></DIV>
<DIV style="position:absolute;top:85;left:475"><nobr><span class="ft2">[20] M. Santha and U. V. Vazirani. Generating</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:503"><nobr><span class="ft10">quasi-random sequences from semi-random sources.<br>Journal of Computer and System Sciences, 33:75­87,<br>1986.</span></nobr></DIV>
<DIV style="position:absolute;top:150;left:475"><nobr><span class="ft2">[21] R. Shaltiel. Recent developments in explicit</span></nobr></DIV>
<DIV style="position:absolute;top:166;left:503"><nobr><span class="ft10">constructions of extractors. Bulletin of the European<br>Association for Theoretical Computer Science,<br>77:67­95, 2002.</span></nobr></DIV>
<DIV style="position:absolute;top:214;left:475"><nobr><span class="ft2">[22] A. Ta-Shma and D. Zuckerman. Extractor codes.</span></nobr></DIV>
<DIV style="position:absolute;top:230;left:503"><nobr><span class="ft2">IEEE Transactions on Information Theory, 50, 2004.</span></nobr></DIV>
<DIV style="position:absolute;top:247;left:475"><nobr><span class="ft2">[23] U. Vazirani. Towards a strong communication</span></nobr></DIV>
<DIV style="position:absolute;top:263;left:503"><nobr><span class="ft10">complexity theory or generating quasi-random<br>sequences from two communicating slightly-random<br>sources (extended abstract). In Proceedings of the 17th<br>Annual ACM Symposium on Theory of Computing,<br>pages 366­378, 1985.</span></nobr></DIV>
<DIV style="position:absolute;top:343;left:475"><nobr><span class="ft2">[24] A. Wigderson and D. Zuckerman. Expanders that</span></nobr></DIV>
<DIV style="position:absolute;top:358;left:503"><nobr><span class="ft10">beat the eigenvalue bound: Explicit construction and<br>applications. Combinatorica, 19(1):125­138, 1999.</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft9">680</span></nobr></DIV>
</DIV>
</BODY>
</HTML>
