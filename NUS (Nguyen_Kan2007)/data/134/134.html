<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
<HEAD>
<TITLE>D:\Paper\HTML\134</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<META name="generator" content="pdftohtml 0.35beta">
<META name="date" content="2004-04-06T09:25:59+00:00">
</HEAD>
<BODY bgcolor="#A0A0A0" vlink="blue" link="blue">
<!-- Page 1 -->
<a name="1"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft0{font-size:24px;font-family:Helvetica;color:#000000;}
	.ft1{font-size:15px;font-family:Helvetica;color:#000000;}
	.ft2{font-size:11px;font-family:Times;color:#000000;}
	.ft3{font-size:12px;font-family:Helvetica;color:#000000;}
	.ft4{font-size:15px;font-family:Times;color:#000000;}
	.ft5{font-size:13px;font-family:Times;color:#000000;}
	.ft6{font-size:11px;line-height:15px;font-family:Times;color:#000000;}
	.ft7{font-size:11px;line-height:16px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="134001.png" alt="background image">
<DIV style="position:absolute;top:108;left:132"><nobr><span class="ft0"><b>Machine Learning in Low-level Microarray Analysis</b></span></nobr></DIV>
<DIV style="position:absolute;top:176;left:219"><nobr><span class="ft1">Benjamin I. P. Rubinstein</span></nobr></DIV>
<DIV style="position:absolute;top:171;left:417"><nobr><span class="ft2">1</span></nobr></DIV>
<DIV style="position:absolute;top:167;left:424"><nobr><span class="ft1">,</span></nobr></DIV>
<DIV style="position:absolute;top:171;left:429"><nobr><span class="ft2">2</span></nobr></DIV>
<DIV style="position:absolute;top:176;left:436"><nobr><span class="ft1">, Jon McAuliffe</span></nobr></DIV>
<DIV style="position:absolute;top:171;left:553"><nobr><span class="ft2">3</span></nobr></DIV>
<DIV style="position:absolute;top:176;left:560"><nobr><span class="ft1">, Simon Cawley</span></nobr></DIV>
<DIV style="position:absolute;top:171;left:683"><nobr><span class="ft2">4</span></nobr></DIV>
<DIV style="position:absolute;top:176;left:690"><nobr><span class="ft1">,</span></nobr></DIV>
<DIV style="position:absolute;top:199;left:165"><nobr><span class="ft1">Marimuthu Palaniswami</span></nobr></DIV>
<DIV style="position:absolute;top:194;left:354"><nobr><span class="ft2">5</span></nobr></DIV>
<DIV style="position:absolute;top:199;left:361"><nobr><span class="ft1">, Kotagiri Ramamohanarao</span></nobr></DIV>
<DIV style="position:absolute;top:194;left:575"><nobr><span class="ft2">1</span></nobr></DIV>
<DIV style="position:absolute;top:199;left:581"><nobr><span class="ft1">, Terence P. Speed</span></nobr></DIV>
<DIV style="position:absolute;top:194;left:731"><nobr><span class="ft2">2</span></nobr></DIV>
<DIV style="position:absolute;top:190;left:738"><nobr><span class="ft1">,</span></nobr></DIV>
<DIV style="position:absolute;top:194;left:743"><nobr><span class="ft2">3</span></nobr></DIV>
<DIV style="position:absolute;top:227;left:176"><nobr><span class="ft1">benr@ieee.org, jon@stat.berkeley.edu, simon cawley@affymetrix.com,</span></nobr></DIV>
<DIV style="position:absolute;top:245;left:200"><nobr><span class="ft1">swami@ee.mu.oz.au, rao@cs.mu.oz.au, terry@stat.berkeley.edu</span></nobr></DIV>
<DIV style="position:absolute;top:272;left:132"><nobr><span class="ft2">1</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:143"><nobr><span class="ft3">Department of Computer Science &amp; Software Engineering, the University of Melbourne, Australia</span></nobr></DIV>
<DIV style="position:absolute;top:291;left:120"><nobr><span class="ft2">2</span></nobr></DIV>
<DIV style="position:absolute;top:294;left:131"><nobr><span class="ft3">Division of Genetics &amp; Bioinformatics, the Walter &amp; Eliza Hall Institute of Medical Research, Australia</span></nobr></DIV>
<DIV style="position:absolute;top:309;left:241"><nobr><span class="ft2">3</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:252"><nobr><span class="ft3">Department of Statistics, University of California at Berkeley, CA</span></nobr></DIV>
<DIV style="position:absolute;top:328;left:272"><nobr><span class="ft2">4</span></nobr></DIV>
<DIV style="position:absolute;top:331;left:283"><nobr><span class="ft3">Data Analysis Group, Affymetrix, Inc., Santa Clara, CA</span></nobr></DIV>
<DIV style="position:absolute;top:347;left:160"><nobr><span class="ft2">5</span></nobr></DIV>
<DIV style="position:absolute;top:350;left:171"><nobr><span class="ft3">Department of Electrical &amp; Electronic Engineering, the University of Melbourne, Australia</span></nobr></DIV>
<DIV style="position:absolute;top:403;left:81"><nobr><span class="ft4"><b>ABSTRACT</b></span></nobr></DIV>
<DIV style="position:absolute;top:429;left:81"><nobr><span class="ft6">Machine learning and data mining have found a multitude<br>of successful applications in microarray analysis, with gene<br>clustering and classification of tissue samples being widely<br>cited examples. Low-level microarray analysis ­ often as-<br>sociated with the pre-processing stage within the microar-<br>ray life-cycle ­ has increasingly become an area of active<br>research, traditionally involving techniques from classical<br>statistics. This paper explores opportunities for the applica-<br>tion of machine learning and data mining methods to several<br>important low-level microarray analysis problems: monitor-<br>ing gene expression, transcript discovery, genotyping and re-<br>sequencing. Relevant methods and ideas from the machine<br>learning community include semi-supervised learning, learn-<br>ing from heterogeneous data, and incremental learning.</span></nobr></DIV>
<DIV style="position:absolute;top:670;left:81"><nobr><span class="ft4"><b>Keywords</b></span></nobr></DIV>
<DIV style="position:absolute;top:695;left:81"><nobr><span class="ft6">Low-level microarray analysis, gene expression estimation,<br>genotyping, re-sequencing, transcript discovery, transduc-<br>tive learning, semi-supervised learning, learning from het-<br>erogeneous data, incremental learning</span></nobr></DIV>
<DIV style="position:absolute;top:779;left:81"><nobr><span class="ft4"><b>1.</b></span></nobr></DIV>
<DIV style="position:absolute;top:779;left:112"><nobr><span class="ft4"><b>INTRODUCTION</b></span></nobr></DIV>
<DIV style="position:absolute;top:801;left:81"><nobr><span class="ft6">DNA microarrays have revolutionized biological research ov-<br>er the short time since their inception [2; 27; 28; 29]. Al-<br>though most widely used for parallel measurement of gene<br>expression [27; 28], microarrays are starting to find common<br>application in other areas of genomics and transcriptomics,<br>including genomic re-sequencing [30; 31], genotyping [32;<br>33], and transcript discovery [34].<br>Research labs armed with microarrays have been able to<br>partake in a range of studies, including finding gene func-<br>tion [35; 36; 37]; correcting mistaken database annotations<br>[36; 7]; performing linkage analyses; determining specific<br>genes involved in biological pathways; identifying genes that<br>are important at certain times of development (or that are<br>turned on/off over a course of treatment); elucidating gene<br>regulatory networks [13]; diagnosing disease in tissue sam-</span></nobr></DIV>
<DIV style="position:absolute;top:677;left:475"><nobr><span class="ft6">Figure 1: The relationship between low-level and high-level<br>microarray analysis.</span></nobr></DIV>
<DIV style="position:absolute;top:750;left:475"><nobr><span class="ft6">ples [38; 39; 40; 41];<br>tioners' misdiagnoses [38]. The common thread among these<br>high-level microarray analysis problems is that they answer<br>sophisticated questions of direct biological interest to medi-<br>cal researchers (such as "which genes are being co-expressed<br>under treatment X?"), where the raw data used are esti-<br>mates of biologically meaningful parameters (such as the<br>expression level estimates for thousands of genes).<br>In contrast to these so-called high-level problems, low-level<br>microarray analysis [19] is concerned with the preceding step<br>in the microarray assay cycle (Figure 1) ­ given raw data<br>straight from a scanner which has no direct biological in-<br>terpretation, clean and summarize this data to produce the<br>biologically meaningful parameter estimates (such as expres-<br>sion level estimates) that are later used in high-level analy-<br>ses.<br>In low-level analysis, more consideration is generally given to<br>the behavior of the underlying molecular biology, microarray<br>technology, and experimental design than in high-level anal-<br>ysis. This makes generative methods readily applicable in<br>low-level problems, facilitating the formulation of confidence</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:77"><nobr><span class="ft5">SIGKDD Explorations.</span></nobr></DIV>
<DIV style="position:absolute;top:750;left:610"><nobr><span class="ft2">and even identifying medical practi-</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:639"><nobr><span class="ft5">Volume 5,Issue 2 - Page 130 </span></nobr></DIV>
</DIV>
<!-- Page 2 -->
<a name="2"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft8{font-size:6px;font-family:Times;color:#000000;}
	.ft9{font-size:6px;line-height:8px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="134002.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft6">statements such as p-values in gene expression calls. Hence,<br>while high-level problems have been tackled with discrimina-<br>tive approaches, such as those found in machine learning and<br>data mining, in addition to classical statistical methods, the<br>low-level analysis community has traditionally called upon<br>only the latter.<br>In this paper we argue that low-level microarray analysis<br>poses a number of interesting problems for the data mining<br>and machine learning community, distinct to the traditional<br>high-level microarray problems. These problems are rele-<br>vant to the long-term success of DNA microarrays and are<br>already topics of active research in the low-level microarray<br>analysis community. It is our hope that this position paper<br>motivates and enables further machine learning research in<br>the area. Although we will focus on high density oligonu-<br>cleotide microarrays, particularly those of the Affymetrix<br>GeneChip variety, the underlying concepts and opportuni-<br>ties remain the same for related technologies. Throughout<br>the paper, we distinguish machine learning from statistics.<br>While these disciplines are closely related and serve as foun-<br>dations for inference in microarray analysis, the distinction<br>does have content. In our view, classical statistics is gener-<br>ative, dealing with relatively low-dimensional data and pa-<br>rameter spaces, while machine learning is often discrimina-<br>tive in nature and explicitly addresses computational issues<br>in high-dimensional data analysis.<br>Section 2 reviews relevant background ideas from machine<br>learning. For an overview of the background molecular biol-<br>ogy and microarray technology, see the guest editorial else-<br>where in this issue. The low-level problems of absolute and<br>differential expression level summarization, expression de-<br>tection, and transcript discovery are reviewed in Section 3,<br>along with suggested applications of machine learning ap-<br>proaches to these problems. Sections 4 and 5 similarly cover<br>microarray-based genotyping and re-sequencing.</span></nobr></DIV>
<DIV style="position:absolute;top:622;left:394"><nobr><span class="ft2">Finally,</span></nobr></DIV>
<DIV style="position:absolute;top:638;left:81"><nobr><span class="ft2">Section 6 concludes the paper.</span></nobr></DIV>
<DIV style="position:absolute;top:679;left:81"><nobr><span class="ft4"><b>2.</b></span></nobr></DIV>
<DIV style="position:absolute;top:679;left:112"><nobr><span class="ft4"><b>BACKGROUND MACHINE LEARNING</b></span></nobr></DIV>
<DIV style="position:absolute;top:701;left:81"><nobr><span class="ft6">We assume familiarity with the notions of unsupervised learn-<br>ing (clustering) and supervised learning (classification and<br>regression). As many of the low-level analysis problems dis-<br>cussed below are amenable to learning from partially labeled<br>data, learning from heterogeneous data, and incremental<br>learning, we briefly review these paradigms here.</span></nobr></DIV>
<DIV style="position:absolute;top:809;left:81"><nobr><span class="ft4"><b>2.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:809;left:121"><nobr><span class="ft4"><b>Learning from Partially Labeled Data</b></span></nobr></DIV>
<DIV style="position:absolute;top:830;left:81"><nobr><span class="ft2">Given an i.i.d. labeled sample {(x</span></nobr></DIV>
<DIV style="position:absolute;top:835;left:286"><nobr><span class="ft8">i</span></nobr></DIV>
<DIV style="position:absolute;top:830;left:291"><nobr><span class="ft2">, y</span></nobr></DIV>
<DIV style="position:absolute;top:835;left:304"><nobr><span class="ft8">i</span></nobr></DIV>
<DIV style="position:absolute;top:830;left:309"><nobr><span class="ft2">)}</span></nobr></DIV>
<DIV style="position:absolute;top:828;left:321"><nobr><span class="ft9">n<br>i=1</span></nobr></DIV>
<DIV style="position:absolute;top:830;left:345"><nobr><span class="ft2">drawn from the</span></nobr></DIV>
<DIV style="position:absolute;top:846;left:81"><nobr><span class="ft6">unknown and fixed joint distribution F (x, y), and an i.i.d.<br>unlabeled sample {x</span></nobr></DIV>
<DIV style="position:absolute;top:866;left:200"><nobr><span class="ft8">i</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:205"><nobr><span class="ft2">}</span></nobr></DIV>
<DIV style="position:absolute;top:859;left:211"><nobr><span class="ft9">m<br>i=n+1</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:249"><nobr><span class="ft2">drawn from the marginal distri-</span></nobr></DIV>
<DIV style="position:absolute;top:877;left:81"><nobr><span class="ft6">bution F (x), the problem of learning from partially labeled<br>data [22; 20] is to use the data in choosing a function ^</span></nobr></DIV>
<DIV style="position:absolute;top:893;left:399"><nobr><span class="ft2">g</span></nobr></DIV>
<DIV style="position:absolute;top:897;left:406"><nobr><span class="ft8">m</span></nobr></DIV>
<DIV style="position:absolute;top:893;left:416"><nobr><span class="ft2">(X)</span></nobr></DIV>
<DIV style="position:absolute;top:909;left:81"><nobr><span class="ft6">approximating E(Y |X) where (X, Y )  F . This problem<br>has been motivated by a number of applications where only<br>limited labeled data is present, say due to expense, while un-<br>labeled data is plentiful [16]. This is particularly the case in<br>the areas of text classification, medical research, and com-<br>puter vision [42], within which much of the research into<br>learning from partially labeled data has occurred.<br>This problem, also called the labeled-unlabeled data prob-<br>lem [42], has been explored under a number of closely-related<br>guises. Some of the earliest approaches used so-called hybrid<br>learners [6], where an unsupervised learning algorithm as-</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft6">signs labels to the unlabeled data, thereby expanding the la-<br>beled dataset for subsequent supervised learning. The term<br>multimodal learning is sometimes used to refer to partially<br>labeled learning in the computer vision literature [17]. Co-<br>training is a form of partially labeled learning where the two<br>datasets may be of different types and one proceeds by us-<br>ing the unlabeled data to bootstrap weak learners trained<br>on the labeled data [16].<br>More recently, semi-supervised learning [25] and transduc-<br>tive learning [26] have gained popularity. Equivalent to par-<br>tially labeled learning, semi-supervised learning includes a<br>number of successful algorithms, such as those based on the<br>support vector machine (SVM) [25; 8]. Transductive learn-<br>ers, on the other hand, aim to predict labels for just the<br>unlabeled data at hand, without producing the inductive<br>approximation ^</span></nobr></DIV>
<DIV style="position:absolute;top:323;left:569"><nobr><span class="ft2">g</span></nobr></DIV>
<DIV style="position:absolute;top:327;left:576"><nobr><span class="ft8">m</span></nobr></DIV>
<DIV style="position:absolute;top:323;left:586"><nobr><span class="ft2">. This approach can be used to gener-</span></nobr></DIV>
<DIV style="position:absolute;top:339;left:475"><nobr><span class="ft6">alize the aforementioned hybrid learners, whose unsuper-<br>vised step typically ignores the labeled data. In particu-<br>lar, it is shown in [26] that direct transduction is more ef-<br>fective than the traditional two-step approach of induction<br>followed by deduction. A number of transductive schemes<br>have been proposed, such as those based on the SVM [4; 25],<br>a graph-based transductive learner [9], and a leave-one-out<br>error ridge regression method [26]. Joachims [25] describes<br>an approximate solver for the semi-supervised SVM which<br>utilizes a fast SVM optimizer as an inner loop.<br>The story is not all good. [10] tells us that while unlabeled<br>data may be useful, labeled examples are exponentially more<br>valuable in a suitable sense. [43] tells us that unlabeled data<br>may lead the transductive SVM to maximize the wrong mar-<br>gin, and in [42] it is shown that unlabeled data may in fact<br>degrade classifier performance under certain conditions re-<br>lating the risk and empirical risk. Nonetheless, learning from<br>partially labeled data has enjoyed great success in many the-<br>oretical and empirical studies [16; 42; 44; 43].<br>We are especially interested in partially labeled learning as<br>an approach to the low-level microarray analysis problems<br>discussed in Sections 3­5, where we have relatively few la-<br>beled examples but an abundant source of unlabeled data.<br>[45] is a recent example of partially labeled learning applied<br>to high-level microarray analysis.</span></nobr></DIV>
<DIV style="position:absolute;top:717;left:694"><nobr><span class="ft2">There, the problem of</span></nobr></DIV>
<DIV style="position:absolute;top:733;left:475"><nobr><span class="ft6">predicting gene function is tackled using a semi-supervised<br>scheme trained on a two-component dataset of DNA mi-<br>croarray expression profiles and phylogenetic profiles from<br>whole-genome sequence comparisons. This leads us to the<br>next relevant idea from machine learning.</span></nobr></DIV>
<DIV style="position:absolute;top:824;left:475"><nobr><span class="ft4"><b>2.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:824;left:516"><nobr><span class="ft4"><b>Learning from Heterogeneous Data</b></span></nobr></DIV>
<DIV style="position:absolute;top:846;left:475"><nobr><span class="ft6">Learning from heterogeneous data is the process of learning<br>from training data, labeled or not, that can be partitioned<br>into subsets, each of which contains a different type of data<br>structure or originates from a different source. This notion<br>is equivalent to the methods of data fusion [5].<br>Research into learning from heterogeneous data tends to<br>be quite domain-specific and has enjoyed increasing interest<br>from the bioinformatics community in particular (e.g., [18]).<br>[46] presents a kernel-based framework for learning from het-<br>erogeneous descriptions of a collection of genes, proteins or<br>other entities. The authors demonstrate the method's supe-<br>riority to the homogeneous case on the problem of predict-<br>ing yeast protein function using knowledge of amino acid<br>sequence, protein complex data, gene expression data, and<br>known protein-protein interactions.</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:77"><nobr><span class="ft5">SIGKDD Explorations.</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:639"><nobr><span class="ft5">Volume 5,Issue 2 - Page 131 </span></nobr></DIV>
</DIV>
<!-- Page 3 -->
<a name="3"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft10{font-size:14px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="134003.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft6">[37] proposes an SVM method for classifying gene function<br>from microarray expression estimates and phylogenetic pro-<br>files. This is achieved through the construction of an ex-<br>plicitly heterogeneous kernel: first separate kernels are con-<br>structed for each data type, taking into account high-order<br>within-type correlations, then these kernels are combined,<br>ignoring high-order across-type correlations.<br>Our interest in learning from heterogeneous data arises be-<br>cause several sources of knowledge relevant to low-level mi-<br>croarray analysis are available, and incorporating such prob-<br>lem domain knowledge has been shown to improve the per-<br>formance of learning algorithms in the past.</span></nobr></DIV>
<DIV style="position:absolute;top:288;left:81"><nobr><span class="ft4"><b>2.3</b></span></nobr></DIV>
<DIV style="position:absolute;top:288;left:121"><nobr><span class="ft4"><b>Incremental Learning</b></span></nobr></DIV>
<DIV style="position:absolute;top:310;left:81"><nobr><span class="ft6">Incremental learning is focused on learning from data pre-<br>sented sequentially, where the model may be required to<br>make predictions on unseen data during training. This is in<br>contrast to cases where all training occurs before any pre-<br>dictions are made (batch learning ), and is similar to online<br>learning [24].<br>A number of incremental learning algorithms have been pro-<br>posed and applied in the literature. For example, several<br>incremental support vector machines have been studied [24;<br>21; 47]. In [48], incremental learning is applied to distributed<br>video surveillance. SVM algorithm parameter selection is<br>investigated in [47]. [21] applies an incremental SVM to de-<br>tecting concept drift ­ the problem of varying distributions<br>over long periods of data gathering ­ and to adaptive classi-<br>fication of documents with respect to user interest. An exact<br>incremental SVM is proposed in [24], where decremental un-<br>learning of incremental training data is possible. This can<br>be used to efficiently evaluate the computationally-expensive<br>leave-one-out error measure.<br>Due to the relatively small sizes of datasets typically avail-<br>able in low-level microarray analysis, there is great potential<br>for learners that can incrementally incorporate new data<br>gathered in the lab, thereby improving estimator perfor-<br>mance specific to that lab's patterns of microarray assay.</span></nobr></DIV>
<DIV style="position:absolute;top:711;left:81"><nobr><span class="ft4"><b>3.</b></span></nobr></DIV>
<DIV style="position:absolute;top:711;left:112"><nobr><span class="ft4"><b>EXPRESSION ANALYSIS</b></span></nobr></DIV>
<DIV style="position:absolute;top:732;left:81"><nobr><span class="ft6">The most successful application of DNA microarray tech-<br>nology to date has been to gene expression analysis. Tra-<br>ditionally, this has involved estimating gene expression lev-<br>els (Section 3.1), an area that is being addressed through<br>successful statistical methods and active statistics research.<br>However, the task of determining transcription activity over<br>entire chromosomes (Section 3.2) is less well developed and<br>offers serious opportunities for machine learning.</span></nobr></DIV>
<DIV style="position:absolute;top:870;left:81"><nobr><span class="ft4"><b>3.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:870;left:121"><nobr><span class="ft4"><b>Gene Expression Monitoring</b></span></nobr></DIV>
<DIV style="position:absolute;top:904;left:81"><nobr><span class="ft10"><i>3.1.1</i></span></nobr></DIV>
<DIV style="position:absolute;top:904;left:130"><nobr><span class="ft10"><i>The Problem</i></span></nobr></DIV>
<DIV style="position:absolute;top:924;left:81"><nobr><span class="ft6">Traditional microarrays measure mRNA target abundance<br>using the scanned intensities of fluorescence from tagged<br>molecules hybridized to substrate-attached probes [29]. The<br>brighter the intensity within a cell of identical probes, the<br>more hybridization there has been to those probes (Fig-<br>ure 2a). The scanned intensity, then, roughly corresponds<br>to target abundance.<br>Since probes are limited in length while targets may be thou-<br>sands of bases long, the GeneChip uses a set of probes to<br>detect each target nucleic acid. The probes are spread out</span></nobr></DIV>
<DIV style="position:absolute;top:411;left:475"><nobr><span class="ft6">Figure 2: Probe-level features for expression level summa-<br>rization: (a) a cell of probes; (b) target transcript, per-<br>fect match probe and mis-match probe sequences; and (c)<br>scanned and image-analyzed probe-level intensities.</span></nobr></DIV>
<DIV style="position:absolute;top:500;left:475"><nobr><span class="ft6">along a 600 base pair region close to the 3' end of the tran-<br>script. To measure the effects of cross-hybridization, or un-<br>intended hybridization of target A to the probes intended for<br>target B, a system of probe pairs is used. In each pair, a per-<br>fect match (PM) probe contains the target's exact comple-<br>mentary sequence, while a mismatch (MM) probe replaces<br>the middle base of the perfect match probe with its Watson-<br>Crick complement. In this way, a target is probed by a probe<br>set of 11-20 PM-MM probe pairs. The aim is roughly for<br>the PMs to measure signal plus noise and for the MMs to<br>measure just noise, so that the signal is revealed using some<br>function of (PM - MM). Figure 2b depicts the probe set ar-<br>rangement, while Figure 2c gives an example of the scanned<br>intensities. We may now define the expression level summa-<br>rization problem.</span></nobr></DIV>
<DIV style="position:absolute;top:748;left:490"><nobr><span class="ft2">Low-level Problem 1. Given a probe set's intensities (pos-</span></nobr></DIV>
<DIV style="position:absolute;top:763;left:475"><nobr><span class="ft6">sibly after background correction and normalization), the<br>expression level summarization problem is to estimate the<br>amount of target transcript present in the sample.</span></nobr></DIV>
<DIV style="position:absolute;top:823;left:475"><nobr><span class="ft6">While the expression level summary aims to estimate gene<br>expression level from the features of Figure 2, expression<br>detection is concerned with determining the presence of any<br>gene expression at all.</span></nobr></DIV>
<DIV style="position:absolute;top:898;left:490"><nobr><span class="ft2">Low-level Problem 2. Given a probe set's intensities, pos-</span></nobr></DIV>
<DIV style="position:absolute;top:913;left:475"><nobr><span class="ft6">sibly normalized, the expression detection problem is to pre-<br>dict whether the target transcript is present (P) or absent<br>(A) in the sample, or otherwise call marginal (M) if it is too<br>difficult to tell. In addition to the P/M/A detection call, we<br>wish to state a confidence level in the call, such as a p-value.</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:475"><nobr><span class="ft6">Detection calls are not as widely utilized as expression level<br>estimates. They are often used, for example, to filter out<br>genes with negligible expression before performing computat-<br>ionally-expensive high-level analyses, such as clustering on<br>gene expression profiles.</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:77"><nobr><span class="ft5">SIGKDD Explorations.</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:639"><nobr><span class="ft5">Volume 5,Issue 2 - Page 132 </span></nobr></DIV>
</DIV>
<!-- Page 4 -->
<a name="4"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft11{font-size:5px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="134004.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft6">The previous two problems dealt with estimates based on a<br>single probe-set read from a single array. Comparative stud-<br>ies, on the other hand, involve assaying two arrays, one the<br>baseline and the other the experiment, followed by compu-<br>tation of a single comparative estimate.</span></nobr></DIV>
<DIV style="position:absolute;top:173;left:96"><nobr><span class="ft2">Low-level Problem 3. Given two sets of intensities, possi-</span></nobr></DIV>
<DIV style="position:absolute;top:189;left:81"><nobr><span class="ft2">bly normalized, for the same probe set on two arrays:</span></nobr></DIV>
<DIV style="position:absolute;top:211;left:81"><nobr><span class="ft2">a. The differential expression level summarization problem</span></nobr></DIV>
<DIV style="position:absolute;top:226;left:98"><nobr><span class="ft6">is to estimate the relative abundance of target transcript<br>on each array.</span></nobr></DIV>
<DIV style="position:absolute;top:266;left:80"><nobr><span class="ft2">b. The comparison call problem is to predict whether the</span></nobr></DIV>
<DIV style="position:absolute;top:282;left:98"><nobr><span class="ft6">expression of the target has increased, not changed, or<br>decreased from one chip to the other. As in Low-level<br>Problem 2, a statement of confidence in the call should<br>be supplied.</span></nobr></DIV>
<DIV style="position:absolute;top:353;left:81"><nobr><span class="ft6">The log-ratio of expression levels for a target is sometimes<br>known as the relative expression level [3] and is closely re-<br>lated to the notion of fold change (which is sign(log-ratio) ×</span></nobr></DIV>
<DIV style="position:absolute;top:404;left:81"><nobr><span class="ft6">2log-ratio). Comparison calls are sometimes referred to as<br>change calls. An advantage of working with these compar-<br>ative estimates is that probe-specific affinities (one cause<br>of undesired variation) are approximately cancelled out by<br>taking ratios [3].<br>All of these problems are complicated by exogenous sources<br>of variation which cloud the quantities we are interested in.<br>[49] proposes a breakdown of the sources of variation in mi-<br>croarray experiments into intrinsic noise (variation inherent<br>in the experiment's subjects), intermediate noise (arising<br>for example from laboratory procedures), and measurement<br>error (variation due to the instrumentation, such as array<br>manufacture, scanning, or in silico processing).</span></nobr></DIV>
<DIV style="position:absolute;top:619;left:81"><nobr><span class="ft10"><i>3.1.2</i></span></nobr></DIV>
<DIV style="position:absolute;top:619;left:130"><nobr><span class="ft10"><i>Current Approaches</i></span></nobr></DIV>
<DIV style="position:absolute;top:639;left:81"><nobr><span class="ft6">At the level of microarray design, sophisticated probe model-<br>ing and combinatorial techniques are used to reduce probe-<br>specific effects and cross-hybridization. However, much of<br>the unwanted variation identified above must still be tack-<br>led during low-level analysis. This means that care must<br>be taken with the relevant statistical issues. For example,<br>in experimental design, we must trade off between biologi-<br>cal replicates (across samples) and technical replicates (one<br>sample across chips). Background correction and normal-<br>ization, for reducing systematic variation within and across<br>replicate arrays, also surface as major considerations [19;<br>11].<br>Three popular approaches to Low-level Problem 1 [11] are<br>the Affymetrix microarray suite (MAS) 5.0 signal measure<br>[14; 3; 1], the robust multi-array average (RMA) [50; 11]<br>and the model-based expression index (MBEI) [51].<br>MAS5 first performs background correction by subtracting a<br>background estimate for each cell, computed by partitioning<br>the array into rectangular zones and setting the background<br>of each zone to that zone's second-percentile intensity. Next<br>MAS5 subtracts an "ideal mismatch value" from each PM<br>intensity and log-transforms the adjusted PMs to stabilize<br>the variance. A robust mean is computed for the resulting<br>values using a biweight estimator, and finally this value is<br>scaled using a trimmed mean to produce the signal estimate.<br>RMA proceeds by first performing quantile normalization<br>[52], which puts the probe intensity distributions across repli-<br>cate arrays on the same scale. RMA then models the PMs</span></nobr></DIV>
<DIV style="position:absolute;top:315;left:475"><nobr><span class="ft6">Figure 3: An ROC curve: (0, 0) and (1, 1) correspond to<br>the "always negative" and "always positive" classifiers re-<br>spectively. The closer to the ideal point (0, 1) the better.<br>Neither of the two families A or B dominates the other. In-<br>stead, one or the other is better according to the desired<br>trade-off between FP and TP.</span></nobr></DIV>
<DIV style="position:absolute;top:443;left:475"><nobr><span class="ft7">as background plus signal, where the signal is exponentially<br>and the background normally distributed ­ MM intensities<br>are not used in RMA. A robust additive model is used to<br>model the PM signal (in log-space) as the sum of the log<br>scale expression level, a probe affinity effect, and an i.i.d.<br>error term. Finally, median polish estimates the model pa-<br>rameters and produces the log-scale expression level sum-<br>mary.<br>MBEI fits P M</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:561"><nobr><span class="ft8">i,j</span></nobr></DIV>
<DIV style="position:absolute;top:569;left:575"><nobr><span class="ft2">-M M</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:615"><nobr><span class="ft8">i,j</span></nobr></DIV>
<DIV style="position:absolute;top:570;left:632"><nobr><span class="ft2">= </span></nobr></DIV>
<DIV style="position:absolute;top:575;left:653"><nobr><span class="ft8">i</span></nobr></DIV>
<DIV style="position:absolute;top:570;left:658"><nobr><span class="ft2"></span></nobr></DIV>
<DIV style="position:absolute;top:575;left:666"><nobr><span class="ft8">j</span></nobr></DIV>
<DIV style="position:absolute;top:570;left:673"><nobr><span class="ft2">+</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:690"><nobr><span class="ft8">i,j</span></nobr></DIV>
<DIV style="position:absolute;top:570;left:703"><nobr><span class="ft2">, using maximum like-</span></nobr></DIV>
<DIV style="position:absolute;top:586;left:475"><nobr><span class="ft2">lihood to estimate the per-gene expression levels </span></nobr></DIV>
<DIV style="position:absolute;top:590;left:769"><nobr><span class="ft8">i</span></nobr></DIV>
<DIV style="position:absolute;top:586;left:774"><nobr><span class="ft2">. Here the</span></nobr></DIV>
<DIV style="position:absolute;top:601;left:475"><nobr><span class="ft2"></span></nobr></DIV>
<DIV style="position:absolute;top:606;left:483"><nobr><span class="ft8">j</span></nobr></DIV>
<DIV style="position:absolute;top:601;left:494"><nobr><span class="ft2">are probe-specific affinities and the</span></nobr></DIV>
<DIV style="position:absolute;top:606;left:717"><nobr><span class="ft8">i,j</span></nobr></DIV>
<DIV style="position:absolute;top:601;left:735"><nobr><span class="ft2">are i.i.d. normal</span></nobr></DIV>
<DIV style="position:absolute;top:617;left:475"><nobr><span class="ft6">errors.<br>Although it may seem that expression detection is just a<br>matter of thresholding expression level estimates, this has<br>proven not to be the case [53]. It is known that expres-<br>sion level estimators often have difficulty at low levels of ex-<br>pression, while detection algorithms are designed with this<br>setting in mind.<br>The most widely used detection algorithm for the GeneChip<br>is a method based on a Wilcoxon signed-rank test [54; 3;<br>55]. This algorithm corresponds to a hypothesis test of H</span></nobr></DIV>
<DIV style="position:absolute;top:765;left:820"><nobr><span class="ft8">0</span></nobr></DIV>
<DIV style="position:absolute;top:761;left:830"><nobr><span class="ft2">:</span></nobr></DIV>
<DIV style="position:absolute;top:776;left:475"><nobr><span class="ft2">median(</span></nobr></DIV>
<DIV style="position:absolute;top:773;left:529"><nobr><span class="ft8">P M</span></nobr></DIV>
<DIV style="position:absolute;top:776;left:547"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:773;left:552"><nobr><span class="ft8">-M M</span></nobr></DIV>
<DIV style="position:absolute;top:776;left:583"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:784;left:529"><nobr><span class="ft8">P M</span></nobr></DIV>
<DIV style="position:absolute;top:787;left:548"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:784;left:552"><nobr><span class="ft8">+M M</span></nobr></DIV>
<DIV style="position:absolute;top:787;left:582"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:776;left:589"><nobr><span class="ft2">) =  versus H</span></nobr></DIV>
<DIV style="position:absolute;top:781;left:680"><nobr><span class="ft8">1</span></nobr></DIV>
<DIV style="position:absolute;top:776;left:691"><nobr><span class="ft2">: median(</span></nobr></DIV>
<DIV style="position:absolute;top:773;left:753"><nobr><span class="ft8">P M</span></nobr></DIV>
<DIV style="position:absolute;top:776;left:772"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:773;left:776"><nobr><span class="ft8">-M M</span></nobr></DIV>
<DIV style="position:absolute;top:776;left:807"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:784;left:753"><nobr><span class="ft8">P M</span></nobr></DIV>
<DIV style="position:absolute;top:787;left:772"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:784;left:776"><nobr><span class="ft8">+M M</span></nobr></DIV>
<DIV style="position:absolute;top:787;left:807"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:776;left:813"><nobr><span class="ft2">) &gt;</span></nobr></DIV>
<DIV style="position:absolute;top:794;left:475"><nobr><span class="ft6"> , where  is a small positive constant. These hypotheses<br>correspond to absence and presence of expression, respec-<br>tively. The test is conducted using a p-value for a sum of<br>signed ranks R</span></nobr></DIV>
<DIV style="position:absolute;top:845;left:568"><nobr><span class="ft8">i</span></nobr></DIV>
<DIV style="position:absolute;top:841;left:579"><nobr><span class="ft2">=</span></nobr></DIV>
<DIV style="position:absolute;top:838;left:597"><nobr><span class="ft8">P M</span></nobr></DIV>
<DIV style="position:absolute;top:841;left:616"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:837;left:621"><nobr><span class="ft8">-M M</span></nobr></DIV>
<DIV style="position:absolute;top:841;left:651"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:848;left:597"><nobr><span class="ft8">P M</span></nobr></DIV>
<DIV style="position:absolute;top:851;left:616"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:848;left:621"><nobr><span class="ft8">+M M</span></nobr></DIV>
<DIV style="position:absolute;top:851;left:651"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:840;left:662"><nobr><span class="ft2">-  . The p-value is thresh-</span></nobr></DIV>
<DIV style="position:absolute;top:859;left:475"><nobr><span class="ft2">olded so that values in [0, </span></nobr></DIV>
<DIV style="position:absolute;top:863;left:651"><nobr><span class="ft8">1</span></nobr></DIV>
<DIV style="position:absolute;top:859;left:657"><nobr><span class="ft2">), [</span></nobr></DIV>
<DIV style="position:absolute;top:863;left:686"><nobr><span class="ft8">1</span></nobr></DIV>
<DIV style="position:absolute;top:859;left:692"><nobr><span class="ft2">, </span></nobr></DIV>
<DIV style="position:absolute;top:863;left:707"><nobr><span class="ft8">2</span></nobr></DIV>
<DIV style="position:absolute;top:859;left:713"><nobr><span class="ft2">), and [</span></nobr></DIV>
<DIV style="position:absolute;top:863;left:770"><nobr><span class="ft8">2</span></nobr></DIV>
<DIV style="position:absolute;top:859;left:777"><nobr><span class="ft2">, 1] result</span></nobr></DIV>
<DIV style="position:absolute;top:874;left:475"><nobr><span class="ft6">in present, marginal, and absent calls, respectively. Here<br>0 &lt; </span></nobr></DIV>
<DIV style="position:absolute;top:895;left:510"><nobr><span class="ft8">1</span></nobr></DIV>
<DIV style="position:absolute;top:890;left:521"><nobr><span class="ft2">&lt; </span></nobr></DIV>
<DIV style="position:absolute;top:895;left:545"><nobr><span class="ft8">2</span></nobr></DIV>
<DIV style="position:absolute;top:890;left:555"><nobr><span class="ft2">&lt; 0.5 control the trade-off between false posi-</span></nobr></DIV>
<DIV style="position:absolute;top:906;left:475"><nobr><span class="ft6">tives (FP) and true positives (TP).<br>Recently, a number of alternate rank sum-based algorithms<br>have been proposed [53]. One in particular ­ a variant on<br>the MAS5 method where scores are set to R</span></nobr></DIV>
<DIV style="position:absolute;top:959;left:747"><nobr><span class="ft8">i</span></nobr></DIV>
<DIV style="position:absolute;top:954;left:756"><nobr><span class="ft2">= log</span></nobr></DIV>
<DIV style="position:absolute;top:951;left:795"><nobr><span class="ft8">P M</span></nobr></DIV>
<DIV style="position:absolute;top:954;left:814"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:962;left:794"><nobr><span class="ft8">M M</span></nobr></DIV>
<DIV style="position:absolute;top:965;left:815"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:954;left:827"><nobr><span class="ft2">­</span></nobr></DIV>
<DIV style="position:absolute;top:971;left:475"><nobr><span class="ft6">has been shown to outperform MAS5 detection in a range<br>of real-world situations.</span></nobr></DIV>
<DIV style="position:absolute;top:987;left:635"><nobr><span class="ft2">One aspect of the study in [53]</span></nobr></DIV>
<DIV style="position:absolute;top:1003;left:475"><nobr><span class="ft6">of particular interest is the use of the Receiver Operating<br>Characteristic (ROC) Convex Hull method [56] for compar-<br>ing competing classifiers on a spike-in test set.<br>ROC curves (see Figure 3) characterize the classification<br>performance of a family of classifiers parameterized by a tun-</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:77"><nobr><span class="ft5">SIGKDD Explorations.</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:639"><nobr><span class="ft5">Volume 5,Issue 2 - Page 133 </span></nobr></DIV>
</DIV>
<!-- Page 5 -->
<a name="5"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="134005.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft6">able parameter that controls the FP-TP trade-off. For ex-<br>ample, as the level of a hypothesis test is decreased, the rate<br>of false positive rejections decreases (by definition), while<br>the rate of false negative acceptances will typically go up.<br>An ROC curve encodes this trade-off, extending the notion<br>of contingency table to an entire curve. It is a more expres-<br>sive object than accuracy, which boils performance down to<br>one number [56; 57].<br>Comparing ROC curves has traditionally been achieved by<br>either choosing the "clear winner" (in the rare case of dom-<br>ination [57]), or choosing the maximizer of the Area Under<br>Curve (AUC). Although AUC works in some cases, it gives<br>equal credit to performance over all misclassification cost<br>and class size settings ­ usually an undesirable strategy if<br>any domain knowledge is available. The ROC Convex Hull<br>method, on the other hand, relates expected-cost optimality<br>to conditions on relative misclassification cost and class size,<br>so that the typical case of semi-dominance (as in Figure 3)<br>can be handled in a principled way ­ rather than selecting<br>p-value thresholds by hand, end-users are provided with the<br>right classifier and thresholds by the method. This use of<br>the ROCCH method demonstrates a surprising application<br>of machine learning to low-level microarray analysis.<br>Many of these absolute expression algorithms have their<br>comparative analogues. For example, MAS5 produces the<br>signal log ratio with an associated confidence interval, us-<br>ing a biweight algorithm [14; 3]. MAS5 also implements a<br>comparison call based on the Wilcoxon signed-rank sum test,<br>just as in the absolute MAS5 detection algorithm above [55].<br>While the Affymetrix microarray suite is the software pack-<br>age bundled with the GeneChip, the Bioconductor project<br>[15] ­ an open-source set of R [12] packages for bioinformat-<br>ics data analysis ­ has been gaining popularity and imple-<br>ments most of the methods discussed here.</span></nobr></DIV>
<DIV style="position:absolute;top:635;left:81"><nobr><span class="ft10"><i>3.1.3</i></span></nobr></DIV>
<DIV style="position:absolute;top:635;left:130"><nobr><span class="ft10"><i>Open Problems</i></span></nobr></DIV>
<DIV style="position:absolute;top:655;left:81"><nobr><span class="ft6">While Low-level Problem 1 involves prediction of continuous<br>expression levels (non-negative real values) given a vector of<br>(non-negative real) perfect match and mismatch intensities,<br>with total length between 22 and 40, Low-level Problem 2 is<br>a 3-class classification problem with call confidence levels.</span></nobr></DIV>
<DIV style="position:absolute;top:752;left:96"><nobr><span class="ft2">Open Problem 1. In the respective settings of Low-level</span></nobr></DIV>
<DIV style="position:absolute;top:765;left:81"><nobr><span class="ft2">Problems 1­3:</span></nobr></DIV>
<DIV style="position:absolute;top:793;left:80"><nobr><span class="ft2">a. What machine learning techniques are competitive with</span></nobr></DIV>
<DIV style="position:absolute;top:809;left:98"><nobr><span class="ft6">algorithms based on classical statistical methods for ex-<br>pression level estimation?</span></nobr></DIV>
<DIV style="position:absolute;top:851;left:81"><nobr><span class="ft2">b. Which machine learning classifiers are competitive for ex-</span></nobr></DIV>
<DIV style="position:absolute;top:867;left:98"><nobr><span class="ft2">pression detection?</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:81"><nobr><span class="ft2">c. What machine learning methods achieve high performance</span></nobr></DIV>
<DIV style="position:absolute;top:910;left:98"><nobr><span class="ft6">on the comparative analogues of the previous two prob-<br>lems, posed on the appropriate product space of microar-<br>ray measurements?</span></nobr></DIV>
<DIV style="position:absolute;top:972;left:81"><nobr><span class="ft6">Comparisons for expression level estimators might be made<br>based on bias and variance, computational efficiency, and bi-<br>ological relevance of learned models. The ROCCH method<br>is ideal for detector comparison. Issues of background cor-<br>rection and normalization across multiple arrays must likely<br>also be addressed to enable competitiveness with the state<br>of the art.</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft6">Research into applying semi-supervised, heterogeneous data<br>and incremental learners to gene expression monitoring is di-<br>rectly motivated by the proportion of labeled to unlabeled<br>data available, the existence of GeneChip domain knowl-<br>edge, and the endemic nature of microarray assays that are<br>continually performed in individual research labs. Biologists<br>could augment the limited labeled probe-level data available<br>with relatively abundant unlabeled data. Labeled data can<br>be procured, for example, from bacterial control experiments<br>with known concentrations, called spike-in assays, and bac-<br>terial control probe sets that are present in some GeneChips<br>for calibration purposes. The former source of labeled data<br>is the more useful for this problem, as it provides examples<br>with a range of labels. Unfortunately, spike-in studies are<br>rare because they are not of independent scientific interest:<br>they are only performed for low-level microarray research.<br>For the few spike-in assays that are available, only a small<br>number of targets are spiked in at an equally small number of<br>concentrations (typically 10). Unlabeled data, in contrast,<br>could be taken from the large collection of available biolog-<br>ically relevant assays; each one providing tens of thousands<br>of data points. Beyond probe intensities, other data sources<br>could include probe sequences and probe-affinity informa-<br>tion derived from probe models. Such information is closely<br>related to the hybridization process and might be of use<br>in expression level estimation: both target and non-specific<br>hybridization are known to be probe-dependent. Although<br>labeled data from spike-in studies are of greatest utility for<br>learning [10], the quantity of unlabeled data produced by<br>a series of biologically interesting microarray assays in any<br>given lab suggests a semi-supervised incremental approach.<br>Since the ROCCH involves taking a pointwise maximum<br>over the individual noisy ROC curves, it incorporates a pos-<br>sibly large degree of uncertainty. It should be possible to<br>extend the results of [53] to quantify this property.</span></nobr></DIV>
<DIV style="position:absolute;top:656;left:490"><nobr><span class="ft2">Open Problem 2. Can the ROC Convex Hull method</span></nobr></DIV>
<DIV style="position:absolute;top:669;left:475"><nobr><span class="ft6">of [56] be extended to provide confidence intervals for its<br>conditions on expected-cost optimality?</span></nobr></DIV>
<DIV style="position:absolute;top:714;left:475"><nobr><span class="ft4"><b>3.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:714;left:516"><nobr><span class="ft4"><b>Transcript Discovery</b></span></nobr></DIV>
<DIV style="position:absolute;top:747;left:475"><nobr><span class="ft10"><i>3.2.1</i></span></nobr></DIV>
<DIV style="position:absolute;top:747;left:525"><nobr><span class="ft10"><i>The Problem</i></span></nobr></DIV>
<DIV style="position:absolute;top:767;left:475"><nobr><span class="ft6">The applications to expression monitoring described above<br>are all related to addressing questions about pre-defined<br>transcripts.</span></nobr></DIV>
<DIV style="position:absolute;top:799;left:557"><nobr><span class="ft2">More precisely, the vast majority of expres-</span></nobr></DIV>
<DIV style="position:absolute;top:814;left:475"><nobr><span class="ft6">sion analysis is performed using probes interrogating only<br>a small sub-sequence of each transcript. This has clearly<br>been a useful approach, but there are at least two potential<br>drawbacks. One is that we can only monitor the expression<br>of genes known to exist at the time of the array's design.<br>Even in a genome as well-studied as that of the human, new<br>transcripts are routinely discovered. Another is that in di-<br>rectly monitoring only a sub-sequence of the transcript, it<br>will often be impossible to distinguish between alternatively<br>spliced forms of the same gene (which may have very differ-<br>ent functional roles).<br>An alternative approach is to use arrays with probes tiled<br>uniformly across genomic sequence, without regard to cur-<br>rent knowledge of transcription.</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:690"><nobr><span class="ft2">Such genome tiling ar-</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:475"><nobr><span class="ft6">rays have been used to monitor expression in all the non-<br>repetitive sequence of human chromosomes 21 and 22 [34],<br>and more widespread use is underway.</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:77"><nobr><span class="ft5">SIGKDD Explorations.</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:639"><nobr><span class="ft5">Volume 5,Issue 2 - Page 134 </span></nobr></DIV>
</DIV>
<!-- Page 6 -->
<a name="6"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="134006.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft6">The problems arising in the analysis of data from genome<br>tiling arrays are essentially the same as those for the ex-<br>pression monitoring arrays described above: estimation of<br>expression level, detection of presence, and detection of dif-<br>ferential expression. There is, however, the additional chal-<br>lenge of determining the number of distinct transcripts and<br>their location within the tiled genomic region.</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:96"><nobr><span class="ft2">Low-level Problem 4. The problem of transcript discovery</span></nobr></DIV>
<DIV style="position:absolute;top:226;left:81"><nobr><span class="ft2">can be viewed in two steps:</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:81"><nobr><span class="ft2">a. Determining the exon structure of genes within a tiled</span></nobr></DIV>
<DIV style="position:absolute;top:268;left:98"><nobr><span class="ft2">region; and</span></nobr></DIV>
<DIV style="position:absolute;top:294;left:80"><nobr><span class="ft2">b. Determining which exons should be classified together as</span></nobr></DIV>
<DIV style="position:absolute;top:310;left:98"><nobr><span class="ft2">part of a single gene's transcript.</span></nobr></DIV>
<DIV style="position:absolute;top:338;left:81"><nobr><span class="ft10"><i>3.2.2</i></span></nobr></DIV>
<DIV style="position:absolute;top:338;left:130"><nobr><span class="ft10"><i>Current Approaches</i></span></nobr></DIV>
<DIV style="position:absolute;top:359;left:81"><nobr><span class="ft6">A simple heuristic approach is taken in [34], in which PM-<br>MM probe pairs are classified as positive or negative based<br>on thresholds applied to the difference and ratio of the PM<br>and MM values. Positions classified as positive and located<br>close to other positive positions are grouped together to form<br>predicted exons.<br>A more effective approach [58] is based on the application of<br>a Wilcoxon signed-rank test in a sliding window along the<br>genomic sequence, using the associated Hodges-Lehmann es-<br>timator for estimation of expression level. Grouping into<br>exons is achieved by thresholding on present call p-values or<br>estimated expression level, then defining groups of probes<br>exceeding the threshold to be exons.</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:81"><nobr><span class="ft10"><i>3.2.3</i></span></nobr></DIV>
<DIV style="position:absolute;top:575;left:130"><nobr><span class="ft10"><i>Open Problems</i></span></nobr></DIV>
<DIV style="position:absolute;top:595;left:81"><nobr><span class="ft6">The problem of detecting exons based on probe intensities<br>(Low-level Problem 4a) is very similar to the problem of<br>absolute expression detection (Low-level Problem 2). For<br>example, the exon detection method of [58] and the MAS5<br>expression detection algorithm [55] are both built around<br>the Wilcoxon signed-rank test. The problem of finding ex-<br>ons has been addressed as described, but the methods are<br>heuristic and there is plenty of room for improvement. Asso-<br>ciating exons to form transcripts (Low-level Problem 4b) has<br>been addressed in a large experiment across almost 70 ex-<br>perimental pairs using a heuristic correlation-based method;<br>again, this presents an opportunity for research into more<br>effective methods.</span></nobr></DIV>
<DIV style="position:absolute;top:816;left:96"><nobr><span class="ft2">Open Problem 3. Are there machine learning methods</span></nobr></DIV>
<DIV style="position:absolute;top:829;left:81"><nobr><span class="ft6">that are able to out-perform current classical statistical meth-<br>ods in transcript discovery as defined in Low-Level Prob-<br>lem 4?</span></nobr></DIV>
<DIV style="position:absolute;top:890;left:81"><nobr><span class="ft6">One possibility which appears well suited to the problem is<br>the use of hidden Markov models where the underlying un-<br>observed Markov chain is over states representing expressed<br>versus non-expressed sequence. The distribution of the ob-<br>served probe intensities would depend on the underlying hid-<br>den state. Another possible approach, considering the suc-<br>cess which has been demonstrated in predicting genes from<br>sequence data alone, would also be to integrate array-derived<br>data with sequence information in prediction of transcripts.</span></nobr></DIV>
<DIV style="position:absolute;top:84;left:475"><nobr><span class="ft4"><b>4.</b></span></nobr></DIV>
<DIV style="position:absolute;top:84;left:507"><nobr><span class="ft4"><b>GENOTYPING</b></span></nobr></DIV>
<DIV style="position:absolute;top:115;left:475"><nobr><span class="ft4"><b>4.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:115;left:516"><nobr><span class="ft4"><b>The Problem</b></span></nobr></DIV>
<DIV style="position:absolute;top:136;left:475"><nobr><span class="ft6">Descriptions of genome sequencing efforts such as the hu-<br>man genome project often lend the impression that there<br>is a unique genomic sequence associated with each species.<br>This is a useful and approximately correct abstraction. But<br>in fact, any two individuals picked at random from a species<br>population will have differing nucleotides at a small fraction<br>of the corresponding positions in their genomes. Such single-<br>nucleotide polymorphisms, or SNPs, help form the basis of<br>genetically-determined variation across individuals. Biolo-<br>gists estimate that about one position in 1,000 in the human<br>genome is a SNP. With over 3 billion bases of genomic DNA,<br>we see that SNPs number in the several millions. Although<br>there are other kinds of individual genomic variation, such<br>as insertions, deletions, and duplications of DNA segments,<br>our focus here is SNPs.<br>Further complicating the picture is the fact that humans are<br>diploid organisms--each person possesses two complete but<br>different copies of the human genome, one inherited from the<br>mother and one from the father. Now consider a polymor-<br>phic position, or locus, at which two different bases occur<br>in the population, say G and T. These variants are called<br>the alleles at the locus, so in this case we are describing a<br>biallelic SNP. A given individual will have inherited either a<br>G or T in the paternal genome, and the same is true of the<br>maternal genome. Thus there are three possible genotypes,<br>or individual genetic signatures, at this SNP: they are de-<br>noted GG, TT, and GT. We do not distinguish the last case<br>from TG, since there is no inherent ordering of the paternal<br>and maternal genomes at a given polymorphic position.<br>We refer generically to the alleles of a biallelic SNP as A and<br>B. Biological evidence suggests that essentially all SNPs are<br>biallelic in humans. The genotyping problem, then, is to es-<br>tablish an individual's genotype as AA, BB, or AB for as<br>many SNPs as possible in the human genome. The com-<br>pletion of the human genome project means that one has<br>recourse to the full genomic sequence surrounding a SNP<br>to help solve the genotyping problem. Furthermore, various<br>large-scale public projects to locate SNPs and identify their<br>alleles exist, notably The SNP Consortium (TSC); the data<br>they generate may also be utilized for genotyping.<br>The major drawback to traditional genotyping protocols are<br>their lack of parallelism, with consequent expense in terms<br>of material and labor. In contrast, Kennedy et al. [33] de-<br>scribe whole-genome sampling analysis (WGSA), which en-<br>ables massively parallel genotyping via genotyping microar-<br>rays.<br>For the Affymetrix Mapping 10k Array, which genotypes<br>approximately 10,000 SNPs across the human genome, each<br>SNP actually has 56 corresponding probes, collectively term-<br>ed a miniblock. The miniblock has 7 probe quartets for the<br>SNP's flanking region on the forward strand and another 7<br>probe quartets for the reverse complement strand, so 4 × 7 ×<br>2 yields 56 probes. Each probe quartet in turn corresponds<br>to a 25-mer in which the SNP is at one of 7 offsets from the<br>central position. The four probes within a probe quartet<br>differ in the base they put at the SNP: a perfect match to<br>the A allele, a perfect match to the B allele, and mismatches<br>for each.</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:490"><nobr><span class="ft2">Low-level Problem 5. Given a SNP's 56-vector of miniblo-</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:77"><nobr><span class="ft5">SIGKDD Explorations.</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:639"><nobr><span class="ft5">Volume 5,Issue 2 - Page 135 </span></nobr></DIV>
</DIV>
<!-- Page 7 -->
<a name="7"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="134007.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft6">ck probe intensities, the genotype calling problem is to pre-<br>dict the individual's corresponding alleles as AA, BB or AB.</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:81"><nobr><span class="ft6">Write PM(A), PM(B), MM(A), and MM(B) for the probe<br>intensities within a quartet. We would then hope that an<br>AA individual has PM(A) &gt; MM(A) but PM(B)  MM(B),<br>for all probe quartets on both strands. For a BB individual,<br>we hope to find just the opposite effect, and an AB indi-<br>vidual should have both PM(A) &gt; MM(A) and PM(B) &gt;<br>MM(B). The mismatch probes in each quartet act as con-<br>trols, establishing the level of nonspecific hybridization for<br>their corresponding perfect match probes. The presence of<br>multiple probe quartets allows for the determination of geno-<br>type even when one strand and/or some offsets do not yield<br>reliable hybridization, say for biochemical reasons.</span></nobr></DIV>
<DIV style="position:absolute;top:329;left:81"><nobr><span class="ft4"><b>4.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:329;left:121"><nobr><span class="ft4"><b>Current Approaches</b></span></nobr></DIV>
<DIV style="position:absolute;top:350;left:81"><nobr><span class="ft6">Low-level Problem 5 is a three-class classification problem.<br>In many machine learning applications, the metric of interest<br>for competing classifiers is predictive accuracy, in this case<br>the probability of correctly genotyping a new individual's<br>SNP based on the miniblock vector. However, in the kinds<br>of genetic studies which take large numbers of genotypes as<br>input, there is usually an explicit requirement that geno-<br>type predictions have a prespecified accuracy, often 99%.<br>To attain such accuracy, it is usually permissible for some<br>fraction of genotypable SNPs to be no-calls; that is, the clas-<br>sifier can refuse to predict a genotype for some miniblocks.<br>When comparing genotypers, our interest therefore lies in<br>the trade-off between the rate of no-calls and the accuracy<br>attained on those SNPs which are called. For example, some<br>studies consider the punt rate, or lowest no-call rate which<br>yields a prespecified accuracy level on the called SNPs.<br>A simple unsupervised approach to training a genotyper<br>is to ignore available labels during training, instead using<br>these labels to subsequently assess the trade-off between ac-<br>curacy and no-call rate for the trained model. This is the<br>strategy pursued by MPAM (modified partitioning around<br>medoids) [59], the discriminative clustering genotyper used<br>for the Affymetrix 10k array. An alternative approach, us-<br>ing a parametric generative model for the clustering, will<br>be described elsewhere.</span></nobr></DIV>
<DIV style="position:absolute;top:728;left:239"><nobr><span class="ft2">It resembles ABACUS, a model</span></nobr></DIV>
<DIV style="position:absolute;top:744;left:81"><nobr><span class="ft6">studied in the context of re-sequencing microarrays [31] (see<br>Section 5).</span></nobr></DIV>
<DIV style="position:absolute;top:785;left:81"><nobr><span class="ft4"><b>4.3</b></span></nobr></DIV>
<DIV style="position:absolute;top:785;left:121"><nobr><span class="ft4"><b>Open Problems</b></span></nobr></DIV>
<DIV style="position:absolute;top:821;left:96"><nobr><span class="ft2">Open Problem 4. Are there machine learning methods</span></nobr></DIV>
<DIV style="position:absolute;top:834;left:81"><nobr><span class="ft6">that are able to meet typical accuracy and punt-rate specifi-<br>cations on the genotype calling problem?</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:81"><nobr><span class="ft6">In order to choose a genotyper using supervised learning,<br>we need labels (true genotypes) along with corresponding<br>miniblock reads from genotyping arrays. Unfortunately, the-<br>re is no large-scale set of publicly available genotypes. In-<br>stead, one makes do with modestly-sized sets of genotypes<br>available commercially from companies using smaller-scale<br>techniques. Of course, no genotyping method is error-free,<br>so in practice one measures concordance with reference geno-<br>types.</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:129"><nobr><span class="ft2">If the concordance is high enough, the remaining</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:81"><nobr><span class="ft6">cases of disagreement between a candidate genotyper and<br>the reference genotypes can be resolved via the older labor-<br>intensive methods. The incomplete nature of reference geno-<br>type data leads naturally to the setting of semi-supervised</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft6">learning. Rather than falling back to unsupervised methods<br>such as those described above, we may consider employing<br>more general semi-supervised learners as described in Sec-<br>tion 2.1. Additionally, the methods of [23] could be used<br>to incorporate low-level physical parametric models of hy-<br>bridization into a kernel-based classifier.</span></nobr></DIV>
<DIV style="position:absolute;top:199;left:475"><nobr><span class="ft4"><b>5.</b></span></nobr></DIV>
<DIV style="position:absolute;top:199;left:507"><nobr><span class="ft4"><b>RE-SEQUENCING</b></span></nobr></DIV>
<DIV style="position:absolute;top:229;left:475"><nobr><span class="ft4"><b>5.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:229;left:516"><nobr><span class="ft4"><b>The Problem</b></span></nobr></DIV>
<DIV style="position:absolute;top:251;left:475"><nobr><span class="ft6">As explained in Section 4, within a single species genomic<br>sequence will vary slightly from one individual to the next.<br>While Low-level Problem 5 focuses on the determination of<br>genotype at a position known in advance to be polymorphic,<br>the problem described in this section concerns locating such<br>polymorphic sites in the first place.<br>The usual starting point is a newly-sequenced genome, such<br>as the recently-finished human genome. It is often the case<br>that, based on previous research, an investigator will be in-<br>terested in detailed study of variation in a particular ge-<br>nomic region (say on the order of tens or hundreds of kilo-<br>bases) and wants to re-sequence this region in a large num-<br>ber of individuals. Such re-sequencing allows for identifi-<br>cation of the small subset of polymorphic locations. Here<br>we consider the more recent challenges of microarray-based<br>re-sequencing of diploid genomic DNA.<br>A typical re-sequencing array uses eight probes to inter-<br>rogate each base of the monitored sequence. These eight<br>probes comprise two quartets, one for the forward strand<br>and one for the reverse. Each quartet is formed of 25-mer<br>probes perfectly complementary to the 25 bases of the ref-<br>erence sequence centered on the interrogated base, but with<br>all four possible bases used at the central position.</span></nobr></DIV>
<DIV style="position:absolute;top:628;left:490"><nobr><span class="ft2">Low-level Problem 6. The goal of the re-sequencing prob-</span></nobr></DIV>
<DIV style="position:absolute;top:643;left:475"><nobr><span class="ft6">lem is to start with a set of probe intensities and classify<br>each position as being one of A, C, G, T, AC, AG, AT, CG,<br>CT, GT, or N, where N represents a `no call' (due to sample<br>failure or ambiguous data).</span></nobr></DIV>
<DIV style="position:absolute;top:720;left:475"><nobr><span class="ft6">The intuition is that for a homozygous position, one of the<br>four probes should be much brighter relative to the others<br>on each strand, and for a heterozygous position, two probes<br>corresponding to the two bases of a SNP should be brighter<br>on each strand. Of particular interest are positions in which<br>the called base is heterozygous, or homozygous and different<br>to the reference sequence, as such positions exhibit polymor-<br>phism and are candidate positions for explaining phenotypic<br>differences between individuals.<br>At face value, this classification problem is much harder than<br>the genotyping problem. There are fewer probes to start<br>with (a miniblock of 8 rather than 40 or more) and more<br>categories (11 as opposed to 3 or 4) into which to classify.</span></nobr></DIV>
<DIV style="position:absolute;top:935;left:475"><nobr><span class="ft4"><b>5.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:935;left:516"><nobr><span class="ft4"><b>Current Approaches</b></span></nobr></DIV>
<DIV style="position:absolute;top:957;left:475"><nobr><span class="ft6">The most recent analysis of the kind of re-sequencing ar-<br>ray discussed here [31] is based on modeling pixel intensities<br>within each probe as independent random variables with<br>a common mean and variance. The model for a homozy-<br>gous base is that, on each strand, the probe correspond-</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:475"><nobr><span class="ft6">three probes have another. The means and variance are es-<br>timated by maximum likelihood, and the likelihood of the</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:77"><nobr><span class="ft5">SIGKDD Explorations.</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:475"><nobr><span class="ft2">ing to the base has one mean and variance, and the other</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:639"><nobr><span class="ft5">Volume 5,Issue 2 - Page 136 </span></nobr></DIV>
</DIV>
<!-- Page 8 -->
<a name="8"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="134008.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft6">model is evaluated. The model for each of the six heterozy-<br>gous possibilities is similar, except two probes correspond to<br>each heterozygote model and the other two are background.<br>The likelihoods (overall and for each strand) are converted<br>to scores and, provided the maximum score exceeds some<br>threshold, the best-scoring model is chosen as the base call.<br>A number of other filters that deal with the signal absence,<br>signal saturation, sample failure, and so on are applied, as is<br>an iterative procedure to account for bias in the background<br>probes. This method, called ABACUS, was found to make<br>base calls at over 80% of all bases, with an estimate accuracy<br>in excess of 99% at the bases which were called.</span></nobr></DIV>
<DIV style="position:absolute;top:285;left:81"><nobr><span class="ft4"><b>5.3</b></span></nobr></DIV>
<DIV style="position:absolute;top:285;left:121"><nobr><span class="ft4"><b>Open Problems</b></span></nobr></DIV>
<DIV style="position:absolute;top:306;left:81"><nobr><span class="ft6">A good base-calling method for re-sequencing arrays already<br>exists in ABACUS, but there remains room for improve-<br>ment. A recent and improved implementation [60] of the<br>ABACUS method on a new genomic region found the over-<br>all sequencing accuracy to be on the order of 99.998%, but<br>the accuracy on heterozygote calls to be about 96.7%. Bi-<br>ologists would value highly an improvement in heterozygote<br>call accuracy.</span></nobr></DIV>
<DIV style="position:absolute;top:449;left:96"><nobr><span class="ft2">Open Problem 5. Can a supervised learning method be</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:81"><nobr><span class="ft6">used to call bases in re-sequencing arrays with accuracy, in<br>particular heterozygote accuracy, in excess of the accuracies<br>achieved by the more classic statistical approaches used to<br>date?</span></nobr></DIV>
<DIV style="position:absolute;top:539;left:81"><nobr><span class="ft6">Considering the ongoing efforts of SNP detection projects,<br>there is an abundance of labeled data available, so the prob-<br>lem seems quite amenable to machine learning approaches.<br>As with the genotyping problem, it would be desirable to<br>have a measure of confidence associated with base calls. It<br>may also be useful to take into account the sequences of the<br>25-mer probes, as there are known sequence-specific effects<br>on the probe intensities.</span></nobr></DIV>
<DIV style="position:absolute;top:683;left:81"><nobr><span class="ft4"><b>6.</b></span></nobr></DIV>
<DIV style="position:absolute;top:683;left:112"><nobr><span class="ft4"><b>CONCLUSIONS</b></span></nobr></DIV>
<DIV style="position:absolute;top:705;left:81"><nobr><span class="ft6">We have described a variety of low-level problems in mi-<br>croarray data analysis and suggested the applicability of<br>methods from several areas of machine learning. Some prop-<br>erties of these problems which should be familiar to ma-<br>chine learning researchers include high-dimensional obser-<br>vations with complicated joint dependencies (probe inten-<br>sities), partially labeled data sets (expression levels, geno-<br>types), data from disparate domains (microarray assays,<br>probe sequences, phylogenetic information), and sequential<br>observations (ongoing experimental work at individual labs).<br>We pointed out the suitability of semi-supervised, heteroge-<br>neous, and incremental learning in these settings. It is worth<br>remarking that analogous problems arise with other high-<br>throughput technologies, such as cDNA and long oligonu-<br>cleotide microarrays, mass spectrometry, and fluorescence-<br>activated cell sorting.<br>There are other issues in low-level analysis we did not cover.<br>Here we mention two of these. Image analysis is the problem<br>of going from raw pixel values in the scanned image of a<br>microarray to a set of pixel intensities for each feature placed<br>on the probe, and then to single-number probe intensities.<br>The surface of the GeneChip contains detectable grid points<br>which facilitate rotation and translation of the image to a<br>canonical alignment; subsequent mapping of each pixel to a</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft6">feature is semi- or fully automated and has not previously<br>raised major analysis issues. However, work is being done<br>on aggressive reduction of feature sizes to a scale where this<br>mapping procedure could become a central concern.<br>On the more theoretical side, probe models based on the<br>physics of polymer hybridization have recently been the fo-<br>cus of considerable interest. These models reflect a signifi-<br>cant increase in the use of biological knowledge for estimat-<br>ing target abundance and present an opportunity for ap-<br>plication of machine learning techniques which can exploit<br>parametric distributions in high-dimensional data analysis,<br>such as graphical models.<br>We close by observing that a fuller awareness of low-level<br>microarray analysis issues will also benefit machine learning<br>researchers involved with high-level problems: the inevitable<br>information reduction from earlier stage to later could well<br>conceal too much of what the unfiltered array data reveal<br>about the biological issue at hand. Familiarity with initial<br>normalization and analysis methods will allow the high-level<br>analyst to account for such a possibility when drawing sci-<br>entific conclusions.</span></nobr></DIV>
<DIV style="position:absolute;top:437;left:475"><nobr><span class="ft4"><b>7.</b></span></nobr></DIV>
<DIV style="position:absolute;top:437;left:507"><nobr><span class="ft4"><b>ACKNOWLEDGMENTS</b></span></nobr></DIV>
<DIV style="position:absolute;top:458;left:475"><nobr><span class="ft6">We thank Rafael Irizarry, Ben Bolstad, Francois Collin and<br>Ken Simpson for many useful discussions and collaboration<br>on low-level microarray analysis.</span></nobr></DIV>
<DIV style="position:absolute;top:524;left:475"><nobr><span class="ft4"><b>8.</b></span></nobr></DIV>
<DIV style="position:absolute;top:524;left:507"><nobr><span class="ft4"><b>REFERENCES</b></span></nobr></DIV>
<DIV style="position:absolute;top:560;left:482"><nobr><span class="ft2">[1] Affymetrix.</span></nobr></DIV>
<DIV style="position:absolute;top:560;left:588"><nobr><span class="ft2">Affymetrix</span></nobr></DIV>
<DIV style="position:absolute;top:560;left:668"><nobr><span class="ft2">Microarray</span></nobr></DIV>
<DIV style="position:absolute;top:560;left:749"><nobr><span class="ft2">Suite</span></nobr></DIV>
<DIV style="position:absolute;top:560;left:794"><nobr><span class="ft2">Guide.</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:503"><nobr><span class="ft2">Affymetrix Inc., Santa Clara, CA, 2001. version 5.0.</span></nobr></DIV>
<DIV style="position:absolute;top:602;left:482"><nobr><span class="ft2">[2] M. Schena. DNA Microarrays: A Practical Approach.</span></nobr></DIV>
<DIV style="position:absolute;top:618;left:503"><nobr><span class="ft2">Oxford University Press, 1999.</span></nobr></DIV>
<DIV style="position:absolute;top:645;left:482"><nobr><span class="ft2">[3] Affymetrix. Statistical algorithms description docu-</span></nobr></DIV>
<DIV style="position:absolute;top:660;left:503"><nobr><span class="ft6">ment. Whitepaper, Affymetrix Inc., Santa Clara, CA,<br>2002.</span></nobr></DIV>
<DIV style="position:absolute;top:703;left:482"><nobr><span class="ft2">[4] A. Gammerman, V. Vovk, and V. Vapnik. Learning by</span></nobr></DIV>
<DIV style="position:absolute;top:718;left:503"><nobr><span class="ft6">transduction. In Fourteenth Conference on Uncertainty<br>in Artificial Intelligence, pages 148­155. Morgan Kauf-<br>mann Publishers, 1998.</span></nobr></DIV>
<DIV style="position:absolute;top:776;left:482"><nobr><span class="ft2">[5] P. K. Varshney. Scanning the issue: Special issue on</span></nobr></DIV>
<DIV style="position:absolute;top:792;left:503"><nobr><span class="ft2">data fusion. Proceedings of the IEEE, 85:3­5, 1997.</span></nobr></DIV>
<DIV style="position:absolute;top:819;left:482"><nobr><span class="ft2">[6] R. O. Duda and P. E. Hart. Pattern Classification and</span></nobr></DIV>
<DIV style="position:absolute;top:834;left:503"><nobr><span class="ft2">Scene Analysis. John Wiley and Sons, New York, 1973.</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:482"><nobr><span class="ft2">[7] T. Gaasterland and S. Bekiranov. Making the most of</span></nobr></DIV>
<DIV style="position:absolute;top:877;left:503"><nobr><span class="ft2">microarray data. Nature Genetics, 24:204­206, 2000.</span></nobr></DIV>
<DIV style="position:absolute;top:903;left:482"><nobr><span class="ft2">[8] K. P. Bennett and A. Demiriz. Semi-supervised sup-</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:503"><nobr><span class="ft6">port vector machines. In Advances in Neural Informa-<br>tion Processing Systems 11, pages 368­374, Cambridge,<br>MA, 1999. MIT Press.</span></nobr></DIV>
<DIV style="position:absolute;top:977;left:482"><nobr><span class="ft2">[9] T. Joachims. Transductive learning via spectral graph</span></nobr></DIV>
<DIV style="position:absolute;top:993;left:503"><nobr><span class="ft6">partitioning. In Proceedings of the International Con-<br>ference on Machine Learning (ICML), 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:475"><nobr><span class="ft2">[10] V. Castelli and T. Cover. On the exponential value of</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:503"><nobr><span class="ft6">labeled samples. Pattern Recognition Letters, 16:105­<br>111, 1995.</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:77"><nobr><span class="ft5">SIGKDD Explorations.</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:639"><nobr><span class="ft5">Volume 5,Issue 2 - Page 137 </span></nobr></DIV>
</DIV>
<!-- Page 9 -->
<a name="9"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="134009.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft2">[11] R. A. Irizarry. Science and Statistics: A Festschrift for</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:109"><nobr><span class="ft6">Terry Speed, volume 40 of Lecture Notes­Monograph<br>Series,</span></nobr></DIV>
<DIV style="position:absolute;top:118;left:163"><nobr><span class="ft2">chapter Measures of gene expression for</span></nobr></DIV>
<DIV style="position:absolute;top:133;left:109"><nobr><span class="ft6">Affymetrix high density oligonucleotide arrays, pages<br>391­402. Institute of Mathematical Statistics, 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:175;left:81"><nobr><span class="ft2">[12] R. Ihaka and R. Gentleman. R: A language for data</span></nobr></DIV>
<DIV style="position:absolute;top:191;left:109"><nobr><span class="ft6">analysis and graphics. Journal of Computational and<br>Graphical Statistics, 5(3):299­314, 1996.</span></nobr></DIV>
<DIV style="position:absolute;top:233;left:81"><nobr><span class="ft2">[13] N. Friedman. Probabilistic models for identifying regu-</span></nobr></DIV>
<DIV style="position:absolute;top:249;left:109"><nobr><span class="ft2">lation networks. Bioinformatics, 19:II57, October 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:81"><nobr><span class="ft2">[14] E. Hubbell, W. M. Liu, and R. Mei. Robust estimators</span></nobr></DIV>
<DIV style="position:absolute;top:291;left:109"><nobr><span class="ft6">for expression analysis. Bioinformatics, 18:1585­1592,<br>2002.</span></nobr></DIV>
<DIV style="position:absolute;top:333;left:81"><nobr><span class="ft2">[15] Bioconductor Core. An overview of projects in comput-</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:109"><nobr><span class="ft6">ing for genomic analysis. Technical report, The Biocon-<br>ductor Project, 2002.</span></nobr></DIV>
<DIV style="position:absolute;top:390;left:81"><nobr><span class="ft2">[16] A. Blum and T. Mitchell. Combining labeled and unla-</span></nobr></DIV>
<DIV style="position:absolute;top:406;left:109"><nobr><span class="ft6">beled data with co-training. In Proceedings of the Work-<br>shop on Computational Learning Theory. Morgan Kauf-<br>mann Publishers, 1998.</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:81"><nobr><span class="ft2">[17] L. Wu, S. L. Oviatt, and P. R. Cohen. Multimodal inte-</span></nobr></DIV>
<DIV style="position:absolute;top:480;left:109"><nobr><span class="ft6">gration - a statistical view. IEEE Transactions on Mul-<br>timedia, 1:334 ­341, 1999.</span></nobr></DIV>
<DIV style="position:absolute;top:522;left:81"><nobr><span class="ft2">[18] A. J. Hartemink and E. Segal. Joint learning from mul-</span></nobr></DIV>
<DIV style="position:absolute;top:537;left:109"><nobr><span class="ft6">tiple types of genomic data. In Proceedings of the Pa-<br>cific Symposium on Biocomputing 2004, 2004.</span></nobr></DIV>
<DIV style="position:absolute;top:579;left:81"><nobr><span class="ft2">[19] G. K. Smyth, Y. H. Yang, and T. P. Speed. Functional</span></nobr></DIV>
<DIV style="position:absolute;top:595;left:109"><nobr><span class="ft6">Genomics: Methods and Protocols, volume 224 of Meth-<br>ods in Molecular Biology, chapter Statistical issues in<br>cDNA microarray data analysis, pages 111­136. Hu-<br>mana Press, Totowa, NJ, 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:668;left:81"><nobr><span class="ft2">[20] A. Blum and S. Chawla. Learning from labeled and</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:109"><nobr><span class="ft6">unlabeled data using graph mincuts. In International<br>Conference on Machine Learning (ICML), 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:726;left:81"><nobr><span class="ft2">[21] R. Klinkenberg and T. Joachims. Detecting concept</span></nobr></DIV>
<DIV style="position:absolute;top:742;left:109"><nobr><span class="ft6">drift with support vector machines. In P. Langley, ed-<br>itor, Proceedings of ICML-00, 17th International Con-<br>ference on Machine Learning, pages 487­494, Stanford,<br>CA, 2000. Morgan Kaufmann Publishers.</span></nobr></DIV>
<DIV style="position:absolute;top:815;left:81"><nobr><span class="ft2">[22] M. Szummer and T. Jaakkola. Partially labeled classifi-</span></nobr></DIV>
<DIV style="position:absolute;top:831;left:109"><nobr><span class="ft6">cation with Markov random walks. In Neural Informa-<br>tion Processing Systems (NIPS), 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:873;left:81"><nobr><span class="ft2">[23] T. S. Jaakkola and D. Haussler. Exploiting generative</span></nobr></DIV>
<DIV style="position:absolute;top:888;left:109"><nobr><span class="ft6">models in discriminative classifiers. In Advances in Neu-<br>ral Information Processing Systems 11: Proceedings of<br>the 1998 Conference, pages 487­493. MIT Press, 1998.</span></nobr></DIV>
<DIV style="position:absolute;top:946;left:81"><nobr><span class="ft2">[24] G. Cauwenberghs and T. Poggio. Incremental and</span></nobr></DIV>
<DIV style="position:absolute;top:962;left:109"><nobr><span class="ft6">decremental support vector machine learning. In NIPS,<br>pages 409­415, 2000.</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:81"><nobr><span class="ft2">[25] T. Joachims. Transductive inference for text classifica-</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:109"><nobr><span class="ft6">tion using support vector machines. In I. Bratko and<br>S. Dzeroski, editors, Proceedings of the 16th Annual<br>Conference on Machine Learning, pages 200­209. Mor-<br>gan Kaufmann, 1999.</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft2">[26] O. Chapelle, V. Vapnik, and J. Weston. Advances</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:503"><nobr><span class="ft6">in Neural Information Processing Systems 12, chapter<br>Transductive inference for estimating values of func-<br>tions. MIT Press, 2000.</span></nobr></DIV>
<DIV style="position:absolute;top:161;left:475"><nobr><span class="ft2">[27] M. Schena, D. Shalon, R. W. Davis, and P. O.</span></nobr></DIV>
<DIV style="position:absolute;top:176;left:503"><nobr><span class="ft6">Brown. Quantitative monitoring of gene expression pat-<br>terns with a complementary DNA microarray. Science,<br>270:467­470, 1995.</span></nobr></DIV>
<DIV style="position:absolute;top:235;left:475"><nobr><span class="ft2">[28] D. J. Lockhart, H. Dong, M. C. Byrne, M. T. Follet-</span></nobr></DIV>
<DIV style="position:absolute;top:251;left:503"><nobr><span class="ft6">tie, M. V. Gallo, M. S. Chee, M. Mittmann, C. Wang,<br>M. Kobayashi, H. Horton, and E. L. Brown. Expression<br>monitoring by hybridization to high-density oligonu-<br>cleotide arrays. Nature Biotechnology, 14:1675­1680,<br>1996.</span></nobr></DIV>
<DIV style="position:absolute;top:341;left:475"><nobr><span class="ft2">[29] R. J. Lipshutz, S. P. A. Fodor, T. R. Gingeras, and</span></nobr></DIV>
<DIV style="position:absolute;top:357;left:503"><nobr><span class="ft6">D. H. Lockhart. High density synthetic oligonucleotide<br>arrays. Nature Genetics, 21:20­24, 1999. Supplement.</span></nobr></DIV>
<DIV style="position:absolute;top:400;left:475"><nobr><span class="ft2">[30] J. B. Fan, D. Gehl, L. Hsie, K. Lindblad-Toh, J. P.</span></nobr></DIV>
<DIV style="position:absolute;top:416;left:503"><nobr><span class="ft6">Laviolette, E. Robinson, R. Lipshutz, D. Wang, T. J.<br>Hudson, and D. Labuda. Assessing DNA sequence vari-<br>ations in human ests in a phylogenetic context using<br>high-density oligonucleotide arrays. Genomics, 80:351­<br>360, September 2002.</span></nobr></DIV>
<DIV style="position:absolute;top:506;left:475"><nobr><span class="ft2">[31] D. J. Cutler, M. E. Zwick, M. M. Carrasquillo, C. T.</span></nobr></DIV>
<DIV style="position:absolute;top:522;left:503"><nobr><span class="ft6">Yohn, K. P. Tobin, C. Kashuk, D. J. Mathews,<br>N. A. Shah, E. E. Eichler, J. A. Warrington, and<br>A. Chakravarti. High-throughput variation detection<br>and genotyping using microarrays. Genome Research,<br>11:1913­1925, November 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:612;left:475"><nobr><span class="ft2">[32] J. B. Fan, X. Chen, M. K. Halushka, A. Berno,</span></nobr></DIV>
<DIV style="position:absolute;top:627;left:503"><nobr><span class="ft6">X. Huang, T. Ryder, R. J. Lipshutz, D. J. Lock-<br>hart, and A. Chakravarti. Parallel genotyping of human<br>SNPs using generic high-density oligonucleotide tag ar-<br>rays. Genome Research, 10:853­860, June 2000.</span></nobr></DIV>
<DIV style="position:absolute;top:702;left:475"><nobr><span class="ft2">[33] G. C. Kennedy, H. Matsuzaki, D. Dong, W. Liu,</span></nobr></DIV>
<DIV style="position:absolute;top:718;left:503"><nobr><span class="ft6">J. Huang, G. Liu, X. Su, M. Cao, W. Chen, J. Zhang,<br>W. Liu, G. Yang, X. Di, T. Ryder, Z. He, U. Surti,<br>M. S. Phillips, M. T. Boyce-Jacino, S. P. A. Fodor, and<br>K. W. Jones. Large-scale genotyping of complex DNA.<br>Nature Biotechnology, October 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:808;left:475"><nobr><span class="ft2">[34] P. Kapranov, S. E. Cawley, J. Drenkow, S. Bekiranov,</span></nobr></DIV>
<DIV style="position:absolute;top:823;left:503"><nobr><span class="ft6">R. L. Strausberg, S. P. A. Fodor, and T. R. Gingeras.<br>Large-scale transcriptional activity in chromosomes 21<br>and 22. Science, 296:916­919, 2002.</span></nobr></DIV>
<DIV style="position:absolute;top:882;left:475"><nobr><span class="ft2">[35] M. Brown, W. N. Grundy, D. Lin, N. Cristianini,</span></nobr></DIV>
<DIV style="position:absolute;top:898;left:503"><nobr><span class="ft6">C. Sugnet, M. Ares Jr, and D. Haussler. Support vec-<br>tor machine classification of microarray gene expression<br>data. Technical Report UCSC-CRL-99-09, Department<br>of Computer Science, University of California at Santa<br>Cruz, 1999.</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:475"><nobr><span class="ft2">[36] M. P. S. Brown, W. N. Grundy, D. Lin, N. Cristianini,</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:503"><nobr><span class="ft6">C. W. Sugnet, T. S. Furey, M. Ares Jr, and D. Haussler.<br>Knowledge-based analysis of microarray gene expres-<br>sion data by using support vector machines. Proceed-<br>ings of the National Academy of Sciences, 97:262­267,<br>1997.</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:77"><nobr><span class="ft5">SIGKDD Explorations.</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:639"><nobr><span class="ft5">Volume 5,Issue 2 - Page 138 </span></nobr></DIV>
</DIV>
<!-- Page 10 -->
<a name="10"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="134010.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft2">[37] P. Pavlidis, J. Weston, J. Cai, and W. N. Grundy.</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:109"><nobr><span class="ft6">Gene functional classification from heterogeneous data.<br>In Proceedings of the Fifth International Conference on<br>Computational Molecular Biology, pages 242­248, 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:81"><nobr><span class="ft2">[38] T. S. Furey, N. Cristianini, N. Duffy, D. W. Bednarski,</span></nobr></DIV>
<DIV style="position:absolute;top:176;left:109"><nobr><span class="ft6">M. Schummer, and D. Haussler. Support vector ma-<br>chine classification and validation of cancer tissue sam-<br>ples using microarray expression data. Bioinformatics,<br>16:906­914, 2000.</span></nobr></DIV>
<DIV style="position:absolute;top:250;left:81"><nobr><span class="ft2">[39] S. Mukherjee,</span></nobr></DIV>
<DIV style="position:absolute;top:250;left:211"><nobr><span class="ft2">P. Tamayo,</span></nobr></DIV>
<DIV style="position:absolute;top:250;left:298"><nobr><span class="ft2">D. Slonim,</span></nobr></DIV>
<DIV style="position:absolute;top:250;left:380"><nobr><span class="ft2">A. Verri,</span></nobr></DIV>
<DIV style="position:absolute;top:265;left:109"><nobr><span class="ft6">T. Golub, J. P. Mesirov, and T. Poggio. Support vec-<br>tor machine classification of microarray data. Technical<br>Report 182, Center for Biological and Computational<br>Learning Massachusetts Institute of Technology, 1998.</span></nobr></DIV>
<DIV style="position:absolute;top:339;left:81"><nobr><span class="ft2">[40] S. Ramaswamy, P. Tamayo, R. Rifkin, S. Mukherjee,</span></nobr></DIV>
<DIV style="position:absolute;top:355;left:109"><nobr><span class="ft6">C. Yeang, M. Angelo, C. Ladd, M. Reich, E. Latulippe,<br>J. P. Mesirov, T. Poggio, W. Gerald, M. Loda, E. S.<br>Lander, and T. R. Golub. Multiclass cancer diagnosis<br>using tumor gene expression signatures. Proceedings of<br>the National Academy of Sciences, 98, 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:444;left:81"><nobr><span class="ft2">[41] C. Yeang, S. Ramaswamy, P. Tamayo, S. Mukher-</span></nobr></DIV>
<DIV style="position:absolute;top:460;left:109"><nobr><span class="ft6">jee, R. M. Rifkin, M. Angelo, M. Reich, E. Lander,<br>J. Mesirov, and T. Golub. Molecular classification of<br>multiple tumor types. Bioinformatics, 1:1­7, 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:518;left:81"><nobr><span class="ft2">[42] F. G. Cozman and I. Cohen. Unlabeled data can de-</span></nobr></DIV>
<DIV style="position:absolute;top:534;left:109"><nobr><span class="ft6">grade classification performance of generative classi-<br>fiers. In Fifteenth International Florida Artificial In-<br>telligence Society Conference, pages 327­331, 2002.</span></nobr></DIV>
<DIV style="position:absolute;top:592;left:81"><nobr><span class="ft2">[43] T. Zhang and F. J. Oles. A probability analysis on</span></nobr></DIV>
<DIV style="position:absolute;top:608;left:109"><nobr><span class="ft6">the value of unlabeled data for classification problems.<br>In Proceedings of the International Conference on Ma-<br>chine Learning, pages 1191­1198, 2000.</span></nobr></DIV>
<DIV style="position:absolute;top:666;left:81"><nobr><span class="ft2">[44] K. Nigam, A. McCallum, S. Thrun, and T. Mitchell.</span></nobr></DIV>
<DIV style="position:absolute;top:682;left:109"><nobr><span class="ft6">Text classification from labeled and unlabeled docu-<br>ments using EM. Machine Learning, 39:103­134, 2000.</span></nobr></DIV>
<DIV style="position:absolute;top:724;left:81"><nobr><span class="ft2">[45] T. Li, S. Zhu, Q. Li, and M. Ogihara. Gene functional</span></nobr></DIV>
<DIV style="position:absolute;top:740;left:109"><nobr><span class="ft6">classification by semi-supervised learning from hetero-<br>geneous data. In Proceedings of the ACM Symposium<br>on Applied Computing, 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:798;left:81"><nobr><span class="ft2">[46] G. R. G. Lanckriet, M. Deng, N. Cristianini, M. I. Jor-</span></nobr></DIV>
<DIV style="position:absolute;top:814;left:109"><nobr><span class="ft6">dan, and W. S. Noble. Kernel-based data fusion and its<br>application to protein function prediction in yeast. In<br>Proceedings of the Pacific Symposium on Biocomputing<br>2004, 2004.</span></nobr></DIV>
<DIV style="position:absolute;top:888;left:81"><nobr><span class="ft2">[47] A. Shilton, M. Palaniswami, D. Ralph, and A. C. Tsoi.</span></nobr></DIV>
<DIV style="position:absolute;top:903;left:109"><nobr><span class="ft6">Incremental training in support vector machines. In<br>Proceedings of the International Joint Conference on<br>Neural Networks, 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:961;left:81"><nobr><span class="ft2">[48] C. P. Diehl. Toward Efficient Collaborative Classifi-</span></nobr></DIV>
<DIV style="position:absolute;top:977;left:109"><nobr><span class="ft6">cation for Distributed Video Surveillance. PhD thesis,<br>Department of Electrical and Computer Engineering,<br>Carnegie Mellon University, 2000.</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:81"><nobr><span class="ft2">[49] J. H. Maindonald, Y. E. Pittelkow, and S. R. Wilson.</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:109"><nobr><span class="ft6">Science and Statistics: A Festschrift for Terry Speed,<br>volume 40 of IMS Lecture Notes­Monograph Series,</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:503"><nobr><span class="ft6">chapter Some Considerations for the Design of Microar-<br>ray Experiments, pages 367­390. Institute of Mathe-<br>matical Statistics, 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:144;left:475"><nobr><span class="ft2">[50] R. A. Irizarry, B. Hobbs, F. Collin, Y. D. Beazer-</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:503"><nobr><span class="ft6">Barclay, K. J. Antonellis, U. Scherf, and T. P. Speed.<br>Exploration, normalization, and summaries of high<br>density oligonucleotide array probe level data. Bio-<br>statistics, 4:249­264, 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:233;left:475"><nobr><span class="ft2">[51] C. Li and W. H. Wong. Model-based analysis of oligonu-</span></nobr></DIV>
<DIV style="position:absolute;top:249;left:503"><nobr><span class="ft6">cleotide arrays: Expression index computation and out-<br>lier detection. Proceedings of the National Academy of<br>Science, 98:31­36, 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:307;left:475"><nobr><span class="ft2">[52] B. M. Bolstad, R. A. Irizarry, M. Astrand, and T. P.</span></nobr></DIV>
<DIV style="position:absolute;top:323;left:503"><nobr><span class="ft6">Speed. A comparison of normalization methods for high<br>density oligonucleotide array data based on bias and<br>variance. Bioinformatics, 19:185­193, 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:380;left:475"><nobr><span class="ft2">[53] B. I. P. Rubinstein and T. P. Speed. Detecting</span></nobr></DIV>
<DIV style="position:absolute;top:396;left:503"><nobr><span class="ft6">gene expression with oligonucleotide microarrays, 2003.<br>manuscript in preparation.</span></nobr></DIV>
<DIV style="position:absolute;top:438;left:475"><nobr><span class="ft2">[54] W. Liu, R. Mei, D. M. Bartell, X. Di, T. A. Webster,</span></nobr></DIV>
<DIV style="position:absolute;top:454;left:503"><nobr><span class="ft6">and T. Ryder. Rank-based algorithms for analysis of<br>microarrays. Proceedings of SPIE, Microarrays: Optical<br>Technologies and Informatics, 4266, 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:512;left:475"><nobr><span class="ft2">[55] W. M. Liu, R. Mei, X. Di, T. B. Ryder, E. Hubbell,</span></nobr></DIV>
<DIV style="position:absolute;top:527;left:503"><nobr><span class="ft6">S. Dee, T. A. Webster, C. A. Harrington, M. H. Ho,<br>J. Baid, and S. P. Smeekens. Analysis of high den-<br>sity expression microarrays with signed-rank call algo-<br>rithms. Bioinformatics, 18:1593­1599, 2002.</span></nobr></DIV>
<DIV style="position:absolute;top:601;left:475"><nobr><span class="ft2">[56] F. Provost and T. Fawcett. Analysis and visualization</span></nobr></DIV>
<DIV style="position:absolute;top:617;left:503"><nobr><span class="ft2">of classifier performance:</span></nobr></DIV>
<DIV style="position:absolute;top:617;left:672"><nobr><span class="ft2">Comparison under impre-</span></nobr></DIV>
<DIV style="position:absolute;top:632;left:503"><nobr><span class="ft6">cise class and cost distributions. In Third International<br>Conference on Knowledge Discovery and Data Mining,<br>Menlo Park, CA, 1997.</span></nobr></DIV>
<DIV style="position:absolute;top:690;left:475"><nobr><span class="ft2">[57] T. Fawcett, F. Provost, and R. Kohavi. The case</span></nobr></DIV>
<DIV style="position:absolute;top:706;left:503"><nobr><span class="ft6">against accuracy estimation for comparing induction al-<br>gorithms. In Fifteenth International Conference on Ma-<br>chine Learning, 1998.</span></nobr></DIV>
<DIV style="position:absolute;top:764;left:475"><nobr><span class="ft2">[58] D. Kampa and et al. Novel RNAs identified from a com-</span></nobr></DIV>
<DIV style="position:absolute;top:779;left:503"><nobr><span class="ft6">prehensive analysis of the transcriptome of human chro-<br>mosomes 21 and 22. Manuscript in preparation.</span></nobr></DIV>
<DIV style="position:absolute;top:822;left:475"><nobr><span class="ft2">[59] W.-M. Liu, X. Di, G. Yang, H. Matsuzaki, J. Huang,</span></nobr></DIV>
<DIV style="position:absolute;top:837;left:503"><nobr><span class="ft6">R. Mei, T. B. Ryder, T. A. Webster, S. Dong, G. Liu,<br>K. W. Jones, G. C. Kennedy, and D. Kulp. Algorithms<br>for large scale genotyping microarrays. Bioinformatics,<br>2003. In press.</span></nobr></DIV>
<DIV style="position:absolute;top:911;left:475"><nobr><span class="ft2">[60] Affymetrix.</span></nobr></DIV>
<DIV style="position:absolute;top:911;left:591"><nobr><span class="ft2">GeneChip</span></nobr></DIV>
<DIV style="position:absolute;top:911;left:670"><nobr><span class="ft2">CustomSeq</span></nobr></DIV>
<DIV style="position:absolute;top:911;left:757"><nobr><span class="ft2">resequencing</span></nobr></DIV>
<DIV style="position:absolute;top:926;left:503"><nobr><span class="ft2">array:</span></nobr></DIV>
<DIV style="position:absolute;top:926;left:560"><nobr><span class="ft2">Performance</span></nobr></DIV>
<DIV style="position:absolute;top:926;left:648"><nobr><span class="ft2">data</span></nobr></DIV>
<DIV style="position:absolute;top:926;left:687"><nobr><span class="ft2">for</span></nobr></DIV>
<DIV style="position:absolute;top:926;left:715"><nobr><span class="ft2">base</span></nobr></DIV>
<DIV style="position:absolute;top:926;left:753"><nobr><span class="ft2">calling</span></nobr></DIV>
<DIV style="position:absolute;top:926;left:805"><nobr><span class="ft2">algo-</span></nobr></DIV>
<DIV style="position:absolute;top:942;left:503"><nobr><span class="ft6">rithm in GeneChip DNA analysis software. Tech-<br>nical</span></nobr></DIV>
<DIV style="position:absolute;top:958;left:545"><nobr><span class="ft2">note,</span></nobr></DIV>
<DIV style="position:absolute;top:958;left:590"><nobr><span class="ft2">Affymetrix</span></nobr></DIV>
<DIV style="position:absolute;top:958;left:669"><nobr><span class="ft2">Inc.,</span></nobr></DIV>
<DIV style="position:absolute;top:958;left:710"><nobr><span class="ft2">Santa</span></nobr></DIV>
<DIV style="position:absolute;top:958;left:758"><nobr><span class="ft2">Clara,</span></nobr></DIV>
<DIV style="position:absolute;top:958;left:810"><nobr><span class="ft2">CA,</span></nobr></DIV>
<DIV style="position:absolute;top:974;left:503"><nobr><span class="ft2">2003.</span></nobr></DIV>
<DIV style="position:absolute;top:974;left:581"><nobr><span class="ft2">http://www.affymetrix.com/support/tech</span></nobr></DIV>
<DIV style="position:absolute;top:989;left:503"><nobr><span class="ft2">nical/technotes/customseq technote.pdf.</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:77"><nobr><span class="ft5">SIGKDD Explorations.</span></nobr></DIV>
<DIV style="position:absolute;top:1125;left:639"><nobr><span class="ft5">Volume 5,Issue 2 - Page 139 </span></nobr></DIV>
</DIV>
</BODY>
</HTML>
