<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
<HEAD>
<TITLE>D:\Paper\HTML\84</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<META name="generator" content="pdftohtml 0.35beta">
<META name="date" content="2004-04-16T13:28:57+00:00">
</HEAD>
<BODY bgcolor="#A0A0A0" vlink="blue" link="blue">
<!-- Page 1 -->
<a name="1"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft0{font-size:24px;font-family:Helvetica;color:#000000;}
	.ft1{font-size:15px;font-family:Helvetica;color:#000000;}
	.ft2{font-size:12px;font-family:Helvetica;color:#000000;}
	.ft3{font-size:15px;font-family:Times;color:#000000;}
	.ft4{font-size:11px;font-family:Times;color:#000000;}
	.ft5{font-size:9px;font-family:Times;color:#000000;}
	.ft6{font-size:9px;font-family:Times;color:#000000;}
	.ft7{font-size:16px;font-family:Courier;color:#000000;}
	.ft8{font-size:11px;font-family:Helvetica;color:#000000;}
	.ft9{font-size:11px;line-height:15px;font-family:Times;color:#000000;}
	.ft10{font-size:9px;line-height:13px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="84001.png" alt="background image">
<DIV style="position:absolute;top:108;left:189"><nobr><span class="ft0"><b>Entropy-based Sensor Selection Heuristic</b></span></nobr></DIV>
<DIV style="position:absolute;top:138;left:314"><nobr><span class="ft0"><b>for Target Localization</b></span></nobr></DIV>
<DIV style="position:absolute;top:206;left:229"><nobr><span class="ft1">Hanbiao Wang</span></nobr></DIV>
<DIV style="position:absolute;top:224;left:177"><nobr><span class="ft2">Department of Computer Science</span></nobr></DIV>
<DIV style="position:absolute;top:246;left:202"><nobr><span class="ft1">hbwang@cs.ucla.edu</span></nobr></DIV>
<DIV style="position:absolute;top:206;left:589"><nobr><span class="ft1">Kung Yao</span></nobr></DIV>
<DIV style="position:absolute;top:224;left:505"><nobr><span class="ft2">Department of Electrical Engineering</span></nobr></DIV>
<DIV style="position:absolute;top:246;left:557"><nobr><span class="ft1">yao@ee.ucla.edu</span></nobr></DIV>
<DIV style="position:absolute;top:272;left:243"><nobr><span class="ft1">Greg Pottie</span></nobr></DIV>
<DIV style="position:absolute;top:291;left:166"><nobr><span class="ft2">Department of Electrical Engineering</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:211"><nobr><span class="ft1">pottie@ee.ucla.edu</span></nobr></DIV>
<DIV style="position:absolute;top:272;left:567"><nobr><span class="ft1">Deborah Estrin</span></nobr></DIV>
<DIV style="position:absolute;top:291;left:516"><nobr><span class="ft2">Department of Computer Science</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:545"><nobr><span class="ft1">destrin@cs.ucla.edu</span></nobr></DIV>
<DIV style="position:absolute;top:339;left:338"><nobr><span class="ft2">University of California, Los Angeles</span></nobr></DIV>
<DIV style="position:absolute;top:355;left:379"><nobr><span class="ft2">Los Angeles, CA 90095</span></nobr></DIV>
<DIV style="position:absolute;top:408;left:81"><nobr><span class="ft3"><b>ABSTRACT</b></span></nobr></DIV>
<DIV style="position:absolute;top:432;left:81"><nobr><span class="ft9">We propose an entropy-based sensor selection heuristic for<br>localization. Given 1) a prior probability distribution of the<br>target location, and 2) the locations and the sensing mod-<br>els of a set of candidate sensors for selection, the heuris-<br>tic selects an informative sensor such that the fusion of the<br>selected sensor observation with the prior target location<br>distribution would yield on average the greatest or nearly<br>the greatest reduction in the entropy of the target location<br>distribution.</span></nobr></DIV>
<DIV style="position:absolute;top:558;left:168"><nobr><span class="ft4">The heuristic greedily selects one sensor in</span></nobr></DIV>
<DIV style="position:absolute;top:573;left:81"><nobr><span class="ft9">each step without retrieving any actual sensor observations.<br>The heuristic is also computationally much simpler than the<br>mutual-information-based approaches. The effectiveness of<br>the heuristic is evaluated using localization simulations in<br>which Gaussian sensing models are assumed for simplicity.<br>The heuristic is more effective when the optimal candidate<br>sensor is more informative.</span></nobr></DIV>
<DIV style="position:absolute;top:700;left:81"><nobr><span class="ft3"><b>Categories and Subject Descriptors</b></span></nobr></DIV>
<DIV style="position:absolute;top:724;left:81"><nobr><span class="ft9">H.1.1 [MODELS AND PRINCIPLES]: Systems and In-<br>formation Theory--Information theory; C.2.4 [COMPUTER-<br>COMMUNICATION NETWORKS]: Distributed Sys-<br>tems--Distributed applications</span></nobr></DIV>
<DIV style="position:absolute;top:804;left:81"><nobr><span class="ft3"><b>General Terms</b></span></nobr></DIV>
<DIV style="position:absolute;top:828;left:81"><nobr><span class="ft4">Algorithms, Management, Theory</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:81"><nobr><span class="ft3"><b>Keywords</b></span></nobr></DIV>
<DIV style="position:absolute;top:885;left:81"><nobr><span class="ft9">sensor selection, information-directed resource management,<br>information fusion, target localization, target tracking, wire-<br>less sensor networks, mutual information, Shannon entropy</span></nobr></DIV>
<DIV style="position:absolute;top:977;left:81"><nobr><span class="ft10">Permission to make digital or hard copies of all or part of this work for<br>personal or classroom use is granted without fee provided that copies are<br>not made or distributed for profit or commercial advantage and that copies<br>bear this notice and the full citation on the first page. To copy otherwise, to<br>republish, to post on servers or to redistribute to lists, requires prior specific<br>permission and/or a fee.<br><i>IPSN'04, </i>April 26­27, 2004, Berkeley, California, USA.<br>Copyright 2004 ACM 1-58113-846-6/04/0004 ...</span></nobr></DIV>
<DIV style="position:absolute;top:1070;left:315"><nobr><span class="ft4">$</span></nobr></DIV>
<DIV style="position:absolute;top:1071;left:322"><nobr><span class="ft5">5.00.</span></nobr></DIV>
<DIV style="position:absolute;top:408;left:475"><nobr><span class="ft3"><b>1.</b></span></nobr></DIV>
<DIV style="position:absolute;top:408;left:507"><nobr><span class="ft3"><b>INTRODUCTION</b></span></nobr></DIV>
<DIV style="position:absolute;top:430;left:489"><nobr><span class="ft4">The recent convergence of micro-electro-mechanical sys-</span></nobr></DIV>
<DIV style="position:absolute;top:445;left:475"><nobr><span class="ft9">tems (MEMS) technology, wireless communication and net-<br>working technology, and low-cost low-power miniature dig-<br>ital hardware design technology has made the concept of<br>wireless sensor networks viable and a new frontier of research<br>[2, 1]. The limited on-board energy storage and the limited<br>wireless channel capacity are the major constraints of wire-<br>less sensor networks. In order to save precious resources,<br>a sensing task should not involve more sensors than neces-<br>sary. From the information-theoretic point of view, sensors<br>are tasked to observe the target in order to increase the in-<br>formation (or to reduce the uncertainty) about the target<br>state. The information gain attributable to one sensor may<br>be very different from that attributable to another when sen-<br>sors have different observation perspectives and sensing un-<br>certainties. Selective use of informative sensors reduces the<br>number of sensors needed to obtain information about the<br>target state and therefore prolongs the system lifetime. In<br>the scenario of localization or tracking using wireless sensor<br>networks, the belief state of the target location can be grad-<br>ually improved by repeatedly selecting the most informative<br>unused sensor until the required accuracy (or uncertainty)<br>level of the target state is achieved.</span></nobr></DIV>
<DIV style="position:absolute;top:791;left:489"><nobr><span class="ft4">There have been several investigations into information-</span></nobr></DIV>
<DIV style="position:absolute;top:806;left:475"><nobr><span class="ft9">theoretic approaches to sensor fusion and management. The<br>idea of using information theory in sensor management was<br>first proposed in [8]. Sensor selection based on expected in-<br>formation gain was introduced for decentralized sensing sys-<br>tems in [12]. The mutual information between the predicted<br>sensor observation and the current target location distribu-<br>tion was proposed to evaluate the expected information gain<br>about the target location attributable to a sensor in [11, 6].<br>On the other hand, without using information theory, Yao<br>et. al. [16] found that the overall localization accuracy de-<br>pends on not only the accuracy of individual sensors but<br>also the sensor locations relative to the target location dur-<br>ing the development of localization algorithms. We propose<br>a novel entropy-based heuristic for sensor selection based on<br>our experiences with target localization. It is computation-<br>ally more efficient than mutual-information-based methods<br>proposed in [11, 6].</span></nobr></DIV>
<DIV style="position:absolute;top:1127;left:452"><nobr><span class="ft8">36</span></nobr></DIV>
</DIV>
<!-- Page 2 -->
<a name="2"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft11{font-size:6px;font-family:Times;color:#000000;}
	.ft12{font-size:-1px;font-family:Times;color:#000000;}
	.ft13{font-size:5px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="84002.png" alt="background image">
<DIV style="position:absolute;top:86;left:94"><nobr><span class="ft4">We use the following notations throughout this paper:</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:81"><nobr><span class="ft9">1. S is the set of candidate sensors for selection, i  S is<br>the sensor index;<br>2. x is the realization of the random vector that denotes the<br>target location;<br>3. x</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:107"><nobr><span class="ft11">t</span></nobr></DIV>
<DIV style="position:absolute;top:165;left:117"><nobr><span class="ft4">is the actual target location;</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:81"><nobr><span class="ft4">4. ^</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:99"><nobr><span class="ft4">x is the maximum likelihood estimate of the target loca-</span></nobr></DIV>
<DIV style="position:absolute;top:196;left:81"><nobr><span class="ft9">tion;<br>5. x</span></nobr></DIV>
<DIV style="position:absolute;top:216;left:107"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:212;left:116"><nobr><span class="ft4">is the deterministic location of sensor i;</span></nobr></DIV>
<DIV style="position:absolute;top:228;left:81"><nobr><span class="ft4">6. z</span></nobr></DIV>
<DIV style="position:absolute;top:232;left:106"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:228;left:115"><nobr><span class="ft4">is the realization of the random variable that denotes</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:81"><nobr><span class="ft9">the observation of sensor i about the target location;<br>7. z</span></nobr></DIV>
<DIV style="position:absolute;top:254;left:107"><nobr><span class="ft11">ti</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:117"><nobr><span class="ft4">is the actual observation of sensor i about the target</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:81"><nobr><span class="ft9">location;<br>8. z</span></nobr></DIV>
<DIV style="position:absolute;top:286;left:106"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:296;left:105"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:117"><nobr><span class="ft4">is the realization of the random variable that denotes</span></nobr></DIV>
<DIV style="position:absolute;top:306;left:81"><nobr><span class="ft4">the view of sensor i about the target location.</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:94"><nobr><span class="ft4">The rest of this paper is organized as follows. Section 2</span></nobr></DIV>
<DIV style="position:absolute;top:337;left:81"><nobr><span class="ft4">describes the heuristic in detail.</span></nobr></DIV>
<DIV style="position:absolute;top:337;left:294"><nobr><span class="ft4">Section 3 evaluates the</span></nobr></DIV>
<DIV style="position:absolute;top:353;left:81"><nobr><span class="ft4">heuristic using simulations.</span></nobr></DIV>
<DIV style="position:absolute;top:353;left:265"><nobr><span class="ft4">Section 4 discusses the dis-</span></nobr></DIV>
<DIV style="position:absolute;top:369;left:81"><nobr><span class="ft9">crepancy between the heuristic and the mutual information<br>based approaches. Section 5 outlines future work. Section 6<br>concludes the paper. Section 7 acknowledges the sponsors.</span></nobr></DIV>
<DIV style="position:absolute;top:433;left:81"><nobr><span class="ft3"><b>2.</b></span></nobr></DIV>
<DIV style="position:absolute;top:433;left:112"><nobr><span class="ft3"><b>SENSOR SELECTION HEURISTIC</b></span></nobr></DIV>
<DIV style="position:absolute;top:455;left:94"><nobr><span class="ft4">This Sect. formulates the sensor selection problem in lo-</span></nobr></DIV>
<DIV style="position:absolute;top:471;left:81"><nobr><span class="ft9">calization, presents the details of the entropy-based sensor<br>selection heuristic, and discusses the relation between the<br>entropy difference proposed in this paper and mutual infor-<br>mation used in previous work about sensor selection.</span></nobr></DIV>
<DIV style="position:absolute;top:542;left:81"><nobr><span class="ft3"><b>2.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:542;left:121"><nobr><span class="ft3"><b>Sensor Selection Problem in Localization</b></span></nobr></DIV>
<DIV style="position:absolute;top:564;left:94"><nobr><span class="ft4">There are several information measures. In this paper, we</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:81"><nobr><span class="ft9">use Shannon entropy [14] to quantify the information gain<br>(or uncertainty reduction) about the target location due to<br>sensor observation. We adopt the greedy sensor selection<br>strategy used in mutual-information-based approaches [11,<br>6]. The greedy strategy gradually reduces the uncertainty<br>of the target location distribution by repeatedly selecting<br>the currently unused sensor with maximal expected informa-<br>tion gain. The observation of the selected sensor is incorpo-<br>rated into the target location distribution using sequential<br>Bayesian filtering [3, 7]. The greedy sensor selection and the<br>sequential information fusion continue until the uncertainty<br>of the target location distribution is less than or equal to<br>the required level. The core problem of the greedy sensor<br>selection approach is how to efficiently evaluate the expected<br>information gain attributable to each candidate sensor with-<br>out actually retrieving sensor data.</span></nobr></DIV>
<DIV style="position:absolute;top:831;left:94"><nobr><span class="ft4">The sensor selection problem is formulated as follows.</span></nobr></DIV>
<DIV style="position:absolute;top:847;left:81"><nobr><span class="ft9">Given<br>1. the prior target location distribution: p(x),<br>2. the locations of candidate sensors for selection: x</span></nobr></DIV>
<DIV style="position:absolute;top:883;left:394"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:399"><nobr><span class="ft4">, i  S,</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:81"><nobr><span class="ft4">3.</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:105"><nobr><span class="ft4">the sensing models of candidate sensors for selection:</span></nobr></DIV>
<DIV style="position:absolute;top:910;left:81"><nobr><span class="ft4">p(z</span></nobr></DIV>
<DIV style="position:absolute;top:914;left:100"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:906;left:104"><nobr><span class="ft4">|x), i  S,</span></nobr></DIV>
<DIV style="position:absolute;top:927;left:81"><nobr><span class="ft4">the objective is to find the sensor ^i whose observation z</span></nobr></DIV>
<DIV style="position:absolute;top:929;left:434"><nobr><span class="ft11">^i</span></nobr></DIV>
<DIV style="position:absolute;top:943;left:81"><nobr><span class="ft9">minimizes the expected conditional entropy of the posterior<br>target location distribution,</span></nobr></DIV>
<DIV style="position:absolute;top:980;left:195"><nobr><span class="ft4">^i = arg min</span></nobr></DIV>
<DIV style="position:absolute;top:994;left:243"><nobr><span class="ft11">iS</span></nobr></DIV>
<DIV style="position:absolute;top:983;left:266"><nobr><span class="ft4">H(x|z</span></nobr></DIV>
<DIV style="position:absolute;top:987;left:303"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:983;left:308"><nobr><span class="ft4">) .</span></nobr></DIV>
<DIV style="position:absolute;top:983;left:422"><nobr><span class="ft4">(1)</span></nobr></DIV>
<DIV style="position:absolute;top:1016;left:81"><nobr><span class="ft9">Equivalently, the observation of sensor ^i maximizes the ex-<br>pected target location entropy reduction,</span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:165"><nobr><span class="ft4">^i = arg max</span></nobr></DIV>
<DIV style="position:absolute;top:1068;left:215"><nobr><span class="ft11">iS</span></nobr></DIV>
<DIV style="position:absolute;top:1056;left:237"><nobr><span class="ft4">(H(x) - H(x|z</span></nobr></DIV>
<DIV style="position:absolute;top:1061;left:328"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1056;left:332"><nobr><span class="ft4">)) .</span></nobr></DIV>
<DIV style="position:absolute;top:1056;left:422"><nobr><span class="ft4">(2)</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft4">H(x) - H(x|z</span></nobr></DIV>
<DIV style="position:absolute;top:91;left:563"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:568"><nobr><span class="ft4">) is one expression of I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:91;left:744"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:749"><nobr><span class="ft4">), the mutual</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:475"><nobr><span class="ft9">information between the target location x and the predicted<br>sensor observation z</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:597"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:118;left:602"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:530"><nobr><span class="ft4">I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:154;left:563"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:568"><nobr><span class="ft4">) =</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:608"><nobr><span class="ft4">p(x, z</span></nobr></DIV>
<DIV style="position:absolute;top:154;left:641"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:646"><nobr><span class="ft4">) log p(x, z</span></nobr></DIV>
<DIV style="position:absolute;top:145;left:715"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:141;left:719"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:158;left:676"><nobr><span class="ft4">p(x)p(z</span></nobr></DIV>
<DIV style="position:absolute;top:163;left:721"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:158;left:725"><nobr><span class="ft4">) dxdz</span></nobr></DIV>
<DIV style="position:absolute;top:154;left:762"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:773"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:816"><nobr><span class="ft4">(3)</span></nobr></DIV>
<DIV style="position:absolute;top:183;left:475"><nobr><span class="ft4">where p(x, z</span></nobr></DIV>
<DIV style="position:absolute;top:188;left:547"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:183;left:552"><nobr><span class="ft4">) = p(z</span></nobr></DIV>
<DIV style="position:absolute;top:188;left:595"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:599"><nobr><span class="ft4">|x)p(x) and p(z</span></nobr></DIV>
<DIV style="position:absolute;top:188;left:691"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:183;left:696"><nobr><span class="ft4">) =</span></nobr></DIV>
<DIV style="position:absolute;top:181;left:719"><nobr><span class="ft12">Ê</span></nobr></DIV>
<DIV style="position:absolute;top:183;left:731"><nobr><span class="ft4">p(x, z</span></nobr></DIV>
<DIV style="position:absolute;top:188;left:764"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:183;left:769"><nobr><span class="ft4">)dx. Thus,</span></nobr></DIV>
<DIV style="position:absolute;top:201;left:475"><nobr><span class="ft9">the observation of sensor ^i maximizes the mutual informa-<br>tion I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:221;left:537"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:217;left:542"><nobr><span class="ft4">),</span></nobr></DIV>
<DIV style="position:absolute;top:239;left:590"><nobr><span class="ft4">^i = arg max</span></nobr></DIV>
<DIV style="position:absolute;top:254;left:639"><nobr><span class="ft11">iS</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:664"><nobr><span class="ft4">I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:247;left:697"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:702"><nobr><span class="ft4">) .</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:816"><nobr><span class="ft4">(4)</span></nobr></DIV>
<DIV style="position:absolute;top:273;left:489"><nobr><span class="ft4">Sensor selection based on (4) is the maximal mutual in-</span></nobr></DIV>
<DIV style="position:absolute;top:289;left:475"><nobr><span class="ft9">formation criterion proposed in [11, 6]. The target location<br>x could be of up to three dimensions. The sensor observa-<br>tion z</span></nobr></DIV>
<DIV style="position:absolute;top:325;left:510"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:321;left:519"><nobr><span class="ft4">(e.g. the direction to a target in a three-dimensional</span></nobr></DIV>
<DIV style="position:absolute;top:336;left:475"><nobr><span class="ft4">space ) could be of up to two dimensions. Therefore I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:341;left:824"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:336;left:829"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:352;left:475"><nobr><span class="ft4">is a complex integral in the joint state space (x, z</span></nobr></DIV>
<DIV style="position:absolute;top:357;left:772"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:352;left:777"><nobr><span class="ft4">) of up to</span></nobr></DIV>
<DIV style="position:absolute;top:368;left:475"><nobr><span class="ft4">five dimensions. The complexity of computing I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:372;left:788"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:368;left:793"><nobr><span class="ft4">) could</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:475"><nobr><span class="ft9">be more than that low-end sensor nodes are capable of. If<br>the observation z</span></nobr></DIV>
<DIV style="position:absolute;top:404;left:582"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:399;left:592"><nobr><span class="ft4">is related to the target location x only</span></nobr></DIV>
<DIV style="position:absolute;top:415;left:475"><nobr><span class="ft4">through the sufficient statistics z(x), then</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:588"><nobr><span class="ft4">I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:444;left:621"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:626"><nobr><span class="ft4">) = I(z(x); z</span></nobr></DIV>
<DIV style="position:absolute;top:444;left:701"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:705"><nobr><span class="ft4">) .</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:816"><nobr><span class="ft4">(5)</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:475"><nobr><span class="ft4">If z(x) has fewer dimensions than x, then I(z(x); z</span></nobr></DIV>
<DIV style="position:absolute;top:468;left:784"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:789"><nobr><span class="ft4">) is less</span></nobr></DIV>
<DIV style="position:absolute;top:479;left:475"><nobr><span class="ft4">complex to compute than I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:484;left:667"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:479;left:672"><nobr><span class="ft4">). In the above special sce-</span></nobr></DIV>
<DIV style="position:absolute;top:495;left:475"><nobr><span class="ft4">nario, I(z(x); z</span></nobr></DIV>
<DIV style="position:absolute;top:499;left:568"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:495;left:572"><nobr><span class="ft4">) has been proposed to replace I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:499;left:805"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:495;left:810"><nobr><span class="ft4">) to</span></nobr></DIV>
<DIV style="position:absolute;top:511;left:475"><nobr><span class="ft9">reduce the complexity of computing mutual information in<br>[11]. In this paper, we propose an alternative entropy-based<br>sensor selection heuristic. In general, the entropy-based sen-<br>sor selection heuristic is computationally much simpler than<br>the mutual information based approaches. However, the ob-<br>servation of the sensor selected by the heuristic would still<br>yield on average the greatest or nearly the greatest entropy<br>reduction of the target location distribution.</span></nobr></DIV>
<DIV style="position:absolute;top:645;left:475"><nobr><span class="ft3"><b>2.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:645;left:515"><nobr><span class="ft3"><b>Entropy-based Sensor Selection Heuristic</b></span></nobr></DIV>
<DIV style="position:absolute;top:667;left:489"><nobr><span class="ft4">During the development of wireless sensor networks for</span></nobr></DIV>
<DIV style="position:absolute;top:683;left:475"><nobr><span class="ft9">localization, we have observed that the localization uncer-<br>tainty reduction attributable to a sensor is greatly effected<br>by the difference of two quantities, namely, the entropy of<br>the distribution of that sensor's view about the target loca-<br>tion, and the entropy of that sensor's sensing model for the<br>actual target location.</span></nobr></DIV>
<DIV style="position:absolute;top:777;left:489"><nobr><span class="ft4">A sensor's view about the target location is the geometric</span></nobr></DIV>
<DIV style="position:absolute;top:793;left:475"><nobr><span class="ft9">projection of the target location onto that sensor's observa-<br>tion perspective. For example, a direction-of-arrival (DOA)<br>sensor's view of the target location is the direction from the<br>sensor to the target. The view of sensor i about the target<br>location is denoted as z</span></nobr></DIV>
<DIV style="position:absolute;top:851;left:622"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:622"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:856;left:629"><nobr><span class="ft4">,which is a function of the target</span></nobr></DIV>
<DIV style="position:absolute;top:871;left:475"><nobr><span class="ft4">location x and the sensor location x</span></nobr></DIV>
<DIV style="position:absolute;top:876;left:694"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:871;left:699"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:896;left:610"><nobr><span class="ft4">z</span></nobr></DIV>
<DIV style="position:absolute;top:890;left:617"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:901;left:616"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:896;left:627"><nobr><span class="ft4">= f(x, x</span></nobr></DIV>
<DIV style="position:absolute;top:900;left:678"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:896;left:683"><nobr><span class="ft4">) .</span></nobr></DIV>
<DIV style="position:absolute;top:896;left:816"><nobr><span class="ft4">(6)</span></nobr></DIV>
<DIV style="position:absolute;top:920;left:475"><nobr><span class="ft4">z</span></nobr></DIV>
<DIV style="position:absolute;top:915;left:482"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:926;left:482"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:920;left:494"><nobr><span class="ft4">usually has less dimensions than x. The probability dis-</span></nobr></DIV>
<DIV style="position:absolute;top:936;left:475"><nobr><span class="ft9">tribution of the view of sensor i about the target location,<br>p(z</span></nobr></DIV>
<DIV style="position:absolute;top:947;left:495"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:957;left:494"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:952;left:501"><nobr><span class="ft4">), is the projection of the target location distribution</span></nobr></DIV>
<DIV style="position:absolute;top:967;left:475"><nobr><span class="ft4">p(x) onto the observation perspective of sensor i,</span></nobr></DIV>
<DIV style="position:absolute;top:999;left:536"><nobr><span class="ft4">p(z</span></nobr></DIV>
<DIV style="position:absolute;top:993;left:555"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:1005;left:555"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:999;left:562"><nobr><span class="ft4">)dz</span></nobr></DIV>
<DIV style="position:absolute;top:993;left:582"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:1005;left:581"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:999;left:592"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:1014;left:614"><nobr><span class="ft11">z</span></nobr></DIV>
<DIV style="position:absolute;top:1011;left:620"><nobr><span class="ft13">v</span></nobr></DIV>
<DIV style="position:absolute;top:1017;left:620"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:1012;left:626"><nobr><span class="ft11">f(x,x</span></nobr></DIV>
<DIV style="position:absolute;top:1016;left:662"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:1012;left:667"><nobr><span class="ft11">)z</span></nobr></DIV>
<DIV style="position:absolute;top:1011;left:685"><nobr><span class="ft13">v</span></nobr></DIV>
<DIV style="position:absolute;top:1017;left:685"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:1012;left:692"><nobr><span class="ft11">+dz</span></nobr></DIV>
<DIV style="position:absolute;top:1011;left:712"><nobr><span class="ft13">v</span></nobr></DIV>
<DIV style="position:absolute;top:1017;left:711"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:999;left:721"><nobr><span class="ft4">p(x)dx .</span></nobr></DIV>
<DIV style="position:absolute;top:999;left:816"><nobr><span class="ft4">(7)</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:475"><nobr><span class="ft4">Alternatively, p(z</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:581"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:581"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:588"><nobr><span class="ft4">) can be regarded as the `noise free' pre-</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:475"><nobr><span class="ft4">diction of the sensor observation distribution p(z</span></nobr></DIV>
<DIV style="position:absolute;top:1055;left:767"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:772"><nobr><span class="ft4">) based on</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:475"><nobr><span class="ft4">the target location distribution p(x).</span></nobr></DIV>
<DIV style="position:absolute;top:1127;left:452"><nobr><span class="ft8">37</span></nobr></DIV>
</DIV>
<!-- Page 3 -->
<a name="3"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft14{font-size:4px;font-family:Helvetica;color:#000000;}
	.ft15{font-size:2px;font-family:Helvetica;color:#000000;}
	.ft16{font-size:10px;font-family:Helvetica;color:#000000;}
	.ft17{font-size:10px;font-family:Helvetica;color:#ffffff;}
	.ft18{font-size:7px;font-family:Helvetica;color:#ffffff;}
	.ft19{font-size:11px;line-height:17px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="84003.png" alt="background image">
<DIV style="position:absolute;top:336;left:422"><nobr><span class="ft14">0</span></nobr></DIV>
<DIV style="position:absolute;top:300;left:422"><nobr><span class="ft14">0.2</span></nobr></DIV>
<DIV style="position:absolute;top:265;left:422"><nobr><span class="ft14">0.4</span></nobr></DIV>
<DIV style="position:absolute;top:229;left:422"><nobr><span class="ft14">0.6</span></nobr></DIV>
<DIV style="position:absolute;top:194;left:422"><nobr><span class="ft14">0.8</span></nobr></DIV>
<DIV style="position:absolute;top:159;left:422"><nobr><span class="ft14">1</span></nobr></DIV>
<DIV style="position:absolute;top:123;left:422"><nobr><span class="ft14">1.2</span></nobr></DIV>
<DIV style="position:absolute;top:87;left:420"><nobr><span class="ft14">x 10</span></nobr></DIV>
<DIV style="position:absolute;top:84;left:433"><nobr><span class="ft15">-4</span></nobr></DIV>
<DIV style="position:absolute;top:355;left:237"><nobr><span class="ft16"><b>East</b></span></nobr></DIV>
<DIV style="position:absolute;top:224;left:92"><nobr><span class="ft16"><b>North</b></span></nobr></DIV>
<DIV style="position:absolute;top:176;left:325"><nobr><span class="ft17"><b>38</b></span></nobr></DIV>
<DIV style="position:absolute;top:172;left:339"><nobr><span class="ft18"><b>o</b></span></nobr></DIV>
<DIV style="position:absolute;top:190;left:335"><nobr><span class="ft17"><b>36</b></span></nobr></DIV>
<DIV style="position:absolute;top:186;left:349"><nobr><span class="ft18"><b>o</b></span></nobr></DIV>
<DIV style="position:absolute;top:320;left:366"><nobr><span class="ft17"><b>0</b></span></nobr></DIV>
<DIV style="position:absolute;top:316;left:373"><nobr><span class="ft18"><b>o</b></span></nobr></DIV>
<DIV style="position:absolute;top:343;left:173"><nobr><span class="ft16"><b>100</b></span></nobr></DIV>
<DIV style="position:absolute;top:343;left:239"><nobr><span class="ft16"><b>200</b></span></nobr></DIV>
<DIV style="position:absolute;top:343;left:305"><nobr><span class="ft16"><b>300</b></span></nobr></DIV>
<DIV style="position:absolute;top:343;left:371"><nobr><span class="ft16"><b>400</b></span></nobr></DIV>
<DIV style="position:absolute;top:304;left:102"><nobr><span class="ft16"><b>50</b></span></nobr></DIV>
<DIV style="position:absolute;top:273;left:95"><nobr><span class="ft16"><b>100</b></span></nobr></DIV>
<DIV style="position:absolute;top:243;left:95"><nobr><span class="ft16"><b>150</b></span></nobr></DIV>
<DIV style="position:absolute;top:213;left:95"><nobr><span class="ft16"><b>200</b></span></nobr></DIV>
<DIV style="position:absolute;top:182;left:95"><nobr><span class="ft16"><b>250</b></span></nobr></DIV>
<DIV style="position:absolute;top:152;left:95"><nobr><span class="ft16"><b>300</b></span></nobr></DIV>
<DIV style="position:absolute;top:121;left:95"><nobr><span class="ft16"><b>350</b></span></nobr></DIV>
<DIV style="position:absolute;top:91;left:95"><nobr><span class="ft16"><b>400</b></span></nobr></DIV>
<DIV style="position:absolute;top:389;left:81"><nobr><span class="ft9">Figure 1: A DOA sensor's view about the target<br>location. Thestatespaceof thetarge</span></nobr></DIV>
<DIV style="position:absolute;top:405;left:354"><nobr><span class="ft4">t location is</span></nobr></DIV>
<DIV style="position:absolute;top:420;left:81"><nobr><span class="ft4">gridded in 1</span></nobr></DIV>
<DIV style="position:absolute;top:417;left:167"><nobr><span class="ft4">× 1 cells. Theimagedepicts theproba-</span></nobr></DIV>
<DIV style="position:absolute;top:436;left:81"><nobr><span class="ft9">bility distribution of thetarget location. Theactual<br>target location is (200, 200), denoted by marker +.<br>From the perspective of the DOA sensor denoted<br>by the square, only the direction to the target is<br>observable. The view of the DOA sensor about the<br>target is in the interval [36</span></nobr></DIV>
<DIV style="position:absolute;top:509;left:273"><nobr><span class="ft11">o</span></nobr></DIV>
<DIV style="position:absolute;top:514;left:279"><nobr><span class="ft4">, 38</span></nobr></DIV>
<DIV style="position:absolute;top:509;left:299"><nobr><span class="ft11">o</span></nobr></DIV>
<DIV style="position:absolute;top:514;left:306"><nobr><span class="ft4">] if and only if the</span></nobr></DIV>
<DIV style="position:absolute;top:530;left:81"><nobr><span class="ft4">target is inside the sector delimited by 36</span></nobr></DIV>
<DIV style="position:absolute;top:525;left:372"><nobr><span class="ft11">o</span></nobr></DIV>
<DIV style="position:absolute;top:530;left:383"><nobr><span class="ft4">lineand</span></nobr></DIV>
<DIV style="position:absolute;top:546;left:81"><nobr><span class="ft4">38</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:94"><nobr><span class="ft11">o</span></nobr></DIV>
<DIV style="position:absolute;top:546;left:106"><nobr><span class="ft4">line.</span></nobr></DIV>
<DIV style="position:absolute;top:588;left:94"><nobr><span class="ft4">In practice, the state space of the target location and the</span></nobr></DIV>
<DIV style="position:absolute;top:603;left:81"><nobr><span class="ft9">sensor view can be discretized by griding for numerical anal-<br>ysis. The discrete representation of p(z</span></nobr></DIV>
<DIV style="position:absolute;top:614;left:319"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:625;left:318"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:619;left:325"><nobr><span class="ft4">) can be computed</span></nobr></DIV>
<DIV style="position:absolute;top:635;left:81"><nobr><span class="ft9">as follows.<br>1. Let</span></nobr></DIV>
<DIV style="position:absolute;top:647;left:123"><nobr><span class="ft4">X be the grid set of the target location x;</span></nobr></DIV>
<DIV style="position:absolute;top:666;left:81"><nobr><span class="ft4">2. Let</span></nobr></DIV>
<DIV style="position:absolute;top:663;left:123"><nobr><span class="ft4">Z be the grid set of the sensor view z</span></nobr></DIV>
<DIV style="position:absolute;top:661;left:352"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:672;left:351"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:666;left:359"><nobr><span class="ft4">;</span></nobr></DIV>
<DIV style="position:absolute;top:682;left:81"><nobr><span class="ft4">3. For each grid point z</span></nobr></DIV>
<DIV style="position:absolute;top:677;left:226"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:687;left:226"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:678;left:237"><nobr><span class="ft4"> Z, initialize p(z</span></nobr></DIV>
<DIV style="position:absolute;top:677;left:345"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:687;left:344"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:682;left:351"><nobr><span class="ft4">) to zero;</span></nobr></DIV>
<DIV style="position:absolute;top:697;left:81"><nobr><span class="ft4">4. For each grid point x</span></nobr></DIV>
<DIV style="position:absolute;top:694;left:233"><nobr><span class="ft4"> X , determine the corresponding</span></nobr></DIV>
<DIV style="position:absolute;top:713;left:81"><nobr><span class="ft4">grid point z</span></nobr></DIV>
<DIV style="position:absolute;top:708;left:153"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:719;left:152"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:710;left:164"><nobr><span class="ft4"> Z using equation (6), and update its prob-</span></nobr></DIV>
<DIV style="position:absolute;top:729;left:81"><nobr><span class="ft4">ability as p(z</span></nobr></DIV>
<DIV style="position:absolute;top:724;left:160"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:735;left:160"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:729;left:167"><nobr><span class="ft4">) = p(z</span></nobr></DIV>
<DIV style="position:absolute;top:724;left:210"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:735;left:209"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:729;left:217"><nobr><span class="ft4">) + p(x);</span></nobr></DIV>
<DIV style="position:absolute;top:745;left:81"><nobr><span class="ft4">5. Normalize p(z</span></nobr></DIV>
<DIV style="position:absolute;top:740;left:183"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:750;left:183"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:745;left:190"><nobr><span class="ft4">) to make the total probability of the sen-</span></nobr></DIV>
<DIV style="position:absolute;top:760;left:81"><nobr><span class="ft9">sor view be 1.<br>The numerical computation of p(z</span></nobr></DIV>
<DIV style="position:absolute;top:771;left:295"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:782;left:294"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:776;left:302"><nobr><span class="ft4">) for a DOA sensor is</span></nobr></DIV>
<DIV style="position:absolute;top:792;left:81"><nobr><span class="ft4">illustrated in Fig. 1 and Fig. 2.</span></nobr></DIV>
<DIV style="position:absolute;top:807;left:94"><nobr><span class="ft4">The entropy of the probability distribution of the view of</span></nobr></DIV>
<DIV style="position:absolute;top:823;left:81"><nobr><span class="ft4">sensor i, H</span></nobr></DIV>
<DIV style="position:absolute;top:818;left:148"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:829;left:147"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:823;left:155"><nobr><span class="ft4">, is</span></nobr></DIV>
<DIV style="position:absolute;top:855;left:168"><nobr><span class="ft4">H</span></nobr></DIV>
<DIV style="position:absolute;top:849;left:181"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:860;left:180"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:855;left:191"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:851;left:206"><nobr><span class="ft4">-</span></nobr></DIV>
<DIV style="position:absolute;top:855;left:235"><nobr><span class="ft4">p(z</span></nobr></DIV>
<DIV style="position:absolute;top:849;left:255"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:860;left:254"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:855;left:261"><nobr><span class="ft4">) log p(z</span></nobr></DIV>
<DIV style="position:absolute;top:849;left:308"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:860;left:308"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:855;left:315"><nobr><span class="ft4">)dz</span></nobr></DIV>
<DIV style="position:absolute;top:849;left:334"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:860;left:334"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:855;left:348"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:855;left:422"><nobr><span class="ft4">(8)</span></nobr></DIV>
<DIV style="position:absolute;top:887;left:81"><nobr><span class="ft4">Given the discrete representation of p(z</span></nobr></DIV>
<DIV style="position:absolute;top:882;left:326"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:892;left:325"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:887;left:332"><nobr><span class="ft4">) with a grid size</span></nobr></DIV>
<DIV style="position:absolute;top:902;left:81"><nobr><span class="ft4">of z</span></nobr></DIV>
<DIV style="position:absolute;top:898;left:110"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:908;left:110"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:902;left:117"><nobr><span class="ft4">, H</span></nobr></DIV>
<DIV style="position:absolute;top:898;left:138"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:908;left:137"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:902;left:149"><nobr><span class="ft4">can be numerically computed as</span></nobr></DIV>
<DIV style="position:absolute;top:930;left:165"><nobr><span class="ft4">H</span></nobr></DIV>
<DIV style="position:absolute;top:924;left:178"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:935;left:177"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:930;left:188"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:926;left:203"><nobr><span class="ft4">-</span></nobr></DIV>
<DIV style="position:absolute;top:930;left:238"><nobr><span class="ft4">p(z</span></nobr></DIV>
<DIV style="position:absolute;top:924;left:258"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:935;left:257"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:930;left:264"><nobr><span class="ft4">) log p(z</span></nobr></DIV>
<DIV style="position:absolute;top:924;left:312"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:935;left:311"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:930;left:318"><nobr><span class="ft4">)z</span></nobr></DIV>
<DIV style="position:absolute;top:924;left:337"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:935;left:337"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:930;left:351"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:930;left:422"><nobr><span class="ft4">(9)</span></nobr></DIV>
<DIV style="position:absolute;top:957;left:94"><nobr><span class="ft4">The sensing model of sensor i for the actual target location</span></nobr></DIV>
<DIV style="position:absolute;top:973;left:81"><nobr><span class="ft4">x</span></nobr></DIV>
<DIV style="position:absolute;top:968;left:89"><nobr><span class="ft11">t</span></nobr></DIV>
<DIV style="position:absolute;top:973;left:98"><nobr><span class="ft4">is p(z</span></nobr></DIV>
<DIV style="position:absolute;top:977;left:130"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:969;left:134"><nobr><span class="ft4">|x</span></nobr></DIV>
<DIV style="position:absolute;top:968;left:147"><nobr><span class="ft11">t</span></nobr></DIV>
<DIV style="position:absolute;top:973;left:152"><nobr><span class="ft4">), which describes the probability distribution of</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:81"><nobr><span class="ft4">the observation of sensor i given that the target is at x</span></nobr></DIV>
<DIV style="position:absolute;top:983;left:401"><nobr><span class="ft11">t</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:406"><nobr><span class="ft4">. The</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:81"><nobr><span class="ft9">sensing model incorporates observation uncertainty from all<br>sources, including the noise corruption to the signal, the sig-<br>nal modeling error of the sensor estimation algorithm, and<br>the inaccuracy of the sensor hardware. For a single-modal<br>target location distribution p(x), we can use the maximum</span></nobr></DIV>
<DIV style="position:absolute;top:340;left:509"><nobr><span class="ft16"><b>10</b></span></nobr></DIV>
<DIV style="position:absolute;top:340;left:553"><nobr><span class="ft16"><b>20</b></span></nobr></DIV>
<DIV style="position:absolute;top:340;left:598"><nobr><span class="ft16"><b>30</b></span></nobr></DIV>
<DIV style="position:absolute;top:340;left:642"><nobr><span class="ft16"><b>40</b></span></nobr></DIV>
<DIV style="position:absolute;top:340;left:686"><nobr><span class="ft16"><b>50</b></span></nobr></DIV>
<DIV style="position:absolute;top:340;left:730"><nobr><span class="ft16"><b>60</b></span></nobr></DIV>
<DIV style="position:absolute;top:340;left:774"><nobr><span class="ft16"><b>70</b></span></nobr></DIV>
<DIV style="position:absolute;top:340;left:819"><nobr><span class="ft16"><b>80</b></span></nobr></DIV>
<DIV style="position:absolute;top:331;left:507"><nobr><span class="ft16"><b>0</b></span></nobr></DIV>
<DIV style="position:absolute;top:290;left:490"><nobr><span class="ft16"><b>0.02</b></span></nobr></DIV>
<DIV style="position:absolute;top:249;left:490"><nobr><span class="ft16"><b>0.04</b></span></nobr></DIV>
<DIV style="position:absolute;top:209;left:490"><nobr><span class="ft16"><b>0.06</b></span></nobr></DIV>
<DIV style="position:absolute;top:168;left:490"><nobr><span class="ft16"><b>0.08</b></span></nobr></DIV>
<DIV style="position:absolute;top:127;left:497"><nobr><span class="ft16"><b>0.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:87;left:490"><nobr><span class="ft16"><b>0.12</b></span></nobr></DIV>
<DIV style="position:absolute;top:352;left:631"><nobr><span class="ft16"><b>DOA (degree)</b></span></nobr></DIV>
<DIV style="position:absolute;top:236;left:487"><nobr><span class="ft16"><b>Probability</b></span></nobr></DIV>
<DIV style="position:absolute;top:386;left:475"><nobr><span class="ft9">Figure2: Thediscreteprobability distribution of a<br>DOA se</span></nobr></DIV>
<DIV style="position:absolute;top:401;left:532"><nobr><span class="ft4">nsor's vie</span></nobr></DIV>
<DIV style="position:absolute;top:401;left:600"><nobr><span class="ft4">w.</span></nobr></DIV>
<DIV style="position:absolute;top:401;left:628"><nobr><span class="ft4">Thestatespaceof theDOA</span></nobr></DIV>
<DIV style="position:absolute;top:417;left:475"><nobr><span class="ft4">sensor view is gridded in 2</span></nobr></DIV>
<DIV style="position:absolute;top:412;left:657"><nobr><span class="ft11">o</span></nobr></DIV>
<DIV style="position:absolute;top:417;left:668"><nobr><span class="ft4">intervals. The target lo-</span></nobr></DIV>
<DIV style="position:absolute;top:433;left:475"><nobr><span class="ft9">cation distribution and theDOA sensor location are<br>illustrated in Fig. 1. Marker X denotes the proba-<br>bility of the DOA view interval [36</span></nobr></DIV>
<DIV style="position:absolute;top:459;left:708"><nobr><span class="ft11">o</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:714"><nobr><span class="ft4">, 38</span></nobr></DIV>
<DIV style="position:absolute;top:459;left:734"><nobr><span class="ft11">o</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:740"><nobr><span class="ft4">], which is the</span></nobr></DIV>
<DIV style="position:absolute;top:480;left:475"><nobr><span class="ft9">summation of theprobability of all target locations<br>inside the sector delimited by 36</span></nobr></DIV>
<DIV style="position:absolute;top:491;left:707"><nobr><span class="ft11">o</span></nobr></DIV>
<DIV style="position:absolute;top:496;left:719"><nobr><span class="ft4">lineand 38</span></nobr></DIV>
<DIV style="position:absolute;top:491;left:796"><nobr><span class="ft11">o</span></nobr></DIV>
<DIV style="position:absolute;top:496;left:809"><nobr><span class="ft4">line</span></nobr></DIV>
<DIV style="position:absolute;top:511;left:475"><nobr><span class="ft9">in Fig. 1. Please note that the sensor view distri-<br>bution does not depends on the sensing uncertainty<br>characteristics at all.</span></nobr></DIV>
<DIV style="position:absolute;top:583;left:475"><nobr><span class="ft4">likelihood estimate ^</span></nobr></DIV>
<DIV style="position:absolute;top:583;left:594"><nobr><span class="ft4">x of the target location to approximate</span></nobr></DIV>
<DIV style="position:absolute;top:599;left:475"><nobr><span class="ft4">the actual target location x</span></nobr></DIV>
<DIV style="position:absolute;top:594;left:642"><nobr><span class="ft11">t</span></nobr></DIV>
<DIV style="position:absolute;top:599;left:647"><nobr><span class="ft4">. Thus the entropy of the sens-</span></nobr></DIV>
<DIV style="position:absolute;top:614;left:475"><nobr><span class="ft4">ing model of sensor i for the actual target location x</span></nobr></DIV>
<DIV style="position:absolute;top:610;left:813"><nobr><span class="ft11">t</span></nobr></DIV>
<DIV style="position:absolute;top:614;left:825"><nobr><span class="ft4">is</span></nobr></DIV>
<DIV style="position:absolute;top:630;left:475"><nobr><span class="ft4">approximated as</span></nobr></DIV>
<DIV style="position:absolute;top:661;left:555"><nobr><span class="ft4">H</span></nobr></DIV>
<DIV style="position:absolute;top:655;left:568"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:661;left:577"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:658;left:591"><nobr><span class="ft4">-</span></nobr></DIV>
<DIV style="position:absolute;top:661;left:620"><nobr><span class="ft4">p(z</span></nobr></DIV>
<DIV style="position:absolute;top:666;left:639"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:658;left:644"><nobr><span class="ft4">|^x) log p(z</span></nobr></DIV>
<DIV style="position:absolute;top:666;left:703"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:658;left:707"><nobr><span class="ft4">|^x)dz</span></nobr></DIV>
<DIV style="position:absolute;top:666;left:739"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:661;left:750"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:661;left:809"><nobr><span class="ft4">(10)</span></nobr></DIV>
<DIV style="position:absolute;top:693;left:475"><nobr><span class="ft19">For a multi-modal target location distribution p(x) with M<br>peaks ^</span></nobr></DIV>
<DIV style="position:absolute;top:710;left:513"><nobr><span class="ft4">x</span></nobr></DIV>
<DIV style="position:absolute;top:705;left:521"><nobr><span class="ft11">(m)</span></nobr></DIV>
<DIV style="position:absolute;top:710;left:540"><nobr><span class="ft4">, where m = 1, . . . , M , the entropy of the sensing</span></nobr></DIV>
<DIV style="position:absolute;top:726;left:475"><nobr><span class="ft4">model of sensor i for the actual target location x</span></nobr></DIV>
<DIV style="position:absolute;top:721;left:782"><nobr><span class="ft11">t</span></nobr></DIV>
<DIV style="position:absolute;top:726;left:793"><nobr><span class="ft4">can be</span></nobr></DIV>
<DIV style="position:absolute;top:741;left:475"><nobr><span class="ft9">approximated as a weighted average of the entropy of the<br>sensing model for all modes,</span></nobr></DIV>
<DIV style="position:absolute;top:794;left:487"><nobr><span class="ft4">H</span></nobr></DIV>
<DIV style="position:absolute;top:789;left:499"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:794;left:508"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:791;left:523"><nobr><span class="ft4">-</span></nobr></DIV>
<DIV style="position:absolute;top:780;left:542"><nobr><span class="ft11">M</span></nobr></DIV>
<DIV style="position:absolute;top:813;left:536"><nobr><span class="ft11">m=1</span></nobr></DIV>
<DIV style="position:absolute;top:794;left:562"><nobr><span class="ft4">p(^</span></nobr></DIV>
<DIV style="position:absolute;top:794;left:574"><nobr><span class="ft4">x</span></nobr></DIV>
<DIV style="position:absolute;top:789;left:583"><nobr><span class="ft11">(m)</span></nobr></DIV>
<DIV style="position:absolute;top:794;left:602"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:794;left:626"><nobr><span class="ft4">p(z</span></nobr></DIV>
<DIV style="position:absolute;top:799;left:645"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:791;left:649"><nobr><span class="ft4">|^x</span></nobr></DIV>
<DIV style="position:absolute;top:789;left:661"><nobr><span class="ft11">(m)</span></nobr></DIV>
<DIV style="position:absolute;top:794;left:681"><nobr><span class="ft4">) log p(z</span></nobr></DIV>
<DIV style="position:absolute;top:799;left:727"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:791;left:732"><nobr><span class="ft4">|^x</span></nobr></DIV>
<DIV style="position:absolute;top:789;left:744"><nobr><span class="ft11">(m)</span></nobr></DIV>
<DIV style="position:absolute;top:794;left:763"><nobr><span class="ft4">)dz</span></nobr></DIV>
<DIV style="position:absolute;top:799;left:782"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:794;left:794"><nobr><span class="ft4">. (11)</span></nobr></DIV>
<DIV style="position:absolute;top:831;left:475"><nobr><span class="ft9">Given a target location distribution p(x), the target location<br>with maximum likelihood or local maximum likelihood can<br>be found using standard search algorithms.</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:489"><nobr><span class="ft4">We have repeatedly observed that the incorporation of</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:475"><nobr><span class="ft9">the observation of sensor i with larger entropy difference<br>H</span></nobr></DIV>
<DIV style="position:absolute;top:905;left:488"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:915;left:487"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:906;left:498"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:905;left:526"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:910;left:537"><nobr><span class="ft4">yields on average larger reduction in the uncer-</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:475"><nobr><span class="ft4">tainty of the posterior target location distribution p(x|z</span></nobr></DIV>
<DIV style="position:absolute;top:930;left:820"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:825"><nobr><span class="ft4">).</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:475"><nobr><span class="ft9">Therefore, given a prior target location distribution and the<br>location and the sensing uncertainty model of a set of can-<br>didate sensors for selection, the entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:968;left:793"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:978;left:792"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:969;left:803"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:968;left:829"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:475"><nobr><span class="ft9">can sort candidate sensors into nearly the same order as mu-<br>tual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:1008;left:613"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:617"><nobr><span class="ft4">) does. Specifically, the sensor with</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:475"><nobr><span class="ft4">the maximal entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:681"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:1025;left:680"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1016;left:691"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:717"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:727"><nobr><span class="ft4">also has the max-</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:475"><nobr><span class="ft4">imum or nearly the maximal mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:1040;left:820"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:825"><nobr><span class="ft4">).</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:475"><nobr><span class="ft4">Hence we propose to use the entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:1046;left:780"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:1057;left:779"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:790"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:1046;left:816"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:822"><nobr><span class="ft4">as</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:475"><nobr><span class="ft4">an alternative to mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:1071;left:744"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:748"><nobr><span class="ft4">) for selecting</span></nobr></DIV>
<DIV style="position:absolute;top:1127;left:452"><nobr><span class="ft8">38</span></nobr></DIV>
</DIV>
<!-- Page 4 -->
<a name="4"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft20{font-size:15px;line-height:17px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="84004.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft9">the most informative sensor. The entropy-based heuristic is<br>to compute H</span></nobr></DIV>
<DIV style="position:absolute;top:97;left:167"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:108;left:166"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:99;left:177"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:97;left:204"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:215"><nobr><span class="ft4">for every candidate sensor i  S and</span></nobr></DIV>
<DIV style="position:absolute;top:118;left:81"><nobr><span class="ft4">then to select sensor ^i such that</span></nobr></DIV>
<DIV style="position:absolute;top:140;left:186"><nobr><span class="ft4">^i = arg max</span></nobr></DIV>
<DIV style="position:absolute;top:155;left:235"><nobr><span class="ft11">iS</span></nobr></DIV>
<DIV style="position:absolute;top:143;left:258"><nobr><span class="ft4">(H</span></nobr></DIV>
<DIV style="position:absolute;top:138;left:276"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:275"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:140;left:285"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:138;left:312"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:143;left:317"><nobr><span class="ft4">) .</span></nobr></DIV>
<DIV style="position:absolute;top:143;left:415"><nobr><span class="ft4">(12)</span></nobr></DIV>
<DIV style="position:absolute;top:174;left:81"><nobr><span class="ft9">In Sect. 3, the validity of the heuristic is evaluated using<br>simulations and the complexity of the heuristic is analyzed<br>for two-dimensional localization.</span></nobr></DIV>
<DIV style="position:absolute;top:206;left:294"><nobr><span class="ft4">The entropy-based sen-</span></nobr></DIV>
<DIV style="position:absolute;top:222;left:81"><nobr><span class="ft9">sor selection heuristic works nearly as well as the mutual-<br>information-based approaches. In addition, the heuristic is<br>computationally much simpler than mutual information.</span></nobr></DIV>
<DIV style="position:absolute;top:279;left:81"><nobr><span class="ft3"><b>2.3</b></span></nobr></DIV>
<DIV style="position:absolute;top:279;left:121"><nobr><span class="ft20"><b>Relation of Entropy Difference<br>and Mutual Information</b></span></nobr></DIV>
<DIV style="position:absolute;top:318;left:94"><nobr><span class="ft4">A brief analysis of the relation between entropy differ-</span></nobr></DIV>
<DIV style="position:absolute;top:334;left:81"><nobr><span class="ft4">ence H</span></nobr></DIV>
<DIV style="position:absolute;top:329;left:124"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:340;left:123"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:331;left:134"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:329;left:161"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:334;left:171"><nobr><span class="ft4">and mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:339;left:355"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:334;left:360"><nobr><span class="ft4">) helps to re-</span></nobr></DIV>
<DIV style="position:absolute;top:350;left:81"><nobr><span class="ft9">veal fundamental properties of our sensor selection heuristic.<br>Mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:370;left:236"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:365;left:241"><nobr><span class="ft4">) has another expression, namely,</span></nobr></DIV>
<DIV style="position:absolute;top:381;left:81"><nobr><span class="ft4">H(z</span></nobr></DIV>
<DIV style="position:absolute;top:386;left:105"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:381;left:110"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:378;left:118"><nobr><span class="ft4">- H(z</span></nobr></DIV>
<DIV style="position:absolute;top:386;left:156"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:378;left:161"><nobr><span class="ft4">|x). The entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:376;left:341"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:387;left:340"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:378;left:350"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:376;left:376"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:381;left:386"><nobr><span class="ft4">is closely</span></nobr></DIV>
<DIV style="position:absolute;top:397;left:81"><nobr><span class="ft4">related to H(z</span></nobr></DIV>
<DIV style="position:absolute;top:401;left:168"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:397;left:173"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:393;left:181"><nobr><span class="ft4">- H(z</span></nobr></DIV>
<DIV style="position:absolute;top:401;left:220"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:393;left:224"><nobr><span class="ft4">|x).</span></nobr></DIV>
<DIV style="position:absolute;top:412;left:94"><nobr><span class="ft4">H(z</span></nobr></DIV>
<DIV style="position:absolute;top:417;left:119"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:412;left:123"><nobr><span class="ft4">) is the entropy of the predicted sensor observation</span></nobr></DIV>
<DIV style="position:absolute;top:428;left:81"><nobr><span class="ft4">distribution p(z</span></nobr></DIV>
<DIV style="position:absolute;top:433;left:175"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:428;left:180"><nobr><span class="ft4">),</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:164"><nobr><span class="ft4">H(z</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:189"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:194"><nobr><span class="ft4">) =</span></nobr></DIV>
<DIV style="position:absolute;top:458;left:217"><nobr><span class="ft4">-</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:246"><nobr><span class="ft4">p(z</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:265"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:270"><nobr><span class="ft4">) log p(z</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:317"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:321"><nobr><span class="ft4">)dz</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:340"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:352"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:415"><nobr><span class="ft4">(13)</span></nobr></DIV>
<DIV style="position:absolute;top:494;left:81"><nobr><span class="ft4">The predicted sensor observation distribution p(z</span></nobr></DIV>
<DIV style="position:absolute;top:499;left:375"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:494;left:380"><nobr><span class="ft4">) becomes</span></nobr></DIV>
<DIV style="position:absolute;top:510;left:81"><nobr><span class="ft4">the sensor's view distribution p(z</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:280"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:515;left:280"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:510;left:287"><nobr><span class="ft4">) when the sensing model</span></nobr></DIV>
<DIV style="position:absolute;top:525;left:81"><nobr><span class="ft4">p(z</span></nobr></DIV>
<DIV style="position:absolute;top:530;left:100"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:522;left:104"><nobr><span class="ft4">|x) is deterministic without uncertainty. The uncer-</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:81"><nobr><span class="ft4">tainty in the sensing model p(z</span></nobr></DIV>
<DIV style="position:absolute;top:546;left:267"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:538;left:271"><nobr><span class="ft4">|x) makes H(z</span></nobr></DIV>
<DIV style="position:absolute;top:546;left:359"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:363"><nobr><span class="ft4">) larger than</span></nobr></DIV>
<DIV style="position:absolute;top:557;left:81"><nobr><span class="ft4">the sensor's view entropy H</span></nobr></DIV>
<DIV style="position:absolute;top:552;left:250"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:562;left:249"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:557;left:261"><nobr><span class="ft4">defined in (8). H</span></nobr></DIV>
<DIV style="position:absolute;top:552;left:365"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:562;left:364"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:557;left:376"><nobr><span class="ft4">closely ap-</span></nobr></DIV>
<DIV style="position:absolute;top:572;left:81"><nobr><span class="ft4">proximates H(z</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:178"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:572;left:182"><nobr><span class="ft4">) when the entropy of the sensing model</span></nobr></DIV>
<DIV style="position:absolute;top:588;left:81"><nobr><span class="ft4">p(z</span></nobr></DIV>
<DIV style="position:absolute;top:593;left:100"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:585;left:104"><nobr><span class="ft4">|x) is small relative to H</span></nobr></DIV>
<DIV style="position:absolute;top:583;left:255"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:594;left:254"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:588;left:262"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:604;left:94"><nobr><span class="ft4">H(z</span></nobr></DIV>
<DIV style="position:absolute;top:609;left:119"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:601;left:123"><nobr><span class="ft4">|x) is actually the expected entropy of the sensing</span></nobr></DIV>
<DIV style="position:absolute;top:620;left:81"><nobr><span class="ft4">model p(x) averaged for all possible target locations,</span></nobr></DIV>
<DIV style="position:absolute;top:653;left:99"><nobr><span class="ft4">H(z</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:123"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:649;left:128"><nobr><span class="ft4">|x) = -</span></nobr></DIV>
<DIV style="position:absolute;top:653;left:193"><nobr><span class="ft4">p(x, z</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:226"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:653;left:231"><nobr><span class="ft4">) log p(z</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:278"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:649;left:282"><nobr><span class="ft4">|x)dxdz</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:329"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:689;left:149"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:689;left:178"><nobr><span class="ft4">p(x){-</span></nobr></DIV>
<DIV style="position:absolute;top:689;left:240"><nobr><span class="ft4">p(z</span></nobr></DIV>
<DIV style="position:absolute;top:693;left:259"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:685;left:264"><nobr><span class="ft4">|x) log p(z</span></nobr></DIV>
<DIV style="position:absolute;top:693;left:323"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:685;left:328"><nobr><span class="ft4">|x)dz</span></nobr></DIV>
<DIV style="position:absolute;top:693;left:359"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:685;left:364"><nobr><span class="ft4">}dx .</span></nobr></DIV>
<DIV style="position:absolute;top:671;left:415"><nobr><span class="ft4">(14)</span></nobr></DIV>
<DIV style="position:absolute;top:722;left:81"><nobr><span class="ft4">When p(x) is a single-modal distribution, H</span></nobr></DIV>
<DIV style="position:absolute;top:717;left:354"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:722;left:365"><nobr><span class="ft4">is defined in</span></nobr></DIV>
<DIV style="position:absolute;top:737;left:81"><nobr><span class="ft9">(10), which is the entropy of the sensing model for the most<br>likely target location estimate ^</span></nobr></DIV>
<DIV style="position:absolute;top:753;left:274"><nobr><span class="ft4">x.</span></nobr></DIV>
<DIV style="position:absolute;top:753;left:298"><nobr><span class="ft4">When p(x) is a multi-</span></nobr></DIV>
<DIV style="position:absolute;top:768;left:81"><nobr><span class="ft4">modal distribution, H</span></nobr></DIV>
<DIV style="position:absolute;top:764;left:214"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:768;left:223"><nobr><span class="ft4">is defined in (11), which is the aver-</span></nobr></DIV>
<DIV style="position:absolute;top:784;left:81"><nobr><span class="ft9">age entropy of the sensing model for all target locations with<br>local maximal likelihood. When the entropy of the sensing<br>model,</span></nobr></DIV>
<DIV style="position:absolute;top:812;left:126"><nobr><span class="ft4">-</span></nobr></DIV>
<DIV style="position:absolute;top:814;left:139"><nobr><span class="ft12">Ê</span></nobr></DIV>
<DIV style="position:absolute;top:816;left:151"><nobr><span class="ft4">p(z</span></nobr></DIV>
<DIV style="position:absolute;top:820;left:170"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:812;left:174"><nobr><span class="ft4">|x) log p(z</span></nobr></DIV>
<DIV style="position:absolute;top:820;left:233"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:812;left:238"><nobr><span class="ft4">|x)dz</span></nobr></DIV>
<DIV style="position:absolute;top:820;left:269"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:816;left:274"><nobr><span class="ft4">, changes gradually with x,</span></nobr></DIV>
<DIV style="position:absolute;top:831;left:81"><nobr><span class="ft4">H</span></nobr></DIV>
<DIV style="position:absolute;top:826;left:93"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:831;left:103"><nobr><span class="ft4">can reasonably approximate H(z</span></nobr></DIV>
<DIV style="position:absolute;top:836;left:302"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:828;left:306"><nobr><span class="ft4">|x).</span></nobr></DIV>
<DIV style="position:absolute;top:847;left:94"><nobr><span class="ft4">The entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:842;left:246"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:853;left:245"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:844;left:255"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:842;left:281"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:847;left:290"><nobr><span class="ft4">reasonably approximates</span></nobr></DIV>
<DIV style="position:absolute;top:863;left:81"><nobr><span class="ft4">the mutual information H(z</span></nobr></DIV>
<DIV style="position:absolute;top:867;left:253"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:863;left:258"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:859;left:267"><nobr><span class="ft4">- H(z</span></nobr></DIV>
<DIV style="position:absolute;top:867;left:306"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:859;left:310"><nobr><span class="ft4">|x) when H</span></nobr></DIV>
<DIV style="position:absolute;top:858;left:383"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:863;left:393"><nobr><span class="ft4">is small</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:81"><nobr><span class="ft4">relative to H</span></nobr></DIV>
<DIV style="position:absolute;top:874;left:158"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:884;left:157"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:168"><nobr><span class="ft4">and the entropy of the sensing model changes</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:81"><nobr><span class="ft9">gradually with x. However, selection of the most informa-<br>tive sensor does not require an exact evaluation of sensor<br>information utility. Instead, an order of sensors in terms of<br>information utility is needed. H</span></nobr></DIV>
<DIV style="position:absolute;top:936;left:282"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:947;left:281"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:938;left:292"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:936;left:319"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:330"><nobr><span class="ft4">could sort sensors</span></nobr></DIV>
<DIV style="position:absolute;top:957;left:81"><nobr><span class="ft9">into approximately the same order as mutual information<br>does. Therefore, a sensor with the maximal entropy differ-<br>ence H</span></nobr></DIV>
<DIV style="position:absolute;top:983;left:124"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:994;left:123"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:985;left:134"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:983;left:161"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:170"><nobr><span class="ft4">also has the maximal or nearly the maximal</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:81"><nobr><span class="ft9">mutual information. The correlation between the entropy<br>difference H</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:155"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:1025;left:154"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1016;left:165"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:192"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:201"><nobr><span class="ft4">and mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:1024;left:384"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:389"><nobr><span class="ft4">) is ana-</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:81"><nobr><span class="ft9">lyzed using simulations in Sect. 3. Section 4 discusses the<br>discrepancy between the heuristic and the mutual informa-<br>tion based approaches.</span></nobr></DIV>
<DIV style="position:absolute;top:84;left:475"><nobr><span class="ft3"><b>3.</b></span></nobr></DIV>
<DIV style="position:absolute;top:84;left:507"><nobr><span class="ft3"><b>HEURISTIC EVALUATION</b></span></nobr></DIV>
<DIV style="position:absolute;top:106;left:489"><nobr><span class="ft4">This Sect. presents the evaluation of the entropy-based</span></nobr></DIV>
<DIV style="position:absolute;top:121;left:475"><nobr><span class="ft4">sensor selection heuristic using simulations.</span></nobr></DIV>
<DIV style="position:absolute;top:121;left:759"><nobr><span class="ft4">The compu-</span></nobr></DIV>
<DIV style="position:absolute;top:137;left:475"><nobr><span class="ft9">tational complexity of the heuristic is also analyzed. The<br>Gaussian noise model has been widely assumed for sensor<br>observations in many localization and tracking algorithms,<br>e.g. the Kalman filter [9]. Successes of these algorithms<br>indicate that the Gaussian sensing model is a reasonable<br>first-order-approximation of the reality. As a starting point,<br>we assume Gaussian sensing models in the evaluative simula-<br>tions for simplicity. The simple Gaussian sensing models as-<br>sumed here are not accurate especially when sensors are very<br>close to the target. To avoid the problem of over-simplified<br>sensing models in the simulations, we only analyze sensors<br>with some middle distance range to the target. The heuris-<br>tic will be evaluated further under more realistic sensing<br>models in the future. Four scenarios of sensor selection for<br>localization have been studied. Three of them involve DOA<br>sensors, range sensors, or time-difference-of-arrival (TDOA)<br>sensors respectively. One of them involves all of the above<br>sensors mixed together. In every sensor selection scenario,<br>both the entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:415;left:660"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:425;left:658"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:416;left:670"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:415;left:697"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:420;left:707"><nobr><span class="ft4">and mutual informa-</span></nobr></DIV>
<DIV style="position:absolute;top:435;left:475"><nobr><span class="ft4">tion I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:440;left:538"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:435;left:543"><nobr><span class="ft4">) are evaluated and compared for all candidate</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:475"><nobr><span class="ft9">sensors. In all sensor selection scenarios, the entropy differ-<br>ence H</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:518"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:472;left:517"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:463;left:528"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:554"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:467;left:563"><nobr><span class="ft4">can sort all candidate sensors into nearly the</span></nobr></DIV>
<DIV style="position:absolute;top:482;left:475"><nobr><span class="ft4">same order as mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:487;left:720"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:482;left:725"><nobr><span class="ft4">) does. Therefore,</span></nobr></DIV>
<DIV style="position:absolute;top:498;left:475"><nobr><span class="ft4">the sensor with the maximal entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:493;left:774"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:504;left:773"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:495;left:783"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:493;left:809"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:498;left:818"><nobr><span class="ft4">se-</span></nobr></DIV>
<DIV style="position:absolute;top:514;left:475"><nobr><span class="ft9">lected by the heuristic always has the maximum or nearly<br>the maximal mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:534;left:718"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:529;left:723"><nobr><span class="ft4">). The larger the</span></nobr></DIV>
<DIV style="position:absolute;top:545;left:475"><nobr><span class="ft4">entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:540;left:599"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:598"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:542;left:608"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:540;left:633"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:545;left:643"><nobr><span class="ft4">and mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:550;left:824"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:545;left:829"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:561;left:475"><nobr><span class="ft4">are, the more consistent their sensor selection decisions are.</span></nobr></DIV>
<DIV style="position:absolute;top:587;left:475"><nobr><span class="ft3"><b>3.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:587;left:515"><nobr><span class="ft3"><b>Selection of DOA Sensors</b></span></nobr></DIV>
<DIV style="position:absolute;top:609;left:489"><nobr><span class="ft4">Consider now entropy-based sensor selection when all can-</span></nobr></DIV>
<DIV style="position:absolute;top:625;left:475"><nobr><span class="ft9">didate sensors are DOA sensors, as depicted in Fig. 3. The<br>prior probability distribution p(x) of the target location x is<br>non-zero in a limited area. We assume the unbiased Gaus-<br>sian sensing models for DOA sensors in some middle distance<br>range to the target. Specifically, given a target location such<br>that 10</span></nobr></DIV>
<DIV style="position:absolute;top:700;left:526"><nobr><span class="ft4"> x - x</span></nobr></DIV>
<DIV style="position:absolute;top:708;left:585"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:700;left:602"><nobr><span class="ft4"> 600, the probability distribution of</span></nobr></DIV>
<DIV style="position:absolute;top:719;left:475"><nobr><span class="ft4">DOA observation z</span></nobr></DIV>
<DIV style="position:absolute;top:724;left:591"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:719;left:600"><nobr><span class="ft4">is assumed to be</span></nobr></DIV>
<DIV style="position:absolute;top:750;left:552"><nobr><span class="ft4">p(z</span></nobr></DIV>
<DIV style="position:absolute;top:754;left:571"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:746;left:576"><nobr><span class="ft4">|x) =</span></nobr></DIV>
<DIV style="position:absolute;top:741;left:628"><nobr><span class="ft4">1</span></nobr></DIV>
<DIV style="position:absolute;top:761;left:613"><nobr><span class="ft4">2 e</span></nobr></DIV>
<DIV style="position:absolute;top:744;left:657"><nobr><span class="ft11">-(z</span></nobr></DIV>
<DIV style="position:absolute;top:748;left:675"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:744;left:680"><nobr><span class="ft11">-z</span></nobr></DIV>
<DIV style="position:absolute;top:742;left:694"><nobr><span class="ft13">v</span></nobr></DIV>
<DIV style="position:absolute;top:748;left:694"><nobr><span class="ft13">i</span></nobr></DIV>
<DIV style="position:absolute;top:744;left:701"><nobr><span class="ft11">)</span></nobr></DIV>
<DIV style="position:absolute;top:742;left:705"><nobr><span class="ft13">2</span></nobr></DIV>
<DIV style="position:absolute;top:746;left:711"><nobr><span class="ft11">/(2</span></nobr></DIV>
<DIV style="position:absolute;top:742;left:733"><nobr><span class="ft13">2</span></nobr></DIV>
<DIV style="position:absolute;top:744;left:739"><nobr><span class="ft11">)</span></nobr></DIV>
<DIV style="position:absolute;top:750;left:751"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:750;left:809"><nobr><span class="ft4">(15)</span></nobr></DIV>
<DIV style="position:absolute;top:784;left:475"><nobr><span class="ft4">where z</span></nobr></DIV>
<DIV style="position:absolute;top:779;left:524"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:790;left:523"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:784;left:537"><nobr><span class="ft4">= f(x, x</span></nobr></DIV>
<DIV style="position:absolute;top:789;left:591"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:784;left:596"><nobr><span class="ft4">) is the direction from sensor i to the</span></nobr></DIV>
<DIV style="position:absolute;top:800;left:475"><nobr><span class="ft9">target location x. For many DOA estimation algorithms<br>like the approximate maximum likelihood (AML) algorithm<br>[4], DOA estimation usually becomes much more uncertain<br>when the candidate sensor is either very near or very far<br>from the target. In this scenario, we exclude sensors that<br>are either outside the study area or within a distance of 10<br>to the area of non-zero p(x).</span></nobr></DIV>
<DIV style="position:absolute;top:910;left:489"><nobr><span class="ft4">The entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:905;left:643"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:915;left:642"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:906;left:653"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:905;left:679"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:910;left:689"><nobr><span class="ft4">and mutual information</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:475"><nobr><span class="ft4">I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:930;left:509"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:513"><nobr><span class="ft4">) of DOA sensors are evaluated and compared in five</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:475"><nobr><span class="ft9">cases. In each case, Gaussian sensing models of the same<br>standard deviation  are assumed for all 100 candidate sen-<br>sors.</span></nobr></DIV>
<DIV style="position:absolute;top:973;left:515"><nobr><span class="ft4">However, the standard deviation  varies with the</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:475"><nobr><span class="ft4">case. As shown in fig. 4, mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:993;left:805"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:809"><nobr><span class="ft4">) vs</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:475"><nobr><span class="ft4">the entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:999;left:625"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:1010;left:624"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1001;left:635"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:999;left:662"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:672"><nobr><span class="ft4">is plotted for all candidate</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:475"><nobr><span class="ft4">sensors in all cases. Mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:1024;left:765"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:770"><nobr><span class="ft4">) increases</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:475"><nobr><span class="ft4">nearly monotonically with the entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:789"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:788"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:798"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:825"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:830"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:475"><nobr><span class="ft4">The larger the entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:1046;left:687"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:1057;left:686"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:695"><nobr><span class="ft4">-H</span></nobr></DIV>
<DIV style="position:absolute;top:1046;left:720"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:729"><nobr><span class="ft4">and mutual infor-</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:475"><nobr><span class="ft4">mation I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:1071;left:554"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:559"><nobr><span class="ft4">) are, the more correlated they are. Therefore,</span></nobr></DIV>
<DIV style="position:absolute;top:1127;left:452"><nobr><span class="ft8">39</span></nobr></DIV>
</DIV>
<!-- Page 5 -->
<a name="5"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft21{font-size:5px;font-family:Helvetica;color:#000000;}
	.ft22{font-size:10px;font-family:Symbol;color:#000000;}
	.ft23{font-size:10px;font-family:Helvetica;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="84005.png" alt="background image">
<DIV style="position:absolute;top:345;left:422"><nobr><span class="ft21">0</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:422"><nobr><span class="ft21">0.2</span></nobr></DIV>
<DIV style="position:absolute;top:271;left:422"><nobr><span class="ft21">0.4</span></nobr></DIV>
<DIV style="position:absolute;top:235;left:422"><nobr><span class="ft21">0.6</span></nobr></DIV>
<DIV style="position:absolute;top:198;left:422"><nobr><span class="ft21">0.8</span></nobr></DIV>
<DIV style="position:absolute;top:161;left:422"><nobr><span class="ft21">1</span></nobr></DIV>
<DIV style="position:absolute;top:125;left:422"><nobr><span class="ft21">1.2</span></nobr></DIV>
<DIV style="position:absolute;top:87;left:419"><nobr><span class="ft21">x 10</span></nobr></DIV>
<DIV style="position:absolute;top:84;left:433"><nobr><span class="ft15">-4</span></nobr></DIV>
<DIV style="position:absolute;top:352;left:164"><nobr><span class="ft16"><b>100</b></span></nobr></DIV>
<DIV style="position:absolute;top:352;left:232"><nobr><span class="ft16"><b>200</b></span></nobr></DIV>
<DIV style="position:absolute;top:352;left:300"><nobr><span class="ft16"><b>300</b></span></nobr></DIV>
<DIV style="position:absolute;top:352;left:368"><nobr><span class="ft16"><b>400</b></span></nobr></DIV>
<DIV style="position:absolute;top:312;left:90"><nobr><span class="ft16"><b>50</b></span></nobr></DIV>
<DIV style="position:absolute;top:280;left:83"><nobr><span class="ft16"><b>100</b></span></nobr></DIV>
<DIV style="position:absolute;top:249;left:83"><nobr><span class="ft16"><b>150</b></span></nobr></DIV>
<DIV style="position:absolute;top:217;left:83"><nobr><span class="ft16"><b>200</b></span></nobr></DIV>
<DIV style="position:absolute;top:186;left:83"><nobr><span class="ft16"><b>250</b></span></nobr></DIV>
<DIV style="position:absolute;top:154;left:83"><nobr><span class="ft16"><b>300</b></span></nobr></DIV>
<DIV style="position:absolute;top:123;left:83"><nobr><span class="ft16"><b>350</b></span></nobr></DIV>
<DIV style="position:absolute;top:91;left:83"><nobr><span class="ft16"><b>400</b></span></nobr></DIV>
<DIV style="position:absolute;top:387;left:81"><nobr><span class="ft9">Figure 3: Scenario of sensor selection for localization<br>using DOA sensors exclusively. The image depicts<br>theprior probability distribution p(x) of thetarget<br>location x. p(x) is zero outside the solid rectangle.<br>The actual target location is (200, 200), denoted by<br>marker +. The squares denote candidate DOA sen-<br>sors for selection. 100 DOA sensors are uniformly<br>randomly placed outside the dotted rectangle. The<br>gap between the solid rectangle and the dotted rect-<br>angleis 10.</span></nobr></DIV>
<DIV style="position:absolute;top:576;left:81"><nobr><span class="ft4">the entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:571;left:228"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:581;left:227"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:572;left:237"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:571;left:262"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:576;left:271"><nobr><span class="ft4">sorts DOA sensors in nearly</span></nobr></DIV>
<DIV style="position:absolute;top:591;left:81"><nobr><span class="ft4">the same order as mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:356"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:591;left:361"><nobr><span class="ft4">) does, espe-</span></nobr></DIV>
<DIV style="position:absolute;top:607;left:81"><nobr><span class="ft4">cially when the entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:602;left:309"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:612;left:307"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:604;left:319"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:602;left:346"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:607;left:357"><nobr><span class="ft4">is large. The</span></nobr></DIV>
<DIV style="position:absolute;top:623;left:81"><nobr><span class="ft9">candidate DOA sensor selected by the proposed heuristic<br>has the maximal entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:633;left:313"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:644;left:312"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:635;left:323"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:633;left:350"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:638;left:355"><nobr><span class="ft4">, and also has</span></nobr></DIV>
<DIV style="position:absolute;top:654;left:81"><nobr><span class="ft4">the maximal mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:659;left:317"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:654;left:321"><nobr><span class="ft4">).</span></nobr></DIV>
<DIV style="position:absolute;top:682;left:81"><nobr><span class="ft3"><b>3.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:682;left:121"><nobr><span class="ft20"><b>Selection of Range Sensors<br>and TDOA Sensors</b></span></nobr></DIV>
<DIV style="position:absolute;top:722;left:94"><nobr><span class="ft4">This Subsect. evaluates the entropy-based sensor selection</span></nobr></DIV>
<DIV style="position:absolute;top:737;left:81"><nobr><span class="ft4">heuristic for range sensors and TDOA sensors respectively.</span></nobr></DIV>
<DIV style="position:absolute;top:753;left:94"><nobr><span class="ft4">Fig. 5 shows the sensor selection scenario in which all</span></nobr></DIV>
<DIV style="position:absolute;top:768;left:81"><nobr><span class="ft9">candidate sensors can only measure the range to the tar-<br>get. The prior probability distribution p(x) of the target<br>location x is non-zero in a limited area. We assume the<br>unbiased Gaussian sensing models p(z</span></nobr></DIV>
<DIV style="position:absolute;top:820;left:311"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:812;left:316"><nobr><span class="ft4">|x) for range sensors</span></nobr></DIV>
<DIV style="position:absolute;top:831;left:81"><nobr><span class="ft9">used in [13]. When the actual range is small relative to the<br>standard deviation  of the Gaussian sensing model, p(z</span></nobr></DIV>
<DIV style="position:absolute;top:852;left:417"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:844;left:422"><nobr><span class="ft4">|x)</span></nobr></DIV>
<DIV style="position:absolute;top:863;left:81"><nobr><span class="ft9">is significantly greater than zero even for negative values<br>of range observation z</span></nobr></DIV>
<DIV style="position:absolute;top:883;left:216"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:221"><nobr><span class="ft4">. Because a range of negative value</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:81"><nobr><span class="ft9">has no physical meaning, the above Gaussian sensing model<br>is not valid for short ranges. To avoid the above difficulty<br>of the Gaussian sensing model, we only consider candidate<br>sensors in some middle distance range to the target. Specif-<br>ically, in this range sensor selection scenario, we exclude<br>sensors that are either outside the study area or within a<br>distance of 32 to the area of non-zero p(x).</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:94"><nobr><span class="ft4">Fig. 6 shows the sensor selection scenario in which only</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:81"><nobr><span class="ft9">TDOA sensors are used. The prior probability distribution<br>p(x) of the target location x is non-zero in a limited area. As<br>in [15], the signal arrival time difference observed by every<br>TDOA sensor is relative to a common reference sensor. We</span></nobr></DIV>
<DIV style="position:absolute;top:347;left:499"><nobr><span class="ft16"><b>-2</b></span></nobr></DIV>
<DIV style="position:absolute;top:347;left:552"><nobr><span class="ft16"><b>-1</b></span></nobr></DIV>
<DIV style="position:absolute;top:347;left:613"><nobr><span class="ft16"><b>0</b></span></nobr></DIV>
<DIV style="position:absolute;top:347;left:666"><nobr><span class="ft16"><b>1</b></span></nobr></DIV>
<DIV style="position:absolute;top:347;left:719"><nobr><span class="ft16"><b>2</b></span></nobr></DIV>
<DIV style="position:absolute;top:347;left:772"><nobr><span class="ft16"><b>3</b></span></nobr></DIV>
<DIV style="position:absolute;top:347;left:825"><nobr><span class="ft16"><b>4</b></span></nobr></DIV>
<DIV style="position:absolute;top:338;left:501"><nobr><span class="ft16"><b>0</b></span></nobr></DIV>
<DIV style="position:absolute;top:307;left:490"><nobr><span class="ft16"><b>0.5</b></span></nobr></DIV>
<DIV style="position:absolute;top:275;left:501"><nobr><span class="ft16"><b>1</b></span></nobr></DIV>
<DIV style="position:absolute;top:244;left:490"><nobr><span class="ft16"><b>1.5</b></span></nobr></DIV>
<DIV style="position:absolute;top:212;left:501"><nobr><span class="ft16"><b>2</b></span></nobr></DIV>
<DIV style="position:absolute;top:181;left:490"><nobr><span class="ft16"><b>2.5</b></span></nobr></DIV>
<DIV style="position:absolute;top:149;left:501"><nobr><span class="ft16"><b>3</b></span></nobr></DIV>
<DIV style="position:absolute;top:118;left:490"><nobr><span class="ft16"><b>3.5</b></span></nobr></DIV>
<DIV style="position:absolute;top:87;left:501"><nobr><span class="ft16"><b>4</b></span></nobr></DIV>
<DIV style="position:absolute;top:360;left:599"><nobr><span class="ft16"><b>Entropy difference (bit)</b></span></nobr></DIV>
<DIV style="position:absolute;top:279;left:487"><nobr><span class="ft16"><b>Mutual information (bit)</b></span></nobr></DIV>
<DIV style="position:absolute;top:96;left:550"><nobr><span class="ft22"></span></nobr></DIV>
<DIV style="position:absolute;top:100;left:557"><nobr><span class="ft23"> = 32</span></nobr></DIV>
<DIV style="position:absolute;top:113;left:550"><nobr><span class="ft22"></span></nobr></DIV>
<DIV style="position:absolute;top:116;left:557"><nobr><span class="ft23"> = 16</span></nobr></DIV>
<DIV style="position:absolute;top:129;left:550"><nobr><span class="ft22"></span></nobr></DIV>
<DIV style="position:absolute;top:133;left:557"><nobr><span class="ft23"> = 8 </span></nobr></DIV>
<DIV style="position:absolute;top:146;left:550"><nobr><span class="ft22"></span></nobr></DIV>
<DIV style="position:absolute;top:150;left:557"><nobr><span class="ft23"> = 4 </span></nobr></DIV>
<DIV style="position:absolute;top:163;left:550"><nobr><span class="ft22"></span></nobr></DIV>
<DIV style="position:absolute;top:166;left:557"><nobr><span class="ft23"> = 2 </span></nobr></DIV>
<DIV style="position:absolute;top:394;left:475"><nobr><span class="ft4">Figure4: Mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:399;left:719"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:394;left:723"><nobr><span class="ft4">) vs entropy dif-</span></nobr></DIV>
<DIV style="position:absolute;top:410;left:475"><nobr><span class="ft4">ference H</span></nobr></DIV>
<DIV style="position:absolute;top:405;left:543"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:416;left:542"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:407;left:554"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:405;left:581"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:410;left:592"><nobr><span class="ft4">of DOA sensors. Each symbol de-</span></nobr></DIV>
<DIV style="position:absolute;top:426;left:475"><nobr><span class="ft4">notes (H</span></nobr></DIV>
<DIV style="position:absolute;top:421;left:535"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:431;left:534"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:422;left:544"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:421;left:570"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:426;left:575"><nobr><span class="ft4">, I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:430;left:614"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:426;left:619"><nobr><span class="ft4">)) pair evaluated for one candi-</span></nobr></DIV>
<DIV style="position:absolute;top:441;left:475"><nobr><span class="ft4">datese</span></nobr></DIV>
<DIV style="position:absolute;top:441;left:525"><nobr><span class="ft4">nsor. Theprior targe</span></nobr></DIV>
<DIV style="position:absolute;top:441;left:678"><nobr><span class="ft4">t location distribution</span></nobr></DIV>
<DIV style="position:absolute;top:457;left:475"><nobr><span class="ft9">and the candidate sensor placements are shown in<br>Fig. 3. Five cases with different standard deviation<br> of Gaussian sensing models are studied. In each<br>case, all candidate sensors are assumed to have the<br>same  value.</span></nobr></DIV>
<DIV style="position:absolute;top:563;left:475"><nobr><span class="ft4">also assume the unbiased Gaussian sensing models p(z</span></nobr></DIV>
<DIV style="position:absolute;top:568;left:812"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:560;left:816"><nobr><span class="ft4">|x)</span></nobr></DIV>
<DIV style="position:absolute;top:579;left:475"><nobr><span class="ft9">for TDOA sensors. In order to be comparable with scenarios<br>of DOA sensors and range sensors, we only consider TDOA<br>sensors in middle range distance to the target. Specifically,<br>we exclude TDOA sensors that are either outside the study<br>area or within a distance of 10 to the area of non-zero p(x).</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:489"><nobr><span class="ft4">Following the same approach to the heuristic evaluation</span></nobr></DIV>
<DIV style="position:absolute;top:673;left:475"><nobr><span class="ft4">for DOA sensors, the entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:668;left:725"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:679;left:724"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:670;left:733"><nobr><span class="ft4">-H</span></nobr></DIV>
<DIV style="position:absolute;top:668;left:757"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:673;left:766"><nobr><span class="ft4">and mutual</span></nobr></DIV>
<DIV style="position:absolute;top:689;left:475"><nobr><span class="ft4">information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:693;left:583"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:689;left:588"><nobr><span class="ft4">) of every candidate sensor are evaluated</span></nobr></DIV>
<DIV style="position:absolute;top:704;left:475"><nobr><span class="ft9">and compared for range sensor selection scenario in Fig. 5<br>and for TDOA sensor selection scenario in Fig. 6 respec-<br>tively. Mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:740;left:673"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:736;left:678"><nobr><span class="ft4">) vs the entropy difference</span></nobr></DIV>
<DIV style="position:absolute;top:751;left:475"><nobr><span class="ft4">H</span></nobr></DIV>
<DIV style="position:absolute;top:746;left:488"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:757;left:487"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:748;left:498"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:746;left:526"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:751;left:536"><nobr><span class="ft4">is plotted in Fig. 7 for all range sensors and in</span></nobr></DIV>
<DIV style="position:absolute;top:767;left:475"><nobr><span class="ft9">Fig. 8 for all TDOA sensors. In both scenarios, mutual in-<br>formation I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:787;left:573"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:783;left:578"><nobr><span class="ft4">) increases nearly monotonically with the</span></nobr></DIV>
<DIV style="position:absolute;top:798;left:475"><nobr><span class="ft4">entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:794;left:601"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:804;left:600"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:795;left:611"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:794;left:638"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:798;left:643"><nobr><span class="ft4">. The larger the entropy differ-</span></nobr></DIV>
<DIV style="position:absolute;top:814;left:475"><nobr><span class="ft4">ence H</span></nobr></DIV>
<DIV style="position:absolute;top:809;left:518"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:820;left:517"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:811;left:526"><nobr><span class="ft4">-H</span></nobr></DIV>
<DIV style="position:absolute;top:809;left:551"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:814;left:560"><nobr><span class="ft4">and mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:819;left:741"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:814;left:745"><nobr><span class="ft4">) are, the more</span></nobr></DIV>
<DIV style="position:absolute;top:830;left:475"><nobr><span class="ft9">correlated they are. Using the proposed heuristic, both the<br>selected range sensor and the selected TDOA sensor have the<br>maximal entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:856;left:658"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:867;left:657"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:858;left:668"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:856;left:695"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:700"><nobr><span class="ft4">, and also have nearly</span></nobr></DIV>
<DIV style="position:absolute;top:877;left:475"><nobr><span class="ft4">the maximal mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:881;left:711"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:877;left:716"><nobr><span class="ft4">).</span></nobr></DIV>
<DIV style="position:absolute;top:903;left:475"><nobr><span class="ft3"><b>3.3</b></span></nobr></DIV>
<DIV style="position:absolute;top:903;left:515"><nobr><span class="ft3"><b>Selection of Mixed Sensors</b></span></nobr></DIV>
<DIV style="position:absolute;top:925;left:489"><nobr><span class="ft4">In order to evaluate the entropy-based sensor selection</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:475"><nobr><span class="ft9">heuristic across different sensing modalities, this Subsect. is<br>devoted to the sensor selection scenario in which candidate<br>sensors are a mixture of DOA sensors, range sensors and<br>TDOA sensors.</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:489"><nobr><span class="ft4">Fig. 9 shows the sensor selection scenario for mixed can-</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:475"><nobr><span class="ft9">didate sensors. Each candidate sensor is randomly assigned<br>one of three sensing modalities, namely, DOA, range, and<br>TDOA. Gaussian sensing models are assumed for all candi-<br>date sensors with middle range distance to the target. Each</span></nobr></DIV>
<DIV style="position:absolute;top:1127;left:452"><nobr><span class="ft8">40</span></nobr></DIV>
</DIV>
<!-- Page 6 -->
<a name="6"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft24{font-size:15px;line-height:20px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="84006.png" alt="background image">
<DIV style="position:absolute;top:345;left:422"><nobr><span class="ft21">0</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:422"><nobr><span class="ft21">0.5</span></nobr></DIV>
<DIV style="position:absolute;top:279;left:422"><nobr><span class="ft21">1</span></nobr></DIV>
<DIV style="position:absolute;top:246;left:422"><nobr><span class="ft21">1.5</span></nobr></DIV>
<DIV style="position:absolute;top:213;left:422"><nobr><span class="ft21">2</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:422"><nobr><span class="ft21">2.5</span></nobr></DIV>
<DIV style="position:absolute;top:147;left:422"><nobr><span class="ft21">3</span></nobr></DIV>
<DIV style="position:absolute;top:114;left:422"><nobr><span class="ft21">3.5</span></nobr></DIV>
<DIV style="position:absolute;top:87;left:419"><nobr><span class="ft21">x 10</span></nobr></DIV>
<DIV style="position:absolute;top:84;left:433"><nobr><span class="ft15">-4</span></nobr></DIV>
<DIV style="position:absolute;top:352;left:164"><nobr><span class="ft16"><b>100</b></span></nobr></DIV>
<DIV style="position:absolute;top:352;left:232"><nobr><span class="ft16"><b>200</b></span></nobr></DIV>
<DIV style="position:absolute;top:352;left:300"><nobr><span class="ft16"><b>300</b></span></nobr></DIV>
<DIV style="position:absolute;top:352;left:368"><nobr><span class="ft16"><b>400</b></span></nobr></DIV>
<DIV style="position:absolute;top:312;left:90"><nobr><span class="ft16"><b>50</b></span></nobr></DIV>
<DIV style="position:absolute;top:280;left:83"><nobr><span class="ft16"><b>100</b></span></nobr></DIV>
<DIV style="position:absolute;top:249;left:83"><nobr><span class="ft16"><b>150</b></span></nobr></DIV>
<DIV style="position:absolute;top:217;left:83"><nobr><span class="ft16"><b>200</b></span></nobr></DIV>
<DIV style="position:absolute;top:186;left:83"><nobr><span class="ft16"><b>250</b></span></nobr></DIV>
<DIV style="position:absolute;top:154;left:83"><nobr><span class="ft16"><b>300</b></span></nobr></DIV>
<DIV style="position:absolute;top:123;left:83"><nobr><span class="ft16"><b>350</b></span></nobr></DIV>
<DIV style="position:absolute;top:91;left:83"><nobr><span class="ft16"><b>400</b></span></nobr></DIV>
<DIV style="position:absolute;top:387;left:81"><nobr><span class="ft9">Figure 5: Scenario of sensor selection for localization<br>using rangese</span></nobr></DIV>
<DIV style="position:absolute;top:403;left:184"><nobr><span class="ft4">nsors.</span></nobr></DIV>
<DIV style="position:absolute;top:403;left:237"><nobr><span class="ft4">Theimagede</span></nobr></DIV>
<DIV style="position:absolute;top:403;left:335"><nobr><span class="ft4">picts theprior</span></nobr></DIV>
<DIV style="position:absolute;top:418;left:81"><nobr><span class="ft9">probability distribution p(x) of thetarget location x.<br>p(x) is zero outside the solid rectangle. The actual<br>target location is (200, 200), denoted by marker +.<br>The circles denote candidate range sensors for se-<br>lection. 100 range sensors are uniformly randomly<br>placed outside the dotted rectangle.</span></nobr></DIV>
<DIV style="position:absolute;top:497;left:351"><nobr><span class="ft4">The gap be-</span></nobr></DIV>
<DIV style="position:absolute;top:512;left:81"><nobr><span class="ft9">tween the solid rectangle and the dotted rectangle<br>is 32.</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:81"><nobr><span class="ft9">candidate sensor is also randomly assigned one of five values<br>of the standard deviation  of the sensing model, namely,<br>2, 4, 8, 16, and 32. 100 candidate sensors are uniformly<br>randomly placed in the vicinity of the prior target location<br>estimation. In order to avoid the difficulties of Gaussian<br>sensing models for DOA sensors and range sensors close to<br>the target, we exclude sensors either outside the study area<br>or within a distance of 32 to the non-zero area of the prior<br>target location distribution p(x).</span></nobr></DIV>
<DIV style="position:absolute;top:716;left:94"><nobr><span class="ft4">The entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:711;left:248"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:722;left:247"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:713;left:258"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:711;left:285"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:716;left:294"><nobr><span class="ft4">and mutual information</span></nobr></DIV>
<DIV style="position:absolute;top:732;left:81"><nobr><span class="ft4">I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:737;left:114"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:732;left:119"><nobr><span class="ft4">) of every candidate sensor are evaluated and plot-</span></nobr></DIV>
<DIV style="position:absolute;top:748;left:81"><nobr><span class="ft4">ted in Fig.</span></nobr></DIV>
<DIV style="position:absolute;top:748;left:163"><nobr><span class="ft4">10.</span></nobr></DIV>
<DIV style="position:absolute;top:748;left:194"><nobr><span class="ft4">The correlation between H</span></nobr></DIV>
<DIV style="position:absolute;top:743;left:366"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:753;left:364"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:744;left:377"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:743;left:405"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:748;left:417"><nobr><span class="ft4">and</span></nobr></DIV>
<DIV style="position:absolute;top:763;left:81"><nobr><span class="ft4">I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:768;left:114"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:763;left:119"><nobr><span class="ft4">) of mixed sensors is very similar to the correlation</span></nobr></DIV>
<DIV style="position:absolute;top:779;left:81"><nobr><span class="ft4">between H</span></nobr></DIV>
<DIV style="position:absolute;top:774;left:147"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:785;left:145"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:776;left:156"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:774;left:182"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:779;left:191"><nobr><span class="ft4">and I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:784;left:251"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:779;left:256"><nobr><span class="ft4">) of sensors with single modal-</span></nobr></DIV>
<DIV style="position:absolute;top:795;left:81"><nobr><span class="ft9">ity. Across various sensing modalities, mutual information<br>I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:815;left:114"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:810;left:119"><nobr><span class="ft4">) increases nearly monotonically with the entropy dif-</span></nobr></DIV>
<DIV style="position:absolute;top:826;left:81"><nobr><span class="ft4">ference H</span></nobr></DIV>
<DIV style="position:absolute;top:821;left:140"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:832;left:139"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:823;left:150"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:821;left:176"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:826;left:181"><nobr><span class="ft4">. Therefore, across various sensing modali-</span></nobr></DIV>
<DIV style="position:absolute;top:842;left:81"><nobr><span class="ft9">ties, the candidate sensor with the maximal entropy differ-<br>ence H</span></nobr></DIV>
<DIV style="position:absolute;top:853;left:125"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:863;left:124"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:854;left:135"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:853;left:162"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:858;left:167"><nobr><span class="ft4">, selected by the proposed heuristic, has the</span></nobr></DIV>
<DIV style="position:absolute;top:873;left:81"><nobr><span class="ft4">maximal mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:293"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:873;left:298"><nobr><span class="ft4">).</span></nobr></DIV>
<DIV style="position:absolute;top:903;left:81"><nobr><span class="ft3"><b>3.4</b></span></nobr></DIV>
<DIV style="position:absolute;top:903;left:121"><nobr><span class="ft3"><b>Computational Complexity</b></span></nobr></DIV>
<DIV style="position:absolute;top:925;left:94"><nobr><span class="ft4">Computational complexity analysis is an important part</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:81"><nobr><span class="ft9">of the evaluation of the heuristic. We will analyze the com-<br>plexity of the heuristic and compare it to the complexity of<br>the mutual-information-based approaches.</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:94"><nobr><span class="ft4">For two-dimensional localization, the target location x is</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:81"><nobr><span class="ft4">two-dimensional. The sensor's view z</span></nobr></DIV>
<DIV style="position:absolute;top:999;left:314"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:1010;left:314"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:327"><nobr><span class="ft4">of the target loca-</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:81"><nobr><span class="ft4">tion x is one-dimensional. The sensor observation z</span></nobr></DIV>
<DIV style="position:absolute;top:1024;left:391"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:400"><nobr><span class="ft4">is one-</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:81"><nobr><span class="ft9">dimensional. We assume that all random variables are grid-<br>ded for numerical computation. Specifically, the area with<br>non-trivial p(x) is gridded into n × n. The interval with</span></nobr></DIV>
<DIV style="position:absolute;top:346;left:816"><nobr><span class="ft21">0</span></nobr></DIV>
<DIV style="position:absolute;top:313;left:816"><nobr><span class="ft21">0.5</span></nobr></DIV>
<DIV style="position:absolute;top:280;left:816"><nobr><span class="ft21">1</span></nobr></DIV>
<DIV style="position:absolute;top:247;left:816"><nobr><span class="ft21">1.5</span></nobr></DIV>
<DIV style="position:absolute;top:215;left:816"><nobr><span class="ft21">2</span></nobr></DIV>
<DIV style="position:absolute;top:182;left:816"><nobr><span class="ft21">2.5</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:816"><nobr><span class="ft21">3</span></nobr></DIV>
<DIV style="position:absolute;top:116;left:816"><nobr><span class="ft21">3.5</span></nobr></DIV>
<DIV style="position:absolute;top:88;left:814"><nobr><span class="ft21">x 10</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:827"><nobr><span class="ft15">-4</span></nobr></DIV>
<DIV style="position:absolute;top:354;left:558"><nobr><span class="ft16"><b>100</b></span></nobr></DIV>
<DIV style="position:absolute;top:354;left:626"><nobr><span class="ft16"><b>200</b></span></nobr></DIV>
<DIV style="position:absolute;top:354;left:695"><nobr><span class="ft16"><b>300</b></span></nobr></DIV>
<DIV style="position:absolute;top:354;left:763"><nobr><span class="ft16"><b>400</b></span></nobr></DIV>
<DIV style="position:absolute;top:313;left:484"><nobr><span class="ft16"><b>50</b></span></nobr></DIV>
<DIV style="position:absolute;top:282;left:477"><nobr><span class="ft16"><b>100</b></span></nobr></DIV>
<DIV style="position:absolute;top:250;left:477"><nobr><span class="ft16"><b>150</b></span></nobr></DIV>
<DIV style="position:absolute;top:219;left:477"><nobr><span class="ft16"><b>200</b></span></nobr></DIV>
<DIV style="position:absolute;top:187;left:477"><nobr><span class="ft16"><b>250</b></span></nobr></DIV>
<DIV style="position:absolute;top:156;left:477"><nobr><span class="ft16"><b>300</b></span></nobr></DIV>
<DIV style="position:absolute;top:124;left:477"><nobr><span class="ft16"><b>350</b></span></nobr></DIV>
<DIV style="position:absolute;top:93;left:477"><nobr><span class="ft16"><b>400</b></span></nobr></DIV>
<DIV style="position:absolute;top:388;left:475"><nobr><span class="ft9">Figure 6: Scenario of sensor selection for localization<br>using TDOA sensors. The image depicts the prior<br>probability distribution p(x) of thetarget location x.<br>p(x) is zero outside the solid rectangle. The actual<br>target location is (200, 200), denoted by marker +.<br>The triangles denote candidate TDOA sensors for<br>selection.</span></nobr></DIV>
<DIV style="position:absolute;top:482;left:553"><nobr><span class="ft4">Every TDOA observation is relative to</span></nobr></DIV>
<DIV style="position:absolute;top:498;left:475"><nobr><span class="ft4">a common reference sensor denoted by marker</span></nobr></DIV>
<DIV style="position:absolute;top:495;left:819"><nobr><span class="ft4">×.</span></nobr></DIV>
<DIV style="position:absolute;top:514;left:475"><nobr><span class="ft9">100 TDOA sensors are uniformly randomly placed<br>outside the dotted rectangle. The gap between the<br>solid rectangle and the dotted rectangle is 10.</span></nobr></DIV>
<DIV style="position:absolute;top:592;left:475"><nobr><span class="ft4">non-trivial p(z</span></nobr></DIV>
<DIV style="position:absolute;top:597;left:562"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:592;left:567"><nobr><span class="ft4">) or p(z</span></nobr></DIV>
<DIV style="position:absolute;top:588;left:613"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:598;left:612"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:592;left:619"><nobr><span class="ft4">) is also gridded into n. We assume</span></nobr></DIV>
<DIV style="position:absolute;top:608;left:475"><nobr><span class="ft9">there are K candidate sensors for selection. K is usually a<br>small number.</span></nobr></DIV>
<DIV style="position:absolute;top:640;left:489"><nobr><span class="ft4">The proposed heuristic evaluates the entropy difference</span></nobr></DIV>
<DIV style="position:absolute;top:655;left:475"><nobr><span class="ft4">H</span></nobr></DIV>
<DIV style="position:absolute;top:650;left:488"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:661;left:487"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:652;left:498"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:650;left:526"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:655;left:537"><nobr><span class="ft4">of all sensors and then selects the one with the</span></nobr></DIV>
<DIV style="position:absolute;top:671;left:475"><nobr><span class="ft4">maximal H</span></nobr></DIV>
<DIV style="position:absolute;top:666;left:544"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:677;left:543"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:668;left:553"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:666;left:578"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:671;left:583"><nobr><span class="ft4">. As shown in (7), p(z</span></nobr></DIV>
<DIV style="position:absolute;top:666;left:715"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:677;left:715"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:671;left:722"><nobr><span class="ft4">) can be computed</span></nobr></DIV>
<DIV style="position:absolute;top:687;left:475"><nobr><span class="ft4">from p(x) with cost O(n</span></nobr></DIV>
<DIV style="position:absolute;top:682;left:629"><nobr><span class="ft11">2</span></nobr></DIV>
<DIV style="position:absolute;top:687;left:636"><nobr><span class="ft4">). As shown in (8), H</span></nobr></DIV>
<DIV style="position:absolute;top:682;left:780"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:692;left:779"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:687;left:793"><nobr><span class="ft4">can be</span></nobr></DIV>
<DIV style="position:absolute;top:702;left:475"><nobr><span class="ft4">computed from p(z</span></nobr></DIV>
<DIV style="position:absolute;top:698;left:590"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:708;left:590"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:702;left:597"><nobr><span class="ft4">) with cost O(n). As shown in (10) and</span></nobr></DIV>
<DIV style="position:absolute;top:718;left:475"><nobr><span class="ft4">(11), H</span></nobr></DIV>
<DIV style="position:absolute;top:713;left:520"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:718;left:529"><nobr><span class="ft4">can be computed from p(z</span></nobr></DIV>
<DIV style="position:absolute;top:723;left:686"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:715;left:690"><nobr><span class="ft4">|x) with cost O(n). The</span></nobr></DIV>
<DIV style="position:absolute;top:734;left:475"><nobr><span class="ft4">cost to compute H</span></nobr></DIV>
<DIV style="position:absolute;top:729;left:588"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:739;left:587"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:730;left:597"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:729;left:622"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:734;left:631"><nobr><span class="ft4">for one candidate sensor is O(n</span></nobr></DIV>
<DIV style="position:absolute;top:729;left:818"><nobr><span class="ft11">2</span></nobr></DIV>
<DIV style="position:absolute;top:734;left:825"><nobr><span class="ft4">).</span></nobr></DIV>
<DIV style="position:absolute;top:749;left:475"><nobr><span class="ft9">Therefore, the total cost for the heuristic to select one out<br>of K candidate sensors is O(n</span></nobr></DIV>
<DIV style="position:absolute;top:760;left:657"><nobr><span class="ft11">2</span></nobr></DIV>
<DIV style="position:absolute;top:765;left:663"><nobr><span class="ft4">).</span></nobr></DIV>
<DIV style="position:absolute;top:781;left:489"><nobr><span class="ft4">The mutual-information-based approaches evaluate the mu-</span></nobr></DIV>
<DIV style="position:absolute;top:797;left:475"><nobr><span class="ft4">tual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:801;left:614"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:797;left:619"><nobr><span class="ft4">) of all sensors and then select the</span></nobr></DIV>
<DIV style="position:absolute;top:812;left:475"><nobr><span class="ft4">one with the maximal I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:817;left:653"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:812;left:658"><nobr><span class="ft4">). As shown in (3), I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:817;left:824"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:812;left:829"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:828;left:475"><nobr><span class="ft4">can be directly computed from p(x) and p(z</span></nobr></DIV>
<DIV style="position:absolute;top:832;left:738"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:824;left:743"><nobr><span class="ft4">|x) with cost of</span></nobr></DIV>
<DIV style="position:absolute;top:844;left:475"><nobr><span class="ft4">O(n</span></nobr></DIV>
<DIV style="position:absolute;top:839;left:500"><nobr><span class="ft11">3</span></nobr></DIV>
<DIV style="position:absolute;top:844;left:506"><nobr><span class="ft4">). Therefore, the total cost to select one out of K can-</span></nobr></DIV>
<DIV style="position:absolute;top:859;left:475"><nobr><span class="ft4">didate sensors is O(n</span></nobr></DIV>
<DIV style="position:absolute;top:854;left:603"><nobr><span class="ft11">3</span></nobr></DIV>
<DIV style="position:absolute;top:859;left:609"><nobr><span class="ft4">). As we mentioned early in Subsect.</span></nobr></DIV>
<DIV style="position:absolute;top:875;left:475"><nobr><span class="ft4">2.1, the computational cost of mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:879;left:824"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:875;left:829"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:891;left:475"><nobr><span class="ft9">could be reduced in some special scenarios. In general, how-<br>ever, the heuristic is computationally much simpler than the<br>mutual-information-based approaches.</span></nobr></DIV>
<DIV style="position:absolute;top:961;left:475"><nobr><span class="ft3"><b>4.</b></span></nobr></DIV>
<DIV style="position:absolute;top:961;left:506"><nobr><span class="ft24"><b>DISCREPANCY BETWEEN HEURISTIC<br>AND MUTUAL INFORMATION</b></span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:489"><nobr><span class="ft4">As shown in Sect. 3, when the mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:1008;left:824"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:829"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:475"><nobr><span class="ft4">is close to 0 bit, the entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:728"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:1025;left:726"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1016;left:737"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:764"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:774"><nobr><span class="ft4">might not</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:475"><nobr><span class="ft9">sort candidate sensors into exactly the same order as the<br>mutual information does. Such discrepancy is caused by the<br>dispersion of the correlation between the entropy difference</span></nobr></DIV>
<DIV style="position:absolute;top:1127;left:452"><nobr><span class="ft8">41</span></nobr></DIV>
</DIV>
<!-- Page 7 -->
<a name="7"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft25{font-size:11px;font-family:Helvetica;color:#000000;}
	.ft26{font-size:11px;font-family:Symbol;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="84007.png" alt="background image">
<DIV style="position:absolute;top:356;left:94"><nobr><span class="ft25"><b>-2</b></span></nobr></DIV>
<DIV style="position:absolute;top:356;left:141"><nobr><span class="ft25"><b>-1</b></span></nobr></DIV>
<DIV style="position:absolute;top:356;left:196"><nobr><span class="ft25"><b>0</b></span></nobr></DIV>
<DIV style="position:absolute;top:356;left:243"><nobr><span class="ft25"><b>1</b></span></nobr></DIV>
<DIV style="position:absolute;top:356;left:290"><nobr><span class="ft25"><b>2</b></span></nobr></DIV>
<DIV style="position:absolute;top:356;left:337"><nobr><span class="ft25"><b>3</b></span></nobr></DIV>
<DIV style="position:absolute;top:356;left:384"><nobr><span class="ft25"><b>4</b></span></nobr></DIV>
<DIV style="position:absolute;top:356;left:431"><nobr><span class="ft25"><b>5</b></span></nobr></DIV>
<DIV style="position:absolute;top:346;left:96"><nobr><span class="ft25"><b>0</b></span></nobr></DIV>
<DIV style="position:absolute;top:294;left:96"><nobr><span class="ft25"><b>1</b></span></nobr></DIV>
<DIV style="position:absolute;top:242;left:96"><nobr><span class="ft25"><b>2</b></span></nobr></DIV>
<DIV style="position:absolute;top:190;left:96"><nobr><span class="ft25"><b>3</b></span></nobr></DIV>
<DIV style="position:absolute;top:139;left:96"><nobr><span class="ft25"><b>4</b></span></nobr></DIV>
<DIV style="position:absolute;top:87;left:96"><nobr><span class="ft25"><b>5</b></span></nobr></DIV>
<DIV style="position:absolute;top:369;left:197"><nobr><span class="ft25"><b>Entropy difference (bit)</b></span></nobr></DIV>
<DIV style="position:absolute;top:285;left:93"><nobr><span class="ft25"><b>Mutual information (bit)</b></span></nobr></DIV>
<DIV style="position:absolute;top:96;left:146"><nobr><span class="ft26"></span></nobr></DIV>
<DIV style="position:absolute;top:100;left:154"><nobr><span class="ft8"> = 32</span></nobr></DIV>
<DIV style="position:absolute;top:114;left:146"><nobr><span class="ft26"></span></nobr></DIV>
<DIV style="position:absolute;top:117;left:154"><nobr><span class="ft8"> = 16</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:146"><nobr><span class="ft26"></span></nobr></DIV>
<DIV style="position:absolute;top:135;left:154"><nobr><span class="ft8"> = 8 </span></nobr></DIV>
<DIV style="position:absolute;top:148;left:146"><nobr><span class="ft26"></span></nobr></DIV>
<DIV style="position:absolute;top:152;left:154"><nobr><span class="ft8"> = 4 </span></nobr></DIV>
<DIV style="position:absolute;top:165;left:146"><nobr><span class="ft26"></span></nobr></DIV>
<DIV style="position:absolute;top:169;left:154"><nobr><span class="ft8"> = 2 </span></nobr></DIV>
<DIV style="position:absolute;top:403;left:81"><nobr><span class="ft4">Figure7: Mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:408;left:324"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:403;left:329"><nobr><span class="ft4">) vs entropy dif-</span></nobr></DIV>
<DIV style="position:absolute;top:419;left:81"><nobr><span class="ft4">ference H</span></nobr></DIV>
<DIV style="position:absolute;top:414;left:149"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:424;left:148"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:415;left:160"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:414;left:187"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:419;left:199"><nobr><span class="ft4">of range senors. Each symbol de-</span></nobr></DIV>
<DIV style="position:absolute;top:434;left:81"><nobr><span class="ft4">notes (H</span></nobr></DIV>
<DIV style="position:absolute;top:430;left:140"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:440;left:139"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:431;left:149"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:430;left:175"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:434;left:180"><nobr><span class="ft4">, I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:220"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:434;left:224"><nobr><span class="ft4">)) pair evaluated for one candi-</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:81"><nobr><span class="ft9">date sensor. The prior target location distribution<br>and the candidate sensor placements are shown in<br>Fig. 5. Five cases with different standard deviation<br> of Gaussian sensing models are studied. In each<br>case, all candidate sensors are assumed to have the<br>same  value.</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:81"><nobr><span class="ft4">H</span></nobr></DIV>
<DIV style="position:absolute;top:570;left:93"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:581;left:92"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:572;left:102"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:570;left:128"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:137"><nobr><span class="ft4">and the mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:342"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:347"><nobr><span class="ft4">) when the mu-</span></nobr></DIV>
<DIV style="position:absolute;top:591;left:81"><nobr><span class="ft9">tual information is small. In this Sect., we examine such<br>correlation dispersion and evaluate its impact on the dis-<br>crepancy of sensor selection decisions of the entropy-based<br>heuristic and the mutual information based approaches.</span></nobr></DIV>
<DIV style="position:absolute;top:668;left:81"><nobr><span class="ft3"><b>4.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:668;left:121"><nobr><span class="ft3"><b>Dispersion</b></span></nobr></DIV>
<DIV style="position:absolute;top:690;left:94"><nobr><span class="ft4">In this Subsect., we describe the dispersion of the cor-</span></nobr></DIV>
<DIV style="position:absolute;top:706;left:81"><nobr><span class="ft4">relation between the entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:701;left:342"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:711;left:341"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:702;left:353"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:701;left:380"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:706;left:392"><nobr><span class="ft4">and the</span></nobr></DIV>
<DIV style="position:absolute;top:722;left:81"><nobr><span class="ft4">mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:726;left:235"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:722;left:240"><nobr><span class="ft4">) when the mutual information is</span></nobr></DIV>
<DIV style="position:absolute;top:737;left:81"><nobr><span class="ft9">small. We also examine possible sources for such correlation<br>dispersion.</span></nobr></DIV>
<DIV style="position:absolute;top:768;left:94"><nobr><span class="ft4">Close examination on the convex part of the mutual in-</span></nobr></DIV>
<DIV style="position:absolute;top:784;left:81"><nobr><span class="ft9">formation vs. entropy difference curve in Fig. 7 and Fig. 8<br>reveals that the correlation between the mutual information<br>I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:820;left:114"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:816;left:119"><nobr><span class="ft4">) and the entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:811;left:309"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:821;left:308"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:812;left:319"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:811;left:346"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:816;left:356"><nobr><span class="ft4">is not strictly</span></nobr></DIV>
<DIV style="position:absolute;top:831;left:81"><nobr><span class="ft9">monotonic. Instead, there is obvious dispersion of the cor-<br>relation. The convex part corresponds to the situation in<br>which candidate sensors are not very informative because<br>the mutual information between the target location distribu-<br>tion and the sensor observation is close to 0 bit. In another<br>words, when candidate sensors are not very informative, the<br>entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:921;left:204"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:931;left:203"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:922;left:212"><nobr><span class="ft4">-H</span></nobr></DIV>
<DIV style="position:absolute;top:921;left:237"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:245"><nobr><span class="ft4">might not sort candidate sensors</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:81"><nobr><span class="ft4">into the same order as the mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:946;left:395"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:400"><nobr><span class="ft4">) does.</span></nobr></DIV>
<DIV style="position:absolute;top:957;left:81"><nobr><span class="ft9">Given a set of candidate sensors whose observation could<br>only reduce a little amount of uncertainty of the target lo-<br>cation distribution, the sensor selected on the basis of the<br>maximum entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:999;left:273"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:1010;left:272"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1001;left:283"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:999;left:311"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:321"><nobr><span class="ft4">might not have the</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:81"><nobr><span class="ft4">maximum mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:1024;left:304"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:309"><nobr><span class="ft4">). Thus, there might</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:81"><nobr><span class="ft9">be discrepancy between the sensor selection decision of the<br>entropy-based heuristic and that of the mutual information<br>based approaches if no candidate sensor is very informative.</span></nobr></DIV>
<DIV style="position:absolute;top:356;left:489"><nobr><span class="ft25"><b>-4</b></span></nobr></DIV>
<DIV style="position:absolute;top:356;left:554"><nobr><span class="ft25"><b>-2</b></span></nobr></DIV>
<DIV style="position:absolute;top:356;left:628"><nobr><span class="ft25"><b>0</b></span></nobr></DIV>
<DIV style="position:absolute;top:356;left:694"><nobr><span class="ft25"><b>2</b></span></nobr></DIV>
<DIV style="position:absolute;top:356;left:759"><nobr><span class="ft25"><b>4</b></span></nobr></DIV>
<DIV style="position:absolute;top:356;left:825"><nobr><span class="ft25"><b>6</b></span></nobr></DIV>
<DIV style="position:absolute;top:346;left:491"><nobr><span class="ft25"><b>0</b></span></nobr></DIV>
<DIV style="position:absolute;top:303;left:491"><nobr><span class="ft25"><b>1</b></span></nobr></DIV>
<DIV style="position:absolute;top:260;left:491"><nobr><span class="ft25"><b>2</b></span></nobr></DIV>
<DIV style="position:absolute;top:216;left:491"><nobr><span class="ft25"><b>3</b></span></nobr></DIV>
<DIV style="position:absolute;top:173;left:491"><nobr><span class="ft25"><b>4</b></span></nobr></DIV>
<DIV style="position:absolute;top:130;left:491"><nobr><span class="ft25"><b>5</b></span></nobr></DIV>
<DIV style="position:absolute;top:87;left:491"><nobr><span class="ft25"><b>6</b></span></nobr></DIV>
<DIV style="position:absolute;top:369;left:592"><nobr><span class="ft25"><b>Entropy difference (bit)</b></span></nobr></DIV>
<DIV style="position:absolute;top:285;left:487"><nobr><span class="ft25"><b>Mutual information (bit)</b></span></nobr></DIV>
<DIV style="position:absolute;top:96;left:541"><nobr><span class="ft26"></span></nobr></DIV>
<DIV style="position:absolute;top:100;left:549"><nobr><span class="ft8"> = 32</span></nobr></DIV>
<DIV style="position:absolute;top:114;left:541"><nobr><span class="ft26"></span></nobr></DIV>
<DIV style="position:absolute;top:117;left:549"><nobr><span class="ft8"> = 16</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:541"><nobr><span class="ft26"></span></nobr></DIV>
<DIV style="position:absolute;top:135;left:549"><nobr><span class="ft8"> = 8 </span></nobr></DIV>
<DIV style="position:absolute;top:148;left:541"><nobr><span class="ft26"></span></nobr></DIV>
<DIV style="position:absolute;top:152;left:549"><nobr><span class="ft8"> = 4 </span></nobr></DIV>
<DIV style="position:absolute;top:165;left:541"><nobr><span class="ft26"></span></nobr></DIV>
<DIV style="position:absolute;top:169;left:549"><nobr><span class="ft8"> = 2 </span></nobr></DIV>
<DIV style="position:absolute;top:403;left:475"><nobr><span class="ft4">Figure8: Mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:408;left:719"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:403;left:723"><nobr><span class="ft4">) vs entropy dif-</span></nobr></DIV>
<DIV style="position:absolute;top:419;left:475"><nobr><span class="ft4">ference H</span></nobr></DIV>
<DIV style="position:absolute;top:414;left:543"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:424;left:542"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:415;left:553"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:414;left:580"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:419;left:590"><nobr><span class="ft4">of TDOA senors. Each symbol de-</span></nobr></DIV>
<DIV style="position:absolute;top:434;left:475"><nobr><span class="ft4">notes (H</span></nobr></DIV>
<DIV style="position:absolute;top:430;left:535"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:440;left:534"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:431;left:544"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:430;left:570"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:434;left:575"><nobr><span class="ft4">, I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:614"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:434;left:619"><nobr><span class="ft4">)) pair evaluated for one candi-</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:475"><nobr><span class="ft4">datese</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:525"><nobr><span class="ft4">nsor. Theprior targe</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:678"><nobr><span class="ft4">t location distribution</span></nobr></DIV>
<DIV style="position:absolute;top:466;left:475"><nobr><span class="ft9">and the candidate sensor placements are shown in<br>Fig. 6. Five cases with different standard deviation<br> of Gaussian sensing models are studied. In each<br>case, all candidate sensors are assumed to have the<br>same  value.</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:489"><nobr><span class="ft4">There might be multiple causes of such correlation disper-</span></nobr></DIV>
<DIV style="position:absolute;top:591;left:475"><nobr><span class="ft4">sion between the entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:586;left:701"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:597;left:700"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:588;left:709"><nobr><span class="ft4">-H</span></nobr></DIV>
<DIV style="position:absolute;top:586;left:734"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:591;left:742"><nobr><span class="ft4">and the mutual</span></nobr></DIV>
<DIV style="position:absolute;top:607;left:475"><nobr><span class="ft4">information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:611;left:583"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:607;left:588"><nobr><span class="ft4">). As pointed out in Subsect. 2.3, the en-</span></nobr></DIV>
<DIV style="position:absolute;top:623;left:475"><nobr><span class="ft4">tropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:618;left:585"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:628;left:584"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:619;left:592"><nobr><span class="ft4">-H</span></nobr></DIV>
<DIV style="position:absolute;top:618;left:617"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:623;left:626"><nobr><span class="ft4">can be viewed as an approximation</span></nobr></DIV>
<DIV style="position:absolute;top:638;left:475"><nobr><span class="ft4">of the mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:643;left:672"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:638;left:677"><nobr><span class="ft4">). Thus, the order of sen-</span></nobr></DIV>
<DIV style="position:absolute;top:654;left:475"><nobr><span class="ft4">sors sorted by the entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:649;left:708"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:659;left:707"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:650;left:716"><nobr><span class="ft4">-H</span></nobr></DIV>
<DIV style="position:absolute;top:649;left:741"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:654;left:750"><nobr><span class="ft4">is intrinsically</span></nobr></DIV>
<DIV style="position:absolute;top:669;left:475"><nobr><span class="ft4">an approximation of that by the mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:674;left:820"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:669;left:825"><nobr><span class="ft4">).</span></nobr></DIV>
<DIV style="position:absolute;top:685;left:475"><nobr><span class="ft9">In practice, the discretization of the state space of the tar-<br>get location random variable and the sensor view random<br>variable might also introduce inaccuracy into the evaluation<br>of H</span></nobr></DIV>
<DIV style="position:absolute;top:727;left:505"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:738;left:503"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:732;left:511"><nobr><span class="ft4">. Besides, as shown in (10) and (11), the maximum</span></nobr></DIV>
<DIV style="position:absolute;top:748;left:475"><nobr><span class="ft9">likelihood estimate of the target location is used to approxi-<br>mate the actual target location when evaluating the entropy<br>of the sensing model for the actual target location.</span></nobr></DIV>
<DIV style="position:absolute;top:809;left:475"><nobr><span class="ft3"><b>4.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:809;left:515"><nobr><span class="ft3"><b>Impact</b></span></nobr></DIV>
<DIV style="position:absolute;top:831;left:489"><nobr><span class="ft4">In this Subsect., we examine the impact of the dispersion</span></nobr></DIV>
<DIV style="position:absolute;top:847;left:475"><nobr><span class="ft4">of the correlation between the entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:842;left:792"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:853;left:791"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:844;left:802"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:842;left:829"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:863;left:475"><nobr><span class="ft4">and the mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:867;left:680"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:863;left:685"><nobr><span class="ft4">) when the mutual infor-</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:475"><nobr><span class="ft9">mation is small. The analysis shows that such correlation<br>dispersion causes very little degradation to the quality of<br>sensor selection decision of the entropy-based heuristic.</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:489"><nobr><span class="ft4">As shown by the convex part of the mutual information</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:475"><nobr><span class="ft9">vs. entropy difference curve in Fig. 7 and Fig. 8, there is<br>dispersion of the correlation between the entropy difference<br>H</span></nobr></DIV>
<DIV style="position:absolute;top:968;left:488"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:978;left:487"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:969;left:495"><nobr><span class="ft4">-H</span></nobr></DIV>
<DIV style="position:absolute;top:968;left:518"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:973;left:527"><nobr><span class="ft4">and the mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:977;left:728"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:973;left:732"><nobr><span class="ft4">) when candidate</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:475"><nobr><span class="ft9">sensors are not very informative. We model such dispersion<br>using a uniform distribution bounded by a parallelogram il-<br>lustrated in Fig. 11. A candidate sensor could assume any<br>position (H</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:546"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:545"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:557"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:583"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:588"><nobr><span class="ft4">, I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:1040;left:631"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:636"><nobr><span class="ft4">)) within the parallelogram with</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:475"><nobr><span class="ft9">uniform probability. As shown in Fig. 11, the geometry of<br>the parallelogram is defined by parameters a, b and c. a</span></nobr></DIV>
<DIV style="position:absolute;top:1127;left:452"><nobr><span class="ft8">42</span></nobr></DIV>
</DIV>
<!-- Page 8 -->
<a name="8"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft27{font-size:11px;line-height:15px;font-family:Helvetica;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="84008.png" alt="background image">
<DIV style="position:absolute;top:346;left:422"><nobr><span class="ft21">0</span></nobr></DIV>
<DIV style="position:absolute;top:309;left:422"><nobr><span class="ft21">0.2</span></nobr></DIV>
<DIV style="position:absolute;top:273;left:422"><nobr><span class="ft21">0.4</span></nobr></DIV>
<DIV style="position:absolute;top:236;left:422"><nobr><span class="ft21">0.6</span></nobr></DIV>
<DIV style="position:absolute;top:199;left:422"><nobr><span class="ft21">0.8</span></nobr></DIV>
<DIV style="position:absolute;top:163;left:422"><nobr><span class="ft21">1</span></nobr></DIV>
<DIV style="position:absolute;top:126;left:422"><nobr><span class="ft21">1.2</span></nobr></DIV>
<DIV style="position:absolute;top:88;left:419"><nobr><span class="ft21">x 10</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:433"><nobr><span class="ft15">-4</span></nobr></DIV>
<DIV style="position:absolute;top:354;left:164"><nobr><span class="ft16"><b>100</b></span></nobr></DIV>
<DIV style="position:absolute;top:354;left:232"><nobr><span class="ft16"><b>200</b></span></nobr></DIV>
<DIV style="position:absolute;top:354;left:300"><nobr><span class="ft16"><b>300</b></span></nobr></DIV>
<DIV style="position:absolute;top:354;left:368"><nobr><span class="ft16"><b>400</b></span></nobr></DIV>
<DIV style="position:absolute;top:313;left:90"><nobr><span class="ft16"><b>50</b></span></nobr></DIV>
<DIV style="position:absolute;top:282;left:83"><nobr><span class="ft16"><b>100</b></span></nobr></DIV>
<DIV style="position:absolute;top:250;left:83"><nobr><span class="ft16"><b>150</b></span></nobr></DIV>
<DIV style="position:absolute;top:219;left:83"><nobr><span class="ft16"><b>200</b></span></nobr></DIV>
<DIV style="position:absolute;top:187;left:83"><nobr><span class="ft16"><b>250</b></span></nobr></DIV>
<DIV style="position:absolute;top:156;left:83"><nobr><span class="ft16"><b>300</b></span></nobr></DIV>
<DIV style="position:absolute;top:124;left:83"><nobr><span class="ft16"><b>350</b></span></nobr></DIV>
<DIV style="position:absolute;top:93;left:83"><nobr><span class="ft16"><b>400</b></span></nobr></DIV>
<DIV style="position:absolute;top:388;left:81"><nobr><span class="ft9">Figure 9: Scenario of sensor selection for localiza-<br>tion using sensors with various modalities. The im-<br>agedepicts theprior probability distribution p(x) of<br>thetarge</span></nobr></DIV>
<DIV style="position:absolute;top:435;left:145"><nobr><span class="ft4">t location x. p(x) is zero outside the solid</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:81"><nobr><span class="ft9">rectangle. The actual target location is (200, 200),<br>denoted by marker +. The squares, the circles, and<br>the triangles denote DOA sensors, range sensors and<br>TDOA sensors respectively. Every TDOA observa-<br>tion is relative to a common reference sensor de-<br>noted by marker</span></nobr></DIV>
<DIV style="position:absolute;top:526;left:200"><nobr><span class="ft4">×. Each sensor is randomly chosen</span></nobr></DIV>
<DIV style="position:absolute;top:545;left:81"><nobr><span class="ft4">to bea DOA se</span></nobr></DIV>
<DIV style="position:absolute;top:545;left:198"><nobr><span class="ft4">nsor, a rangese</span></nobr></DIV>
<DIV style="position:absolute;top:545;left:314"><nobr><span class="ft4">nsor, or a TDOA</span></nobr></DIV>
<DIV style="position:absolute;top:561;left:81"><nobr><span class="ft9">sensor. Each sensor is also randomly assigned one<br>of five values of the standard deviation  of Gaus-<br>sian sensing models, namely, 2, 4, 8, 16, and 32. The<br>sizeof a symbol indicates themagnitudeof . 100<br>sensors of various sensing modalities and  values<br>areuniformly randomly place</span></nobr></DIV>
<DIV style="position:absolute;top:639;left:292"><nobr><span class="ft4">d outsidethedotte</span></nobr></DIV>
<DIV style="position:absolute;top:639;left:430"><nobr><span class="ft4">d</span></nobr></DIV>
<DIV style="position:absolute;top:655;left:81"><nobr><span class="ft9">rectangle. The gap between the solid rectangle and<br>the dotted rectangle is 32.</span></nobr></DIV>
<DIV style="position:absolute;top:721;left:81"><nobr><span class="ft4">is the variation scope of entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:717;left:354"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:727;left:353"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:718;left:363"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:717;left:390"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:722;left:399"><nobr><span class="ft4">among</span></nobr></DIV>
<DIV style="position:absolute;top:737;left:81"><nobr><span class="ft9">the set of candidate sensors. c indicates the variation scope<br>of the mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:757;left:279"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:753;left:283"><nobr><span class="ft4">) among the set of candi-</span></nobr></DIV>
<DIV style="position:absolute;top:768;left:81"><nobr><span class="ft9">date sensors. b describes the magnitude of dispersion of the<br>correlation between the entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:779;left:350"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:790;left:349"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:781;left:359"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:779;left:384"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:784;left:394"><nobr><span class="ft4">and the</span></nobr></DIV>
<DIV style="position:absolute;top:800;left:81"><nobr><span class="ft4">mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:805;left:234"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:800;left:239"><nobr><span class="ft4">). Although the bounded uniform</span></nobr></DIV>
<DIV style="position:absolute;top:816;left:81"><nobr><span class="ft9">distribution is not accurate, it captures the major features<br>of the correlation dispersion revealed by simulations in Sect.<br>3. We choose this dispersion model for simplicity. As the<br>first order approximation, the simple dispersion model does<br>help to reveal some major characteristics of the impact of<br>the correlation dispersion on the heuristics-based sensor se-<br>lection.</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:94"><nobr><span class="ft4">A typical dispersion scenario is illustrated in Fig.</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:422"><nobr><span class="ft4">11.</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:81"><nobr><span class="ft4">The mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:946;left:265"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:269"><nobr><span class="ft4">) of candidate sensors varies</span></nobr></DIV>
<DIV style="position:absolute;top:957;left:81"><nobr><span class="ft9">from 0 bit to 1 bit. Correspondingly, the entropy difference<br>H</span></nobr></DIV>
<DIV style="position:absolute;top:968;left:93"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:978;left:92"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:969;left:103"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:968;left:129"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:973;left:138"><nobr><span class="ft4">of candidate sensors changes from</span></nobr></DIV>
<DIV style="position:absolute;top:969;left:347"><nobr><span class="ft4">-2 bit to 0 bit.</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:81"><nobr><span class="ft4">For any value of the entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:983;left:324"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:994;left:323"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:985;left:332"><nobr><span class="ft4">-H</span></nobr></DIV>
<DIV style="position:absolute;top:983;left:356"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:361"><nobr><span class="ft4">, the disperse</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:81"><nobr><span class="ft4">of the mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:1008;left:271"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:275"><nobr><span class="ft4">) is 0.1 bit. Given the above</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:81"><nobr><span class="ft9">scenario, we run 10, 000 simulations. In each simulation, 8<br>candidate sensors randomly assume their (H</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:346"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:345"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:354"><nobr><span class="ft4">-H</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:378"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:383"><nobr><span class="ft4">, I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:1040;left:424"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:429"><nobr><span class="ft4">))</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:81"><nobr><span class="ft9">pairs within the specified dispersion range. In each simula-<br>tion, we identify both the sensor with the maximum entropy</span></nobr></DIV>
<DIV style="position:absolute;top:356;left:489"><nobr><span class="ft25"><b>-2</b></span></nobr></DIV>
<DIV style="position:absolute;top:356;left:579"><nobr><span class="ft25"><b>0</b></span></nobr></DIV>
<DIV style="position:absolute;top:356;left:661"><nobr><span class="ft25"><b>2</b></span></nobr></DIV>
<DIV style="position:absolute;top:356;left:743"><nobr><span class="ft25"><b>4</b></span></nobr></DIV>
<DIV style="position:absolute;top:356;left:825"><nobr><span class="ft25"><b>6</b></span></nobr></DIV>
<DIV style="position:absolute;top:346;left:491"><nobr><span class="ft25"><b>0</b></span></nobr></DIV>
<DIV style="position:absolute;top:303;left:491"><nobr><span class="ft25"><b>1</b></span></nobr></DIV>
<DIV style="position:absolute;top:260;left:491"><nobr><span class="ft25"><b>2</b></span></nobr></DIV>
<DIV style="position:absolute;top:216;left:491"><nobr><span class="ft25"><b>3</b></span></nobr></DIV>
<DIV style="position:absolute;top:173;left:491"><nobr><span class="ft25"><b>4</b></span></nobr></DIV>
<DIV style="position:absolute;top:130;left:491"><nobr><span class="ft25"><b>5</b></span></nobr></DIV>
<DIV style="position:absolute;top:87;left:491"><nobr><span class="ft25"><b>6</b></span></nobr></DIV>
<DIV style="position:absolute;top:369;left:592"><nobr><span class="ft25"><b>Entropy difference (bit)</b></span></nobr></DIV>
<DIV style="position:absolute;top:285;left:487"><nobr><span class="ft25"><b>Mutual information (bit)</b></span></nobr></DIV>
<DIV style="position:absolute;top:100;left:541"><nobr><span class="ft27">TDOA sensor <br>DOA sensor  <br>range sensor</span></nobr></DIV>
<DIV style="position:absolute;top:403;left:475"><nobr><span class="ft4">Figure10: Mutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:408;left:741"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:403;left:745"><nobr><span class="ft4">) vs entropy</span></nobr></DIV>
<DIV style="position:absolute;top:419;left:475"><nobr><span class="ft4">difference H</span></nobr></DIV>
<DIV style="position:absolute;top:414;left:562"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:424;left:561"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:415;left:573"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:414;left:601"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:419;left:613"><nobr><span class="ft4">of mixed senors.</span></nobr></DIV>
<DIV style="position:absolute;top:419;left:744"><nobr><span class="ft4">Each symbol</span></nobr></DIV>
<DIV style="position:absolute;top:434;left:475"><nobr><span class="ft4">denotes (H</span></nobr></DIV>
<DIV style="position:absolute;top:430;left:551"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:440;left:550"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:431;left:559"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:430;left:584"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:434;left:590"><nobr><span class="ft4">, I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:629"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:434;left:634"><nobr><span class="ft4">)) pair evaluated for one can-</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:475"><nobr><span class="ft9">didate sensor. The prior target location distribution<br>and the candidate sensor placements are shown in<br>Fig. 9.</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:475"><nobr><span class="ft4">difference H</span></nobr></DIV>
<DIV style="position:absolute;top:528;left:550"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:539;left:549"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:530;left:560"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:528;left:586"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:596"><nobr><span class="ft4">and the sensor with the maximum mu-</span></nobr></DIV>
<DIV style="position:absolute;top:549;left:475"><nobr><span class="ft4">tual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:553;left:615"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:549;left:620"><nobr><span class="ft4">). With 87.8% chance, the sensor</span></nobr></DIV>
<DIV style="position:absolute;top:565;left:475"><nobr><span class="ft9">selected by the entropy-based heuristic also has the maxi-<br>mum mutual information. Even when the heuristic fails to<br>select the sensor of the maximum mutual information, the<br>mutual information of the selected sensor is on average only<br>about 0.026 bit less than the maximum mutual information.<br>Overall, the mutual information of the sensor selected by the<br>entropy-based heuristic is about 0.026×(1-87.8%) = 0.0032<br>bit less than the maximum mutual information. Therefore,<br>most of the time, the correlation dispersion does not cause<br>discrepancy of the sensor selection decisions between the<br>entropy-based heuristic and the mutual information based<br>approaches. Over all, the entropy-based heuristic introduces<br>very little degradation to the quality of the sensor select de-<br>cision even when candidate sensors are not very informative.</span></nobr></DIV>
<DIV style="position:absolute;top:784;left:489"><nobr><span class="ft4">We have analyzed the impact of the correlation disper-</span></nobr></DIV>
<DIV style="position:absolute;top:800;left:475"><nobr><span class="ft9">sion for different configurations of a, b, c, and the number<br>of candidate sensors. In table 1 , a = 2 bit, b = 0.1 bit and<br>c = 1 bit are fixed. We only change the number of candi-<br>date sensors. The chance for the heuristic to successfully<br>select the sensor with the maximum mutual information de-<br>creases as the number of candidate sensors increases. When<br>the heuristic fails to select the sensor with the maximum<br>mutual information, the degradation of sensor selection de-<br>cision based on the heuristic compared to that based on<br>the mutual information does not change with the number of<br>candidate sensors. Thus, the overall degradation of sensor<br>selection decision based on the heuristic compared to that<br>based on mutual information also increases as the number<br>of candidate sensors increases.</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:489"><nobr><span class="ft4">In table 2 , a = 2 bit and c = 1 bit are fixed and the</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:475"><nobr><span class="ft4">number of candidate sensors are fixed to be 8.</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:782"><nobr><span class="ft4">We only</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:475"><nobr><span class="ft9">change the dispersion width b. The chance for the heuristic<br>to successfully select the sensor with the maximum mutual</span></nobr></DIV>
<DIV style="position:absolute;top:1127;left:452"><nobr><span class="ft8">43</span></nobr></DIV>
</DIV>
<!-- Page 9 -->
<a name="9"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft28{font-size:7px;font-family:Helvetica;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="84009.png" alt="background image">
<DIV style="position:absolute;top:330;left:103"><nobr><span class="ft16"><b>-2</b></span></nobr></DIV>
<DIV style="position:absolute;top:330;left:173"><nobr><span class="ft16"><b>-1.5</b></span></nobr></DIV>
<DIV style="position:absolute;top:330;left:252"><nobr><span class="ft16"><b>-1</b></span></nobr></DIV>
<DIV style="position:absolute;top:330;left:322"><nobr><span class="ft16"><b>-0.5</b></span></nobr></DIV>
<DIV style="position:absolute;top:330;left:408"><nobr><span class="ft16"><b>0</b></span></nobr></DIV>
<DIV style="position:absolute;top:321;left:105"><nobr><span class="ft16"><b>0</b></span></nobr></DIV>
<DIV style="position:absolute;top:263;left:95"><nobr><span class="ft16"><b>0.5</b></span></nobr></DIV>
<DIV style="position:absolute;top:204;left:105"><nobr><span class="ft16"><b>1</b></span></nobr></DIV>
<DIV style="position:absolute;top:145;left:95"><nobr><span class="ft16"><b>1.5</b></span></nobr></DIV>
<DIV style="position:absolute;top:86;left:105"><nobr><span class="ft16"><b>2</b></span></nobr></DIV>
<DIV style="position:absolute;top:342;left:197"><nobr><span class="ft16"><b>Entropy difference (bit)</b></span></nobr></DIV>
<DIV style="position:absolute;top:266;left:92"><nobr><span class="ft16"><b>Mutual information (bit)</b></span></nobr></DIV>
<DIV style="position:absolute;top:200;left:418"><nobr><span class="ft28"><b>b </b></span></nobr></DIV>
<DIV style="position:absolute;top:312;left:260"><nobr><span class="ft28"><b>a </b></span></nobr></DIV>
<DIV style="position:absolute;top:265;left:427"><nobr><span class="ft28"><b>c </b></span></nobr></DIV>
<DIV style="position:absolute;top:375;left:81"><nobr><span class="ft9">Figure 11: Discrepancy between the entropy-based<br>sensor selection heuristic and the mutual informa-<br>tion based approaches when candidate sensors are<br>not very informative. The dispersion of the corre-<br>lation between the entropy difference H</span></nobr></DIV>
<DIV style="position:absolute;top:433;left:365"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:444;left:364"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:435;left:375"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:433;left:402"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:438;left:414"><nobr><span class="ft4">and</span></nobr></DIV>
<DIV style="position:absolute;top:454;left:81"><nobr><span class="ft4">themutual information I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:458;left:282"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:454;left:287"><nobr><span class="ft4">) is modeled by a uni-</span></nobr></DIV>
<DIV style="position:absolute;top:470;left:81"><nobr><span class="ft9">form distribution bounded by a parallelogram. The<br>geometry of the parallelogram is defined by param-<br>eters a, b and c. Candidate sensors are denoted by<br>marker</span></nobr></DIV>
<DIV style="position:absolute;top:513;left:136"><nobr><span class="ft4">× whosecoordinates are(H</span></nobr></DIV>
<DIV style="position:absolute;top:512;left:333"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:522;left:332"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:513;left:343"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:512;left:370"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:516;left:375"><nobr><span class="ft4">, I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:521;left:419"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:516;left:423"><nobr><span class="ft4">)).</span></nobr></DIV>
<DIV style="position:absolute;top:532;left:81"><nobr><span class="ft9">The entropy-based heuristic selects the rightmost<br>sensor, which has the maximum entropy difference<br>H</span></nobr></DIV>
<DIV style="position:absolute;top:559;left:93"><nobr><span class="ft11">v</span></nobr></DIV>
<DIV style="position:absolute;top:569;left:92"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:560;left:104"><nobr><span class="ft4">- H</span></nobr></DIV>
<DIV style="position:absolute;top:559;left:131"><nobr><span class="ft11">si</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:143"><nobr><span class="ft4">and is enclosed by a square marker. The</span></nobr></DIV>
<DIV style="position:absolute;top:579;left:81"><nobr><span class="ft9">mutual information based approaches selects the top<br>sensor, which has the maximum mutual information<br>I(x; z</span></nobr></DIV>
<DIV style="position:absolute;top:615;left:114"><nobr><span class="ft11">i</span></nobr></DIV>
<DIV style="position:absolute;top:611;left:119"><nobr><span class="ft4">) and is enclosed by a diamond-shaped marker.</span></nobr></DIV>
<DIV style="position:absolute;top:626;left:81"><nobr><span class="ft9">The above two selected sensors might not be the<br>same. In the scenario of this figure, a = 2 bits, b = 0.1<br>bit, c = 1 bit, and 8 candidatesensors areavailable<br>for selection.</span></nobr></DIV>
<DIV style="position:absolute;top:719;left:81"><nobr><span class="ft9">information decreases as the dispersion width b increases.<br>When the heuristic fails to select the sensor with the max-<br>imum mutual information, the degradation of sensor selec-<br>tion decision based on the heuristic compared to that based<br>on the mutual information increases as the dispersion width<br>b increases. Thus, the overall degradation of sensor selection<br>decision based on the heuristic compared to that based on<br>mutual information also increases as the dispersion width b<br>increases.</span></nobr></DIV>
<DIV style="position:absolute;top:860;left:94"><nobr><span class="ft4">In table 3 , a = 2 bit and b = 0.1 bit are fixed and</span></nobr></DIV>
<DIV style="position:absolute;top:875;left:81"><nobr><span class="ft4">the number of candidate sensors are fixed to be 8.</span></nobr></DIV>
<DIV style="position:absolute;top:875;left:420"><nobr><span class="ft4">We</span></nobr></DIV>
<DIV style="position:absolute;top:891;left:81"><nobr><span class="ft9">only change the mutual information variation scope c. The<br>chance for the heuristic to successfully select the sensor with<br>the maximum mutual information increases as the mutual<br>information variation scope c increases. When the heuristic</span></nobr></DIV>
<DIV style="position:absolute;top:995;left:88"><nobr><span class="ft4">Table 1: Impact Change with Number of Sensors</span></nobr></DIV>
<DIV style="position:absolute;top:1011;left:89"><nobr><span class="ft4">Number of Candidate Sensors</span></nobr></DIV>
<DIV style="position:absolute;top:1011;left:301"><nobr><span class="ft4">4</span></nobr></DIV>
<DIV style="position:absolute;top:1011;left:356"><nobr><span class="ft4">8</span></nobr></DIV>
<DIV style="position:absolute;top:1011;left:407"><nobr><span class="ft4">16</span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:111"><nobr><span class="ft4">Chance of Success (%)</span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:293"><nobr><span class="ft4">93.6</span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:347"><nobr><span class="ft4">87.8</span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:402"><nobr><span class="ft4">78.2</span></nobr></DIV>
<DIV style="position:absolute;top:1044;left:91"><nobr><span class="ft4">Degradation per Failure (bit)</span></nobr></DIV>
<DIV style="position:absolute;top:1044;left:289"><nobr><span class="ft4">0.026</span></nobr></DIV>
<DIV style="position:absolute;top:1044;left:344"><nobr><span class="ft4">0.026</span></nobr></DIV>
<DIV style="position:absolute;top:1044;left:398"><nobr><span class="ft4">0.026</span></nobr></DIV>
<DIV style="position:absolute;top:1060;left:102"><nobr><span class="ft4">Overall Degradation (bit)</span></nobr></DIV>
<DIV style="position:absolute;top:1060;left:286"><nobr><span class="ft4">0.0016</span></nobr></DIV>
<DIV style="position:absolute;top:1060;left:340"><nobr><span class="ft4">0.0032</span></nobr></DIV>
<DIV style="position:absolute;top:1060;left:395"><nobr><span class="ft4">0.0058</span></nobr></DIV>
<DIV style="position:absolute;top:96;left:487"><nobr><span class="ft4">Table2: Impact Changewith Dispersion Width</span></nobr></DIV>
<DIV style="position:absolute;top:111;left:499"><nobr><span class="ft4">Dispersion Width b (bit)</span></nobr></DIV>
<DIV style="position:absolute;top:111;left:685"><nobr><span class="ft4">0.05</span></nobr></DIV>
<DIV style="position:absolute;top:111;left:744"><nobr><span class="ft4">0.1</span></nobr></DIV>
<DIV style="position:absolute;top:111;left:795"><nobr><span class="ft4">0.2</span></nobr></DIV>
<DIV style="position:absolute;top:128;left:506"><nobr><span class="ft4">Chance of Success (%)</span></nobr></DIV>
<DIV style="position:absolute;top:128;left:685"><nobr><span class="ft4">93.6</span></nobr></DIV>
<DIV style="position:absolute;top:128;left:740"><nobr><span class="ft4">87.8</span></nobr></DIV>
<DIV style="position:absolute;top:128;left:791"><nobr><span class="ft4">78.1</span></nobr></DIV>
<DIV style="position:absolute;top:144;left:485"><nobr><span class="ft4">Degradation per Failure (bit)</span></nobr></DIV>
<DIV style="position:absolute;top:144;left:682"><nobr><span class="ft4">0.013</span></nobr></DIV>
<DIV style="position:absolute;top:144;left:737"><nobr><span class="ft4">0.026</span></nobr></DIV>
<DIV style="position:absolute;top:144;left:788"><nobr><span class="ft4">0.054</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:496"><nobr><span class="ft4">Overall Degradation (bit)</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:679"><nobr><span class="ft4">0.0008</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:733"><nobr><span class="ft4">0.0032</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:788"><nobr><span class="ft4">0.012</span></nobr></DIV>
<DIV style="position:absolute;top:207;left:481"><nobr><span class="ft4">Table3: Impact Changewith Mutual Info. Scope</span></nobr></DIV>
<DIV style="position:absolute;top:222;left:492"><nobr><span class="ft4">Mutual Info. Scope c (bit)</span></nobr></DIV>
<DIV style="position:absolute;top:222;left:688"><nobr><span class="ft4">0.5</span></nobr></DIV>
<DIV style="position:absolute;top:222;left:748"><nobr><span class="ft4">1</span></nobr></DIV>
<DIV style="position:absolute;top:222;left:802"><nobr><span class="ft4">2</span></nobr></DIV>
<DIV style="position:absolute;top:238;left:505"><nobr><span class="ft4">Chance of Success (%)</span></nobr></DIV>
<DIV style="position:absolute;top:238;left:684"><nobr><span class="ft4">78.2</span></nobr></DIV>
<DIV style="position:absolute;top:238;left:739"><nobr><span class="ft4">87.8</span></nobr></DIV>
<DIV style="position:absolute;top:238;left:793"><nobr><span class="ft4">93.6</span></nobr></DIV>
<DIV style="position:absolute;top:255;left:484"><nobr><span class="ft4">Degradation per Failure (bit)</span></nobr></DIV>
<DIV style="position:absolute;top:255;left:681"><nobr><span class="ft4">0.027</span></nobr></DIV>
<DIV style="position:absolute;top:255;left:735"><nobr><span class="ft4">0.026</span></nobr></DIV>
<DIV style="position:absolute;top:255;left:790"><nobr><span class="ft4">0.025</span></nobr></DIV>
<DIV style="position:absolute;top:271;left:495"><nobr><span class="ft4">Overall Degradation (bit)</span></nobr></DIV>
<DIV style="position:absolute;top:271;left:678"><nobr><span class="ft4">0.0058</span></nobr></DIV>
<DIV style="position:absolute;top:271;left:732"><nobr><span class="ft4">0.0032</span></nobr></DIV>
<DIV style="position:absolute;top:271;left:787"><nobr><span class="ft4">0.0016</span></nobr></DIV>
<DIV style="position:absolute;top:320;left:475"><nobr><span class="ft9">fails to select the sensor with the maximum mutual informa-<br>tion, the degradation of sensor selection decision based on<br>the heuristic compared to that based on the mutual infor-<br>mation does not change much with the mutual information<br>variation scope c. Thus, the overall degradation of sensor<br>selection decision based on the heuristic compared to that<br>based on mutual information decreases as the mutual infor-<br>mation variation scope c increases.</span></nobr></DIV>
<DIV style="position:absolute;top:445;left:489"><nobr><span class="ft4">In table 4 , b = 0.1 bit is fixed and the number of can-</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:475"><nobr><span class="ft9">didate sensors are fixed to be 8. We proportionally change<br>the entropy difference variation scope a and the mutual in-<br>formation variation scope c so that c/a = 1/2 is fixed. The<br>chance for the heuristic to successfully select the sensor with<br>the maximum mutual information increases as the entropy<br>difference variation scope a and the mutual information vari-<br>ation scope c proportionally increase. When the heuristic<br>fails to select the sensor with the maximum mutual infor-<br>mation, the degradation of sensor selection decision based<br>on the heuristic compared to that based on the mutual in-<br>formation does not change. Thus, the overall degradation of<br>sensor selection decision based on the heuristic compared to<br>that based on mutual information decreases as the entropy<br>difference variation scope a and the mutual information vari-<br>ation scope c proportionally increase.</span></nobr></DIV>
<DIV style="position:absolute;top:714;left:475"><nobr><span class="ft3"><b>5.</b></span></nobr></DIV>
<DIV style="position:absolute;top:714;left:507"><nobr><span class="ft3"><b>FUTURE WORK</b></span></nobr></DIV>
<DIV style="position:absolute;top:746;left:475"><nobr><span class="ft3"><b>5.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:746;left:515"><nobr><span class="ft3"><b>Prior Target Location Distribution</b></span></nobr></DIV>
<DIV style="position:absolute;top:768;left:489"><nobr><span class="ft4">When the sensors is selected for tracking a temporally con-</span></nobr></DIV>
<DIV style="position:absolute;top:784;left:475"><nobr><span class="ft9">tinuous source, the prior target location distribution at time<br>t + 1 can be obtained from the posterior target location dis-<br>tribution at time t by using the target dynamic model as de-<br>scribed in [11]. However, when the sensor selection heuristic<br>is applied to locate a temporally discontinuous source such<br>as a bird call, it is not straightforward to obtain the prior<br>target location distribution used in the sequential Bayesian<br>fusion. One possible solution to the above problem could be<br>as follows. First, all sensors buffer the signal once an event</span></nobr></DIV>
<DIV style="position:absolute;top:963;left:475"><nobr><span class="ft9">Table4: Impact Changewith Entropy Diff. Scopec<br>and Mutual Info. Scope a in Proportion</span></nobr></DIV>
<DIV style="position:absolute;top:995;left:490"><nobr><span class="ft4">Entropy Diff. Scope a (bit)</span></nobr></DIV>
<DIV style="position:absolute;top:995;left:693"><nobr><span class="ft4">1</span></nobr></DIV>
<DIV style="position:absolute;top:995;left:748"><nobr><span class="ft4">2</span></nobr></DIV>
<DIV style="position:absolute;top:995;left:802"><nobr><span class="ft4">4</span></nobr></DIV>
<DIV style="position:absolute;top:1011;left:492"><nobr><span class="ft4">Mutual Info. Scope c (bit)</span></nobr></DIV>
<DIV style="position:absolute;top:1011;left:688"><nobr><span class="ft4">0.5</span></nobr></DIV>
<DIV style="position:absolute;top:1011;left:748"><nobr><span class="ft4">1</span></nobr></DIV>
<DIV style="position:absolute;top:1011;left:802"><nobr><span class="ft4">2</span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:505"><nobr><span class="ft4">Chance of Success (%)</span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:684"><nobr><span class="ft4">78.2</span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:739"><nobr><span class="ft4">87.8</span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:793"><nobr><span class="ft4">93.6</span></nobr></DIV>
<DIV style="position:absolute;top:1044;left:484"><nobr><span class="ft4">Degradation per Failure (bit)</span></nobr></DIV>
<DIV style="position:absolute;top:1044;left:681"><nobr><span class="ft4">0.026</span></nobr></DIV>
<DIV style="position:absolute;top:1044;left:735"><nobr><span class="ft4">0.026</span></nobr></DIV>
<DIV style="position:absolute;top:1044;left:790"><nobr><span class="ft4">0.026</span></nobr></DIV>
<DIV style="position:absolute;top:1060;left:495"><nobr><span class="ft4">Overall Degradation (bit)</span></nobr></DIV>
<DIV style="position:absolute;top:1060;left:678"><nobr><span class="ft4">0.0058</span></nobr></DIV>
<DIV style="position:absolute;top:1060;left:732"><nobr><span class="ft4">0.0032</span></nobr></DIV>
<DIV style="position:absolute;top:1060;left:787"><nobr><span class="ft4">0.0016</span></nobr></DIV>
<DIV style="position:absolute;top:1127;left:452"><nobr><span class="ft8">44</span></nobr></DIV>
</DIV>
<!-- Page 10 -->
<a name="10"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="84010.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft9">such as a bird call is detected. Then, all triggered sensors<br>elect a leader that received the strongest signal intensity us-<br>ing a protocol similar to that described in [10]. Finally, the<br>leader can pick a few sensors to generate an initial prior tar-<br>get location distribution assuming a certain sensing model.<br>With the initial prior target location distribution, we can<br>apply the sensor selection heuristic to incrementally reduce<br>the uncertainty of the target location distribution. We plan<br>to implement and test the above mechanism in the future.</span></nobr></DIV>
<DIV style="position:absolute;top:241;left:81"><nobr><span class="ft3"><b>5.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:241;left:121"><nobr><span class="ft3"><b>Discretization of State Space</b></span></nobr></DIV>
<DIV style="position:absolute;top:263;left:94"><nobr><span class="ft4">There is a trade offof computational efficiency and nu-</span></nobr></DIV>
<DIV style="position:absolute;top:278;left:81"><nobr><span class="ft9">merical accuracy in the discretization of the state space of<br>random variables such as the target location and the sen-<br>sor view. The bigger the grid size is, the fewer grids are<br>involved in the computation. However, a bigger grid size<br>also introduces more inaccuracy into the evaluation of the<br>entropy difference heuristic. In the future, we must study<br>more details about the trade offin order to choose a proper<br>grid size.</span></nobr></DIV>
<DIV style="position:absolute;top:417;left:81"><nobr><span class="ft3"><b>5.3</b></span></nobr></DIV>
<DIV style="position:absolute;top:417;left:121"><nobr><span class="ft3"><b>Sensing Uncertainty Model</b></span></nobr></DIV>
<DIV style="position:absolute;top:439;left:94"><nobr><span class="ft4">We have assumed Gaussian sensing models in the simu-</span></nobr></DIV>
<DIV style="position:absolute;top:455;left:81"><nobr><span class="ft9">lations as the first step to evaluate the heuristic. Inaccu-<br>racy of sensing models diminishes the effectiveness of any<br>sensor selection criterion. We plan to construct a more re-<br>alistic sensing model for the AML-based DOA estimation.<br>We have implemented AML algorithm for real-time DOA<br>estimation on a wireless sensor network testbed [5].</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:420"><nobr><span class="ft4">We</span></nobr></DIV>
<DIV style="position:absolute;top:549;left:81"><nobr><span class="ft9">will first analyze the sensing uncertainty characteristic of<br>the AML algorithm, and then experimentally validate and<br>refine it using the testbed. We will also evaluate the effec-<br>tiveness of the entropy-based sensor selection heuristic using<br>realistic sensing models and implement the heuristic on the<br>real-time wireless sensor network testbed for localization.</span></nobr></DIV>
<DIV style="position:absolute;top:668;left:81"><nobr><span class="ft3"><b>6.</b></span></nobr></DIV>
<DIV style="position:absolute;top:668;left:112"><nobr><span class="ft3"><b>CONCLUSION</b></span></nobr></DIV>
<DIV style="position:absolute;top:690;left:94"><nobr><span class="ft4">We have proposed an entropy-based sensor selection heuris-</span></nobr></DIV>
<DIV style="position:absolute;top:706;left:81"><nobr><span class="ft9">tic for localization. The effectiveness of the heuristic has<br>been evaluated using simulations in which Gaussian sensing<br>models are assumed for simplicity. Simulations have shown<br>that the heuristic selects the sensor with nearly the maximal<br>mutual information between the target location and the sen-<br>sor observation. Given the prior target location distribution,<br>the sensor locations, and the sensing models, on average,<br>the sensor selected by the heuristic would yield nearly the<br>greatest reduction in the entropy of the posterior target lo-<br>cation distribution. The heuristic is more effective when the<br>optimal candidate sensor is more informative. As mutual-<br>information-based sensor selection approaches [11, 6] do, the<br>heuristic greedily selects one sensor in each step without re-<br>trieving any actual sensor observations. In addition, in gen-<br>eral, our heuristic is computationally much simpler than the<br>mutual-information-based approaches.</span></nobr></DIV>
<DIV style="position:absolute;top:982;left:81"><nobr><span class="ft3"><b>7.</b></span></nobr></DIV>
<DIV style="position:absolute;top:982;left:112"><nobr><span class="ft3"><b>ACKNOWLEDGMENTS</b></span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:94"><nobr><span class="ft4">This material is based upon work partially supported by</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:81"><nobr><span class="ft9">the National Science Foundation (NSF) under Cooperative<br>Agreement #CCR-0121778, and DARPA SensIT program<br>under contract AFRL/IFG 315 330-1865 and AROD-MURI<br>PSU 50126.</span></nobr></DIV>
<DIV style="position:absolute;top:84;left:475"><nobr><span class="ft3"><b>8.</b></span></nobr></DIV>
<DIV style="position:absolute;top:84;left:507"><nobr><span class="ft3"><b>REFERENCES</b></span></nobr></DIV>
<DIV style="position:absolute;top:100;left:482"><nobr><span class="ft4">[1] I. F. Akyildiz, W. Su, Y. Sankarasubramaniam, and</span></nobr></DIV>
<DIV style="position:absolute;top:116;left:503"><nobr><span class="ft9">E. Cayirci. Wireless sensor networks: a survey.<br>Computer Networks, 38(4):393­442, March 2002.</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:482"><nobr><span class="ft4">[2] G. Asada, M. Dong, T. Lin, F. Newberg, G. Pottie,</span></nobr></DIV>
<DIV style="position:absolute;top:164;left:503"><nobr><span class="ft9">W. Kaiser, and H. Marcy. Wireless integrated network<br>sensors: low power systems on a chip. In Proc. the<br>European Solid State Circuits Conference, The Hague,<br>Netherlands, 1998.</span></nobr></DIV>
<DIV style="position:absolute;top:229;left:482"><nobr><span class="ft4">[3] J. M. Bernardo and A. F. M. Smith. Bayesian theory.</span></nobr></DIV>
<DIV style="position:absolute;top:244;left:503"><nobr><span class="ft4">Wiley, New York, 1996.</span></nobr></DIV>
<DIV style="position:absolute;top:262;left:482"><nobr><span class="ft4">[4] J. Chen, R. Hudson, and K. Yao. Maximum-likelihood</span></nobr></DIV>
<DIV style="position:absolute;top:277;left:503"><nobr><span class="ft9">source localization and unknown sensor location<br>estimation for wideband signals in the near-field. IEEE<br>T. Signal Proces., 50(8):1843­1854, August 2002.</span></nobr></DIV>
<DIV style="position:absolute;top:326;left:482"><nobr><span class="ft4">[5] J. Chen, L. Yip, J. Elson, H. Wang, D. Maniezzo,</span></nobr></DIV>
<DIV style="position:absolute;top:342;left:503"><nobr><span class="ft9">R. Hudson, K. Yao, and D. Estrin. Coherent acoustic<br>array processing and localization on wireless sensor<br>networks. Proc. the IEEE, 91(8):1154­1162, August<br>2003.</span></nobr></DIV>
<DIV style="position:absolute;top:406;left:482"><nobr><span class="ft4">[6] E. Ertin, J. Fisher, and L. Potter. Maximum mutual</span></nobr></DIV>
<DIV style="position:absolute;top:421;left:503"><nobr><span class="ft9">information principle for dynamic sensor query<br>problems. In Proc. IPSN'03, Palo Alto, CA, April<br>2003.</span></nobr></DIV>
<DIV style="position:absolute;top:470;left:482"><nobr><span class="ft4">[7] S. Haykin. Adpative filter theory. Prentice Hall, New</span></nobr></DIV>
<DIV style="position:absolute;top:486;left:503"><nobr><span class="ft4">Jersey, USA, 1996.</span></nobr></DIV>
<DIV style="position:absolute;top:503;left:482"><nobr><span class="ft4">[8] K. Hintz and E. McVey. A measure of the information</span></nobr></DIV>
<DIV style="position:absolute;top:519;left:503"><nobr><span class="ft9">gain attributable to cueing. IEEE T. Syst. Man Cyb.,<br>21(2):434­442, 1991.</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:482"><nobr><span class="ft4">[9] R. E. Kalman. A new approach to linear filtering and</span></nobr></DIV>
<DIV style="position:absolute;top:567;left:503"><nobr><span class="ft9">prediction problems. Trans. of the ASME­Journal of<br>Basic Engineering, 82(Series D):35­45, 1960.</span></nobr></DIV>
<DIV style="position:absolute;top:600;left:475"><nobr><span class="ft4">[10] J. Liu, J. Liu, J. Reich, P. Cheung, and F. Zhao.</span></nobr></DIV>
<DIV style="position:absolute;top:616;left:503"><nobr><span class="ft9">Distributed group management for track initiation<br>and maintenance in target localization applications. In<br>Proc. International Workshop on Informaiton<br>Processing in Sensor Networks (IPSN), Palo Alto,<br>CA, April 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:696;left:475"><nobr><span class="ft4">[11] J. Liu, J. Reich, and F. Zhao. Collaborative</span></nobr></DIV>
<DIV style="position:absolute;top:711;left:503"><nobr><span class="ft9">in-network processing for target tracking. EURASIP<br>JASP: Special Issues on Sensor Networks,<br>2003(4):378­391, March 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:760;left:475"><nobr><span class="ft4">[12] J. Manyika and H. Durrant-Whyte. Data fusion and</span></nobr></DIV>
<DIV style="position:absolute;top:776;left:503"><nobr><span class="ft9">sensor management: a decentralized<br>information-theoretic approach. Ellis Horwood, New<br>York, 1994.</span></nobr></DIV>
<DIV style="position:absolute;top:824;left:475"><nobr><span class="ft4">[13] A. Savvides, W. Garber, S. Adlakha, R. Moses, and</span></nobr></DIV>
<DIV style="position:absolute;top:840;left:503"><nobr><span class="ft9">M. B. Srivastava. On the error characteristics of<br>multihop node localization in ad-hoc sensor networks.<br>In Proc. IPSN'03, Palo Alto, CA, USA, April 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:889;left:475"><nobr><span class="ft4">[14] C. E. Shannon. A mathematical theory of</span></nobr></DIV>
<DIV style="position:absolute;top:904;left:503"><nobr><span class="ft9">communication. Bell Systems Technical Journal,<br>27(6):379­423 and 623­656, 1948.</span></nobr></DIV>
<DIV style="position:absolute;top:937;left:475"><nobr><span class="ft4">[15] T. Tung, K. Yao, C. Reed, R. Hudson, D. Chen, and</span></nobr></DIV>
<DIV style="position:absolute;top:953;left:503"><nobr><span class="ft9">J. Chen. Source localization and time delay estimation<br>using constrained least squares and best path<br>smoothing. In Proc. SPIE'99, volume 3807, pages<br>220­223, July 1999.</span></nobr></DIV>
<DIV style="position:absolute;top:1017;left:475"><nobr><span class="ft4">[16] K. Yao, R. Hudson, C. Reed, D. Chen, and</span></nobr></DIV>
<DIV style="position:absolute;top:1033;left:503"><nobr><span class="ft9">F. Lorenzelli. Blind beamforming source localization<br>on a sensor array system. In AWAIRS project<br>presentation at UCLA, USA, December 1997.</span></nobr></DIV>
<DIV style="position:absolute;top:1127;left:452"><nobr><span class="ft8">45</span></nobr></DIV>
</DIV>
</BODY>
</HTML>
