<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
<HEAD>
<TITLE>p473-steyvers.dvi</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<META name="generator" content="pdftohtml 0.35beta">
<META name="date" content="2004-08-05T21:35:33+00:00">
</HEAD>
<BODY bgcolor="#A0A0A0" vlink="blue" link="blue">
<!-- Page 1 -->
<a name="1"></a>
<DIV style="position:relative;width:928;height:1263;">
<STYLE type="text/css">
<!--
	.ft0{font-size:24px;font-family:Times;color:#000000;}
	.ft1{font-size:15px;font-family:Times;color:#000000;}
	.ft2{font-size:12px;font-family:Times;color:#000000;}
	.ft3{font-size:11px;font-family:Times;color:#000000;}
	.ft4{font-size:9px;font-family:Times;color:#000000;}
	.ft5{font-size:13px;font-family:Helvetica;color:#000000;}
	.ft6{font-size:11px;font-family:Times;color:#000000;}
	.ft7{font-size:11px;line-height:15px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="928" height="1263" src="151001.png" alt="background image">
<DIV style="position:absolute;top:103;left:154"><nobr><span class="ft0"><b>Probabilistic Author-Topic Models for Information</b></span></nobr></DIV>
<DIV style="position:absolute;top:133;left:406"><nobr><span class="ft0"><b>Discovery</b></span></nobr></DIV>
<DIV style="position:absolute;top:203;left:194"><nobr><span class="ft1">Mark Steyvers</span></nobr></DIV>
<DIV style="position:absolute;top:222;left:170"><nobr><span class="ft2">Department of Cognitive</span></nobr></DIV>
<DIV style="position:absolute;top:237;left:220"><nobr><span class="ft2">Sciences</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:154"><nobr><span class="ft2">University of California, Irvine</span></nobr></DIV>
<DIV style="position:absolute;top:269;left:156"><nobr><span class="ft2">Irvine, CA 92697-5100, USA</span></nobr></DIV>
<DIV style="position:absolute;top:288;left:177"><nobr><span class="ft1">msteyver@uci.edu</span></nobr></DIV>
<DIV style="position:absolute;top:203;left:405"><nobr><span class="ft1">Padhraic Smyth,</span></nobr></DIV>
<DIV style="position:absolute;top:221;left:401"><nobr><span class="ft1">Michal Rosen-Zvi</span></nobr></DIV>
<DIV style="position:absolute;top:240;left:388"><nobr><span class="ft2">Department of Computer</span></nobr></DIV>
<DIV style="position:absolute;top:255;left:443"><nobr><span class="ft2">Science</span></nobr></DIV>
<DIV style="position:absolute;top:271;left:373"><nobr><span class="ft2">University of California, Irvine</span></nobr></DIV>
<DIV style="position:absolute;top:287;left:376"><nobr><span class="ft2">Irvine, CA 92697-3425, USA</span></nobr></DIV>
<DIV style="position:absolute;top:313;left:368"><nobr><span class="ft3">{</span></nobr></DIV>
<DIV style="position:absolute;top:306;left:375"><nobr><span class="ft1">smyth,michal</span></nobr></DIV>
<DIV style="position:absolute;top:313;left:480"><nobr><span class="ft3">}</span></nobr></DIV>
<DIV style="position:absolute;top:306;left:486"><nobr><span class="ft1">@ics.uci.edu</span></nobr></DIV>
<DIV style="position:absolute;top:203;left:624"><nobr><span class="ft1">Thomas Griffiths</span></nobr></DIV>
<DIV style="position:absolute;top:222;left:601"><nobr><span class="ft2">Department of Psychology</span></nobr></DIV>
<DIV style="position:absolute;top:237;left:627"><nobr><span class="ft2">Stanford University</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:624"><nobr><span class="ft2">Stanford, CA 94305</span></nobr></DIV>
<DIV style="position:absolute;top:272;left:588"><nobr><span class="ft1">gruffydd@psych.stanford.edu</span></nobr></DIV>
<DIV style="position:absolute;top:360;left:93"><nobr><span class="ft1">ABSTRACT</span></nobr></DIV>
<DIV style="position:absolute;top:388;left:93"><nobr><span class="ft7">We propose a new unsupervised learning technique for ex-<br>tracting information from large text collections. We model<br>documents as if they were generated by a two-stage stochas-<br>tic process. Each author is represented by a probability<br>distribution over topics, and each topic is represented as<br>a probability distribution over words for that topic. The<br>words in a multi-author paper are assumed to be the result<br>of a mixture of each authors' topic mixture. The topic-word<br>and author-topic distributions are learned from data in an<br>unsupervised manner using a Markov chain Monte Carlo al-<br>gorithm. We apply the methodology to a large corpus of<br>160,000 abstracts and 85,000 authors from the well-known<br>CiteSeer digital library, and learn a model with 300 topics.<br>We discuss in detail the interpretation of the results dis-<br>covered by the system including specific topic and author<br>models, ranking of authors by topic and topics by author,<br>significant trends in the computer science literature between<br>1990 and 2002, parsing of abstracts by topics and authors<br>and detection of unusual papers by specific authors. An on-<br>line query interface to the model is also discussed that allows<br>interactive exploration of author-topic models for corpora<br>such as CiteSeer.</span></nobr></DIV>
<DIV style="position:absolute;top:740;left:93"><nobr><span class="ft1">Categories and Subject Descriptors</span></nobr></DIV>
<DIV style="position:absolute;top:740;left:93"><nobr><span class="ft7">I.2.6 [Artificial<br>Intelligence]: Learning</span></nobr></DIV>
<DIV style="position:absolute;top:778;left:93"><nobr><span class="ft1">General Terms</span></nobr></DIV>
<DIV style="position:absolute;top:778;left:93"><nobr><span class="ft3">algorithms, experimentation</span></nobr></DIV>
<DIV style="position:absolute;top:800;left:93"><nobr><span class="ft7">Keywords: unsupervised learning, Gibbs sampling, text<br>modeling</span></nobr></DIV>
<DIV style="position:absolute;top:843;left:93"><nobr><span class="ft1">1. INTRODUCTION</span></nobr></DIV>
<DIV style="position:absolute;top:870;left:107"><nobr><span class="ft3">With the advent of the Web and various specialized digi-</span></nobr></DIV>
<DIV style="position:absolute;top:886;left:93"><nobr><span class="ft7">tal libraries, the automatic extraction of useful information<br>from text has become an increasingly important research<br>area in data mining. In this paper we discuss a new algo-</span></nobr></DIV>
<DIV style="position:absolute;top:974;left:93"><nobr><span class="ft4">Permission to make digital or hard copies of all or part of this work for</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:93"><nobr><span class="ft4">personal or classroom use is granted without fee provided that copies are</span></nobr></DIV>
<DIV style="position:absolute;top:1001;left:93"><nobr><span class="ft4">not made or distributed for profit or commercial advantage and that copies</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:93"><nobr><span class="ft4">bear this notice and the full citation on the first page. To copy otherwise, to</span></nobr></DIV>
<DIV style="position:absolute;top:1028;left:93"><nobr><span class="ft4">republish, to post on servers or to redistribute to lists, requires prior specific</span></nobr></DIV>
<DIV style="position:absolute;top:1042;left:93"><nobr><span class="ft4">permission and/or a fee.</span></nobr></DIV>
<DIV style="position:absolute;top:1055;left:93"><nobr><span class="ft4">KDD'04, August 22­25, 2004, Seattle, Washington, USA.</span></nobr></DIV>
<DIV style="position:absolute;top:1069;left:93"><nobr><span class="ft4">Copyright 2004 ACM 1-58113-888-1/04/0008 ...</span></nobr></DIV>
<DIV style="position:absolute;top:1070;left:327"><nobr><span class="ft3">$</span></nobr></DIV>
<DIV style="position:absolute;top:1069;left:334"><nobr><span class="ft4">5.00.</span></nobr></DIV>
<DIV style="position:absolute;top:367;left:488"><nobr><span class="ft7">rithm that extracts both the topics expressed in large text<br>document collections and models how the authors of docu-<br>ments use those topics. The methodology is illustrated using<br>a sample of 160,000 abstracts and 80,000 authors from the<br>well-known CiteSeer digital library of computer science re-<br>search papers (Lawrence, Giles, and Bollacker, 1999). The<br>algorithm uses a probabilistic model that represents top-<br>ics as probability distributions over words and documents<br>as being composed of multiple topics. A novel feature of<br>our model is the inclusion of author models, in which au-<br>thors are modeled as probability distributions over topics.<br>The author-topic models can be used to support a variety<br>of interactive and exploratory queries on the set of docu-<br>ments and authors, including analysis of topic trends over<br>time, finding the authors who are most likely to write on a<br>given topic, and finding the most unusual paper written by<br>a given author. Bayesian unsupervised learning is used to<br>fit the model to a document collection.</span></nobr></DIV>
<DIV style="position:absolute;top:649;left:501"><nobr><span class="ft3">Supervised learning techniques for automated categoriza-</span></nobr></DIV>
<DIV style="position:absolute;top:665;left:488"><nobr><span class="ft7">tion of documents into known classes or topics has received<br>considerable attention in recent years (e.g., Yang, 1998).<br>For many document collections, however, neither predefined<br>topics nor labeled documents may be available. Further-<br>more, there is considerable motivation to uncover hidden<br>topic structure in large corpora, particularly in rapidly chang-<br>ing fields such as computer science and biology, where pre-<br>defined topic categories may not accurately reflect rapidly<br>evolving content.</span></nobr></DIV>
<DIV style="position:absolute;top:806;left:501"><nobr><span class="ft3">Automatic extraction of topics from text, via unsuper-</span></nobr></DIV>
<DIV style="position:absolute;top:822;left:488"><nobr><span class="ft7">vised learning, has been addressed in prior work using a<br>number of different approaches. One general approach is<br>to represent the high-dimensional term vectors in a lower-<br>dimensional space. Local regions in the lower-dimensional<br>space can then be associated with specific topics. For ex-<br>ample, the WEBSOM system (Lagus et al. 1999) uses non-<br>linear dimensionality reduction via self-organizing maps to<br>represent term vectors in a two-dimensional layout. Lin-<br>ear projection techniques, such as latent semantic indexing<br>(LSI), are also widely used (Berry, Dumais, and O' Brien,<br>1995). For example, Deerwester et al. (1990), while not<br>using the term "topics" per se, state:</span></nobr></DIV>
<DIV style="position:absolute;top:1019;left:522"><nobr><span class="ft7">Roughly speaking, these factors may be thought<br>of as artificial concepts; they represent extracted<br>common meaning components of many different<br>words and documents.</span></nobr></DIV>
<DIV style="position:absolute;top:54;left:91"><nobr><span class="ft5"><b>Research Track Paper</b></span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:460"><nobr><span class="ft6">306</span></nobr></DIV>
</DIV>
<!-- Page 2 -->
<a name="2"></a>
<DIV style="position:relative;width:928;height:1263;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="928" height="1263" src="151002.png" alt="background image">
<DIV style="position:absolute;top:86;left:107"><nobr><span class="ft3">A somewhat different approach is to cluster the docu-</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:93"><nobr><span class="ft7">ments into groups containing similar semantic content, using<br>any of a variety of well-known document clustering tech-<br>niques (e.g., Cutting et al., 1992; McCallum, Nigam, and<br>Ungar, 2000; Popescul et al., 2000). Each cluster of docu-<br>ments can then be associated with a latent topic (e.g., as<br>represented by the mean term vector for documents in the<br>cluster). While clustering can provide useful broad informa-<br>tion about topics, clusters are inherently limited by the fact<br>that each document is (typically) only associated with one<br>cluster. This is often at odds with the multi-topic nature of<br>text documents in many contexts. In particular, combina-<br>tions of diverse topics within a single document are difficult<br>to represent. For example, this present paper contains at<br>least two significantly different topics: document modeling<br>and Bayesian estimation. For this reason, other representa-<br>tions (such as those discussed below) that allow documents<br>to be composed of multiple topics generally provide better<br>models for sets of documents (e.g., better out of sample pre-<br>dictions, Blei, Ng, and Jordan (2003)).</span></nobr></DIV>
<DIV style="position:absolute;top:400;left:107"><nobr><span class="ft3">Hofmann (1999) introduced the aspect model (also re-</span></nobr></DIV>
<DIV style="position:absolute;top:415;left:93"><nobr><span class="ft7">ferred to as probabilistic LSI, or pLSI) as a probabilistic<br>alternative to projection and clustering methods. In pLSI,<br>topics are modeled as multinomial probability distributions<br>over words, and documents are assumed to be generated<br>by the activation of multiple topics. While the pLSI model<br>produced impressive results on a number of text document<br>problems such as information retrieval, the parameterization<br>of the model was susceptible to overfitting and did not pro-<br>vide a straightforward way to make inferences about new<br>documents not seen in the training data. Blei, Ng, and<br>Jordan (2003) addressed these limitations by proposing a<br>more general Bayesian probabilistic topic model called la-<br>tent Dirichlet allocation (LDA). The parameters of the LDA<br>model (the topic-word and document-topic distributions)<br>are estimated using an approximation technique known as<br>variational EM, since standard estimation methods are in-<br>tractable. Griffiths and Steyvers (2004) showed how Gibbs<br>sampling, a Markov chain Monte Carlo technique, could be<br>applied in this model, and illustrated this approach using 11<br>years of abstract data from the Proceedings of the National<br>Academy of Sciences.</span></nobr></DIV>
<DIV style="position:absolute;top:745;left:107"><nobr><span class="ft3">Our focus here is to extend the probabilistic topic mod-</span></nobr></DIV>
<DIV style="position:absolute;top:761;left:93"><nobr><span class="ft7">els to include authorship information. Joint author-topic<br>modeling has received little or no attention as far as we<br>are aware. The areas of stylometry, authorship attribution,<br>and forensic linguistics focus on the problem of identify-<br>ing what author wrote a given piece of text. For example,<br>Mosteller and Wallace (1964) used Bayesian techniques to<br>infer whether Hamilton or Madison was the more likely au-<br>thor of disputed Federalist papers. More recent work of a<br>similar nature includes authorship analysis of a purported<br>poem by Shakespeare (Thisted and Efron, 1987), identifying<br>authors of software programs (Gray, Sallis, and MacDonell,<br>1997), and the use of techniques such as support vector ma-<br>chines (Diederich et al., 2003) for author identification.</span></nobr></DIV>
<DIV style="position:absolute;top:965;left:107"><nobr><span class="ft3">These author identification methods emphasize the use of</span></nobr></DIV>
<DIV style="position:absolute;top:980;left:93"><nobr><span class="ft7">distinctive stylistic features (such as sentence length) that<br>characterize a specific author. In contrast, the models we<br>present here focus on extracting the general semantic con-<br>tent of a document, rather than the stylistic details of how<br>it was written. For example, in our model we omit common<br>"stop" words since they are generally irrelevant to the topic</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:488"><nobr><span class="ft7">of the document--however, the distributions of stop words<br>can be quite useful in stylometry. While "topic" information<br>could be usefully combined with stylistic features for author<br>classification we do not pursue this idea in this particular<br>paper.</span></nobr></DIV>
<DIV style="position:absolute;top:164;left:501"><nobr><span class="ft3">Graph-based and network-based models are also frequently</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:488"><nobr><span class="ft7">used as a basis for representation and analysis of relations<br>among scientific authors. For example, Newman (2001),<br>Mutschke (2003) and Erten et al. (2003) use methods from<br>bibliometrics, social networks, and graph theory to ana-<br>lyze and visualize co-author and citation relations in the<br>scientific literature. Kautz, Selman, and Shah (1997) de-<br>veloped the interactive ReferralWeb system for exploring<br>networks of computer scientists working in artificial intel-<br>ligence and information retrieval, and White and Smyth<br>(2003) used PageRank-style ranking algorithms to analyze<br>co-author graphs. In all of this work only the network con-<br>nectivity information is used--the text information from the<br>underlying documents is not used in modeling. Thus, while<br>the grouping of authors via these network models can implic-<br>itly provide indications of latent topics, there is no explicit<br>representation of the topics in terms of the text content (the<br>words) of the documents.</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:501"><nobr><span class="ft3">The novelty of the work described in this paper lies in</span></nobr></DIV>
<DIV style="position:absolute;top:463;left:488"><nobr><span class="ft7">the proposal of a probabilistic model that represents both<br>authors and topics, and the application of this model to a<br>large well-known document corpus in computer science. As<br>we will show later in the paper, the model provides a general<br>framework for exploration, discovery, and query-answering<br>in the context of the relationships of author and topics for<br>large document collections.</span></nobr></DIV>
<DIV style="position:absolute;top:572;left:501"><nobr><span class="ft3">The outline of the paper is as follows: in Section 2 we de-</span></nobr></DIV>
<DIV style="position:absolute;top:588;left:488"><nobr><span class="ft7">scribe the author-topic model and outline how the parame-<br>ters of the model (the topic-word distributions and author-<br>topic distributions) can be learned from training data con-<br>sisting of documents with known authors. Section 3 illus-<br>trates the application of the model to a large collection of<br>abstracts from the CiteSeer system, with examples of spe-<br>cific topics and specific author models that are learned by<br>the algorithm. In Section 4 we illustrate a number of appli-<br>cations of the model, including the characterization of topic<br>trends over time (which provides some interesting insights<br>on the direction of research in computer science), and the<br>characterization of which papers are most typical and least<br>typical for a given author. An online query interface to the<br>system is described in Section 5, allowing users to query the<br>model over the Web--an interesting feature of the model is<br>the coupling of Bayesian sampling and relational database<br>technology to answer queries in real-time. Section 6 con-<br>tains a brief discussion of future directions and concluding<br>comments.</span></nobr></DIV>
<DIV style="position:absolute;top:906;left:488"><nobr><span class="ft1">2. AN OVERVIEW OF THE AUTHOR-TOPIC</span></nobr></DIV>
<DIV style="position:absolute;top:927;left:519"><nobr><span class="ft1">MODEL</span></nobr></DIV>
<DIV style="position:absolute;top:961;left:488"><nobr><span class="ft1">2.1 The Probabilistic Generative Model</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:501"><nobr><span class="ft3">The author-topic model reduces the process of writing a</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:488"><nobr><span class="ft7">scientific document to a simple series of probabilistic steps.<br>The model not only discovers what topics are expressed in a<br>document, but also which authors are associated with each<br>topic. To simplify the representation of documents, we use<br>a bag of words assumption that reduces each document to a</span></nobr></DIV>
<DIV style="position:absolute;top:54;left:692"><nobr><span class="ft5"><b>Research Track Paper</b></span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:460"><nobr><span class="ft6">307</span></nobr></DIV>
</DIV>
<!-- Page 3 -->
<a name="3"></a>
<DIV style="position:relative;width:928;height:1263;">
<STYLE type="text/css">
<!--
	.ft8{font-size:14px;font-family:Times;color:#000000;}
	.ft9{font-size:6px;font-family:Times;color:#000000;}
	.ft10{font-size:7px;font-family:Times;color:#000000;}
	.ft11{font-size:5px;font-family:Times;color:#000000;}
	.ft12{font-size:11px;line-height:16px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="928" height="1263" src="151003.png" alt="background image">
<DIV style="position:absolute;top:135;left:269"><nobr><span class="ft8"><i>x</i></span></nobr></DIV>
<DIV style="position:absolute;top:184;left:270"><nobr><span class="ft8"><i>z</i></span></nobr></DIV>
<DIV style="position:absolute;top:233;left:267"><nobr><span class="ft8"><i>w</i></span></nobr></DIV>
<DIV style="position:absolute;top:261;left:313"><nobr><span class="ft4">D</span></nobr></DIV>
<DIV style="position:absolute;top:231;left:182"><nobr><span class="ft1"></span></nobr></DIV>
<DIV style="position:absolute;top:231;left:123"><nobr><span class="ft1"></span></nobr></DIV>
<DIV style="position:absolute;top:133;left:118"><nobr><span class="ft1"></span></nobr></DIV>
<DIV style="position:absolute;top:135;left:178"><nobr><span class="ft1"></span></nobr></DIV>
<DIV style="position:absolute;top:164;left:200"><nobr><span class="ft9"><i>K</i></span></nobr></DIV>
<DIV style="position:absolute;top:261;left:200"><nobr><span class="ft4">T</span></nobr></DIV>
<DIV style="position:absolute;top:96;left:277"><nobr><span class="ft10"><b>d</b></span></nobr></DIV>
<DIV style="position:absolute;top:85;left:267"><nobr><span class="ft8"><i>a</i></span></nobr></DIV>
<DIV style="position:absolute;top:87;left:346"><nobr><span class="ft10"><b>Given the set of </b></span></nobr></DIV>
<DIV style="position:absolute;top:99;left:346"><nobr><span class="ft10"><b>co-authors:</b></span></nobr></DIV>
<DIV style="position:absolute;top:254;left:288"><nobr><span class="ft4">N</span></nobr></DIV>
<DIV style="position:absolute;top:260;left:296"><nobr><span class="ft11"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:138;left:349"><nobr><span class="ft10"><b>1. Choose an author</b></span></nobr></DIV>
<DIV style="position:absolute;top:185;left:349"><nobr><span class="ft10"><b>2. Choose a topic </b></span></nobr></DIV>
<DIV style="position:absolute;top:197;left:362"><nobr><span class="ft10"><b>given the author</b></span></nobr></DIV>
<DIV style="position:absolute;top:236;left:349"><nobr><span class="ft10"><b>3. Choose a word</b></span></nobr></DIV>
<DIV style="position:absolute;top:248;left:359"><nobr><span class="ft10"><b>given the topic</b></span></nobr></DIV>
<DIV style="position:absolute;top:298;left:93"><nobr><span class="ft7">Figure 1: The graphical model for the author-topic<br>model using plate notation.</span></nobr></DIV>
<DIV style="position:absolute;top:360;left:93"><nobr><span class="ft7">vector of counts, where each vector element corresponds to<br>the number of times a term appears in the document.</span></nobr></DIV>
<DIV style="position:absolute;top:392;left:107"><nobr><span class="ft3">Each author is associated with a multinomial distribution</span></nobr></DIV>
<DIV style="position:absolute;top:407;left:93"><nobr><span class="ft7">over topics. A document with multiple authors has a dis-<br>tribution over topics that is a mixture of the distributions<br>associated with the authors. When generating a document,<br>an author is chosen at random for each individual word in<br>the document. This author picks a topic from his or her<br>multinomial distribution over topics, and then samples a<br>word from the multinomial distribution over words associ-<br>ated with that topic. This process is repeated for all words<br>in the document.</span></nobr></DIV>
<DIV style="position:absolute;top:548;left:107"><nobr><span class="ft3">In the model, the authors produce words from a set of</span></nobr></DIV>
<DIV style="position:absolute;top:565;left:93"><nobr><span class="ft3">T</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:109"><nobr><span class="ft3">topics. When T is kept relatively small relative to the</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:93"><nobr><span class="ft7">number of authors and vocabulary size, the author-topic<br>model applies a form of dimensionality reduction to docu-<br>ments; topics are learned which capture the variability in<br>word choice across a large set of documents and authors.<br>In our simulations, we use 300 topics (see Rosen-Zvi et al.<br>(2004) for an exploration of different numbers of topics).</span></nobr></DIV>
<DIV style="position:absolute;top:674;left:107"><nobr><span class="ft3">Figure 1 illustrates the generative process with a graph-</span></nobr></DIV>
<DIV style="position:absolute;top:690;left:93"><nobr><span class="ft7">ical model using plate notation. For readers not familiar<br>with plate notation, shaded and unshaded variables indi-<br>cate observed and latent variables respectively. An arrow<br>indicates a conditional dependency between variables and<br>plates (the boxes in the figure) indicate repeated sampling<br>with the number of repetitions given by the variable in the<br>bottom (see Buntine (1994) for an introduction). In the<br>author-topic model, observed variables not only include the<br>words w in a document but also the set of coauthors A</span></nobr></DIV>
<DIV style="position:absolute;top:821;left:426"><nobr><span class="ft9"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:815;left:438"><nobr><span class="ft3">on</span></nobr></DIV>
<DIV style="position:absolute;top:831;left:93"><nobr><span class="ft7">each document d. Currently, the model does not specify the<br>generative process of how authors choose to collaborate. In-<br>stead, we assume the model is provided with the authorship<br>information on every document in the collection.</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:107"><nobr><span class="ft3">Each author (from a set of K authors) is associated with</span></nobr></DIV>
<DIV style="position:absolute;top:909;left:93"><nobr><span class="ft7">a multinomial distribution over topics, represented by .<br>Each topic is associated with a multinomial distribution over<br>words, represented by . The multinomial distributions <br>and  have a symmetric Dirichlet prior with hyperparame-<br>ters  and  (see Rosen-Zvi et al. (2004) for details). For<br>each word in the document, we sample an author x uni-<br>formly from A</span></nobr></DIV>
<DIV style="position:absolute;top:1009;left:179"><nobr><span class="ft9"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:185"><nobr><span class="ft3">, then sample a topic z from the multinomial</span></nobr></DIV>
<DIV style="position:absolute;top:1019;left:93"><nobr><span class="ft12">distribution  associated with author x and sample a word<br>w</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:109"><nobr><span class="ft3">from a multinomial topic distribution  associated with</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:93"><nobr><span class="ft7">topic z. This sampling process is repeated N times to form<br>document d.</span></nobr></DIV>
<DIV style="position:absolute;top:79;left:488"><nobr><span class="ft1">2.2 Bayesian Estimation of the Model Param-</span></nobr></DIV>
<DIV style="position:absolute;top:95;left:528"><nobr><span class="ft1">eters</span></nobr></DIV>
<DIV style="position:absolute;top:121;left:501"><nobr><span class="ft3">The author-topic model includes two sets of unknown</span></nobr></DIV>
<DIV style="position:absolute;top:137;left:488"><nobr><span class="ft7">parameters--the K author-topic distributions , and the T<br>topic distributions --as well as the latent variables corre-<br>sponding to the assignments of individual words to topics z<br>and authors x. The Expectation-Maximization (EM) algo-<br>rithm is a standard technique for estimating parameters in<br>models with latent variables, finding a mode of the poste-<br>rior distribution over parameters. However, when applied to<br>probabilistic topic models (Hofmann, 1999), this approach<br>is susceptible to local maxima and computationally ineffi-<br>cient (see Blei, Ng, and Jordan, 2003). We pursue an alter-<br>native parameter estimation strategy, outlined by Griffiths<br>and Steyvers (2004), using Gibbs sampling, a Markov chain<br>Monte Carlo algorithm to sample from the posterior distri-<br>bution over parameters. Instead of estimating the model<br>parameters directly, we evaluate the posterior distribution<br>on just x and z and then use the results to infer  and .</span></nobr></DIV>
<DIV style="position:absolute;top:388;left:501"><nobr><span class="ft3">For each word, the topic and author assignment are sam-</span></nobr></DIV>
<DIV style="position:absolute;top:404;left:488"><nobr><span class="ft3">pled from:</span></nobr></DIV>
<DIV style="position:absolute;top:433;left:545"><nobr><span class="ft3">P</span></nobr></DIV>
<DIV style="position:absolute;top:433;left:558"><nobr><span class="ft3">(z</span></nobr></DIV>
<DIV style="position:absolute;top:438;left:570"><nobr><span class="ft9"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:433;left:578"><nobr><span class="ft3">= j, x</span></nobr></DIV>
<DIV style="position:absolute;top:438;left:612"><nobr><span class="ft9"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:433;left:621"><nobr><span class="ft3">= k|w</span></nobr></DIV>
<DIV style="position:absolute;top:438;left:657"><nobr><span class="ft9"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:433;left:666"><nobr><span class="ft3">= m, z</span></nobr></DIV>
<DIV style="position:absolute;top:442;left:706"><nobr><span class="ft9"><i>-i</i></span></nobr></DIV>
<DIV style="position:absolute;top:433;left:719"><nobr><span class="ft3">,</span></nobr></DIV>
<DIV style="position:absolute;top:433;left:725"><nobr><span class="ft3">x</span></nobr></DIV>
<DIV style="position:absolute;top:442;left:733"><nobr><span class="ft9"><i>-i</i></span></nobr></DIV>
<DIV style="position:absolute;top:433;left:747"><nobr><span class="ft3">)</span></nobr></DIV>
<DIV style="position:absolute;top:433;left:766"><nobr><span class="ft3"></span></nobr></DIV>
<DIV style="position:absolute;top:455;left:578"><nobr><span class="ft3">C</span></nobr></DIV>
<DIV style="position:absolute;top:452;left:589"><nobr><span class="ft9"><i>W T</i></span></nobr></DIV>
<DIV style="position:absolute;top:461;left:588"><nobr><span class="ft9"><i>mj</i></span></nobr></DIV>
<DIV style="position:absolute;top:455;left:613"><nobr><span class="ft3">+ </span></nobr></DIV>
<DIV style="position:absolute;top:481;left:572"><nobr><span class="ft9"><i>m</i></span></nobr></DIV>
<DIV style="position:absolute;top:474;left:589"><nobr><span class="ft3">C</span></nobr></DIV>
<DIV style="position:absolute;top:473;left:599"><nobr><span class="ft9"><i>W T</i></span></nobr></DIV>
<DIV style="position:absolute;top:482;left:598"><nobr><span class="ft9"><i>m j</i></span></nobr></DIV>
<DIV style="position:absolute;top:473;left:623"><nobr><span class="ft3">+ V </span></nobr></DIV>
<DIV style="position:absolute;top:455;left:678"><nobr><span class="ft3">C</span></nobr></DIV>
<DIV style="position:absolute;top:452;left:689"><nobr><span class="ft9"><i>AT</i></span></nobr></DIV>
<DIV style="position:absolute;top:461;left:688"><nobr><span class="ft9"><i>kj</i></span></nobr></DIV>
<DIV style="position:absolute;top:454;left:709"><nobr><span class="ft3">+ </span></nobr></DIV>
<DIV style="position:absolute;top:481;left:675"><nobr><span class="ft9"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:474;left:687"><nobr><span class="ft3">C</span></nobr></DIV>
<DIV style="position:absolute;top:473;left:698"><nobr><span class="ft9"><i>AT</i></span></nobr></DIV>
<DIV style="position:absolute;top:482;left:697"><nobr><span class="ft9"><i>kj</i></span></nobr></DIV>
<DIV style="position:absolute;top:473;left:718"><nobr><span class="ft3">+ T </span></nobr></DIV>
<DIV style="position:absolute;top:464;left:829"><nobr><span class="ft3">(1)</span></nobr></DIV>
<DIV style="position:absolute;top:504;left:501"><nobr><span class="ft3">where z</span></nobr></DIV>
<DIV style="position:absolute;top:509;left:550"><nobr><span class="ft9"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:504;left:561"><nobr><span class="ft3">= j and x</span></nobr></DIV>
<DIV style="position:absolute;top:509;left:628"><nobr><span class="ft9"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:504;left:639"><nobr><span class="ft3">= k represent the assignments of</span></nobr></DIV>
<DIV style="position:absolute;top:520;left:488"><nobr><span class="ft7">the ith word in a document to topic j and author k respec-<br>tively, w</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:539"><nobr><span class="ft9"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:536;left:547"><nobr><span class="ft3">= m represents the observation that the ith word</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:488"><nobr><span class="ft3">is the mth word in the lexicon, and z</span></nobr></DIV>
<DIV style="position:absolute;top:560;left:724"><nobr><span class="ft9"><i>-i</i></span></nobr></DIV>
<DIV style="position:absolute;top:552;left:737"><nobr><span class="ft3">,</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:744"><nobr><span class="ft3">x</span></nobr></DIV>
<DIV style="position:absolute;top:560;left:752"><nobr><span class="ft9"><i>-i</i></span></nobr></DIV>
<DIV style="position:absolute;top:551;left:771"><nobr><span class="ft3">represent all</span></nobr></DIV>
<DIV style="position:absolute;top:567;left:488"><nobr><span class="ft7">topic and author assignments not including the ith word.<br>Furthermore, C</span></nobr></DIV>
<DIV style="position:absolute;top:581;left:585"><nobr><span class="ft9"><i>W T</i></span></nobr></DIV>
<DIV style="position:absolute;top:589;left:584"><nobr><span class="ft9"><i>mj</i></span></nobr></DIV>
<DIV style="position:absolute;top:583;left:611"><nobr><span class="ft3">is the number of times word m is as-</span></nobr></DIV>
<DIV style="position:absolute;top:598;left:488"><nobr><span class="ft12">signed to topic j, not including the current instance, and<br>C</span></nobr></DIV>
<DIV style="position:absolute;top:612;left:499"><nobr><span class="ft9"><i>AT</i></span></nobr></DIV>
<DIV style="position:absolute;top:621;left:498"><nobr><span class="ft9"><i>kj</i></span></nobr></DIV>
<DIV style="position:absolute;top:614;left:520"><nobr><span class="ft3">is the number of times author k is assigned to topic j,</span></nobr></DIV>
<DIV style="position:absolute;top:630;left:488"><nobr><span class="ft7">not including the current instance, and V is the size of the<br>lexicon.</span></nobr></DIV>
<DIV style="position:absolute;top:661;left:501"><nobr><span class="ft3">During parameter estimation, the algorithm only needs to</span></nobr></DIV>
<DIV style="position:absolute;top:677;left:488"><nobr><span class="ft12">keep track of a V × T (word by topic) count matrix, and a<br>K</span></nobr></DIV>
<DIV style="position:absolute;top:693;left:502"><nobr><span class="ft3">× T (author by topic) count matrix, both of which can be</span></nobr></DIV>
<DIV style="position:absolute;top:708;left:488"><nobr><span class="ft12">represented efficiently in sparse format. From these count<br>matrices, we can easily estimate the topic-word distributions<br></span></nobr></DIV>
<DIV style="position:absolute;top:740;left:501"><nobr><span class="ft3">and author-topic distributions  by:</span></nobr></DIV>
<DIV style="position:absolute;top:779;left:585"><nobr><span class="ft3"></span></nobr></DIV>
<DIV style="position:absolute;top:784;left:593"><nobr><span class="ft9"><i>mj</i></span></nobr></DIV>
<DIV style="position:absolute;top:779;left:622"><nobr><span class="ft3">=</span></nobr></DIV>
<DIV style="position:absolute;top:770;left:670"><nobr><span class="ft3">C</span></nobr></DIV>
<DIV style="position:absolute;top:767;left:681"><nobr><span class="ft9"><i>W T</i></span></nobr></DIV>
<DIV style="position:absolute;top:776;left:680"><nobr><span class="ft9"><i>mj</i></span></nobr></DIV>
<DIV style="position:absolute;top:769;left:704"><nobr><span class="ft3">+ </span></nobr></DIV>
<DIV style="position:absolute;top:796;left:663"><nobr><span class="ft9"><i>m</i></span></nobr></DIV>
<DIV style="position:absolute;top:789;left:680"><nobr><span class="ft3">C</span></nobr></DIV>
<DIV style="position:absolute;top:787;left:691"><nobr><span class="ft9"><i>W T</i></span></nobr></DIV>
<DIV style="position:absolute;top:796;left:690"><nobr><span class="ft9"><i>m j</i></span></nobr></DIV>
<DIV style="position:absolute;top:788;left:714"><nobr><span class="ft3">+ V </span></nobr></DIV>
<DIV style="position:absolute;top:779;left:829"><nobr><span class="ft3">(2)</span></nobr></DIV>
<DIV style="position:absolute;top:823;left:591"><nobr><span class="ft3"></span></nobr></DIV>
<DIV style="position:absolute;top:827;left:597"><nobr><span class="ft9"><i>kj</i></span></nobr></DIV>
<DIV style="position:absolute;top:822;left:622"><nobr><span class="ft3">=</span></nobr></DIV>
<DIV style="position:absolute;top:813;left:667"><nobr><span class="ft3">C</span></nobr></DIV>
<DIV style="position:absolute;top:810;left:678"><nobr><span class="ft9"><i>AT</i></span></nobr></DIV>
<DIV style="position:absolute;top:819;left:677"><nobr><span class="ft9"><i>kj</i></span></nobr></DIV>
<DIV style="position:absolute;top:812;left:698"><nobr><span class="ft3">+ </span></nobr></DIV>
<DIV style="position:absolute;top:839;left:663"><nobr><span class="ft9"><i>j</i></span></nobr></DIV>
<DIV style="position:absolute;top:832;left:675"><nobr><span class="ft3">C</span></nobr></DIV>
<DIV style="position:absolute;top:831;left:686"><nobr><span class="ft9"><i>AT</i></span></nobr></DIV>
<DIV style="position:absolute;top:840;left:685"><nobr><span class="ft9"><i>kj</i></span></nobr></DIV>
<DIV style="position:absolute;top:832;left:706"><nobr><span class="ft3">+ T </span></nobr></DIV>
<DIV style="position:absolute;top:822;left:829"><nobr><span class="ft3">(3)</span></nobr></DIV>
<DIV style="position:absolute;top:862;left:488"><nobr><span class="ft3">where </span></nobr></DIV>
<DIV style="position:absolute;top:867;left:535"><nobr><span class="ft9"><i>mj</i></span></nobr></DIV>
<DIV style="position:absolute;top:862;left:555"><nobr><span class="ft3">is the probability of using word m in topic j, and</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:488"><nobr><span class="ft3"></span></nobr></DIV>
<DIV style="position:absolute;top:883;left:494"><nobr><span class="ft9"><i>kj</i></span></nobr></DIV>
<DIV style="position:absolute;top:878;left:512"><nobr><span class="ft3">is the probability of using topic j by author k. These</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:488"><nobr><span class="ft7">values correspond to the predictive distributions over new<br>words w and new topics z conditioned on w and z.</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:501"><nobr><span class="ft3">We start the algorithm by assigning words to random top-</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:488"><nobr><span class="ft7">ics and authors (from the set of authors on the document).<br>Each Gibbs sample then constitutes applying Equation (1)<br>to every word token in the document collection. This sam-<br>pling process is repeated for I iterations. In this paper we<br>primarily focus on results based on a single sample so that<br>specific topics can be identified and interpreted--in tasks in-<br>volving prediction of words and authors one can average over<br>topics and use multiple samples when doing so (Rosen-Zvi<br>et al., 2004).</span></nobr></DIV>
<DIV style="position:absolute;top:54;left:91"><nobr><span class="ft5"><b>Research Track Paper</b></span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:460"><nobr><span class="ft6">308</span></nobr></DIV>
</DIV>
<!-- Page 4 -->
<a name="4"></a>
<DIV style="position:relative;width:928;height:1263;">
<STYLE type="text/css">
<!--
	.ft13{font-size:4px;font-family:Times;color:#000000;}
	.ft14{font-size:15px;line-height:32px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="928" height="1263" src="151004.png" alt="background image">
<DIV style="position:absolute;top:123;left:114"><nobr><span class="ft13"><b>WORD</b></span></nobr></DIV>
<DIV style="position:absolute;top:123;left:153"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:123;left:206"><nobr><span class="ft13"><b>WORD</b></span></nobr></DIV>
<DIV style="position:absolute;top:123;left:245"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:123;left:297"><nobr><span class="ft13"><b>WORD</b></span></nobr></DIV>
<DIV style="position:absolute;top:123;left:336"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:123;left:389"><nobr><span class="ft13"><b>WORD</b></span></nobr></DIV>
<DIV style="position:absolute;top:123;left:428"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:133;left:106"><nobr><span class="ft13"><b>PATTERNS</b></span></nobr></DIV>
<DIV style="position:absolute;top:133;left:154"><nobr><span class="ft13"><b>0.1965</b></span></nobr></DIV>
<DIV style="position:absolute;top:133;left:206"><nobr><span class="ft13"><b>USER</b></span></nobr></DIV>
<DIV style="position:absolute;top:133;left:246"><nobr><span class="ft13"><b>0.3290</b></span></nobr></DIV>
<DIV style="position:absolute;top:133;left:290"><nobr><span class="ft13"><b>MAGNETIC</b></span></nobr></DIV>
<DIV style="position:absolute;top:133;left:337"><nobr><span class="ft13"><b>0.0155</b></span></nobr></DIV>
<DIV style="position:absolute;top:133;left:383"><nobr><span class="ft13"><b>METHODS</b></span></nobr></DIV>
<DIV style="position:absolute;top:133;left:429"><nobr><span class="ft13"><b>0.5319</b></span></nobr></DIV>
<DIV style="position:absolute;top:143;left:108"><nobr><span class="ft13"><b>PATTERN</b></span></nobr></DIV>
<DIV style="position:absolute;top:143;left:154"><nobr><span class="ft13"><b>0.1821</b></span></nobr></DIV>
<DIV style="position:absolute;top:143;left:197"><nobr><span class="ft13"><b>INTERFACE</b></span></nobr></DIV>
<DIV style="position:absolute;top:143;left:246"><nobr><span class="ft13"><b>0.1378</b></span></nobr></DIV>
<DIV style="position:absolute;top:143;left:296"><nobr><span class="ft13"><b>STARS</b></span></nobr></DIV>
<DIV style="position:absolute;top:143;left:337"><nobr><span class="ft13"><b>0.0145</b></span></nobr></DIV>
<DIV style="position:absolute;top:143;left:385"><nobr><span class="ft13"><b>METHOD</b></span></nobr></DIV>
<DIV style="position:absolute;top:143;left:429"><nobr><span class="ft13"><b>0.1403</b></span></nobr></DIV>
<DIV style="position:absolute;top:153;left:107"><nobr><span class="ft13"><b>MATCHING</b></span></nobr></DIV>
<DIV style="position:absolute;top:153;left:154"><nobr><span class="ft13"><b>0.1375</b></span></nobr></DIV>
<DIV style="position:absolute;top:153;left:204"><nobr><span class="ft13"><b>USERS</b></span></nobr></DIV>
<DIV style="position:absolute;top:153;left:246"><nobr><span class="ft13"><b>0.1060</b></span></nobr></DIV>
<DIV style="position:absolute;top:153;left:296"><nobr><span class="ft13"><b>SOLAR</b></span></nobr></DIV>
<DIV style="position:absolute;top:153;left:337"><nobr><span class="ft13"><b>0.0135</b></span></nobr></DIV>
<DIV style="position:absolute;top:153;left:378"><nobr><span class="ft13"><b>TECHNIQUES</b></span></nobr></DIV>
<DIV style="position:absolute;top:153;left:429"><nobr><span class="ft13"><b>0.0442</b></span></nobr></DIV>
<DIV style="position:absolute;top:163;left:112"><nobr><span class="ft13"><b>MATCH</b></span></nobr></DIV>
<DIV style="position:absolute;top:163;left:154"><nobr><span class="ft13"><b>0.0337</b></span></nobr></DIV>
<DIV style="position:absolute;top:163;left:195"><nobr><span class="ft13"><b>INTERFACES</b></span></nobr></DIV>
<DIV style="position:absolute;top:163;left:246"><nobr><span class="ft13"><b>0.0498</b></span></nobr></DIV>
<DIV style="position:absolute;top:163;left:291"><nobr><span class="ft13"><b>EMISSION</b></span></nobr></DIV>
<DIV style="position:absolute;top:163;left:337"><nobr><span class="ft13"><b>0.0127</b></span></nobr></DIV>
<DIV style="position:absolute;top:163;left:379"><nobr><span class="ft13"><b>DEVELOPED</b></span></nobr></DIV>
<DIV style="position:absolute;top:163;left:429"><nobr><span class="ft13"><b>0.0216</b></span></nobr></DIV>
<DIV style="position:absolute;top:172;left:115"><nobr><span class="ft13"><b>TEXT</b></span></nobr></DIV>
<DIV style="position:absolute;top:172;left:154"><nobr><span class="ft13"><b>0.0242</b></span></nobr></DIV>
<DIV style="position:absolute;top:172;left:203"><nobr><span class="ft13"><b>SYSTEM</b></span></nobr></DIV>
<DIV style="position:absolute;top:172;left:246"><nobr><span class="ft13"><b>0.0434</b></span></nobr></DIV>
<DIV style="position:absolute;top:172;left:298"><nobr><span class="ft13"><b>MASS</b></span></nobr></DIV>
<DIV style="position:absolute;top:172;left:337"><nobr><span class="ft13"><b>0.0125</b></span></nobr></DIV>
<DIV style="position:absolute;top:172;left:385"><nobr><span class="ft13"><b>APPLIED</b></span></nobr></DIV>
<DIV style="position:absolute;top:172;left:429"><nobr><span class="ft13"><b>0.0162</b></span></nobr></DIV>
<DIV style="position:absolute;top:182;left:108"><nobr><span class="ft13"><b>PRESENT</b></span></nobr></DIV>
<DIV style="position:absolute;top:182;left:154"><nobr><span class="ft13"><b>0.0207</b></span></nobr></DIV>
<DIV style="position:absolute;top:182;left:194"><nobr><span class="ft13"><b>INTERACTION</b></span></nobr></DIV>
<DIV style="position:absolute;top:182;left:246"><nobr><span class="ft13"><b>0.0296</b></span></nobr></DIV>
<DIV style="position:absolute;top:182;left:282"><nobr><span class="ft13"><b>OBSERVATIONS 0.0120</b></span></nobr></DIV>
<DIV style="position:absolute;top:182;left:388"><nobr><span class="ft13"><b>BASED</b></span></nobr></DIV>
<DIV style="position:absolute;top:182;left:429"><nobr><span class="ft13"><b>0.0153</b></span></nobr></DIV>
<DIV style="position:absolute;top:192;left:108"><nobr><span class="ft13"><b>MATCHES</b></span></nobr></DIV>
<DIV style="position:absolute;top:192;left:154"><nobr><span class="ft13"><b>0.0167</b></span></nobr></DIV>
<DIV style="position:absolute;top:192;left:194"><nobr><span class="ft13"><b>INTERACTIVE</b></span></nobr></DIV>
<DIV style="position:absolute;top:192;left:246"><nobr><span class="ft13"><b>0.0214</b></span></nobr></DIV>
<DIV style="position:absolute;top:192;left:298"><nobr><span class="ft13"><b>STAR</b></span></nobr></DIV>
<DIV style="position:absolute;top:192;left:337"><nobr><span class="ft13"><b>0.0118</b></span></nobr></DIV>
<DIV style="position:absolute;top:192;left:377"><nobr><span class="ft13"><b>APPROACHES</b></span></nobr></DIV>
<DIV style="position:absolute;top:192;left:429"><nobr><span class="ft13"><b>0.0133</b></span></nobr></DIV>
<DIV style="position:absolute;top:202;left:113"><nobr><span class="ft13"><b>PAPER</b></span></nobr></DIV>
<DIV style="position:absolute;top:202;left:154"><nobr><span class="ft13"><b>0.0126</b></span></nobr></DIV>
<DIV style="position:absolute;top:202;left:199"><nobr><span class="ft13"><b>USABILITY</b></span></nobr></DIV>
<DIV style="position:absolute;top:202;left:246"><nobr><span class="ft13"><b>0.0132</b></span></nobr></DIV>
<DIV style="position:absolute;top:202;left:300"><nobr><span class="ft13"><b>RAY</b></span></nobr></DIV>
<DIV style="position:absolute;top:202;left:337"><nobr><span class="ft13"><b>0.0112</b></span></nobr></DIV>
<DIV style="position:absolute;top:202;left:383"><nobr><span class="ft13"><b>COMPARE</b></span></nobr></DIV>
<DIV style="position:absolute;top:202;left:429"><nobr><span class="ft13"><b>0.0113</b></span></nobr></DIV>
<DIV style="position:absolute;top:212;left:113"><nobr><span class="ft13"><b>SHOW</b></span></nobr></DIV>
<DIV style="position:absolute;top:212;left:154"><nobr><span class="ft13"><b>0.0124</b></span></nobr></DIV>
<DIV style="position:absolute;top:212;left:197"><nobr><span class="ft13"><b>GRAPHICAL</b></span></nobr></DIV>
<DIV style="position:absolute;top:212;left:246"><nobr><span class="ft13"><b>0.0092</b></span></nobr></DIV>
<DIV style="position:absolute;top:212;left:291"><nobr><span class="ft13"><b>GALAXIES</b></span></nobr></DIV>
<DIV style="position:absolute;top:212;left:337"><nobr><span class="ft13"><b>0.0105</b></span></nobr></DIV>
<DIV style="position:absolute;top:212;left:381"><nobr><span class="ft13"><b>PRACTICAL</b></span></nobr></DIV>
<DIV style="position:absolute;top:212;left:429"><nobr><span class="ft13"><b>0.0112</b></span></nobr></DIV>
<DIV style="position:absolute;top:222;left:106"><nobr><span class="ft13"><b>APPROACH</b></span></nobr></DIV>
<DIV style="position:absolute;top:222;left:154"><nobr><span class="ft13"><b>0.0099</b></span></nobr></DIV>
<DIV style="position:absolute;top:222;left:196"><nobr><span class="ft13"><b>PROTOTYPE</b></span></nobr></DIV>
<DIV style="position:absolute;top:222;left:246"><nobr><span class="ft13"><b>0.0086</b></span></nobr></DIV>
<DIV style="position:absolute;top:222;left:289"><nobr><span class="ft13"><b>OBSERVED</b></span></nobr></DIV>
<DIV style="position:absolute;top:222;left:337"><nobr><span class="ft13"><b>0.0098</b></span></nobr></DIV>
<DIV style="position:absolute;top:222;left:381"><nobr><span class="ft13"><b>STANDARD</b></span></nobr></DIV>
<DIV style="position:absolute;top:222;left:429"><nobr><span class="ft13"><b>0.0102</b></span></nobr></DIV>
<DIV style="position:absolute;top:241;left:110"><nobr><span class="ft13"><b>AUTHOR</b></span></nobr></DIV>
<DIV style="position:absolute;top:241;left:153"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:241;left:202"><nobr><span class="ft13"><b>AUTHOR</b></span></nobr></DIV>
<DIV style="position:absolute;top:241;left:245"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:241;left:293"><nobr><span class="ft13"><b>AUTHOR</b></span></nobr></DIV>
<DIV style="position:absolute;top:241;left:336"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:241;left:385"><nobr><span class="ft13"><b>AUTHOR</b></span></nobr></DIV>
<DIV style="position:absolute;top:241;left:428"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:251;left:108"><nobr><span class="ft13"><b>Navarro_G</b></span></nobr></DIV>
<DIV style="position:absolute;top:251;left:154"><nobr><span class="ft13"><b>0.0133</b></span></nobr></DIV>
<DIV style="position:absolute;top:251;left:193"><nobr><span class="ft13"><b>Shneiderman_B</b></span></nobr></DIV>
<DIV style="position:absolute;top:251;left:246"><nobr><span class="ft13"><b>0.0051</b></span></nobr></DIV>
<DIV style="position:absolute;top:251;left:294"><nobr><span class="ft13"><b>Falcke_H</b></span></nobr></DIV>
<DIV style="position:absolute;top:251;left:337"><nobr><span class="ft13"><b>0.0140</b></span></nobr></DIV>
<DIV style="position:absolute;top:251;left:381"><nobr><span class="ft13"><b>Srinivasan_A</b></span></nobr></DIV>
<DIV style="position:absolute;top:251;left:429"><nobr><span class="ft13"><b>0.0018</b></span></nobr></DIV>
<DIV style="position:absolute;top:261;left:113"><nobr><span class="ft13"><b>Amir_A</b></span></nobr></DIV>
<DIV style="position:absolute;top:261;left:154"><nobr><span class="ft13"><b>0.0099</b></span></nobr></DIV>
<DIV style="position:absolute;top:261;left:196"><nobr><span class="ft13"><b>Rauterberg_M</b></span></nobr></DIV>
<DIV style="position:absolute;top:261;left:246"><nobr><span class="ft13"><b>0.0046</b></span></nobr></DIV>
<DIV style="position:absolute;top:261;left:294"><nobr><span class="ft13"><b>Linsky_J</b></span></nobr></DIV>
<DIV style="position:absolute;top:261;left:337"><nobr><span class="ft13"><b>0.0082</b></span></nobr></DIV>
<DIV style="position:absolute;top:261;left:384"><nobr><span class="ft13"><b>Mooney_R</b></span></nobr></DIV>
<DIV style="position:absolute;top:261;left:429"><nobr><span class="ft13"><b>0.0018</b></span></nobr></DIV>
<DIV style="position:absolute;top:271;left:106"><nobr><span class="ft13"><b>Gasieniec_L</b></span></nobr></DIV>
<DIV style="position:absolute;top:271;left:154"><nobr><span class="ft13"><b>0.0062</b></span></nobr></DIV>
<DIV style="position:absolute;top:271;left:199"><nobr><span class="ft13"><b>Harrison_M</b></span></nobr></DIV>
<DIV style="position:absolute;top:271;left:246"><nobr><span class="ft13"><b>0.0025</b></span></nobr></DIV>
<DIV style="position:absolute;top:271;left:294"><nobr><span class="ft13"><b>Butler_R</b></span></nobr></DIV>
<DIV style="position:absolute;top:271;left:337"><nobr><span class="ft13"><b>0.0077</b></span></nobr></DIV>
<DIV style="position:absolute;top:271;left:386"><nobr><span class="ft13"><b>Owren_B</b></span></nobr></DIV>
<DIV style="position:absolute;top:271;left:429"><nobr><span class="ft13"><b>0.0018</b></span></nobr></DIV>
<DIV style="position:absolute;top:281;left:102"><nobr><span class="ft13"><b>Baeza-Yates_R</b></span></nobr></DIV>
<DIV style="position:absolute;top:281;left:154"><nobr><span class="ft13"><b>0.0048</b></span></nobr></DIV>
<DIV style="position:absolute;top:281;left:196"><nobr><span class="ft13"><b>Winiwarter_W</b></span></nobr></DIV>
<DIV style="position:absolute;top:281;left:246"><nobr><span class="ft13"><b>0.0024</b></span></nobr></DIV>
<DIV style="position:absolute;top:281;left:294"><nobr><span class="ft13"><b>Knapp_G</b></span></nobr></DIV>
<DIV style="position:absolute;top:281;left:337"><nobr><span class="ft13"><b>0.0067</b></span></nobr></DIV>
<DIV style="position:absolute;top:281;left:383"><nobr><span class="ft13"><b>Warnow_T</b></span></nobr></DIV>
<DIV style="position:absolute;top:281;left:429"><nobr><span class="ft13"><b>0.0016</b></span></nobr></DIV>
<DIV style="position:absolute;top:291;left:112"><nobr><span class="ft13"><b>Baker_B</b></span></nobr></DIV>
<DIV style="position:absolute;top:291;left:154"><nobr><span class="ft13"><b>0.0042</b></span></nobr></DIV>
<DIV style="position:absolute;top:291;left:198"><nobr><span class="ft13"><b>Ardissono_L</b></span></nobr></DIV>
<DIV style="position:absolute;top:291;left:246"><nobr><span class="ft13"><b>0.0021</b></span></nobr></DIV>
<DIV style="position:absolute;top:291;left:290"><nobr><span class="ft13"><b>Bjorkman_K</b></span></nobr></DIV>
<DIV style="position:absolute;top:291;left:337"><nobr><span class="ft13"><b>0.0065</b></span></nobr></DIV>
<DIV style="position:absolute;top:291;left:385"><nobr><span class="ft13"><b>Fensel_D</b></span></nobr></DIV>
<DIV style="position:absolute;top:291;left:429"><nobr><span class="ft13"><b>0.0016</b></span></nobr></DIV>
<DIV style="position:absolute;top:300;left:109"><nobr><span class="ft13"><b>Arikawa_S</b></span></nobr></DIV>
<DIV style="position:absolute;top:300;left:154"><nobr><span class="ft13"><b>0.0041</b></span></nobr></DIV>
<DIV style="position:absolute;top:300;left:202"><nobr><span class="ft13"><b>Billsus_D</b></span></nobr></DIV>
<DIV style="position:absolute;top:300;left:246"><nobr><span class="ft13"><b>0.0019</b></span></nobr></DIV>
<DIV style="position:absolute;top:300;left:293"><nobr><span class="ft13"><b>Kundu_M</b></span></nobr></DIV>
<DIV style="position:absolute;top:300;left:337"><nobr><span class="ft13"><b>0.0060</b></span></nobr></DIV>
<DIV style="position:absolute;top:300;left:385"><nobr><span class="ft13"><b>Godsill_S</b></span></nobr></DIV>
<DIV style="position:absolute;top:300;left:429"><nobr><span class="ft13"><b>0.0014</b></span></nobr></DIV>
<DIV style="position:absolute;top:310;left:102"><nobr><span class="ft13"><b>Crochemore_M</b></span></nobr></DIV>
<DIV style="position:absolute;top:310;left:154"><nobr><span class="ft13"><b>0.0037</b></span></nobr></DIV>
<DIV style="position:absolute;top:310;left:202"><nobr><span class="ft13"><b>Catarci_T</b></span></nobr></DIV>
<DIV style="position:absolute;top:310;left:246"><nobr><span class="ft13"><b>0.0017</b></span></nobr></DIV>
<DIV style="position:absolute;top:310;left:283"><nobr><span class="ft13"><b>Christensen-D_J 0.0057</b></span></nobr></DIV>
<DIV style="position:absolute;top:310;left:388"><nobr><span class="ft13"><b>Saad_Y</b></span></nobr></DIV>
<DIV style="position:absolute;top:310;left:429"><nobr><span class="ft13"><b>0.0014</b></span></nobr></DIV>
<DIV style="position:absolute;top:320;left:110"><nobr><span class="ft13"><b>Rytter_W</b></span></nobr></DIV>
<DIV style="position:absolute;top:320;left:154"><nobr><span class="ft13"><b>0.0034</b></span></nobr></DIV>
<DIV style="position:absolute;top:320;left:208"><nobr><span class="ft13"><b>St_R</b></span></nobr></DIV>
<DIV style="position:absolute;top:320;left:246"><nobr><span class="ft13"><b>0.0017</b></span></nobr></DIV>
<DIV style="position:absolute;top:320;left:292"><nobr><span class="ft13"><b>Mursula_K</b></span></nobr></DIV>
<DIV style="position:absolute;top:320;left:337"><nobr><span class="ft13"><b>0.0054</b></span></nobr></DIV>
<DIV style="position:absolute;top:320;left:385"><nobr><span class="ft13"><b>Hansen_J</b></span></nobr></DIV>
<DIV style="position:absolute;top:320;left:429"><nobr><span class="ft13"><b>0.0013</b></span></nobr></DIV>
<DIV style="position:absolute;top:330;left:108"><nobr><span class="ft13"><b>Raffinot_M</b></span></nobr></DIV>
<DIV style="position:absolute;top:330;left:154"><nobr><span class="ft13"><b>0.0032</b></span></nobr></DIV>
<DIV style="position:absolute;top:330;left:202"><nobr><span class="ft13"><b>Picard_R</b></span></nobr></DIV>
<DIV style="position:absolute;top:330;left:246"><nobr><span class="ft13"><b>0.0016</b></span></nobr></DIV>
<DIV style="position:absolute;top:330;left:291"><nobr><span class="ft13"><b>Cranmer_S</b></span></nobr></DIV>
<DIV style="position:absolute;top:330;left:337"><nobr><span class="ft13"><b>0.0051</b></span></nobr></DIV>
<DIV style="position:absolute;top:330;left:386"><nobr><span class="ft13"><b>Zhang_Y</b></span></nobr></DIV>
<DIV style="position:absolute;top:330;left:429"><nobr><span class="ft13"><b>0.0013</b></span></nobr></DIV>
<DIV style="position:absolute;top:340;left:108"><nobr><span class="ft13"><b>Ukkonen_E</b></span></nobr></DIV>
<DIV style="position:absolute;top:340;left:154"><nobr><span class="ft13"><b>0.0032</b></span></nobr></DIV>
<DIV style="position:absolute;top:340;left:199"><nobr><span class="ft13"><b>Zukerman_I</b></span></nobr></DIV>
<DIV style="position:absolute;top:340;left:246"><nobr><span class="ft13"><b>0.0016</b></span></nobr></DIV>
<DIV style="position:absolute;top:340;left:294"><nobr><span class="ft13"><b>Nagar_N</b></span></nobr></DIV>
<DIV style="position:absolute;top:340;left:337"><nobr><span class="ft13"><b>0.0050</b></span></nobr></DIV>
<DIV style="position:absolute;top:340;left:382"><nobr><span class="ft13"><b>Dietterich_T</b></span></nobr></DIV>
<DIV style="position:absolute;top:340;left:429"><nobr><span class="ft13"><b>0.0013</b></span></nobr></DIV>
<DIV style="position:absolute;top:383;left:114"><nobr><span class="ft13"><b>WORD</b></span></nobr></DIV>
<DIV style="position:absolute;top:383;left:153"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:383;left:206"><nobr><span class="ft13"><b>WORD</b></span></nobr></DIV>
<DIV style="position:absolute;top:383;left:245"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:383;left:297"><nobr><span class="ft13"><b>WORD</b></span></nobr></DIV>
<DIV style="position:absolute;top:383;left:336"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:383;left:389"><nobr><span class="ft13"><b>WORD</b></span></nobr></DIV>
<DIV style="position:absolute;top:383;left:428"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:393;left:115"><nobr><span class="ft13"><b>DATA</b></span></nobr></DIV>
<DIV style="position:absolute;top:393;left:154"><nobr><span class="ft13"><b>0.1622</b></span></nobr></DIV>
<DIV style="position:absolute;top:393;left:192"><nobr><span class="ft13"><b>PROBABILISTIC 0.0869</b></span></nobr></DIV>
<DIV style="position:absolute;top:393;left:289"><nobr><span class="ft13"><b>RETRIEVAL</b></span></nobr></DIV>
<DIV style="position:absolute;top:393;left:337"><nobr><span class="ft13"><b>0.1208</b></span></nobr></DIV>
<DIV style="position:absolute;top:393;left:387"><nobr><span class="ft13"><b>QUERY</b></span></nobr></DIV>
<DIV style="position:absolute;top:393;left:429"><nobr><span class="ft13"><b>0.1406</b></span></nobr></DIV>
<DIV style="position:absolute;top:403;left:112"><nobr><span class="ft13"><b>MINING</b></span></nobr></DIV>
<DIV style="position:absolute;top:403;left:154"><nobr><span class="ft13"><b>0.0657</b></span></nobr></DIV>
<DIV style="position:absolute;top:403;left:200"><nobr><span class="ft13"><b>BAYESIAN</b></span></nobr></DIV>
<DIV style="position:absolute;top:403;left:246"><nobr><span class="ft13"><b>0.0791</b></span></nobr></DIV>
<DIV style="position:absolute;top:403;left:284"><nobr><span class="ft13"><b>INFORMATION</b></span></nobr></DIV>
<DIV style="position:absolute;top:403;left:337"><nobr><span class="ft13"><b>0.0613</b></span></nobr></DIV>
<DIV style="position:absolute;top:403;left:384"><nobr><span class="ft13"><b>QUERIES</b></span></nobr></DIV>
<DIV style="position:absolute;top:403;left:429"><nobr><span class="ft13"><b>0.0947</b></span></nobr></DIV>
<DIV style="position:absolute;top:413;left:105"><nobr><span class="ft13"><b>DISCOVERY</b></span></nobr></DIV>
<DIV style="position:absolute;top:413;left:154"><nobr><span class="ft13"><b>0.0408</b></span></nobr></DIV>
<DIV style="position:absolute;top:413;left:195"><nobr><span class="ft13"><b>PROBABILITY</b></span></nobr></DIV>
<DIV style="position:absolute;top:413;left:246"><nobr><span class="ft13"><b>0.0740</b></span></nobr></DIV>
<DIV style="position:absolute;top:413;left:298"><nobr><span class="ft13"><b>TEXT</b></span></nobr></DIV>
<DIV style="position:absolute;top:413;left:337"><nobr><span class="ft13"><b>0.0461</b></span></nobr></DIV>
<DIV style="position:absolute;top:413;left:382"><nobr><span class="ft13"><b>DATABASE</b></span></nobr></DIV>
<DIV style="position:absolute;top:413;left:429"><nobr><span class="ft13"><b>0.0932</b></span></nobr></DIV>
<DIV style="position:absolute;top:422;left:104"><nobr><span class="ft13"><b>ATTRIBUTES</b></span></nobr></DIV>
<DIV style="position:absolute;top:422;left:154"><nobr><span class="ft13"><b>0.0343</b></span></nobr></DIV>
<DIV style="position:absolute;top:422;left:204"><nobr><span class="ft13"><b>MODEL</b></span></nobr></DIV>
<DIV style="position:absolute;top:422;left:246"><nobr><span class="ft13"><b>0.0533</b></span></nobr></DIV>
<DIV style="position:absolute;top:422;left:286"><nobr><span class="ft13"><b>DOCUMENTS</b></span></nobr></DIV>
<DIV style="position:absolute;top:422;left:337"><nobr><span class="ft13"><b>0.0385</b></span></nobr></DIV>
<DIV style="position:absolute;top:422;left:380"><nobr><span class="ft13"><b>DATABASES</b></span></nobr></DIV>
<DIV style="position:absolute;top:422;left:429"><nobr><span class="ft13"><b>0.0468</b></span></nobr></DIV>
<DIV style="position:absolute;top:432;left:102"><nobr><span class="ft13"><b>ASSOCIATION</b></span></nobr></DIV>
<DIV style="position:absolute;top:432;left:154"><nobr><span class="ft13"><b>0.0328</b></span></nobr></DIV>
<DIV style="position:absolute;top:432;left:202"><nobr><span class="ft13"><b>MODELS</b></span></nobr></DIV>
<DIV style="position:absolute;top:432;left:246"><nobr><span class="ft13"><b>0.0466</b></span></nobr></DIV>
<DIV style="position:absolute;top:432;left:291"><nobr><span class="ft13"><b>INDEXING</b></span></nobr></DIV>
<DIV style="position:absolute;top:432;left:337"><nobr><span class="ft13"><b>0.0369</b></span></nobr></DIV>
<DIV style="position:absolute;top:432;left:390"><nobr><span class="ft13"><b>DATA</b></span></nobr></DIV>
<DIV style="position:absolute;top:432;left:429"><nobr><span class="ft13"><b>0.0426</b></span></nobr></DIV>
<DIV style="position:absolute;top:442;left:113"><nobr><span class="ft13"><b>LARGE</b></span></nobr></DIV>
<DIV style="position:absolute;top:442;left:154"><nobr><span class="ft13"><b>0.0279</b></span></nobr></DIV>
<DIV style="position:absolute;top:442;left:192"><nobr><span class="ft13"><b>PROBABILITIES 0.0308</b></span></nobr></DIV>
<DIV style="position:absolute;top:442;left:288"><nobr><span class="ft13"><b>DOCUMENT</b></span></nobr></DIV>
<DIV style="position:absolute;top:442;left:337"><nobr><span class="ft13"><b>0.0316</b></span></nobr></DIV>
<DIV style="position:absolute;top:442;left:379"><nobr><span class="ft13"><b>RELATIONAL</b></span></nobr></DIV>
<DIV style="position:absolute;top:442;left:429"><nobr><span class="ft13"><b>0.0384</b></span></nobr></DIV>
<DIV style="position:absolute;top:452;left:104"><nobr><span class="ft13"><b>DATABASES</b></span></nobr></DIV>
<DIV style="position:absolute;top:452;left:154"><nobr><span class="ft13"><b>0.0257</b></span></nobr></DIV>
<DIV style="position:absolute;top:452;left:197"><nobr><span class="ft13"><b>INFERENCE</b></span></nobr></DIV>
<DIV style="position:absolute;top:452;left:246"><nobr><span class="ft13"><b>0.0306</b></span></nobr></DIV>
<DIV style="position:absolute;top:452;left:295"><nobr><span class="ft13"><b>QUERY</b></span></nobr></DIV>
<DIV style="position:absolute;top:452;left:337"><nobr><span class="ft13"><b>0.0261</b></span></nobr></DIV>
<DIV style="position:absolute;top:452;left:391"><nobr><span class="ft13"><b>JOIN</b></span></nobr></DIV>
<DIV style="position:absolute;top:452;left:429"><nobr><span class="ft13"><b>0.0188</b></span></nobr></DIV>
<DIV style="position:absolute;top:462;left:103"><nobr><span class="ft13"><b>KNOWLEDGE</b></span></nobr></DIV>
<DIV style="position:absolute;top:462;left:154"><nobr><span class="ft13"><b>0.0175</b></span></nobr></DIV>
<DIV style="position:absolute;top:462;left:194"><nobr><span class="ft13"><b>CONDITIONAL</b></span></nobr></DIV>
<DIV style="position:absolute;top:462;left:246"><nobr><span class="ft13"><b>0.0274</b></span></nobr></DIV>
<DIV style="position:absolute;top:462;left:291"><nobr><span class="ft13"><b>CONTENT</b></span></nobr></DIV>
<DIV style="position:absolute;top:462;left:337"><nobr><span class="ft13"><b>0.0256</b></span></nobr></DIV>
<DIV style="position:absolute;top:462;left:378"><nobr><span class="ft13"><b>PROCESSING</b></span></nobr></DIV>
<DIV style="position:absolute;top:462;left:429"><nobr><span class="ft13"><b>0.0165</b></span></nobr></DIV>
<DIV style="position:absolute;top:472;left:106"><nobr><span class="ft13"><b>PATTERNS</b></span></nobr></DIV>
<DIV style="position:absolute;top:472;left:154"><nobr><span class="ft13"><b>0.0174</b></span></nobr></DIV>
<DIV style="position:absolute;top:472;left:205"><nobr><span class="ft13"><b>PRIOR</b></span></nobr></DIV>
<DIV style="position:absolute;top:472;left:246"><nobr><span class="ft13"><b>0.0273</b></span></nobr></DIV>
<DIV style="position:absolute;top:472;left:293"><nobr><span class="ft13"><b>SEARCH</b></span></nobr></DIV>
<DIV style="position:absolute;top:472;left:337"><nobr><span class="ft13"><b>0.0174</b></span></nobr></DIV>
<DIV style="position:absolute;top:472;left:383"><nobr><span class="ft13"><b>SOURCES</b></span></nobr></DIV>
<DIV style="position:absolute;top:472;left:429"><nobr><span class="ft13"><b>0.0114</b></span></nobr></DIV>
<DIV style="position:absolute;top:482;left:114"><nobr><span class="ft13"><b>ITEMS</b></span></nobr></DIV>
<DIV style="position:absolute;top:482;left:154"><nobr><span class="ft13"><b>0.0173</b></span></nobr></DIV>
<DIV style="position:absolute;top:482;left:197"><nobr><span class="ft13"><b>POSTERIOR</b></span></nobr></DIV>
<DIV style="position:absolute;top:482;left:246"><nobr><span class="ft13"><b>0.0228</b></span></nobr></DIV>
<DIV style="position:absolute;top:482;left:287"><nobr><span class="ft13"><b>RELEVANCE</b></span></nobr></DIV>
<DIV style="position:absolute;top:482;left:337"><nobr><span class="ft13"><b>0.0171</b></span></nobr></DIV>
<DIV style="position:absolute;top:482;left:376"><nobr><span class="ft13"><b>OPTIMIZATION</b></span></nobr></DIV>
<DIV style="position:absolute;top:482;left:429"><nobr><span class="ft13"><b>0.0110</b></span></nobr></DIV>
<DIV style="position:absolute;top:501;left:110"><nobr><span class="ft13"><b>AUTHOR</b></span></nobr></DIV>
<DIV style="position:absolute;top:501;left:153"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:501;left:202"><nobr><span class="ft13"><b>AUTHOR</b></span></nobr></DIV>
<DIV style="position:absolute;top:501;left:245"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:501;left:293"><nobr><span class="ft13"><b>AUTHOR</b></span></nobr></DIV>
<DIV style="position:absolute;top:501;left:336"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:501;left:385"><nobr><span class="ft13"><b>AUTHOR</b></span></nobr></DIV>
<DIV style="position:absolute;top:501;left:428"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:511;left:114"><nobr><span class="ft13"><b>Han_J</b></span></nobr></DIV>
<DIV style="position:absolute;top:511;left:154"><nobr><span class="ft13"><b>0.0164</b></span></nobr></DIV>
<DIV style="position:absolute;top:511;left:204"><nobr><span class="ft13"><b>Koller_D</b></span></nobr></DIV>
<DIV style="position:absolute;top:511;left:246"><nobr><span class="ft13"><b>0.0104</b></span></nobr></DIV>
<DIV style="position:absolute;top:511;left:296"><nobr><span class="ft13"><b>Oard_D</b></span></nobr></DIV>
<DIV style="position:absolute;top:511;left:337"><nobr><span class="ft13"><b>0.0097</b></span></nobr></DIV>
<DIV style="position:absolute;top:511;left:389"><nobr><span class="ft13"><b>Levy_A</b></span></nobr></DIV>
<DIV style="position:absolute;top:511;left:429"><nobr><span class="ft13"><b>0.0092</b></span></nobr></DIV>
<DIV style="position:absolute;top:521;left:113"><nobr><span class="ft13"><b>Zaki_M</b></span></nobr></DIV>
<DIV style="position:absolute;top:521;left:154"><nobr><span class="ft13"><b>0.0089</b></span></nobr></DIV>
<DIV style="position:absolute;top:521;left:196"><nobr><span class="ft13"><b>Heckerman_D</b></span></nobr></DIV>
<DIV style="position:absolute;top:521;left:246"><nobr><span class="ft13"><b>0.0079</b></span></nobr></DIV>
<DIV style="position:absolute;top:521;left:291"><nobr><span class="ft13"><b>Hawking_D</b></span></nobr></DIV>
<DIV style="position:absolute;top:521;left:337"><nobr><span class="ft13"><b>0.0065</b></span></nobr></DIV>
<DIV style="position:absolute;top:521;left:382"><nobr><span class="ft13"><b>Naughton_J</b></span></nobr></DIV>
<DIV style="position:absolute;top:521;left:429"><nobr><span class="ft13"><b>0.0078</b></span></nobr></DIV>
<DIV style="position:absolute;top:531;left:115"><nobr><span class="ft13"><b>Liu_B</b></span></nobr></DIV>
<DIV style="position:absolute;top:531;left:154"><nobr><span class="ft13"><b>0.0071</b></span></nobr></DIV>
<DIV style="position:absolute;top:531;left:195"><nobr><span class="ft13"><b>Ghahramani_Z</b></span></nobr></DIV>
<DIV style="position:absolute;top:531;left:246"><nobr><span class="ft13"><b>0.0060</b></span></nobr></DIV>
<DIV style="position:absolute;top:531;left:295"><nobr><span class="ft13"><b>Croft_W</b></span></nobr></DIV>
<DIV style="position:absolute;top:531;left:337"><nobr><span class="ft13"><b>0.0057</b></span></nobr></DIV>
<DIV style="position:absolute;top:531;left:387"><nobr><span class="ft13"><b>Suciu_D</b></span></nobr></DIV>
<DIV style="position:absolute;top:531;left:429"><nobr><span class="ft13"><b>0.0075</b></span></nobr></DIV>
<DIV style="position:absolute;top:541;left:109"><nobr><span class="ft13"><b>Cheung_D</b></span></nobr></DIV>
<DIV style="position:absolute;top:541;left:154"><nobr><span class="ft13"><b>0.0066</b></span></nobr></DIV>
<DIV style="position:absolute;top:541;left:199"><nobr><span class="ft13"><b>Friedman_N</b></span></nobr></DIV>
<DIV style="position:absolute;top:541;left:246"><nobr><span class="ft13"><b>0.0060</b></span></nobr></DIV>
<DIV style="position:absolute;top:541;left:294"><nobr><span class="ft13"><b>Jones_K</b></span></nobr></DIV>
<DIV style="position:absolute;top:541;left:337"><nobr><span class="ft13"><b>0.0053</b></span></nobr></DIV>
<DIV style="position:absolute;top:541;left:384"><nobr><span class="ft13"><b>Raschid_L</b></span></nobr></DIV>
<DIV style="position:absolute;top:541;left:429"><nobr><span class="ft13"><b>0.0075</b></span></nobr></DIV>
<DIV style="position:absolute;top:550;left:112"><nobr><span class="ft13"><b>Shim_K</b></span></nobr></DIV>
<DIV style="position:absolute;top:550;left:154"><nobr><span class="ft13"><b>0.0051</b></span></nobr></DIV>
<DIV style="position:absolute;top:550;left:198"><nobr><span class="ft13"><b>Myllymaki_P</b></span></nobr></DIV>
<DIV style="position:absolute;top:550;left:246"><nobr><span class="ft13"><b>0.0057</b></span></nobr></DIV>
<DIV style="position:absolute;top:550;left:290"><nobr><span class="ft13"><b>Schauble_P</b></span></nobr></DIV>
<DIV style="position:absolute;top:550;left:337"><nobr><span class="ft13"><b>0.0052</b></span></nobr></DIV>
<DIV style="position:absolute;top:550;left:385"><nobr><span class="ft13"><b>DeWitt_D</b></span></nobr></DIV>
<DIV style="position:absolute;top:550;left:429"><nobr><span class="ft13"><b>0.0062</b></span></nobr></DIV>
<DIV style="position:absolute;top:560;left:109"><nobr><span class="ft13"><b>Mannila_H</b></span></nobr></DIV>
<DIV style="position:absolute;top:560;left:154"><nobr><span class="ft13"><b>0.0049</b></span></nobr></DIV>
<DIV style="position:absolute;top:560;left:195"><nobr><span class="ft13"><b>Lukasiewicz_T</b></span></nobr></DIV>
<DIV style="position:absolute;top:560;left:246"><nobr><span class="ft13"><b>0.0054</b></span></nobr></DIV>
<DIV style="position:absolute;top:560;left:290"><nobr><span class="ft13"><b>Voorhees_E</b></span></nobr></DIV>
<DIV style="position:absolute;top:560;left:337"><nobr><span class="ft13"><b>0.0050</b></span></nobr></DIV>
<DIV style="position:absolute;top:560;left:385"><nobr><span class="ft13"><b>Widom_J</b></span></nobr></DIV>
<DIV style="position:absolute;top:560;left:429"><nobr><span class="ft13"><b>0.0058</b></span></nobr></DIV>
<DIV style="position:absolute;top:570;left:109"><nobr><span class="ft13"><b>Rastogi_R</b></span></nobr></DIV>
<DIV style="position:absolute;top:570;left:154"><nobr><span class="ft13"><b>0.0049</b></span></nobr></DIV>
<DIV style="position:absolute;top:570;left:202"><nobr><span class="ft13"><b>Geiger_D</b></span></nobr></DIV>
<DIV style="position:absolute;top:570;left:246"><nobr><span class="ft13"><b>0.0045</b></span></nobr></DIV>
<DIV style="position:absolute;top:570;left:295"><nobr><span class="ft13"><b>Callan_J</b></span></nobr></DIV>
<DIV style="position:absolute;top:570;left:337"><nobr><span class="ft13"><b>0.0046</b></span></nobr></DIV>
<DIV style="position:absolute;top:570;left:382"><nobr><span class="ft13"><b>Abiteboul_S</b></span></nobr></DIV>
<DIV style="position:absolute;top:570;left:429"><nobr><span class="ft13"><b>0.0057</b></span></nobr></DIV>
<DIV style="position:absolute;top:580;left:112"><nobr><span class="ft13"><b>Ganti_V</b></span></nobr></DIV>
<DIV style="position:absolute;top:580;left:154"><nobr><span class="ft13"><b>0.0048</b></span></nobr></DIV>
<DIV style="position:absolute;top:580;left:203"><nobr><span class="ft13"><b>Muller_P</b></span></nobr></DIV>
<DIV style="position:absolute;top:580;left:246"><nobr><span class="ft13"><b>0.0044</b></span></nobr></DIV>
<DIV style="position:absolute;top:580;left:296"><nobr><span class="ft13"><b>Fuhr_N</b></span></nobr></DIV>
<DIV style="position:absolute;top:580;left:337"><nobr><span class="ft13"><b>0.0042</b></span></nobr></DIV>
<DIV style="position:absolute;top:580;left:388"><nobr><span class="ft13"><b>Chu_W</b></span></nobr></DIV>
<DIV style="position:absolute;top:580;left:429"><nobr><span class="ft13"><b>0.0055</b></span></nobr></DIV>
<DIV style="position:absolute;top:590;left:107"><nobr><span class="ft13"><b>Toivonen_H</b></span></nobr></DIV>
<DIV style="position:absolute;top:590;left:154"><nobr><span class="ft13"><b>0.0043</b></span></nobr></DIV>
<DIV style="position:absolute;top:590;left:203"><nobr><span class="ft13"><b>Berger_J</b></span></nobr></DIV>
<DIV style="position:absolute;top:590;left:246"><nobr><span class="ft13"><b>0.0044</b></span></nobr></DIV>
<DIV style="position:absolute;top:590;left:291"><nobr><span class="ft13"><b>Smeaton_A</b></span></nobr></DIV>
<DIV style="position:absolute;top:590;left:337"><nobr><span class="ft13"><b>0.0042</b></span></nobr></DIV>
<DIV style="position:absolute;top:590;left:387"><nobr><span class="ft13"><b>Libkin_L</b></span></nobr></DIV>
<DIV style="position:absolute;top:590;left:429"><nobr><span class="ft13"><b>0.0054</b></span></nobr></DIV>
<DIV style="position:absolute;top:600;left:115"><nobr><span class="ft13"><b>Liu_H</b></span></nobr></DIV>
<DIV style="position:absolute;top:600;left:154"><nobr><span class="ft13"><b>0.0043</b></span></nobr></DIV>
<DIV style="position:absolute;top:600;left:204"><nobr><span class="ft13"><b>Xiang_Y</b></span></nobr></DIV>
<DIV style="position:absolute;top:600;left:246"><nobr><span class="ft13"><b>0.0042</b></span></nobr></DIV>
<DIV style="position:absolute;top:600;left:287"><nobr><span class="ft13"><b>Sanderson_M</b></span></nobr></DIV>
<DIV style="position:absolute;top:600;left:337"><nobr><span class="ft13"><b>0.0041</b></span></nobr></DIV>
<DIV style="position:absolute;top:600;left:385"><nobr><span class="ft13"><b>Kriegel_H</b></span></nobr></DIV>
<DIV style="position:absolute;top:600;left:429"><nobr><span class="ft13"><b>0.0054</b></span></nobr></DIV>
<DIV style="position:absolute;top:110;left:305"><nobr><span class="ft13"><b>TOPIC 29</b></span></nobr></DIV>
<DIV style="position:absolute;top:110;left:397"><nobr><span class="ft13"><b>TOPIC 58</b></span></nobr></DIV>
<DIV style="position:absolute;top:373;left:303"><nobr><span class="ft13"><b>TOPIC 298</b></span></nobr></DIV>
<DIV style="position:absolute;top:373;left:395"><nobr><span class="ft13"><b>TOPIC 139</b></span></nobr></DIV>
<DIV style="position:absolute;top:373;left:122"><nobr><span class="ft13"><b>TOPIC 52</b></span></nobr></DIV>
<DIV style="position:absolute;top:110;left:122"><nobr><span class="ft13"><b>TOPIC 95</b></span></nobr></DIV>
<DIV style="position:absolute;top:110;left:212"><nobr><span class="ft13"><b>TOPIC 293</b></span></nobr></DIV>
<DIV style="position:absolute;top:373;left:214"><nobr><span class="ft13"><b>TOPIC 68</b></span></nobr></DIV>
<DIV style="position:absolute;top:629;left:93"><nobr><span class="ft7">Figure 2: Eight example topics extracted from the<br>CiteSeer database. Each is illustrated with the 10<br>most likely words and authors with corresponding<br>probabilities.</span></nobr></DIV>
<DIV style="position:absolute;top:764;left:114"><nobr><span class="ft13"><b>WORD</b></span></nobr></DIV>
<DIV style="position:absolute;top:764;left:153"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:764;left:206"><nobr><span class="ft13"><b>WORD</b></span></nobr></DIV>
<DIV style="position:absolute;top:764;left:245"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:764;left:297"><nobr><span class="ft13"><b>WORD</b></span></nobr></DIV>
<DIV style="position:absolute;top:764;left:336"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:764;left:389"><nobr><span class="ft13"><b>WORD</b></span></nobr></DIV>
<DIV style="position:absolute;top:764;left:428"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:774;left:115"><nobr><span class="ft13"><b>DATA</b></span></nobr></DIV>
<DIV style="position:absolute;top:774;left:154"><nobr><span class="ft13"><b>0.1468</b></span></nobr></DIV>
<DIV style="position:absolute;top:774;left:192"><nobr><span class="ft13"><b>PROBABILISTIC 0.0826</b></span></nobr></DIV>
<DIV style="position:absolute;top:774;left:289"><nobr><span class="ft13"><b>RETRIEVAL</b></span></nobr></DIV>
<DIV style="position:absolute;top:774;left:337"><nobr><span class="ft13"><b>0.1381</b></span></nobr></DIV>
<DIV style="position:absolute;top:774;left:387"><nobr><span class="ft13"><b>QUERY</b></span></nobr></DIV>
<DIV style="position:absolute;top:774;left:429"><nobr><span class="ft13"><b>0.1699</b></span></nobr></DIV>
<DIV style="position:absolute;top:784;left:112"><nobr><span class="ft13"><b>MINING</b></span></nobr></DIV>
<DIV style="position:absolute;top:784;left:154"><nobr><span class="ft13"><b>0.0631</b></span></nobr></DIV>
<DIV style="position:absolute;top:784;left:200"><nobr><span class="ft13"><b>BAYESIAN</b></span></nobr></DIV>
<DIV style="position:absolute;top:784;left:246"><nobr><span class="ft13"><b>0.0751</b></span></nobr></DIV>
<DIV style="position:absolute;top:784;left:284"><nobr><span class="ft13"><b>INFORMATION</b></span></nobr></DIV>
<DIV style="position:absolute;top:784;left:337"><nobr><span class="ft13"><b>0.0600</b></span></nobr></DIV>
<DIV style="position:absolute;top:784;left:384"><nobr><span class="ft13"><b>QUERIES</b></span></nobr></DIV>
<DIV style="position:absolute;top:784;left:429"><nobr><span class="ft13"><b>0.1209</b></span></nobr></DIV>
<DIV style="position:absolute;top:793;left:105"><nobr><span class="ft13"><b>DISCOVERY</b></span></nobr></DIV>
<DIV style="position:absolute;top:793;left:154"><nobr><span class="ft13"><b>0.0396</b></span></nobr></DIV>
<DIV style="position:absolute;top:793;left:195"><nobr><span class="ft13"><b>PROBABILITY</b></span></nobr></DIV>
<DIV style="position:absolute;top:793;left:246"><nobr><span class="ft13"><b>0.0628</b></span></nobr></DIV>
<DIV style="position:absolute;top:793;left:297"><nobr><span class="ft13"><b>INDEX</b></span></nobr></DIV>
<DIV style="position:absolute;top:793;left:337"><nobr><span class="ft13"><b>0.0529</b></span></nobr></DIV>
<DIV style="position:absolute;top:793;left:391"><nobr><span class="ft13"><b>JOIN</b></span></nobr></DIV>
<DIV style="position:absolute;top:793;left:429"><nobr><span class="ft13"><b>0.0258</b></span></nobr></DIV>
<DIV style="position:absolute;top:803;left:104"><nobr><span class="ft13"><b>ATTRIBUTES</b></span></nobr></DIV>
<DIV style="position:absolute;top:803;left:154"><nobr><span class="ft13"><b>0.0392</b></span></nobr></DIV>
<DIV style="position:absolute;top:803;left:204"><nobr><span class="ft13"><b>MODEL</b></span></nobr></DIV>
<DIV style="position:absolute;top:803;left:246"><nobr><span class="ft13"><b>0.0364</b></span></nobr></DIV>
<DIV style="position:absolute;top:803;left:291"><nobr><span class="ft13"><b>INDEXING</b></span></nobr></DIV>
<DIV style="position:absolute;top:803;left:337"><nobr><span class="ft13"><b>0.0469</b></span></nobr></DIV>
<DIV style="position:absolute;top:803;left:390"><nobr><span class="ft13"><b>DATA</b></span></nobr></DIV>
<DIV style="position:absolute;top:803;left:429"><nobr><span class="ft13"><b>0.0212</b></span></nobr></DIV>
<DIV style="position:absolute;top:813;left:102"><nobr><span class="ft13"><b>ASSOCIATION</b></span></nobr></DIV>
<DIV style="position:absolute;top:813;left:154"><nobr><span class="ft13"><b>0.0316</b></span></nobr></DIV>
<DIV style="position:absolute;top:813;left:192"><nobr><span class="ft13"><b>PROBABILITIES 0.0313</b></span></nobr></DIV>
<DIV style="position:absolute;top:813;left:295"><nobr><span class="ft13"><b>QUERY</b></span></nobr></DIV>
<DIV style="position:absolute;top:813;left:337"><nobr><span class="ft13"><b>0.0319</b></span></nobr></DIV>
<DIV style="position:absolute;top:813;left:376"><nobr><span class="ft13"><b>OPTIMIZATION</b></span></nobr></DIV>
<DIV style="position:absolute;top:813;left:429"><nobr><span class="ft13"><b>0.0171</b></span></nobr></DIV>
<DIV style="position:absolute;top:823;left:113"><nobr><span class="ft13"><b>RULES</b></span></nobr></DIV>
<DIV style="position:absolute;top:823;left:154"><nobr><span class="ft13"><b>0.0252</b></span></nobr></DIV>
<DIV style="position:absolute;top:823;left:197"><nobr><span class="ft13"><b>INFERENCE</b></span></nobr></DIV>
<DIV style="position:absolute;top:823;left:246"><nobr><span class="ft13"><b>0.0294</b></span></nobr></DIV>
<DIV style="position:absolute;top:823;left:291"><nobr><span class="ft13"><b>CONTENT</b></span></nobr></DIV>
<DIV style="position:absolute;top:823;left:337"><nobr><span class="ft13"><b>0.0299</b></span></nobr></DIV>
<DIV style="position:absolute;top:823;left:378"><nobr><span class="ft13"><b>PROCESSING</b></span></nobr></DIV>
<DIV style="position:absolute;top:823;left:429"><nobr><span class="ft13"><b>0.0162</b></span></nobr></DIV>
<DIV style="position:absolute;top:833;left:106"><nobr><span class="ft13"><b>PATTERNS</b></span></nobr></DIV>
<DIV style="position:absolute;top:833;left:154"><nobr><span class="ft13"><b>0.0210</b></span></nobr></DIV>
<DIV style="position:absolute;top:833;left:202"><nobr><span class="ft13"><b>MODELS</b></span></nobr></DIV>
<DIV style="position:absolute;top:833;left:246"><nobr><span class="ft13"><b>0.0273</b></span></nobr></DIV>
<DIV style="position:absolute;top:833;left:296"><nobr><span class="ft13"><b>BASED</b></span></nobr></DIV>
<DIV style="position:absolute;top:833;left:337"><nobr><span class="ft13"><b>0.0224</b></span></nobr></DIV>
<DIV style="position:absolute;top:833;left:379"><nobr><span class="ft13"><b>RELATIONAL</b></span></nobr></DIV>
<DIV style="position:absolute;top:833;left:429"><nobr><span class="ft13"><b>0.0131</b></span></nobr></DIV>
<DIV style="position:absolute;top:843;left:113"><nobr><span class="ft13"><b>LARGE</b></span></nobr></DIV>
<DIV style="position:absolute;top:843;left:154"><nobr><span class="ft13"><b>0.0207</b></span></nobr></DIV>
<DIV style="position:absolute;top:843;left:194"><nobr><span class="ft13"><b>CONDITIONAL</b></span></nobr></DIV>
<DIV style="position:absolute;top:843;left:246"><nobr><span class="ft13"><b>0.0262</b></span></nobr></DIV>
<DIV style="position:absolute;top:843;left:293"><nobr><span class="ft13"><b>SEARCH</b></span></nobr></DIV>
<DIV style="position:absolute;top:843;left:337"><nobr><span class="ft13"><b>0.0219</b></span></nobr></DIV>
<DIV style="position:absolute;top:843;left:382"><nobr><span class="ft13"><b>DATABASE</b></span></nobr></DIV>
<DIV style="position:absolute;top:843;left:429"><nobr><span class="ft13"><b>0.0128</b></span></nobr></DIV>
<DIV style="position:absolute;top:852;left:106"><nobr><span class="ft13"><b>ATTRIBUTE</b></span></nobr></DIV>
<DIV style="position:absolute;top:852;left:154"><nobr><span class="ft13"><b>0.0183</b></span></nobr></DIV>
<DIV style="position:absolute;top:852;left:193"><nobr><span class="ft13"><b>DISTRIBUTION</b></span></nobr></DIV>
<DIV style="position:absolute;top:852;left:246"><nobr><span class="ft13"><b>0.0261</b></span></nobr></DIV>
<DIV style="position:absolute;top:852;left:287"><nobr><span class="ft13"><b>RELEVANCE</b></span></nobr></DIV>
<DIV style="position:absolute;top:852;left:337"><nobr><span class="ft13"><b>0.0212</b></span></nobr></DIV>
<DIV style="position:absolute;top:852;left:375"><nobr><span class="ft13"><b>AGGREGATION 0.0117</b></span></nobr></DIV>
<DIV style="position:absolute;top:862;left:104"><nobr><span class="ft13"><b>DATABASES</b></span></nobr></DIV>
<DIV style="position:absolute;top:862;left:154"><nobr><span class="ft13"><b>0.0179</b></span></nobr></DIV>
<DIV style="position:absolute;top:862;left:205"><nobr><span class="ft13"><b>PRIOR</b></span></nobr></DIV>
<DIV style="position:absolute;top:862;left:246"><nobr><span class="ft13"><b>0.0259</b></span></nobr></DIV>
<DIV style="position:absolute;top:862;left:289"><nobr><span class="ft13"><b>SIMILARITY</b></span></nobr></DIV>
<DIV style="position:absolute;top:862;left:337"><nobr><span class="ft13"><b>0.0178</b></span></nobr></DIV>
<DIV style="position:absolute;top:862;left:386"><nobr><span class="ft13"><b>RESULT</b></span></nobr></DIV>
<DIV style="position:absolute;top:862;left:429"><nobr><span class="ft13"><b>0.0106</b></span></nobr></DIV>
<DIV style="position:absolute;top:882;left:110"><nobr><span class="ft13"><b>AUTHOR</b></span></nobr></DIV>
<DIV style="position:absolute;top:882;left:153"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:882;left:202"><nobr><span class="ft13"><b>AUTHOR</b></span></nobr></DIV>
<DIV style="position:absolute;top:882;left:245"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:882;left:293"><nobr><span class="ft13"><b>AUTHOR</b></span></nobr></DIV>
<DIV style="position:absolute;top:882;left:336"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:882;left:385"><nobr><span class="ft13"><b>AUTHOR</b></span></nobr></DIV>
<DIV style="position:absolute;top:882;left:428"><nobr><span class="ft13"><b>PROB.</b></span></nobr></DIV>
<DIV style="position:absolute;top:892;left:114"><nobr><span class="ft13"><b>Han_J</b></span></nobr></DIV>
<DIV style="position:absolute;top:892;left:154"><nobr><span class="ft13"><b>0.0157</b></span></nobr></DIV>
<DIV style="position:absolute;top:892;left:204"><nobr><span class="ft13"><b>Koller_D</b></span></nobr></DIV>
<DIV style="position:absolute;top:892;left:246"><nobr><span class="ft13"><b>0.0109</b></span></nobr></DIV>
<DIV style="position:absolute;top:892;left:296"><nobr><span class="ft13"><b>Oard_D</b></span></nobr></DIV>
<DIV style="position:absolute;top:892;left:337"><nobr><span class="ft13"><b>0.0080</b></span></nobr></DIV>
<DIV style="position:absolute;top:892;left:382"><nobr><span class="ft13"><b>Naughton_J</b></span></nobr></DIV>
<DIV style="position:absolute;top:892;left:429"><nobr><span class="ft13"><b>0.0103</b></span></nobr></DIV>
<DIV style="position:absolute;top:902;left:113"><nobr><span class="ft13"><b>Zaki_M</b></span></nobr></DIV>
<DIV style="position:absolute;top:902;left:154"><nobr><span class="ft13"><b>0.0104</b></span></nobr></DIV>
<DIV style="position:absolute;top:902;left:196"><nobr><span class="ft13"><b>Heckerman_D</b></span></nobr></DIV>
<DIV style="position:absolute;top:902;left:246"><nobr><span class="ft13"><b>0.0079</b></span></nobr></DIV>
<DIV style="position:absolute;top:902;left:290"><nobr><span class="ft13"><b>Voorhees_E</b></span></nobr></DIV>
<DIV style="position:absolute;top:902;left:337"><nobr><span class="ft13"><b>0.0053</b></span></nobr></DIV>
<DIV style="position:absolute;top:902;left:387"><nobr><span class="ft13"><b>Suciu_D</b></span></nobr></DIV>
<DIV style="position:absolute;top:902;left:429"><nobr><span class="ft13"><b>0.0091</b></span></nobr></DIV>
<DIV style="position:absolute;top:911;left:115"><nobr><span class="ft13"><b>Liu_B</b></span></nobr></DIV>
<DIV style="position:absolute;top:911;left:154"><nobr><span class="ft13"><b>0.0080</b></span></nobr></DIV>
<DIV style="position:absolute;top:911;left:199"><nobr><span class="ft13"><b>Friedman_N</b></span></nobr></DIV>
<DIV style="position:absolute;top:911;left:246"><nobr><span class="ft13"><b>0.0076</b></span></nobr></DIV>
<DIV style="position:absolute;top:911;left:291"><nobr><span class="ft13"><b>Hawking_D</b></span></nobr></DIV>
<DIV style="position:absolute;top:911;left:337"><nobr><span class="ft13"><b>0.0053</b></span></nobr></DIV>
<DIV style="position:absolute;top:911;left:389"><nobr><span class="ft13"><b>Levy_A</b></span></nobr></DIV>
<DIV style="position:absolute;top:911;left:429"><nobr><span class="ft13"><b>0.0080</b></span></nobr></DIV>
<DIV style="position:absolute;top:921;left:109"><nobr><span class="ft13"><b>Cheung_D</b></span></nobr></DIV>
<DIV style="position:absolute;top:921;left:154"><nobr><span class="ft13"><b>0.0075</b></span></nobr></DIV>
<DIV style="position:absolute;top:921;left:195"><nobr><span class="ft13"><b>Ghahramani_Z</b></span></nobr></DIV>
<DIV style="position:absolute;top:921;left:246"><nobr><span class="ft13"><b>0.0060</b></span></nobr></DIV>
<DIV style="position:absolute;top:921;left:290"><nobr><span class="ft13"><b>Schauble_P</b></span></nobr></DIV>
<DIV style="position:absolute;top:921;left:337"><nobr><span class="ft13"><b>0.0051</b></span></nobr></DIV>
<DIV style="position:absolute;top:921;left:385"><nobr><span class="ft13"><b>DeWitt_D</b></span></nobr></DIV>
<DIV style="position:absolute;top:921;left:429"><nobr><span class="ft13"><b>0.0077</b></span></nobr></DIV>
<DIV style="position:absolute;top:931;left:107"><nobr><span class="ft13"><b>Hamilton_H</b></span></nobr></DIV>
<DIV style="position:absolute;top:931;left:154"><nobr><span class="ft13"><b>0.0058</b></span></nobr></DIV>
<DIV style="position:absolute;top:931;left:195"><nobr><span class="ft13"><b>Lukasiewicz_T</b></span></nobr></DIV>
<DIV style="position:absolute;top:931;left:246"><nobr><span class="ft13"><b>0.0053</b></span></nobr></DIV>
<DIV style="position:absolute;top:931;left:295"><nobr><span class="ft13"><b>Croft_W</b></span></nobr></DIV>
<DIV style="position:absolute;top:931;left:337"><nobr><span class="ft13"><b>0.0051</b></span></nobr></DIV>
<DIV style="position:absolute;top:931;left:387"><nobr><span class="ft13"><b>Wong_L</b></span></nobr></DIV>
<DIV style="position:absolute;top:931;left:429"><nobr><span class="ft13"><b>0.0071</b></span></nobr></DIV>
<DIV style="position:absolute;top:941;left:109"><nobr><span class="ft13"><b>Mannila_H</b></span></nobr></DIV>
<DIV style="position:absolute;top:941;left:154"><nobr><span class="ft13"><b>0.0056</b></span></nobr></DIV>
<DIV style="position:absolute;top:941;left:198"><nobr><span class="ft13"><b>Myllymaki_P</b></span></nobr></DIV>
<DIV style="position:absolute;top:941;left:246"><nobr><span class="ft13"><b>0.0053</b></span></nobr></DIV>
<DIV style="position:absolute;top:941;left:294"><nobr><span class="ft13"><b>Jones_K</b></span></nobr></DIV>
<DIV style="position:absolute;top:941;left:337"><nobr><span class="ft13"><b>0.0041</b></span></nobr></DIV>
<DIV style="position:absolute;top:941;left:388"><nobr><span class="ft13"><b>Ross_K</b></span></nobr></DIV>
<DIV style="position:absolute;top:941;left:429"><nobr><span class="ft13"><b>0.0067</b></span></nobr></DIV>
<DIV style="position:absolute;top:951;left:114"><nobr><span class="ft13"><b>Brin_S</b></span></nobr></DIV>
<DIV style="position:absolute;top:951;left:154"><nobr><span class="ft13"><b>0.0055</b></span></nobr></DIV>
<DIV style="position:absolute;top:951;left:204"><nobr><span class="ft13"><b>Poole_D</b></span></nobr></DIV>
<DIV style="position:absolute;top:951;left:246"><nobr><span class="ft13"><b>0.0050</b></span></nobr></DIV>
<DIV style="position:absolute;top:951;left:295"><nobr><span class="ft13"><b>Bruza_P</b></span></nobr></DIV>
<DIV style="position:absolute;top:951;left:337"><nobr><span class="ft13"><b>0.0041</b></span></nobr></DIV>
<DIV style="position:absolute;top:951;left:385"><nobr><span class="ft13"><b>Kriegel_H</b></span></nobr></DIV>
<DIV style="position:absolute;top:951;left:429"><nobr><span class="ft13"><b>0.0055</b></span></nobr></DIV>
<DIV style="position:absolute;top:961;left:112"><nobr><span class="ft13"><b>Ganti_V</b></span></nobr></DIV>
<DIV style="position:absolute;top:961;left:154"><nobr><span class="ft13"><b>0.0050</b></span></nobr></DIV>
<DIV style="position:absolute;top:961;left:204"><nobr><span class="ft13"><b>Xiang_Y</b></span></nobr></DIV>
<DIV style="position:absolute;top:961;left:246"><nobr><span class="ft13"><b>0.0048</b></span></nobr></DIV>
<DIV style="position:absolute;top:961;left:298"><nobr><span class="ft13"><b>Lee_D</b></span></nobr></DIV>
<DIV style="position:absolute;top:961;left:337"><nobr><span class="ft13"><b>0.0040</b></span></nobr></DIV>
<DIV style="position:absolute;top:961;left:385"><nobr><span class="ft13"><b>Mumick_I</b></span></nobr></DIV>
<DIV style="position:absolute;top:961;left:429"><nobr><span class="ft13"><b>0.0054</b></span></nobr></DIV>
<DIV style="position:absolute;top:970;left:115"><nobr><span class="ft13"><b>Liu_H</b></span></nobr></DIV>
<DIV style="position:absolute;top:970;left:154"><nobr><span class="ft13"><b>0.0050</b></span></nobr></DIV>
<DIV style="position:absolute;top:970;left:195"><nobr><span class="ft13"><b>vanderGaag_L</b></span></nobr></DIV>
<DIV style="position:absolute;top:970;left:246"><nobr><span class="ft13"><b>0.0047</b></span></nobr></DIV>
<DIV style="position:absolute;top:970;left:291"><nobr><span class="ft13"><b>Smeaton_A</b></span></nobr></DIV>
<DIV style="position:absolute;top:970;left:337"><nobr><span class="ft13"><b>0.0040</b></span></nobr></DIV>
<DIV style="position:absolute;top:970;left:384"><nobr><span class="ft13"><b>Raschid_L</b></span></nobr></DIV>
<DIV style="position:absolute;top:970;left:429"><nobr><span class="ft13"><b>0.0053</b></span></nobr></DIV>
<DIV style="position:absolute;top:980;left:107"><nobr><span class="ft13"><b>Toivonen_H</b></span></nobr></DIV>
<DIV style="position:absolute;top:980;left:154"><nobr><span class="ft13"><b>0.0049</b></span></nobr></DIV>
<DIV style="position:absolute;top:980;left:203"><nobr><span class="ft13"><b>Berger_J</b></span></nobr></DIV>
<DIV style="position:absolute;top:980;left:246"><nobr><span class="ft13"><b>0.0040</b></span></nobr></DIV>
<DIV style="position:absolute;top:980;left:295"><nobr><span class="ft13"><b>Callan_J</b></span></nobr></DIV>
<DIV style="position:absolute;top:980;left:337"><nobr><span class="ft13"><b>0.0039</b></span></nobr></DIV>
<DIV style="position:absolute;top:980;left:380"><nobr><span class="ft13"><b>Kossmann_D</b></span></nobr></DIV>
<DIV style="position:absolute;top:980;left:429"><nobr><span class="ft13"><b>0.0053</b></span></nobr></DIV>
<DIV style="position:absolute;top:753;left:120"><nobr><span class="ft13"><b>TOPIC 276</b></span></nobr></DIV>
<DIV style="position:absolute;top:753;left:212"><nobr><span class="ft13"><b>TOPIC 158</b></span></nobr></DIV>
<DIV style="position:absolute;top:753;left:303"><nobr><span class="ft13"><b>TOPIC 213</b></span></nobr></DIV>
<DIV style="position:absolute;top:753;left:397"><nobr><span class="ft13"><b>TOPIC 15</b></span></nobr></DIV>
<DIV style="position:absolute;top:1010;left:93"><nobr><span class="ft7">Figure 3: The four most similar topics to the top-<br>ics in the bottom row of Figure 2, obtained from a<br>different Markov chain run.</span></nobr></DIV>
<DIV style="position:absolute;top:79;left:488"><nobr><span class="ft14">3. AUTHOR-TOPICS FOR CITESEER<br>3.1 Learning the Model</span></nobr></DIV>
<DIV style="position:absolute;top:138;left:501"><nobr><span class="ft3">Our collection of CiteSeer abstracts contains D = 162, 489</span></nobr></DIV>
<DIV style="position:absolute;top:154;left:488"><nobr><span class="ft7">abstracts with K = 85, 465 authors. We preprocessed the<br>text by removing all punctuation and common stop words.<br>This led to a vocabulary size of V = 30, 799, and a total of<br>11, 685, 514 word tokens.</span></nobr></DIV>
<DIV style="position:absolute;top:216;left:501"><nobr><span class="ft3">There is inevitably some noise in data of this form given</span></nobr></DIV>
<DIV style="position:absolute;top:232;left:488"><nobr><span class="ft7">that many of the fields (paper title, author names, year, ab-<br>stract) were extracted automatically by CiteSeer from PDF<br>or postscript or other document formats. We chose the sim-<br>ple convention of identifying authors by their first initial and<br>second name, e.g., A Einstein, given that multiple first ini-<br>tials or fully spelled first names were only available for a rela-<br>tively small fraction of papers. This means of course that for<br>some very common names (e.g., J Wang or J Smith) there<br>will be multiple actual individuals represented by a single<br>name in the model. This is a known limitation of working<br>with this type of data (e.g., see Newman (2001) for further<br>discussion). There are algorithmic techniques that could<br>be used to automatically resolve these identity problems--<br>however, in this paper, we don't pursue these options and<br>instead for simplicity work with the first-initial/last-name<br>representation of individual authors.</span></nobr></DIV>
<DIV style="position:absolute;top:483;left:501"><nobr><span class="ft3">In our simulations, the number of topics T was fixed at</span></nobr></DIV>
<DIV style="position:absolute;top:499;left:488"><nobr><span class="ft7">300 and the smoothing parameters  and  (Figure 1) were<br>set at 0.16 and 0.01 respectively. We ran 5 independent<br>Gibbs sampling chains for 2000 iterations each. On a 2GHz<br>PC workstation, each iteration took 400 seconds, leading to<br>a total run time on the order of several days per chain.</span></nobr></DIV>
<DIV style="position:absolute;top:583;left:488"><nobr><span class="ft1">3.2 Author-Topic and Topic-Word Models for</span></nobr></DIV>
<DIV style="position:absolute;top:600;left:528"><nobr><span class="ft1">the CiteSeer Database</span></nobr></DIV>
<DIV style="position:absolute;top:627;left:501"><nobr><span class="ft3">We now discuss the author-topic and topic-word distribu-</span></nobr></DIV>
<DIV style="position:absolute;top:643;left:488"><nobr><span class="ft7">tions learned from the CiteSeer data. Figure 2 illustrates<br>eight different topics (out of 300), obtained at the 2000th<br>iteration of a particular Gibbs sampler run.</span></nobr></DIV>
<DIV style="position:absolute;top:690;left:501"><nobr><span class="ft3">Each table in Figure 2 shows the 10 words that are most</span></nobr></DIV>
<DIV style="position:absolute;top:705;left:488"><nobr><span class="ft7">likely to be produced if that topic is activated, and the 10<br>authors who are most likely to have produced a word if it is<br>known to have come from that topic. The words associated<br>with each topic are quite intuitive and, indeed, quite precise<br>in the sense of conveying a semantic summary of a particular<br>field of research. The authors associated with each topic<br>are also quite representative--note that the top 10 authors<br>associated with a topic by the model are not necessarily the<br>most well-known authors in that area, but rather are the<br>authors who tend to produce the most words for that topic<br>(in the CiteSeer abstracts).</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:501"><nobr><span class="ft3">The first 3 topics at the top of Figure 2, topics #163, #87</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:488"><nobr><span class="ft7">and #20 show examples of 3 quite specific and precise topics<br>on string matching, human-computer interaction, and as-<br>tronomy respectively. The bottom four topics (#205, #209,<br>#289, and #10) are examples of topics with direct relevance<br>to data mining--namely data mining itself, probabilistic<br>learning, information retrieval, and database querying and<br>indexing. The model includes several other topics related<br>to data mining, such as predictive modeling and neural net-<br>works, as well as topics that span the full range of research<br>areas encompassed by documents in CiteSeer. The full list is<br>available at http://www.datalab.uci.edu/author-topic.</span></nobr></DIV>
<DIV style="position:absolute;top:1066;left:501"><nobr><span class="ft3">Topic #273 (top right Figure 2) provides an example of a</span></nobr></DIV>
<DIV style="position:absolute;top:54;left:692"><nobr><span class="ft5"><b>Research Track Paper</b></span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:460"><nobr><span class="ft6">309</span></nobr></DIV>
</DIV>
<!-- Page 5 -->
<a name="5"></a>
<DIV style="position:relative;width:928;height:1263;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="928" height="1263" src="151005.png" alt="background image">
<DIV style="position:absolute;top:86;left:93"><nobr><span class="ft7">topic that is not directly related to a specific research area.<br>A fraction of topics, perhaps 10 to 20%, are devoted to "non-<br>research-specific" topics, the "glue" that makes up our re-<br>search papers, including general terminology for describing<br>methods and experiments, funding acknowledgments and<br>parts of addresses(which inadvertently crept in to the ab-<br>stracts), and so forth.</span></nobr></DIV>
<DIV style="position:absolute;top:196;left:107"><nobr><span class="ft3">We found that the topics obtained from different Gibbs</span></nobr></DIV>
<DIV style="position:absolute;top:212;left:93"><nobr><span class="ft7">sampling runs were quite stable. For example, Figure 3<br>shows the 4 most similar topics to the topics in the bot-<br>tom row of Figure 2, but from a different run. There is<br>some variability in terms of ranking of specific words and<br>authors for each topic, and in the exact values of the associ-<br>ated probabilities, but overall the topics match very closely.</span></nobr></DIV>
<DIV style="position:absolute;top:325;left:93"><nobr><span class="ft1">4. APPLICATIONS OF THE AUTHOR-TOPIC</span></nobr></DIV>
<DIV style="position:absolute;top:346;left:125"><nobr><span class="ft1">MODEL TO CITESEER</span></nobr></DIV>
<DIV style="position:absolute;top:381;left:93"><nobr><span class="ft1">4.1 Topic Trends over Time</span></nobr></DIV>
<DIV style="position:absolute;top:407;left:107"><nobr><span class="ft3">Of the original 162,489 abstracts in our data set, estimated</span></nobr></DIV>
<DIV style="position:absolute;top:423;left:93"><nobr><span class="ft7">years of publication were provided by CiteSeer for 130, 545 of<br>these abstracts. There is a steady (and well-known) increase<br>year by year in the number of online documents through the<br>1990's. From 1999 through 2002, however, the number of<br>documents for which the year is known drops off sharply--<br>the years 2001 and 2002 in particular are under-represented<br>in this set. This is due to fact that it is easier for CiteSeer to<br>determine the date of publication of older documents, e.g.,<br>by using citations to these documents.</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:107"><nobr><span class="ft3">We used the yearly data to analyze trends in topics over</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:93"><nobr><span class="ft7">time. Using the same 300 topic model described earlier, the<br>documents were partitioned by year, and for each year all<br>of the words were assigned to their most likely topic using<br>the model. The fraction of words assigned to each topic for<br>a given year was then calculated for each of the 300 topics<br>and for each year from 1990 to 2002.</span></nobr></DIV>
<DIV style="position:absolute;top:674;left:107"><nobr><span class="ft3">These fractions provide interesting and useful indicators of</span></nobr></DIV>
<DIV style="position:absolute;top:690;left:93"><nobr><span class="ft7">relative topic popularity in the research literature in recent<br>years. Figure 4 shows the results of plotting several different<br>topics. Each topic is indicated in the legend by the five<br>most probable words in the topic. The top left plot shows<br>a steady increase (roughly three-fold) in machine learning<br>and data mining topics. The top right plot shows a "tale of<br>two topics": an increase in information-retrieval coupled to<br>an apparent decrease in natural language processing.</span></nobr></DIV>
<DIV style="position:absolute;top:815;left:107"><nobr><span class="ft3">On the second row, on the left we see a steady decrease in</span></nobr></DIV>
<DIV style="position:absolute;top:831;left:93"><nobr><span class="ft7">two "classical" computer science topics, operating systems<br>and programming languages. On the right, however, we see<br>the reverse behavior, namely a corresponding substantial<br>growth in Web-related topics.</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:107"><nobr><span class="ft3">In the third row, the left plot illustrates trends within</span></nobr></DIV>
<DIV style="position:absolute;top:909;left:93"><nobr><span class="ft7">database research: a decrease in the transaction and concurrency-<br>related topic, query-related research holding steady over time,<br>and a slow but steady increase in integration-related database<br>research. The plot on the right in the third row illustrates<br>the changing fortunes of security-related research--a decline<br>in the early 90's but then a seemingly dramatic upward trend<br>starting around 1995.</span></nobr></DIV>
<DIV style="position:absolute;top:1019;left:107"><nobr><span class="ft3">The lower left plot on the bottom row illustrates the some-</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:93"><nobr><span class="ft7">what noisy trends of three topics that were "hot" in the<br>1990's: neural networks exhibits a steady decline since the<br>early 1990's (as machine learning has moved on to areas such</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:488"><nobr><span class="ft7">as support vector machines), genetic algorithms appears to<br>be relatively stable, and wavelets may have peaked in the<br>1994­98 time period.</span></nobr></DIV>
<DIV style="position:absolute;top:133;left:501"><nobr><span class="ft3">Finally, as with any large data set there are always some</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:488"><nobr><span class="ft7">surprises in store. The final figure on the bottom right shows<br>two somewhat unexpected "topics". The first topic consists<br>entirely of French words (in fact the model discovered 3 such<br>French language topics ). The apparent peaking of French<br>words in the mid-1990s is likely to be an artifact of how Cite-<br>Seer preprocesses data rather than any indication of French<br>research productivity. The lower curve corresponds to a<br>topic consisting of largely Greek letters, presumably from<br>more theoretically oriented papers--fans of theory may be<br>somewhat dismayed to see that there is an apparent steady<br>decline in the relative frequency of Greek letters in abstracts<br>since the mid-1990s!</span></nobr></DIV>
<DIV style="position:absolute;top:337;left:501"><nobr><span class="ft3">The time-trend results above should be interpreted with</span></nobr></DIV>
<DIV style="position:absolute;top:353;left:488"><nobr><span class="ft7">some caution. As mentioned earlier, the data for 2001 and<br>2002 are relatively sparse compared to earlier years. In addi-<br>tion, the numbers are based on a rather skewed sample (on-<br>line documents obtained by the CiteSeer system for which<br>years are known). Furthermore, the fractions per year only<br>indicate the relative number of words assigned to a topic<br>by the model and make no direct assessment of the quality<br>or importance of a particular sub-area of computer science.<br>Nonetheless, despite these caveats, the results are quite in-<br>formative and indicate substantial shifts in research topics<br>within the field of computer science.</span></nobr></DIV>
<DIV style="position:absolute;top:525;left:501"><nobr><span class="ft3">In terms of related work, Popescul et al. (2000) investi-</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:488"><nobr><span class="ft7">gated time trends in CiteSeer documents using a document<br>clustering approach. 31K documents were clustered into 15<br>clusters based on co-citation information while the text in-<br>formation in the documents was not used. Our author-topic<br>model uses the opposite approach. In effect we use the text<br>information directly to discover topics and do not explic-<br>itly model the "author network" (although implicitly the<br>co-author connections are used by the model). A direct<br>quantitative comparison is difficult, but we can say that our<br>model with 300 topics appears to produce much more no-<br>ticeable and precise time-trends than the 15-cluster model.</span></nobr></DIV>
<DIV style="position:absolute;top:726;left:488"><nobr><span class="ft1">4.2 Topics and Authors for New Documents</span></nobr></DIV>
<DIV style="position:absolute;top:752;left:501"><nobr><span class="ft3">In many applications, we would like to quickly assess the</span></nobr></DIV>
<DIV style="position:absolute;top:768;left:488"><nobr><span class="ft7">topic and author assignments for new documents not con-<br>tained in our subset of the CiteSeer collection. Because our<br>Monte Carlo algorithm requires significant processing time<br>for 160K documents, it would be computationally inefficient<br>to rerun the algorithm for every new document added to the<br>collection (even though from a Bayesian inference viewpoint<br>this is the optimal approach). Our strategy instead is to<br>apply an efficient Monte Carlo algorithm that runs only on<br>the word tokens in the new document, leading quickly to<br>likely assignments of words to authors and topics. We start<br>by assigning words randomly to co-authors and topics. We<br>then sample new assignments of words to topics and authors<br>by applying Equation 1 only to the word tokens in the new<br>document each time temporarily updating the count matri-<br>ces C</span></nobr></DIV>
<DIV style="position:absolute;top:986;left:522"><nobr><span class="ft9"><i>W T</i></span></nobr></DIV>
<DIV style="position:absolute;top:988;left:547"><nobr><span class="ft3">and C</span></nobr></DIV>
<DIV style="position:absolute;top:986;left:586"><nobr><span class="ft9"><i>AT</i></span></nobr></DIV>
<DIV style="position:absolute;top:988;left:603"><nobr><span class="ft3">. The resulting assignments of words to</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:488"><nobr><span class="ft7">authors and topics can be saved after a few iterations (10<br>iterations in our simulations).</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:501"><nobr><span class="ft3">Figure 5 shows an example of this type of inference. Ab-</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:488"><nobr><span class="ft7">stracts from two authors, B Scholkopf and A Darwiche were<br>combined together into 1 "pseudo-abstract" and the docu-</span></nobr></DIV>
<DIV style="position:absolute;top:54;left:91"><nobr><span class="ft5"><b>Research Track Paper</b></span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:460"><nobr><span class="ft6">310</span></nobr></DIV>
</DIV>
<!-- Page 6 -->
<a name="6"></a>
<DIV style="position:relative;width:928;height:1263;">
<STYLE type="text/css">
<!--
	.ft15{font-size:2px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="928" height="1263" src="151006.png" alt="background image">
<DIV style="position:absolute;top:306;left:170"><nobr><span class="ft11"><i>1990</i></span></nobr></DIV>
<DIV style="position:absolute;top:306;left:215"><nobr><span class="ft11"><i>1992</i></span></nobr></DIV>
<DIV style="position:absolute;top:306;left:259"><nobr><span class="ft11"><i>1994</i></span></nobr></DIV>
<DIV style="position:absolute;top:306;left:304"><nobr><span class="ft11"><i>1996</i></span></nobr></DIV>
<DIV style="position:absolute;top:306;left:348"><nobr><span class="ft11"><i>1998</i></span></nobr></DIV>
<DIV style="position:absolute;top:306;left:392"><nobr><span class="ft11"><i>2000</i></span></nobr></DIV>
<DIV style="position:absolute;top:306;left:437"><nobr><span class="ft11"><i>2002</i></span></nobr></DIV>
<DIV style="position:absolute;top:300;left:173"><nobr><span class="ft11"><i>1</i></span></nobr></DIV>
<DIV style="position:absolute;top:270;left:173"><nobr><span class="ft11"><i>2</i></span></nobr></DIV>
<DIV style="position:absolute;top:240;left:173"><nobr><span class="ft11"><i>3</i></span></nobr></DIV>
<DIV style="position:absolute;top:210;left:173"><nobr><span class="ft11"><i>4</i></span></nobr></DIV>
<DIV style="position:absolute;top:180;left:173"><nobr><span class="ft11"><i>5</i></span></nobr></DIV>
<DIV style="position:absolute;top:150;left:173"><nobr><span class="ft11"><i>6</i></span></nobr></DIV>
<DIV style="position:absolute;top:120;left:173"><nobr><span class="ft11"><i>7</i></span></nobr></DIV>
<DIV style="position:absolute;top:90;left:173"><nobr><span class="ft11"><i>8 x 10</i></span></nobr></DIV>
<DIV style="position:absolute;top:83;left:192"><nobr><span class="ft15">-3</span></nobr></DIV>
<DIV style="position:absolute;top:314;left:304"><nobr><span class="ft11"><i>Year</i></span></nobr></DIV>
<DIV style="position:absolute;top:250;left:170"><nobr><span class="ft11"><i>Fraction of Words Assigned to Topic</i></span></nobr></DIV>
<DIV style="position:absolute;top:148;left:217"><nobr><span class="ft11"><i>114:regression-variance-estimator</i></span></nobr></DIV>
<DIV style="position:absolute;top:157;left:217"><nobr><span class="ft11"><i>        -estimators-bias         </i></span></nobr></DIV>
<DIV style="position:absolute;top:165;left:217"><nobr><span class="ft11"><i>153:classification-training-classifier</i></span></nobr></DIV>
<DIV style="position:absolute;top:173;left:217"><nobr><span class="ft11"><i>        -classifiers-generalization   </i></span></nobr></DIV>
<DIV style="position:absolute;top:181;left:217"><nobr><span class="ft11"><i>205:data-mining-attributes-discovery</i></span></nobr></DIV>
<DIV style="position:absolute;top:190;left:217"><nobr><span class="ft11"><i>        -association                </i></span></nobr></DIV>
<DIV style="position:absolute;top:307;left:493"><nobr><span class="ft11"><i>1990</i></span></nobr></DIV>
<DIV style="position:absolute;top:307;left:537"><nobr><span class="ft11"><i>1992</i></span></nobr></DIV>
<DIV style="position:absolute;top:306;left:582"><nobr><span class="ft11"><i>1994</i></span></nobr></DIV>
<DIV style="position:absolute;top:306;left:626"><nobr><span class="ft11"><i>1996</i></span></nobr></DIV>
<DIV style="position:absolute;top:306;left:670"><nobr><span class="ft11"><i>1998</i></span></nobr></DIV>
<DIV style="position:absolute;top:306;left:715"><nobr><span class="ft11"><i>2000</i></span></nobr></DIV>
<DIV style="position:absolute;top:306;left:759"><nobr><span class="ft11"><i>2002</i></span></nobr></DIV>
<DIV style="position:absolute;top:301;left:495"><nobr><span class="ft11"><i>2</i></span></nobr></DIV>
<DIV style="position:absolute;top:265;left:495"><nobr><span class="ft11"><i>3</i></span></nobr></DIV>
<DIV style="position:absolute;top:230;left:495"><nobr><span class="ft11"><i>4</i></span></nobr></DIV>
<DIV style="position:absolute;top:195;left:495"><nobr><span class="ft11"><i>5</i></span></nobr></DIV>
<DIV style="position:absolute;top:160;left:495"><nobr><span class="ft11"><i>6</i></span></nobr></DIV>
<DIV style="position:absolute;top:125;left:495"><nobr><span class="ft11"><i>7</i></span></nobr></DIV>
<DIV style="position:absolute;top:90;left:495"><nobr><span class="ft11"><i>8 x 10</i></span></nobr></DIV>
<DIV style="position:absolute;top:83;left:515"><nobr><span class="ft15">-3</span></nobr></DIV>
<DIV style="position:absolute;top:314;left:627"><nobr><span class="ft11"><i>Year</i></span></nobr></DIV>
<DIV style="position:absolute;top:250;left:493"><nobr><span class="ft11"><i>Fraction of Words Assigned to Topic</i></span></nobr></DIV>
<DIV style="position:absolute;top:97;left:622"><nobr><span class="ft11"><i>280:language-semantic-natural</i></span></nobr></DIV>
<DIV style="position:absolute;top:105;left:622"><nobr><span class="ft11"><i>        -linguistic-grammar  </i></span></nobr></DIV>
<DIV style="position:absolute;top:114;left:622"><nobr><span class="ft11"><i>289:retrieval-text-documents </i></span></nobr></DIV>
<DIV style="position:absolute;top:122;left:622"><nobr><span class="ft11"><i>        -information-document</i></span></nobr></DIV>
<DIV style="position:absolute;top:546;left:175"><nobr><span class="ft11"><i>1990</i></span></nobr></DIV>
<DIV style="position:absolute;top:546;left:218"><nobr><span class="ft11"><i>1992</i></span></nobr></DIV>
<DIV style="position:absolute;top:546;left:262"><nobr><span class="ft11"><i>1994</i></span></nobr></DIV>
<DIV style="position:absolute;top:546;left:306"><nobr><span class="ft11"><i>1996</i></span></nobr></DIV>
<DIV style="position:absolute;top:546;left:350"><nobr><span class="ft11"><i>1998</i></span></nobr></DIV>
<DIV style="position:absolute;top:546;left:393"><nobr><span class="ft11"><i>2000</i></span></nobr></DIV>
<DIV style="position:absolute;top:546;left:437"><nobr><span class="ft11"><i>2002</i></span></nobr></DIV>
<DIV style="position:absolute;top:541;left:177"><nobr><span class="ft11"><i>2</i></span></nobr></DIV>
<DIV style="position:absolute;top:517;left:177"><nobr><span class="ft11"><i>3</i></span></nobr></DIV>
<DIV style="position:absolute;top:494;left:177"><nobr><span class="ft11"><i>4</i></span></nobr></DIV>
<DIV style="position:absolute;top:471;left:177"><nobr><span class="ft11"><i>5</i></span></nobr></DIV>
<DIV style="position:absolute;top:448;left:177"><nobr><span class="ft11"><i>6</i></span></nobr></DIV>
<DIV style="position:absolute;top:425;left:177"><nobr><span class="ft11"><i>7</i></span></nobr></DIV>
<DIV style="position:absolute;top:402;left:177"><nobr><span class="ft11"><i>8</i></span></nobr></DIV>
<DIV style="position:absolute;top:379;left:177"><nobr><span class="ft11"><i>9</i></span></nobr></DIV>
<DIV style="position:absolute;top:356;left:173"><nobr><span class="ft11"><i>10</i></span></nobr></DIV>
<DIV style="position:absolute;top:333;left:173"><nobr><span class="ft11"><i>11 x 10</i></span></nobr></DIV>
<DIV style="position:absolute;top:326;left:196"><nobr><span class="ft15">-3</span></nobr></DIV>
<DIV style="position:absolute;top:554;left:306"><nobr><span class="ft11"><i>Year</i></span></nobr></DIV>
<DIV style="position:absolute;top:491;left:170"><nobr><span class="ft11"><i>Fraction of Words Assigned to Topic</i></span></nobr></DIV>
<DIV style="position:absolute;top:341;left:316"><nobr><span class="ft11"><i>60:programming-language-concurrent</i></span></nobr></DIV>
<DIV style="position:absolute;top:349;left:316"><nobr><span class="ft11"><i>      -languages-implementation   </i></span></nobr></DIV>
<DIV style="position:absolute;top:358;left:316"><nobr><span class="ft11"><i>139:system-operating-file</i></span></nobr></DIV>
<DIV style="position:absolute;top:366;left:316"><nobr><span class="ft11"><i>        -systems-kernel  </i></span></nobr></DIV>
<DIV style="position:absolute;top:547;left:506"><nobr><span class="ft13"><b>1990</b></span></nobr></DIV>
<DIV style="position:absolute;top:547;left:549"><nobr><span class="ft13"><b>1992</b></span></nobr></DIV>
<DIV style="position:absolute;top:547;left:591"><nobr><span class="ft13"><b>1994</b></span></nobr></DIV>
<DIV style="position:absolute;top:547;left:633"><nobr><span class="ft13"><b>1996</b></span></nobr></DIV>
<DIV style="position:absolute;top:547;left:675"><nobr><span class="ft13"><b>1998</b></span></nobr></DIV>
<DIV style="position:absolute;top:547;left:718"><nobr><span class="ft13"><b>2000</b></span></nobr></DIV>
<DIV style="position:absolute;top:547;left:760"><nobr><span class="ft13"><b>2002</b></span></nobr></DIV>
<DIV style="position:absolute;top:541;left:509"><nobr><span class="ft13"><b>0</b></span></nobr></DIV>
<DIV style="position:absolute;top:508;left:495"><nobr><span class="ft13"><b>0.002</b></span></nobr></DIV>
<DIV style="position:absolute;top:474;left:495"><nobr><span class="ft13"><b>0.004</b></span></nobr></DIV>
<DIV style="position:absolute;top:441;left:495"><nobr><span class="ft13"><b>0.006</b></span></nobr></DIV>
<DIV style="position:absolute;top:408;left:495"><nobr><span class="ft13"><b>0.008</b></span></nobr></DIV>
<DIV style="position:absolute;top:374;left:499"><nobr><span class="ft13"><b>0.01</b></span></nobr></DIV>
<DIV style="position:absolute;top:341;left:495"><nobr><span class="ft13"><b>0.012</b></span></nobr></DIV>
<DIV style="position:absolute;top:554;left:634"><nobr><span class="ft13"><b>Year</b></span></nobr></DIV>
<DIV style="position:absolute;top:493;left:493"><nobr><span class="ft13"><b>Fraction of Words Assigned to Topic</b></span></nobr></DIV>
<DIV style="position:absolute;top:357;left:551"><nobr><span class="ft13"><b>7:web-user-world-wide-users</b></span></nobr></DIV>
<DIV style="position:absolute;top:364;left:551"><nobr><span class="ft13"><b>80:mobile-wireless-devices</b></span></nobr></DIV>
<DIV style="position:absolute;top:372;left:551"><nobr><span class="ft13"><b>     -mobility-ad         </b></span></nobr></DIV>
<DIV style="position:absolute;top:380;left:551"><nobr><span class="ft13"><b>275:multicast-multimedia-media</b></span></nobr></DIV>
<DIV style="position:absolute;top:388;left:551"><nobr><span class="ft13"><b>        -delivery-applications</b></span></nobr></DIV>
<DIV style="position:absolute;top:800;left:175"><nobr><span class="ft11"><i>1990</i></span></nobr></DIV>
<DIV style="position:absolute;top:800;left:218"><nobr><span class="ft11"><i>1992</i></span></nobr></DIV>
<DIV style="position:absolute;top:800;left:262"><nobr><span class="ft11"><i>1994</i></span></nobr></DIV>
<DIV style="position:absolute;top:800;left:306"><nobr><span class="ft11"><i>1996</i></span></nobr></DIV>
<DIV style="position:absolute;top:800;left:350"><nobr><span class="ft11"><i>1998</i></span></nobr></DIV>
<DIV style="position:absolute;top:800;left:393"><nobr><span class="ft11"><i>2000</i></span></nobr></DIV>
<DIV style="position:absolute;top:800;left:437"><nobr><span class="ft11"><i>2002</i></span></nobr></DIV>
<DIV style="position:absolute;top:794;left:177"><nobr><span class="ft11"><i>1</i></span></nobr></DIV>
<DIV style="position:absolute;top:771;left:177"><nobr><span class="ft11"><i>2</i></span></nobr></DIV>
<DIV style="position:absolute;top:748;left:177"><nobr><span class="ft11"><i>3</i></span></nobr></DIV>
<DIV style="position:absolute;top:725;left:177"><nobr><span class="ft11"><i>4</i></span></nobr></DIV>
<DIV style="position:absolute;top:702;left:177"><nobr><span class="ft11"><i>5</i></span></nobr></DIV>
<DIV style="position:absolute;top:679;left:177"><nobr><span class="ft11"><i>6</i></span></nobr></DIV>
<DIV style="position:absolute;top:656;left:177"><nobr><span class="ft11"><i>7</i></span></nobr></DIV>
<DIV style="position:absolute;top:633;left:177"><nobr><span class="ft11"><i>8</i></span></nobr></DIV>
<DIV style="position:absolute;top:610;left:177"><nobr><span class="ft11"><i>9</i></span></nobr></DIV>
<DIV style="position:absolute;top:587;left:173"><nobr><span class="ft11"><i>10 x 10</i></span></nobr></DIV>
<DIV style="position:absolute;top:579;left:196"><nobr><span class="ft15">-3</span></nobr></DIV>
<DIV style="position:absolute;top:807;left:306"><nobr><span class="ft11"><i>Year</i></span></nobr></DIV>
<DIV style="position:absolute;top:744;left:170"><nobr><span class="ft11"><i>Fraction of Words Assigned to Topic</i></span></nobr></DIV>
<DIV style="position:absolute;top:601;left:269"><nobr><span class="ft11"><i>10:query-queries-index-data-join</i></span></nobr></DIV>
<DIV style="position:absolute;top:609;left:269"><nobr><span class="ft11"><i>261:transaction-transactions    </i></span></nobr></DIV>
<DIV style="position:absolute;top:617;left:269"><nobr><span class="ft11"><i>        -concurrency-copy-copies</i></span></nobr></DIV>
<DIV style="position:absolute;top:625;left:269"><nobr><span class="ft11"><i>194:integration-view-views-data</i></span></nobr></DIV>
<DIV style="position:absolute;top:633;left:269"><nobr><span class="ft11"><i>        -incremental           </i></span></nobr></DIV>
<DIV style="position:absolute;top:799;left:493"><nobr><span class="ft11"><i>1990</i></span></nobr></DIV>
<DIV style="position:absolute;top:799;left:537"><nobr><span class="ft11"><i>1992</i></span></nobr></DIV>
<DIV style="position:absolute;top:799;left:582"><nobr><span class="ft11"><i>1994</i></span></nobr></DIV>
<DIV style="position:absolute;top:799;left:626"><nobr><span class="ft11"><i>1996</i></span></nobr></DIV>
<DIV style="position:absolute;top:799;left:670"><nobr><span class="ft11"><i>1998</i></span></nobr></DIV>
<DIV style="position:absolute;top:799;left:715"><nobr><span class="ft11"><i>2000</i></span></nobr></DIV>
<DIV style="position:absolute;top:799;left:759"><nobr><span class="ft11"><i>2002</i></span></nobr></DIV>
<DIV style="position:absolute;top:794;left:495"><nobr><span class="ft11"><i>1</i></span></nobr></DIV>
<DIV style="position:absolute;top:767;left:495"><nobr><span class="ft11"><i>2</i></span></nobr></DIV>
<DIV style="position:absolute;top:741;left:495"><nobr><span class="ft11"><i>3</i></span></nobr></DIV>
<DIV style="position:absolute;top:715;left:495"><nobr><span class="ft11"><i>4</i></span></nobr></DIV>
<DIV style="position:absolute;top:689;left:495"><nobr><span class="ft11"><i>5</i></span></nobr></DIV>
<DIV style="position:absolute;top:662;left:495"><nobr><span class="ft11"><i>6</i></span></nobr></DIV>
<DIV style="position:absolute;top:636;left:495"><nobr><span class="ft11"><i>7</i></span></nobr></DIV>
<DIV style="position:absolute;top:610;left:495"><nobr><span class="ft11"><i>8</i></span></nobr></DIV>
<DIV style="position:absolute;top:583;left:495"><nobr><span class="ft11"><i>9 x 10</i></span></nobr></DIV>
<DIV style="position:absolute;top:576;left:515"><nobr><span class="ft15">-3</span></nobr></DIV>
<DIV style="position:absolute;top:807;left:627"><nobr><span class="ft11"><i>Year</i></span></nobr></DIV>
<DIV style="position:absolute;top:743;left:493"><nobr><span class="ft11"><i>Fraction of Words Assigned to Topic</i></span></nobr></DIV>
<DIV style="position:absolute;top:605;left:540"><nobr><span class="ft11"><i>120:security-secure-access-key-authentication</i></span></nobr></DIV>
<DIV style="position:absolute;top:614;left:540"><nobr><span class="ft11"><i>240:key-attack-encryption-hash-keys</i></span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:171"><nobr><span class="ft11"><i>1990</i></span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:215"><nobr><span class="ft11"><i>1992</i></span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:259"><nobr><span class="ft11"><i>1994</i></span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:304"><nobr><span class="ft11"><i>1996</i></span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:348"><nobr><span class="ft11"><i>1998</i></span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:392"><nobr><span class="ft11"><i>2000</i></span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:437"><nobr><span class="ft11"><i>2002</i></span></nobr></DIV>
<DIV style="position:absolute;top:1047;left:173"><nobr><span class="ft11"><i>1</i></span></nobr></DIV>
<DIV style="position:absolute;top:1012;left:173"><nobr><span class="ft11"><i>2</i></span></nobr></DIV>
<DIV style="position:absolute;top:977;left:173"><nobr><span class="ft11"><i>3</i></span></nobr></DIV>
<DIV style="position:absolute;top:942;left:173"><nobr><span class="ft11"><i>4</i></span></nobr></DIV>
<DIV style="position:absolute;top:907;left:173"><nobr><span class="ft11"><i>5</i></span></nobr></DIV>
<DIV style="position:absolute;top:872;left:173"><nobr><span class="ft11"><i>6</i></span></nobr></DIV>
<DIV style="position:absolute;top:837;left:173"><nobr><span class="ft11"><i>7 x 10</i></span></nobr></DIV>
<DIV style="position:absolute;top:829;left:192"><nobr><span class="ft15">-3</span></nobr></DIV>
<DIV style="position:absolute;top:1061;left:304"><nobr><span class="ft11"><i>Year</i></span></nobr></DIV>
<DIV style="position:absolute;top:997;left:170"><nobr><span class="ft11"><i>Fraction of Words Assigned to Topic</i></span></nobr></DIV>
<DIV style="position:absolute;top:835;left:245"><nobr><span class="ft11"><i>23:neural-networks-network-training-learning</i></span></nobr></DIV>
<DIV style="position:absolute;top:844;left:245"><nobr><span class="ft11"><i>35:wavelet-operator-operators-basis</i></span></nobr></DIV>
<DIV style="position:absolute;top:852;left:245"><nobr><span class="ft11"><i>     -coefficients                 </i></span></nobr></DIV>
<DIV style="position:absolute;top:860;left:245"><nobr><span class="ft11"><i>242:genetic-evolutionary-evolution-population-ga</i></span></nobr></DIV>
<DIV style="position:absolute;top:1054;left:506"><nobr><span class="ft13"><b>1990</b></span></nobr></DIV>
<DIV style="position:absolute;top:1054;left:549"><nobr><span class="ft13"><b>1992</b></span></nobr></DIV>
<DIV style="position:absolute;top:1054;left:591"><nobr><span class="ft13"><b>1994</b></span></nobr></DIV>
<DIV style="position:absolute;top:1054;left:633"><nobr><span class="ft13"><b>1996</b></span></nobr></DIV>
<DIV style="position:absolute;top:1054;left:675"><nobr><span class="ft13"><b>1998</b></span></nobr></DIV>
<DIV style="position:absolute;top:1054;left:718"><nobr><span class="ft13"><b>2000</b></span></nobr></DIV>
<DIV style="position:absolute;top:1054;left:760"><nobr><span class="ft13"><b>2002</b></span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:509"><nobr><span class="ft13"><b>0</b></span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:495"><nobr><span class="ft13"><b>0.002</b></span></nobr></DIV>
<DIV style="position:absolute;top:981;left:495"><nobr><span class="ft13"><b>0.004</b></span></nobr></DIV>
<DIV style="position:absolute;top:948;left:495"><nobr><span class="ft13"><b>0.006</b></span></nobr></DIV>
<DIV style="position:absolute;top:915;left:495"><nobr><span class="ft13"><b>0.008</b></span></nobr></DIV>
<DIV style="position:absolute;top:881;left:499"><nobr><span class="ft13"><b>0.01</b></span></nobr></DIV>
<DIV style="position:absolute;top:848;left:495"><nobr><span class="ft13"><b>0.012</b></span></nobr></DIV>
<DIV style="position:absolute;top:1061;left:634"><nobr><span class="ft13"><b>Year</b></span></nobr></DIV>
<DIV style="position:absolute;top:1000;left:493"><nobr><span class="ft13"><b>Fraction of Words Assigned to Topic</b></span></nobr></DIV>
<DIV style="position:absolute;top:1014;left:547"><nobr><span class="ft13"><b>47:la-les-une-nous-est</b></span></nobr></DIV>
<DIV style="position:absolute;top:1022;left:547"><nobr><span class="ft13"><b>157:gamma-delta-ff-omega-oe</b></span></nobr></DIV>
<DIV style="position:absolute;top:1084;left:251"><nobr><span class="ft3">Figure 4: Topic trends for research topics in computer science.</span></nobr></DIV>
<DIV style="position:absolute;top:54;left:692"><nobr><span class="ft5"><b>Research Track Paper</b></span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:460"><nobr><span class="ft6">311</span></nobr></DIV>
</DIV>
<!-- Page 7 -->
<a name="7"></a>
<DIV style="position:relative;width:928;height:1263;">
<STYLE type="text/css">
<!--
	.ft16{font-size:9px;font-family:Times;color:#fc0000;}
	.ft17{font-size:9px;font-family:Times;color:#0000fc;}
	.ft18{font-size:9px;font-family:Times;color:#cc0000;}
	.ft19{font-size:5px;font-family:Times;color:#cc0000;}
	.ft20{font-size:5px;font-family:Times;color:#fc0000;}
	.ft21{font-size:9px;font-family:Times;color:#ba0000;}
	.ft22{font-size:5px;font-family:Times;color:#ba0000;}
	.ft23{font-size:9px;font-family:Times;color:#ed0000;}
	.ft24{font-size:5px;font-family:Times;color:#ed0000;}
	.ft25{font-size:9px;font-family:Times;color:#000027;}
	.ft26{font-size:9px;font-family:Times;color:#5a0000;}
	.ft27{font-size:9px;font-family:Times;color:#0000cc;}
	.ft28{font-size:5px;font-family:Times;color:#0000cc;}
	.ft29{font-size:9px;font-family:Times;color:#000039;}
	.ft30{font-size:9px;font-family:Times;color:#790000;}
	.ft31{font-size:9px;font-family:Times;color:#8b0000;}
	.ft32{font-size:5px;font-family:Times;color:#8b0000;}
	.ft33{font-size:9px;font-family:Times;color:#000069;}
	.ft34{font-size:9px;font-family:Times;color:#690000;}
	.ft35{font-size:9px;font-family:Times;color:#000006;}
	.ft36{font-size:9px;font-family:Times;color:#ac0000;}
	.ft37{font-size:5px;font-family:Times;color:#ac0000;}
	.ft38{font-size:9px;font-family:Times;color:#0000ed;}
	.ft39{font-size:5px;font-family:Times;color:#0000ed;}
	.ft40{font-size:9px;font-family:Times;color:#480000;}
	.ft41{font-size:9px;font-family:Times;color:#000048;}
	.ft42{font-size:9px;font-family:Times;color:#000017;}
	.ft43{font-size:9px;font-family:Times;color:#9b0000;}
	.ft44{font-size:5px;font-family:Times;color:#9b0000;}
	.ft45{font-size:9px;font-family:Times;color:#00005a;}
	.ft46{font-size:9px;font-family:Times;color:#00009b;}
	.ft47{font-size:5px;font-family:Times;color:#00009b;}
	.ft48{font-size:9px;font-family:Times;color:#170000;}
	.ft49{font-size:9px;font-family:Times;color:#0000dd;}
	.ft50{font-size:5px;font-family:Times;color:#0000dd;}
	.ft51{font-size:5px;font-family:Times;color:#0000fc;}
	.ft52{font-size:9px;font-family:Times;color:#270000;}
	.ft53{font-size:9px;font-family:Times;color:#0000ac;}
	.ft54{font-size:5px;font-family:Times;color:#0000ac;}
	.ft55{font-size:9px;font-family:Times;color:#0000ba;}
	.ft56{font-size:5px;font-family:Times;color:#0000ba;}
	.ft57{font-size:9px;font-family:Times;color:#060000;}
	.ft58{font-size:9px;font-family:Times;color:#00008b;}
	.ft59{font-size:5px;font-family:Times;color:#00008b;}
	.ft60{font-size:9px;font-family:Times;color:#390000;}
	.ft61{font-size:9px;font-family:Times;color:#000079;}
-->
</STYLE>
<IMG width="928" height="1263" src="151007.png" alt="background image">
<DIV style="position:absolute;top:80;left:200"><nobr><span class="ft4">[</span></nobr></DIV>
<DIV style="position:absolute;top:80;left:204"><nobr><span class="ft16">AUTH1=Scholkopf_B</span></nobr></DIV>
<DIV style="position:absolute;top:80;left:306"><nobr><span class="ft4"> ( 69%, 31%)] </span></nobr></DIV>
<DIV style="position:absolute;top:93;left:200"><nobr><span class="ft4">[</span></nobr></DIV>
<DIV style="position:absolute;top:93;left:204"><nobr><span class="ft17">AUTH2=Darwiche_A</span></nobr></DIV>
<DIV style="position:absolute;top:93;left:304"><nobr><span class="ft4"> ( 72%, 28%)] </span></nobr></DIV>
<DIV style="position:absolute;top:123;left:200"><nobr><span class="ft4">A </span></nobr></DIV>
<DIV style="position:absolute;top:123;left:211"><nobr><span class="ft18">method</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:245"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:123;left:248"><nobr><span class="ft4"> is described which like the </span></nobr></DIV>
<DIV style="position:absolute;top:123;left:374"><nobr><span class="ft16">kernel</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:403"><nobr><span class="ft20">1</span></nobr></DIV>
<DIV style="position:absolute;top:123;left:406"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:123;left:409"><nobr><span class="ft21">trick</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:430"><nobr><span class="ft22">1</span></nobr></DIV>
<DIV style="position:absolute;top:123;left:433"><nobr><span class="ft4"> in </span></nobr></DIV>
<DIV style="position:absolute;top:123;left:448"><nobr><span class="ft23">support</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:481"><nobr><span class="ft24">1</span></nobr></DIV>
<DIV style="position:absolute;top:123;left:485"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:123;left:488"><nobr><span class="ft16">vector</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:516"><nobr><span class="ft20">1</span></nobr></DIV>
<DIV style="position:absolute;top:123;left:519"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:123;left:522"><nobr><span class="ft18">machines</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:565"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:123;left:569"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:123;left:571"><nobr><span class="ft16">SVMs</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:600"><nobr><span class="ft20">1</span></nobr></DIV>
<DIV style="position:absolute;top:123;left:604"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:123;left:607"><nobr><span class="ft25">lets</span></nobr></DIV>
<DIV style="position:absolute;top:123;left:622"><nobr><span class="ft4"> us </span></nobr></DIV>
<DIV style="position:absolute;top:123;left:638"><nobr><span class="ft26">generalize</span></nobr></DIV>
<DIV style="position:absolute;top:123;left:684"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:123;left:687"><nobr><span class="ft16">distance</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:724"><nobr><span class="ft20">1</span></nobr></DIV>
<DIV style="position:absolute;top:123;left:727"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:136;left:200"><nobr><span class="ft27">based</span></nobr></DIV>
<DIV style="position:absolute;top:135;left:226"><nobr><span class="ft28">2</span></nobr></DIV>
<DIV style="position:absolute;top:136;left:229"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:136;left:232"><nobr><span class="ft29">algorithms</span></nobr></DIV>
<DIV style="position:absolute;top:136;left:280"><nobr><span class="ft4"> to </span></nobr></DIV>
<DIV style="position:absolute;top:136;left:295"><nobr><span class="ft30">operate</span></nobr></DIV>
<DIV style="position:absolute;top:136;left:328"><nobr><span class="ft4"> in </span></nobr></DIV>
<DIV style="position:absolute;top:136;left:343"><nobr><span class="ft31">feature</span></nobr></DIV>
<DIV style="position:absolute;top:135;left:374"><nobr><span class="ft32">1</span></nobr></DIV>
<DIV style="position:absolute;top:136;left:377"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:136;left:380"><nobr><span class="ft26">spaces</span></nobr></DIV>
<DIV style="position:absolute;top:136;left:409"><nobr><span class="ft4"> usually </span></nobr></DIV>
<DIV style="position:absolute;top:136;left:447"><nobr><span class="ft26">nonlinearly</span></nobr></DIV>
<DIV style="position:absolute;top:136;left:499"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:136;left:502"><nobr><span class="ft25">related</span></nobr></DIV>
<DIV style="position:absolute;top:136;left:532"><nobr><span class="ft4"> to the </span></nobr></DIV>
<DIV style="position:absolute;top:136;left:563"><nobr><span class="ft18">input</span></nobr></DIV>
<DIV style="position:absolute;top:135;left:586"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:136;left:590"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:136;left:593"><nobr><span class="ft30">space</span></nobr></DIV>
<DIV style="position:absolute;top:136;left:618"><nobr><span class="ft4"> This is done by </span></nobr></DIV>
<DIV style="position:absolute;top:149;left:200"><nobr><span class="ft33">identifying</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:249"><nobr><span class="ft4"> a </span></nobr></DIV>
<DIV style="position:absolute;top:149;left:260"><nobr><span class="ft34">class</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:282"><nobr><span class="ft4"> of </span></nobr></DIV>
<DIV style="position:absolute;top:149;left:297"><nobr><span class="ft16">kernels</span></nobr></DIV>
<DIV style="position:absolute;top:147;left:330"><nobr><span class="ft20">1</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:333"><nobr><span class="ft4"> which can be </span></nobr></DIV>
<DIV style="position:absolute;top:149;left:398"><nobr><span class="ft35">represented</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:450"><nobr><span class="ft4"> as </span></nobr></DIV>
<DIV style="position:absolute;top:149;left:465"><nobr><span class="ft36">norm</span></nobr></DIV>
<DIV style="position:absolute;top:147;left:489"><nobr><span class="ft37">1</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:493"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:149;left:496"><nobr><span class="ft38">based</span></nobr></DIV>
<DIV style="position:absolute;top:147;left:521"><nobr><span class="ft39">2</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:525"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:149;left:528"><nobr><span class="ft16">distances</span></nobr></DIV>
<DIV style="position:absolute;top:147;left:569"><nobr><span class="ft20">1</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:572"><nobr><span class="ft4"> in </span></nobr></DIV>
<DIV style="position:absolute;top:149;left:587"><nobr><span class="ft26">Hilbert</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:619"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:149;left:622"><nobr><span class="ft30">spaces</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:651"><nobr><span class="ft4"> It </span></nobr></DIV>
<DIV style="position:absolute;top:149;left:663"><nobr><span class="ft23">turns</span></nobr></DIV>
<DIV style="position:absolute;top:147;left:686"><nobr><span class="ft24">1</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:690"><nobr><span class="ft4"> out that </span></nobr></DIV>
<DIV style="position:absolute;top:162;left:200"><nobr><span class="ft40">common</span></nobr></DIV>
<DIV style="position:absolute;top:162;left:239"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:162;left:242"><nobr><span class="ft16">kernel</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:271"><nobr><span class="ft20">1</span></nobr></DIV>
<DIV style="position:absolute;top:162;left:274"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:162;left:277"><nobr><span class="ft41">algorithms</span></nobr></DIV>
<DIV style="position:absolute;top:162;left:325"><nobr><span class="ft4"> such as </span></nobr></DIV>
<DIV style="position:absolute;top:162;left:364"><nobr><span class="ft16">SVMs</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:392"><nobr><span class="ft20">1</span></nobr></DIV>
<DIV style="position:absolute;top:162;left:396"><nobr><span class="ft4"> and </span></nobr></DIV>
<DIV style="position:absolute;top:162;left:418"><nobr><span class="ft16">kernel</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:446"><nobr><span class="ft20">1</span></nobr></DIV>
<DIV style="position:absolute;top:162;left:450"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:162;left:453"><nobr><span class="ft16">PCA</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:474"><nobr><span class="ft20">1</span></nobr></DIV>
<DIV style="position:absolute;top:162;left:478"><nobr><span class="ft4"> are actually really </span></nobr></DIV>
<DIV style="position:absolute;top:162;left:564"><nobr><span class="ft16">distance</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:601"><nobr><span class="ft20">1</span></nobr></DIV>
<DIV style="position:absolute;top:162;left:605"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:162;left:608"><nobr><span class="ft27">based</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:634"><nobr><span class="ft28">2</span></nobr></DIV>
<DIV style="position:absolute;top:162;left:637"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:162;left:640"><nobr><span class="ft42">algorithms</span></nobr></DIV>
<DIV style="position:absolute;top:162;left:688"><nobr><span class="ft4"> and can be </span></nobr></DIV>
<DIV style="position:absolute;top:175;left:200"><nobr><span class="ft38">run</span></nobr></DIV>
<DIV style="position:absolute;top:173;left:215"><nobr><span class="ft39">2</span></nobr></DIV>
<DIV style="position:absolute;top:175;left:219"><nobr><span class="ft4"> with that </span></nobr></DIV>
<DIV style="position:absolute;top:175;left:264"><nobr><span class="ft30">class</span></nobr></DIV>
<DIV style="position:absolute;top:175;left:286"><nobr><span class="ft4"> of </span></nobr></DIV>
<DIV style="position:absolute;top:175;left:301"><nobr><span class="ft16">kernels</span></nobr></DIV>
<DIV style="position:absolute;top:173;left:334"><nobr><span class="ft20">1</span></nobr></DIV>
<DIV style="position:absolute;top:175;left:337"><nobr><span class="ft4"> too As well as </span></nobr></DIV>
<DIV style="position:absolute;top:175;left:407"><nobr><span class="ft43">providing</span></nobr></DIV>
<DIV style="position:absolute;top:173;left:451"><nobr><span class="ft44">1</span></nobr></DIV>
<DIV style="position:absolute;top:175;left:454"><nobr><span class="ft4"> a useful new </span></nobr></DIV>
<DIV style="position:absolute;top:175;left:517"><nobr><span class="ft18">insight</span></nobr></DIV>
<DIV style="position:absolute;top:173;left:548"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:175;left:551"><nobr><span class="ft4"> into how these </span></nobr></DIV>
<DIV style="position:absolute;top:175;left:622"><nobr><span class="ft45">algorithms</span></nobr></DIV>
<DIV style="position:absolute;top:175;left:670"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:175;left:673"><nobr><span class="ft34">work</span></nobr></DIV>
<DIV style="position:absolute;top:175;left:697"><nobr><span class="ft4"> the </span></nobr></DIV>
<DIV style="position:absolute;top:188;left:200"><nobr><span class="ft46">present</span></nobr></DIV>
<DIV style="position:absolute;top:186;left:233"><nobr><span class="ft47">2</span></nobr></DIV>
<DIV style="position:absolute;top:188;left:236"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:188;left:239"><nobr><span class="ft48">work</span></nobr></DIV>
<DIV style="position:absolute;top:188;left:262"><nobr><span class="ft4"> can </span></nobr></DIV>
<DIV style="position:absolute;top:188;left:284"><nobr><span class="ft29">form</span></nobr></DIV>
<DIV style="position:absolute;top:188;left:305"><nobr><span class="ft4"> the </span></nobr></DIV>
<DIV style="position:absolute;top:188;left:325"><nobr><span class="ft36">basis</span></nobr></DIV>
<DIV style="position:absolute;top:186;left:347"><nobr><span class="ft37">1</span></nobr></DIV>
<DIV style="position:absolute;top:188;left:351"><nobr><span class="ft4"> for </span></nobr></DIV>
<DIV style="position:absolute;top:188;left:370"><nobr><span class="ft26">conceiving</span></nobr></DIV>
<DIV style="position:absolute;top:188;left:419"><nobr><span class="ft4"> new </span></nobr></DIV>
<DIV style="position:absolute;top:188;left:444"><nobr><span class="ft41">algorithms</span></nobr></DIV>
<DIV style="position:absolute;top:188;left:492"><nobr><span class="ft4">  </span></nobr></DIV>
<DIV style="position:absolute;top:218;left:200"><nobr><span class="ft4">This </span></nobr></DIV>
<DIV style="position:absolute;top:218;left:223"><nobr><span class="ft45">paper</span></nobr></DIV>
<DIV style="position:absolute;top:218;left:248"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:218;left:251"><nobr><span class="ft27">presents</span></nobr></DIV>
<DIV style="position:absolute;top:217;left:288"><nobr><span class="ft28">2</span></nobr></DIV>
<DIV style="position:absolute;top:218;left:291"><nobr><span class="ft4"> a </span></nobr></DIV>
<DIV style="position:absolute;top:218;left:302"><nobr><span class="ft30">comprehensive</span></nobr></DIV>
<DIV style="position:absolute;top:218;left:370"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:218;left:373"><nobr><span class="ft40">approach</span></nobr></DIV>
<DIV style="position:absolute;top:218;left:414"><nobr><span class="ft4"> for </span></nobr></DIV>
<DIV style="position:absolute;top:218;left:433"><nobr><span class="ft27">model</span></nobr></DIV>
<DIV style="position:absolute;top:217;left:461"><nobr><span class="ft28">2</span></nobr></DIV>
<DIV style="position:absolute;top:218;left:465"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:218;left:468"><nobr><span class="ft49">based</span></nobr></DIV>
<DIV style="position:absolute;top:217;left:493"><nobr><span class="ft50">2</span></nobr></DIV>
<DIV style="position:absolute;top:218;left:497"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:218;left:500"><nobr><span class="ft17">diagnosis</span></nobr></DIV>
<DIV style="position:absolute;top:217;left:542"><nobr><span class="ft51">2</span></nobr></DIV>
<DIV style="position:absolute;top:218;left:546"><nobr><span class="ft4"> which </span></nobr></DIV>
<DIV style="position:absolute;top:218;left:579"><nobr><span class="ft52">includes</span></nobr></DIV>
<DIV style="position:absolute;top:218;left:616"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:218;left:619"><nobr><span class="ft26">proposals</span></nobr></DIV>
<DIV style="position:absolute;top:218;left:662"><nobr><span class="ft4"> for </span></nobr></DIV>
<DIV style="position:absolute;top:231;left:200"><nobr><span class="ft42">characterizing</span></nobr></DIV>
<DIV style="position:absolute;top:231;left:264"><nobr><span class="ft4"> and </span></nobr></DIV>
<DIV style="position:absolute;top:231;left:286"><nobr><span class="ft53">computing</span></nobr></DIV>
<DIV style="position:absolute;top:230;left:334"><nobr><span class="ft54">2</span></nobr></DIV>
<DIV style="position:absolute;top:231;left:337"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:231;left:340"><nobr><span class="ft27">preferred</span></nobr></DIV>
<DIV style="position:absolute;top:230;left:382"><nobr><span class="ft28">2</span></nobr></DIV>
<DIV style="position:absolute;top:231;left:385"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:231;left:388"><nobr><span class="ft17">diagnoses</span></nobr></DIV>
<DIV style="position:absolute;top:230;left:433"><nobr><span class="ft51">2</span></nobr></DIV>
<DIV style="position:absolute;top:231;left:436"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:231;left:439"><nobr><span class="ft48">assuming</span></nobr></DIV>
<DIV style="position:absolute;top:231;left:481"><nobr><span class="ft4"> that the </span></nobr></DIV>
<DIV style="position:absolute;top:231;left:520"><nobr><span class="ft27">system</span></nobr></DIV>
<DIV style="position:absolute;top:230;left:552"><nobr><span class="ft28">2</span></nobr></DIV>
<DIV style="position:absolute;top:231;left:555"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:231;left:558"><nobr><span class="ft55">description</span></nobr></DIV>
<DIV style="position:absolute;top:230;left:608"><nobr><span class="ft56">2</span></nobr></DIV>
<DIV style="position:absolute;top:231;left:612"><nobr><span class="ft4"> is </span></nobr></DIV>
<DIV style="position:absolute;top:231;left:625"><nobr><span class="ft57">augmented</span></nobr></DIV>
<DIV style="position:absolute;top:231;left:675"><nobr><span class="ft4"> with a </span></nobr></DIV>
<DIV style="position:absolute;top:244;left:200"><nobr><span class="ft17">system</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:231"><nobr><span class="ft51">2</span></nobr></DIV>
<DIV style="position:absolute;top:244;left:235"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:244;left:238"><nobr><span class="ft17">structure</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:277"><nobr><span class="ft51">2</span></nobr></DIV>
<DIV style="position:absolute;top:244;left:281"><nobr><span class="ft4"> a </span></nobr></DIV>
<DIV style="position:absolute;top:244;left:292"><nobr><span class="ft17">directed</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:328"><nobr><span class="ft51">2</span></nobr></DIV>
<DIV style="position:absolute;top:244;left:332"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:244;left:335"><nobr><span class="ft17">graph</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:360"><nobr><span class="ft51">2</span></nobr></DIV>
<DIV style="position:absolute;top:244;left:364"><nobr><span class="ft4"> explicating the </span></nobr></DIV>
<DIV style="position:absolute;top:244;left:436"><nobr><span class="ft48">interconnections</span></nobr></DIV>
<DIV style="position:absolute;top:244;left:510"><nobr><span class="ft4"> between </span></nobr></DIV>
<DIV style="position:absolute;top:244;left:553"><nobr><span class="ft58">system</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:585"><nobr><span class="ft59">2</span></nobr></DIV>
<DIV style="position:absolute;top:244;left:588"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:244;left:591"><nobr><span class="ft27">components</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:646"><nobr><span class="ft28">2</span></nobr></DIV>
<DIV style="position:absolute;top:244;left:649"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:244;left:652"><nobr><span class="ft33">Specifically</span></nobr></DIV>
<DIV style="position:absolute;top:244;left:706"><nobr><span class="ft4"> we </span></nobr></DIV>
<DIV style="position:absolute;top:257;left:200"><nobr><span class="ft4">first </span></nobr></DIV>
<DIV style="position:absolute;top:257;left:221"><nobr><span class="ft33">introduce</span></nobr></DIV>
<DIV style="position:absolute;top:257;left:264"><nobr><span class="ft4"> the </span></nobr></DIV>
<DIV style="position:absolute;top:257;left:283"><nobr><span class="ft41">notion</span></nobr></DIV>
<DIV style="position:absolute;top:257;left:312"><nobr><span class="ft4"> of a </span></nobr></DIV>
<DIV style="position:absolute;top:257;left:335"><nobr><span class="ft46">consequence</span></nobr></DIV>
<DIV style="position:absolute;top:255;left:392"><nobr><span class="ft47">2</span></nobr></DIV>
<DIV style="position:absolute;top:257;left:396"><nobr><span class="ft4"> which is a </span></nobr></DIV>
<DIV style="position:absolute;top:257;left:447"><nobr><span class="ft38">syntactically</span></nobr></DIV>
<DIV style="position:absolute;top:255;left:504"><nobr><span class="ft39">2</span></nobr></DIV>
<DIV style="position:absolute;top:257;left:507"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:257;left:510"><nobr><span class="ft52">unconstrained</span></nobr></DIV>
<DIV style="position:absolute;top:257;left:574"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:257;left:576"><nobr><span class="ft17">propositional</span></nobr></DIV>
<DIV style="position:absolute;top:255;left:636"><nobr><span class="ft51">2</span></nobr></DIV>
<DIV style="position:absolute;top:257;left:639"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:257;left:642"><nobr><span class="ft38">sentence</span></nobr></DIV>
<DIV style="position:absolute;top:255;left:681"><nobr><span class="ft39">2</span></nobr></DIV>
<DIV style="position:absolute;top:257;left:685"><nobr><span class="ft4"> that </span></nobr></DIV>
<DIV style="position:absolute;top:270;left:200"><nobr><span class="ft60">characterizes</span></nobr></DIV>
<DIV style="position:absolute;top:270;left:259"><nobr><span class="ft4"> all </span></nobr></DIV>
<DIV style="position:absolute;top:270;left:276"><nobr><span class="ft55">consistency</span></nobr></DIV>
<DIV style="position:absolute;top:268;left:328"><nobr><span class="ft56">2</span></nobr></DIV>
<DIV style="position:absolute;top:270;left:331"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:270;left:334"><nobr><span class="ft27">based</span></nobr></DIV>
<DIV style="position:absolute;top:268;left:361"><nobr><span class="ft28">2</span></nobr></DIV>
<DIV style="position:absolute;top:270;left:364"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:270;left:367"><nobr><span class="ft17">diagnoses</span></nobr></DIV>
<DIV style="position:absolute;top:268;left:412"><nobr><span class="ft51">2</span></nobr></DIV>
<DIV style="position:absolute;top:270;left:415"><nobr><span class="ft4"> and </span></nobr></DIV>
<DIV style="position:absolute;top:270;left:437"><nobr><span class="ft55">show</span></nobr></DIV>
<DIV style="position:absolute;top:268;left:460"><nobr><span class="ft56">2</span></nobr></DIV>
<DIV style="position:absolute;top:270;left:464"><nobr><span class="ft4"> that </span></nobr></DIV>
<DIV style="position:absolute;top:270;left:487"><nobr><span class="ft55">standard</span></nobr></DIV>
<DIV style="position:absolute;top:268;left:525"><nobr><span class="ft56">2</span></nobr></DIV>
<DIV style="position:absolute;top:270;left:529"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:270;left:532"><nobr><span class="ft45">characterizations</span></nobr></DIV>
<DIV style="position:absolute;top:270;left:608"><nobr><span class="ft4"> of </span></nobr></DIV>
<DIV style="position:absolute;top:270;left:623"><nobr><span class="ft17">diagnoses</span></nobr></DIV>
<DIV style="position:absolute;top:268;left:667"><nobr><span class="ft51">2</span></nobr></DIV>
<DIV style="position:absolute;top:270;left:671"><nobr><span class="ft4"> such as </span></nobr></DIV>
<DIV style="position:absolute;top:283;left:200"><nobr><span class="ft61">minimal</span></nobr></DIV>
<DIV style="position:absolute;top:283;left:238"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:283;left:241"><nobr><span class="ft21">conflicts</span></nobr></DIV>
<DIV style="position:absolute;top:281;left:279"><nobr><span class="ft22">1</span></nobr></DIV>
<DIV style="position:absolute;top:283;left:283"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:283;left:286"><nobr><span class="ft35">correspond</span></nobr></DIV>
<DIV style="position:absolute;top:283;left:336"><nobr><span class="ft4"> to </span></nobr></DIV>
<DIV style="position:absolute;top:283;left:350"><nobr><span class="ft17">syntactic</span></nobr></DIV>
<DIV style="position:absolute;top:281;left:390"><nobr><span class="ft51">2</span></nobr></DIV>
<DIV style="position:absolute;top:283;left:394"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:283;left:397"><nobr><span class="ft31">variations</span></nobr></DIV>
<DIV style="position:absolute;top:281;left:441"><nobr><span class="ft32">1</span></nobr></DIV>
<DIV style="position:absolute;top:283;left:445"><nobr><span class="ft4"> on a </span></nobr></DIV>
<DIV style="position:absolute;top:283;left:470"><nobr><span class="ft49">consequence</span></nobr></DIV>
<DIV style="position:absolute;top:281;left:527"><nobr><span class="ft50">2</span></nobr></DIV>
<DIV style="position:absolute;top:283;left:530"><nobr><span class="ft4"> Second we </span></nobr></DIV>
<DIV style="position:absolute;top:283;left:585"><nobr><span class="ft42">propose</span></nobr></DIV>
<DIV style="position:absolute;top:283;left:621"><nobr><span class="ft4"> a new </span></nobr></DIV>
<DIV style="position:absolute;top:283;left:653"><nobr><span class="ft17">syntactic</span></nobr></DIV>
<DIV style="position:absolute;top:281;left:693"><nobr><span class="ft51">2</span></nobr></DIV>
<DIV style="position:absolute;top:283;left:697"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:283;left:700"><nobr><span class="ft41">variation</span></nobr></DIV>
<DIV style="position:absolute;top:283;left:739"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:296;left:200"><nobr><span class="ft4">on the </span></nobr></DIV>
<DIV style="position:absolute;top:296;left:231"><nobr><span class="ft49">consequence</span></nobr></DIV>
<DIV style="position:absolute;top:294;left:288"><nobr><span class="ft50">2</span></nobr></DIV>
<DIV style="position:absolute;top:296;left:292"><nobr><span class="ft4"> known as </span></nobr></DIV>
<DIV style="position:absolute;top:296;left:340"><nobr><span class="ft17">negation</span></nobr></DIV>
<DIV style="position:absolute;top:294;left:379"><nobr><span class="ft51">2</span></nobr></DIV>
<DIV style="position:absolute;top:296;left:383"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:296;left:386"><nobr><span class="ft45">normal</span></nobr></DIV>
<DIV style="position:absolute;top:296;left:418"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:296;left:421"><nobr><span class="ft42">form</span></nobr></DIV>
<DIV style="position:absolute;top:296;left:442"><nobr><span class="ft4"> NNF and </span></nobr></DIV>
<DIV style="position:absolute;top:296;left:490"><nobr><span class="ft60">discuss</span></nobr></DIV>
<DIV style="position:absolute;top:296;left:522"><nobr><span class="ft4"> its </span></nobr></DIV>
<DIV style="position:absolute;top:296;left:538"><nobr><span class="ft35">merits</span></nobr></DIV>
<DIV style="position:absolute;top:296;left:566"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:296;left:569"><nobr><span class="ft57">compared</span></nobr></DIV>
<DIV style="position:absolute;top:296;left:613"><nobr><span class="ft4"> to </span></nobr></DIV>
<DIV style="position:absolute;top:296;left:628"><nobr><span class="ft61">standard</span></nobr></DIV>
<DIV style="position:absolute;top:296;left:666"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:296;left:669"><nobr><span class="ft48">variations</span></nobr></DIV>
<DIV style="position:absolute;top:296;left:713"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:309;left:200"><nobr><span class="ft4">Third we </span></nobr></DIV>
<DIV style="position:absolute;top:309;left:244"><nobr><span class="ft45">introduce</span></nobr></DIV>
<DIV style="position:absolute;top:309;left:286"><nobr><span class="ft4"> a </span></nobr></DIV>
<DIV style="position:absolute;top:309;left:297"><nobr><span class="ft30">basic</span></nobr></DIV>
<DIV style="position:absolute;top:309;left:320"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:309;left:323"><nobr><span class="ft17">algorithm</span></nobr></DIV>
<DIV style="position:absolute;top:307;left:367"><nobr><span class="ft51">2</span></nobr></DIV>
<DIV style="position:absolute;top:309;left:370"><nobr><span class="ft4"> for </span></nobr></DIV>
<DIV style="position:absolute;top:309;left:389"><nobr><span class="ft41">computing</span></nobr></DIV>
<DIV style="position:absolute;top:309;left:437"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:309;left:440"><nobr><span class="ft33">consequences</span></nobr></DIV>
<DIV style="position:absolute;top:309;left:502"><nobr><span class="ft4"> in NNF given a </span></nobr></DIV>
<DIV style="position:absolute;top:309;left:577"><nobr><span class="ft29">structured</span></nobr></DIV>
<DIV style="position:absolute;top:309;left:622"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:309;left:625"><nobr><span class="ft49">system</span></nobr></DIV>
<DIV style="position:absolute;top:307;left:656"><nobr><span class="ft50">2</span></nobr></DIV>
<DIV style="position:absolute;top:309;left:660"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:309;left:663"><nobr><span class="ft33">description</span></nobr></DIV>
<DIV style="position:absolute;top:309;left:713"><nobr><span class="ft4"> We </span></nobr></DIV>
<DIV style="position:absolute;top:322;left:200"><nobr><span class="ft45">show</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:224"><nobr><span class="ft4"> that if the </span></nobr></DIV>
<DIV style="position:absolute;top:322;left:273"><nobr><span class="ft27">system</span></nobr></DIV>
<DIV style="position:absolute;top:320;left:304"><nobr><span class="ft28">2</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:307"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:322;left:310"><nobr><span class="ft17">structure</span></nobr></DIV>
<DIV style="position:absolute;top:320;left:350"><nobr><span class="ft51">2</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:354"><nobr><span class="ft4"> does not contain </span></nobr></DIV>
<DIV style="position:absolute;top:322;left:433"><nobr><span class="ft46">cycles</span></nobr></DIV>
<DIV style="position:absolute;top:320;left:461"><nobr><span class="ft47">2</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:465"><nobr><span class="ft4"> then there is always a </span></nobr></DIV>
<DIV style="position:absolute;top:322;left:567"><nobr><span class="ft45">linear</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:593"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:322;left:596"><nobr><span class="ft27">size</span></nobr></DIV>
<DIV style="position:absolute;top:320;left:613"><nobr><span class="ft28">2</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:617"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:322;left:620"><nobr><span class="ft27">consequence</span></nobr></DIV>
<DIV style="position:absolute;top:320;left:677"><nobr><span class="ft28">2</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:681"><nobr><span class="ft4"> in NNF </span></nobr></DIV>
<DIV style="position:absolute;top:335;left:200"><nobr><span class="ft4">which can be </span></nobr></DIV>
<DIV style="position:absolute;top:335;left:262"><nobr><span class="ft29">computed</span></nobr></DIV>
<DIV style="position:absolute;top:335;left:307"><nobr><span class="ft4"> in </span></nobr></DIV>
<DIV style="position:absolute;top:335;left:321"><nobr><span class="ft52">linear</span></nobr></DIV>
<DIV style="position:absolute;top:335;left:347"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:335;left:349"><nobr><span class="ft46">time</span></nobr></DIV>
<DIV style="position:absolute;top:333;left:370"><nobr><span class="ft47">2</span></nobr></DIV>
<DIV style="position:absolute;top:335;left:373"><nobr><span class="ft4"> For </span></nobr></DIV>
<DIV style="position:absolute;top:335;left:394"><nobr><span class="ft21">arbitrary</span></nobr></DIV>
<DIV style="position:absolute;top:333;left:433"><nobr><span class="ft22">1</span></nobr></DIV>
<DIV style="position:absolute;top:335;left:436"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:335;left:439"><nobr><span class="ft49">system</span></nobr></DIV>
<DIV style="position:absolute;top:333;left:471"><nobr><span class="ft50">2</span></nobr></DIV>
<DIV style="position:absolute;top:335;left:475"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:335;left:478"><nobr><span class="ft38">structures</span></nobr></DIV>
<DIV style="position:absolute;top:333;left:521"><nobr><span class="ft39">2</span></nobr></DIV>
<DIV style="position:absolute;top:335;left:525"><nobr><span class="ft4"> we </span></nobr></DIV>
<DIV style="position:absolute;top:335;left:544"><nobr><span class="ft41">show</span></nobr></DIV>
<DIV style="position:absolute;top:335;left:568"><nobr><span class="ft4"> a </span></nobr></DIV>
<DIV style="position:absolute;top:335;left:578"><nobr><span class="ft35">precise</span></nobr></DIV>
<DIV style="position:absolute;top:335;left:610"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:335;left:613"><nobr><span class="ft25">connection</span></nobr></DIV>
<DIV style="position:absolute;top:335;left:662"><nobr><span class="ft4"> between the </span></nobr></DIV>
<DIV style="position:absolute;top:348;left:200"><nobr><span class="ft53">complexity</span></nobr></DIV>
<DIV style="position:absolute;top:346;left:250"><nobr><span class="ft54">2</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:254"><nobr><span class="ft4"> of </span></nobr></DIV>
<DIV style="position:absolute;top:348;left:269"><nobr><span class="ft55">computing</span></nobr></DIV>
<DIV style="position:absolute;top:346;left:318"><nobr><span class="ft56">2</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:321"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:348;left:324"><nobr><span class="ft61">consequences</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:386"><nobr><span class="ft4"> and the </span></nobr></DIV>
<DIV style="position:absolute;top:348;left:424"><nobr><span class="ft33">topology</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:464"><nobr><span class="ft4"> of the </span></nobr></DIV>
<DIV style="position:absolute;top:348;left:496"><nobr><span class="ft35">underlying</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:544"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:348;left:547"><nobr><span class="ft55">system</span></nobr></DIV>
<DIV style="position:absolute;top:346;left:579"><nobr><span class="ft56">2</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:582"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:348;left:585"><nobr><span class="ft17">structure</span></nobr></DIV>
<DIV style="position:absolute;top:346;left:625"><nobr><span class="ft51">2</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:628"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:348;left:631"><nobr><span class="ft29">Finally</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:663"><nobr><span class="ft4"> we </span></nobr></DIV>
<DIV style="position:absolute;top:348;left:682"><nobr><span class="ft58">present</span></nobr></DIV>
<DIV style="position:absolute;top:346;left:715"><nobr><span class="ft59">2</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:718"><nobr><span class="ft4"> an </span></nobr></DIV>
<DIV style="position:absolute;top:360;left:200"><nobr><span class="ft49">algorithm</span></nobr></DIV>
<DIV style="position:absolute;top:359;left:244"><nobr><span class="ft50">2</span></nobr></DIV>
<DIV style="position:absolute;top:360;left:248"><nobr><span class="ft4"> that </span></nobr></DIV>
<DIV style="position:absolute;top:360;left:270"><nobr><span class="ft58">enumerates</span></nobr></DIV>
<DIV style="position:absolute;top:359;left:322"><nobr><span class="ft59">2</span></nobr></DIV>
<DIV style="position:absolute;top:360;left:325"><nobr><span class="ft4"> the </span></nobr></DIV>
<DIV style="position:absolute;top:360;left:345"><nobr><span class="ft27">preferred</span></nobr></DIV>
<DIV style="position:absolute;top:359;left:386"><nobr><span class="ft28">2</span></nobr></DIV>
<DIV style="position:absolute;top:360;left:389"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:360;left:392"><nobr><span class="ft17">diagnoses</span></nobr></DIV>
<DIV style="position:absolute;top:359;left:437"><nobr><span class="ft51">2</span></nobr></DIV>
<DIV style="position:absolute;top:360;left:440"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:360;left:443"><nobr><span class="ft25">characterized</span></nobr></DIV>
<DIV style="position:absolute;top:360;left:503"><nobr><span class="ft4"> by a </span></nobr></DIV>
<DIV style="position:absolute;top:360;left:528"><nobr><span class="ft27">consequence</span></nobr></DIV>
<DIV style="position:absolute;top:359;left:585"><nobr><span class="ft28">2</span></nobr></DIV>
<DIV style="position:absolute;top:360;left:589"><nobr><span class="ft4"> The </span></nobr></DIV>
<DIV style="position:absolute;top:360;left:612"><nobr><span class="ft49">algorithm</span></nobr></DIV>
<DIV style="position:absolute;top:359;left:656"><nobr><span class="ft50">2</span></nobr></DIV>
<DIV style="position:absolute;top:360;left:660"><nobr><span class="ft4"> is </span></nobr></DIV>
<DIV style="position:absolute;top:360;left:673"><nobr><span class="ft23">shown</span></nobr></DIV>
<DIV style="position:absolute;top:359;left:702"><nobr><span class="ft24">1</span></nobr></DIV>
<DIV style="position:absolute;top:360;left:706"><nobr><span class="ft4"> to take </span></nobr></DIV>
<DIV style="position:absolute;top:373;left:200"><nobr><span class="ft60">linear</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:226"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:373;left:229"><nobr><span class="ft27">time</span></nobr></DIV>
<DIV style="position:absolute;top:372;left:249"><nobr><span class="ft28">2</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:252"><nobr><span class="ft4"> in the </span></nobr></DIV>
<DIV style="position:absolute;top:373;left:283"><nobr><span class="ft27">size</span></nobr></DIV>
<DIV style="position:absolute;top:372;left:301"><nobr><span class="ft28">2</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:304"><nobr><span class="ft4"> of the </span></nobr></DIV>
<DIV style="position:absolute;top:373;left:336"><nobr><span class="ft38">consequence</span></nobr></DIV>
<DIV style="position:absolute;top:372;left:394"><nobr><span class="ft39">2</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:397"><nobr><span class="ft4"> if the </span></nobr></DIV>
<DIV style="position:absolute;top:373;left:427"><nobr><span class="ft33">preference</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:474"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:373;left:477"><nobr><span class="ft23">criterion</span></nobr></DIV>
<DIV style="position:absolute;top:372;left:514"><nobr><span class="ft24">1</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:518"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:373;left:521"><nobr><span class="ft60">satisfies</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:558"><nobr><span class="ft4"> some </span></nobr></DIV>
<DIV style="position:absolute;top:373;left:587"><nobr><span class="ft40">general</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:620"><nobr><span class="ft4"> </span></nobr></DIV>
<DIV style="position:absolute;top:373;left:623"><nobr><span class="ft57">conditions</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:670"><nobr><span class="ft4">  </span></nobr></DIV>
<DIV style="position:absolute;top:404;left:200"><nobr><span class="ft2"> </span></nobr></DIV>
<DIV style="position:absolute;top:408;left:179"><nobr><span class="ft3">Figure 5: Automated labeling of a pseudo-abstract from two authors by the model.</span></nobr></DIV>
<DIV style="position:absolute;top:452;left:93"><nobr><span class="ft7">ment treated as if they had both written it. These two au-<br>thors work in relatively different but not entirely unrelated<br>sub-areas of computer science: Scholkopf in machine learn-<br>ing and Darwiche in probabilistic reasoning. The document<br>is then parsed by the model. i.e., words are assigned to these<br>authors. We would hope that the author-topic model, condi-<br>tioned now on these two authors, can separate the combined<br>abstract into its component parts.</span></nobr></DIV>
<DIV style="position:absolute;top:578;left:107"><nobr><span class="ft3">Figure 5 shows the results after the model has classified</span></nobr></DIV>
<DIV style="position:absolute;top:594;left:93"><nobr><span class="ft7">each word according to the most likely author. Note that<br>the model only sees a bag of words and is not aware of the<br>word order that we see in the figure. For readers viewing<br>this in color, the more red a word is the more likely it is to<br>have been generated (according to the model) by Scholkopf<br>(and blue for Darwiche). For readers viewing the figure in<br>black and white, the superscript 1 indicates words classified<br>by the model for Scholkopf, and superscript 2 for Darwiche.<br>The results show that all of the significant content words<br>(such as kernel, support, vector, diagnoses, directed, graph)<br>are classified correctly. As we might expect most of the "er-<br>rors" are words (such as "based" or "criterion") that are not<br>specific to either authors' area of research. Were we to use<br>word order in the classification, and classify (for example)<br>whole sentences, the accuracy would increase further. As it<br>is, the model correctly classifies 69% of Scholkopf's words<br>and 72% of Darwiche's.</span></nobr></DIV>
<DIV style="position:absolute;top:881;left:93"><nobr><span class="ft1">4.3 Detecting the Most Surprising and Least</span></nobr></DIV>
<DIV style="position:absolute;top:899;left:134"><nobr><span class="ft1">Surprising Papers for an Author</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:107"><nobr><span class="ft3">In Tables 1 through 3 we used the model to score papers</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:93"><nobr><span class="ft7">attributed to three well-known researchers in computer sci-<br>ence (Christos Faloutsos, Michael Jordan, and Tom Mitchell).<br>For each document for each of these authors we calculate<br>a perplexity score. Perplexity is widely used in language<br>modeling to assess the predictive power of a model. It is a<br>measure of how surprising the words are from the model's<br>perspective, loosely equivalent to the effective branching fac-<br>tor. Formally, the perplexity score of a new unobserved doc-<br>ument d that contains a set of words W</span></nobr></DIV>
<DIV style="position:absolute;top:1072;left:342"><nobr><span class="ft9"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:1066;left:354"><nobr><span class="ft3">and conditioned</span></nobr></DIV>
<DIV style="position:absolute;top:452;left:488"><nobr><span class="ft3">on a topic model for a specific author a is:</span></nobr></DIV>
<DIV style="position:absolute;top:484;left:544"><nobr><span class="ft3">Perplexity(W</span></nobr></DIV>
<DIV style="position:absolute;top:490;left:624"><nobr><span class="ft9"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:484;left:631"><nobr><span class="ft3">|a) = exp - log p(W</span></nobr></DIV>
<DIV style="position:absolute;top:481;left:756"><nobr><span class="ft9"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:476;left:762"><nobr><span class="ft3">|a)</span></nobr></DIV>
<DIV style="position:absolute;top:493;left:730"><nobr><span class="ft3">|W</span></nobr></DIV>
<DIV style="position:absolute;top:499;left:748"><nobr><span class="ft9"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:493;left:754"><nobr><span class="ft3">|</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:488"><nobr><span class="ft3">where p(W</span></nobr></DIV>
<DIV style="position:absolute;top:522;left:556"><nobr><span class="ft9"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:517;left:563"><nobr><span class="ft3">|a) is the probability assigned by the author</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:488"><nobr><span class="ft3">topic model to the words W</span></nobr></DIV>
<DIV style="position:absolute;top:538;left:659"><nobr><span class="ft9"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:533;left:670"><nobr><span class="ft3">conditioned on the single au-</span></nobr></DIV>
<DIV style="position:absolute;top:548;left:488"><nobr><span class="ft3">thor a, and |W</span></nobr></DIV>
<DIV style="position:absolute;top:554;left:580"><nobr><span class="ft9"><i>d</i></span></nobr></DIV>
<DIV style="position:absolute;top:548;left:587"><nobr><span class="ft3">| is the number of words in the document.</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:488"><nobr><span class="ft7">Even if the document was written by multiple authors we<br>evaluate the perplexity score relative to a single author in<br>order to judge perplexity relative to that individual.</span></nobr></DIV>
<DIV style="position:absolute;top:611;left:501"><nobr><span class="ft3">Our goal here is not to evaluate the out-of-sample predic-</span></nobr></DIV>
<DIV style="position:absolute;top:627;left:488"><nobr><span class="ft7">tive power of the model, but to explore the range of per-<br>plexity scores that the model assigns to papers from specific<br>authors. Lower scores imply that the words w are less sur-<br>prising to the model (lower bounded by zero).In particular<br>we are interested in the abstracts that the model consid-<br>ers most surprising (highest perplexity) and least surprising<br>(lowest perplexity)--in each table we list the 2 abstracts<br>with the highest perplexity scores, the median perplexity,<br>and the 2 abstracts with the lowest perplexity scores.</span></nobr></DIV>
<DIV style="position:absolute;top:768;left:501"><nobr><span class="ft3">Table 1 for Christos Faloutsos shows that the two papers</span></nobr></DIV>
<DIV style="position:absolute;top:784;left:488"><nobr><span class="ft7">with the highest perplexities have significantly higher per-<br>plexity scores than the median and the two lowest perplexity<br>papers. The high perplexity papers are related to "query by<br>example" and the QBIC image database system, while the<br>low perplexity papers are on high-dimensional indexing. As<br>far as the topic model for Faloutsos is concerned, the index-<br>ing papers are much more typical of his work than the query<br>by example papers.</span></nobr></DIV>
<DIV style="position:absolute;top:909;left:501"><nobr><span class="ft3">Tables 2 and 3 provide interesting examples in that the</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:488"><nobr><span class="ft7">most perplexing papers (from the model's viewpoint) for<br>each author are papers that the author did not write at<br>all. As mentioned earlier, by combining all T Mitchell's and<br>M Jordan's together, the data set may contain authors who<br>are different from Tom Mitchell at CMU and Michael Jor-<br>dan at Berkeley. Thus, the highest perplexity paper for<br>T Mitchell is in fact authored by a Toby Mitchell and is on<br>the topic of estimating radiation doses (quite different from<br>the machine learning work of Tom Mitchell). Similarly, for<br>Michael Jordan, the most perplexing paper is on software</span></nobr></DIV>
<DIV style="position:absolute;top:54;left:91"><nobr><span class="ft5"><b>Research Track Paper</b></span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:460"><nobr><span class="ft6">312</span></nobr></DIV>
</DIV>
<!-- Page 8 -->
<a name="8"></a>
<DIV style="position:relative;width:928;height:1263;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="928" height="1263" src="151008.png" alt="background image">
<DIV style="position:absolute;top:95;left:204"><nobr><span class="ft3">Table 1: Papers ranked by perplexity for C. Faloutsos, from 31 documents.</span></nobr></DIV>
<DIV style="position:absolute;top:111;left:634"><nobr><span class="ft3">Paper Title</span></nobr></DIV>
<DIV style="position:absolute;top:111;left:720"><nobr><span class="ft3">Perplexity Score</span></nobr></DIV>
<DIV style="position:absolute;top:130;left:334"><nobr><span class="ft3">MindReader: Querying databases through multiple examples</span></nobr></DIV>
<DIV style="position:absolute;top:130;left:750"><nobr><span class="ft3">1503.7</span></nobr></DIV>
<DIV style="position:absolute;top:146;left:408"><nobr><span class="ft3">Efficient and effective querying by image content</span></nobr></DIV>
<DIV style="position:absolute;top:146;left:750"><nobr><span class="ft3">1498.2</span></nobr></DIV>
<DIV style="position:absolute;top:163;left:593"><nobr><span class="ft3">MEDIAN SCORE</span></nobr></DIV>
<DIV style="position:absolute;top:163;left:753"><nobr><span class="ft3">603.5</span></nobr></DIV>
<DIV style="position:absolute;top:179;left:122"><nobr><span class="ft3">Beyond uniformity and independence: analysis of R-trees using the concept of fractal dimension</span></nobr></DIV>
<DIV style="position:absolute;top:179;left:753"><nobr><span class="ft3">288.9</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:347"><nobr><span class="ft3">The TV-tree: an index structure for high-dimensional data</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:753"><nobr><span class="ft3">217.2</span></nobr></DIV>
<DIV style="position:absolute;top:226;left:211"><nobr><span class="ft3">Table 2: Papers ranked by perplexity for M. Jordan, from 33 documents.</span></nobr></DIV>
<DIV style="position:absolute;top:242;left:635"><nobr><span class="ft3">Paper Title</span></nobr></DIV>
<DIV style="position:absolute;top:242;left:720"><nobr><span class="ft3">Perplexity Score</span></nobr></DIV>
<DIV style="position:absolute;top:261;left:299"><nobr><span class="ft3">Software configuration management in an object oriented database</span></nobr></DIV>
<DIV style="position:absolute;top:261;left:750"><nobr><span class="ft3">1386.0</span></nobr></DIV>
<DIV style="position:absolute;top:277;left:164"><nobr><span class="ft3">Are arm trajectories planned in kinematic or dynamic coordinates? An adaptation study</span></nobr></DIV>
<DIV style="position:absolute;top:277;left:750"><nobr><span class="ft3">1319.2</span></nobr></DIV>
<DIV style="position:absolute;top:293;left:593"><nobr><span class="ft3">MEDIAN SCORE</span></nobr></DIV>
<DIV style="position:absolute;top:293;left:753"><nobr><span class="ft3">372.4</span></nobr></DIV>
<DIV style="position:absolute;top:310;left:277"><nobr><span class="ft3">On convergence properties of the EM algorithm for Gaussian mixtures</span></nobr></DIV>
<DIV style="position:absolute;top:310;left:753"><nobr><span class="ft3">180.0</span></nobr></DIV>
<DIV style="position:absolute;top:326;left:323"><nobr><span class="ft3">Supervised learning from incomplete data via an EM approach</span></nobr></DIV>
<DIV style="position:absolute;top:326;left:753"><nobr><span class="ft3">179.0</span></nobr></DIV>
<DIV style="position:absolute;top:357;left:210"><nobr><span class="ft3">Table 3: Papers ranked by perplexity for T. Mitchell from 15 documents.</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:638"><nobr><span class="ft3">Paper Title</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:723"><nobr><span class="ft3">Perplexity Score</span></nobr></DIV>
<DIV style="position:absolute;top:392;left:118"><nobr><span class="ft3">A method for estimating occupational radiation dose to individuals, using weekly dosimetry data</span></nobr></DIV>
<DIV style="position:absolute;top:392;left:753"><nobr><span class="ft3">2002.9</span></nobr></DIV>
<DIV style="position:absolute;top:408;left:297"><nobr><span class="ft3">Text classification from labeled and unlabeled documents using EM</span></nobr></DIV>
<DIV style="position:absolute;top:408;left:756"><nobr><span class="ft3">845.4</span></nobr></DIV>
<DIV style="position:absolute;top:424;left:596"><nobr><span class="ft3">MEDIAN SCORE</span></nobr></DIV>
<DIV style="position:absolute;top:424;left:756"><nobr><span class="ft3">411.5</span></nobr></DIV>
<DIV style="position:absolute;top:441;left:558"><nobr><span class="ft3">Learning one more thing</span></nobr></DIV>
<DIV style="position:absolute;top:441;left:756"><nobr><span class="ft3">266.5</span></nobr></DIV>
<DIV style="position:absolute;top:457;left:371"><nobr><span class="ft3">Explanation based learning for mobile robot perception</span></nobr></DIV>
<DIV style="position:absolute;top:457;left:756"><nobr><span class="ft3">264.2</span></nobr></DIV>
<DIV style="position:absolute;top:504;left:93"><nobr><span class="ft7">configuration management and was written by Mick Jordan<br>of Sun Microsystems. In fact, of the 7 most perplexing pa-<br>pers for M Jordan, 6 are on software management and the<br>JAVA programming language, all written by Mick Jordan.<br>However, the 2nd most perplexing paper was in fact co-<br>authored by Michael Jordan, but in the area of modeling of<br>motor planning, which is a far less common topic compared<br>to the machine learning papers that Jordan typically writes.</span></nobr></DIV>
<DIV style="position:absolute;top:642;left:93"><nobr><span class="ft1">5. AN AUTHOR-TOPIC BROWSER</span></nobr></DIV>
<DIV style="position:absolute;top:669;left:107"><nobr><span class="ft3">We have built a JAVA-based query interface tool that sup-</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:93"><nobr><span class="ft3">ports interactive querying of the model</span></nobr></DIV>
<DIV style="position:absolute;top:683;left:331"><nobr><span class="ft9"><i>1</i></span></nobr></DIV>
<DIV style="position:absolute;top:684;left:337"><nobr><span class="ft3">. The tool allows a</span></nobr></DIV>
<DIV style="position:absolute;top:700;left:93"><nobr><span class="ft7">user to query about authors, topics, documents, or words.<br>For example, given a query on a particular author the tool<br>retrieves and displays the most likely topics and their prob-<br>abilities for that author, the 5 most probable words for each<br>topic, and the document titles in the database for that au-<br>thor. Figure 6(a) (top panel) shows the result of querying<br>on Pazzani M and the resulting topic distribution (highly-<br>ranked topics include machine learning, classification, rule-<br>based systems, data mining, and information retrieval).</span></nobr></DIV>
<DIV style="position:absolute;top:841;left:107"><nobr><span class="ft3">Mouse-clicking on one of the topics (e.g., the data mining</span></nobr></DIV>
<DIV style="position:absolute;top:857;left:93"><nobr><span class="ft7">topic as shown in the figure) produces the screen display to<br>the left (Figure 6(b)). The most likely words for this topic<br>and the most likely authors given a word from this topic are<br>then displayed. We have found this to be a useful technique<br>for interactively exploring topics and authors, e.g., which<br>authors are active in a particular research area.</span></nobr></DIV>
<DIV style="position:absolute;top:951;left:107"><nobr><span class="ft3">Similarly, one can click on a particular paper (e.g., the</span></nobr></DIV>
<DIV style="position:absolute;top:967;left:93"><nobr><span class="ft7">paper A Learning Agent for Wireless News Access as shown<br>in the lower screenshot (Figure 6(c)) and the display in the<br>panel to the right is then produced. This display shows the<br>words in the documents and their counts, the probability<br>distribution over topics for the paper given the word counts</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:94"><nobr><span class="ft9"><i>1</i></span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:100"><nobr><span class="ft3">A prototype online version of the tool can be accessed at</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:93"><nobr><span class="ft3">http://www.datalab.uci.edu/author-topic</span></nobr></DIV>
<DIV style="position:absolute;top:1066;left:368"><nobr><span class="ft3">.</span></nobr></DIV>
<DIV style="position:absolute;top:504;left:488"><nobr><span class="ft7">(ranked by highest probability first), and a probability dis-<br>tribution over authors, based on the proportion of words<br>assigned by the model to each topic and author respectively.</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:501"><nobr><span class="ft3">The system is implemented using a combination of a re-</span></nobr></DIV>
<DIV style="position:absolute;top:567;left:488"><nobr><span class="ft7">lational database and real-time Bayesian estimation (a rela-<br>tively rare combination of these technologies for a real-time<br>query-answering system as far as we are aware). We use<br>a database to store and index both (a) the sparse author-<br>topic and topic-word count matrices that are learned by our<br>algorithm from the training data, and (b) various tables de-<br>scribing the data such as document-word, document-author,<br>and document-title tables. For a large document set such<br>as CiteSeer (and with 300 topics) these tables can run into<br>the hundred's of megabytes of memory--thus, we do not<br>load them into main memory automatically but instead issue<br>SQL commands to retrieve the relevant records in real-time.</span></nobr></DIV>
<DIV style="position:absolute;top:755;left:501"><nobr><span class="ft3">For most of the queries we have implemented to date the</span></nobr></DIV>
<DIV style="position:absolute;top:771;left:488"><nobr><span class="ft7">queries can be answered by simple table lookup followed by<br>appropriate normalization (if needed) of the stored counts<br>to generate conditional probabilities. For example, display-<br>ing the topic distribution for a specific author is simply a<br>matter of retrieving the appropriate record. However, when<br>a document is the basis of a query (e.g., as in the lower<br>screenshot, Figure 6(c)) we must compute in real-time the<br>conditional distribution of the fraction of words assigned to<br>each topic and author, a calculation that cannot be com-<br>puted in closed form. This requires retrieving all the rele-<br>vant word-topic counts for the words in the document via<br>SQL, then executing the estimation algorithm outlined in<br>Section 4.2 in real-time using Gibbs sampling, and display-<br>ing the results to the user. The user can change adjust the<br>burn-in time, the number of samples and the lag time in the<br>sampling algorithm--typically we have found that as few as<br>10 Gibbs samples gives quite reasonable results (and takes<br>on the order of 1 or 2 seconds depending on the machine<br>being used other factors).</span></nobr></DIV>
<DIV style="position:absolute;top:54;left:692"><nobr><span class="ft5"><b>Research Track Paper</b></span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:460"><nobr><span class="ft6">313</span></nobr></DIV>
</DIV>
<!-- Page 9 -->
<a name="9"></a>
<DIV style="position:relative;width:928;height:1263;">
<STYLE type="text/css">
<!--
	.ft62{font-size:16px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="928" height="1263" src="151009.png" alt="background image">
<DIV style="position:absolute;top:292;left:110"><nobr><span class="ft62">(b)</span></nobr></DIV>
<DIV style="position:absolute;top:89;left:341"><nobr><span class="ft62">(a)</span></nobr></DIV>
<DIV style="position:absolute;top:761;left:382"><nobr><span class="ft62">(c)</span></nobr></DIV>
<DIV style="position:absolute;top:1063;left:93"><nobr><span class="ft7">Figure 6: Examples of screenshots from the interactive query browser for the author-topic model with (a)<br>querying on author Pazzani M, (b) querying on a topic (data mining) relevant to that author, and (c) querying<br>on a particular document written by the author.</span></nobr></DIV>
<DIV style="position:absolute;top:54;left:91"><nobr><span class="ft5"><b>Research Track Paper</b></span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:460"><nobr><span class="ft6">314</span></nobr></DIV>
</DIV>
<!-- Page 10 -->
<a name="10"></a>
<DIV style="position:relative;width:928;height:1263;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="928" height="1263" src="151010.png" alt="background image">
<DIV style="position:absolute;top:79;left:93"><nobr><span class="ft1">6. CONCLUSIONS</span></nobr></DIV>
<DIV style="position:absolute;top:105;left:107"><nobr><span class="ft3">We have introduced a probabilistic algorithm that can</span></nobr></DIV>
<DIV style="position:absolute;top:121;left:93"><nobr><span class="ft7">that can automatically extract information about authors,<br>topics, and documents from large text corpora. The method<br>uses a generative probabilistic model that links authors to<br>observed words in documents via latent topics. We demon-<br>strated that Bayesian estimation can be used to learn such<br>author-topic models from very large text corpora, using Cite-<br>Seer abstracts as a working example. The resulting CiteSeer<br>author-topic model was shown to extract substantial novel<br>"hidden" information from the set of abstracts, including<br>topic time-trends, author-topic relations, unusual papers for<br>specific authors and so forth. Other potential applications<br>not discussed here include recommending potential review-<br>ers for a paper based on both the words in the paper and the<br>names of the authors. Even though the underlying proba-<br>bilistic model is quite simple, and ignores several aspects of<br>real-world document generation (such as topic correlation,<br>author interaction, and so forth), it nonetheless provides a<br>useful first step in understanding author-topic structure in<br>large text corpora.</span></nobr></DIV>
<DIV style="position:absolute;top:436;left:93"><nobr><span class="ft1">Acknowledgements</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:93"><nobr><span class="ft7">We would like to thank Steve Lawrence, C. Lee Giles, and<br>Isaac Council for providing the CiteSeer data used in this<br>paper. We also thank Momo Alhazzazi, Amnon Meyers,<br>and Joshua O'Madadhain for assistance in software devel-<br>opment and data preprocessing. The research in this paper<br>was supported in part by the National Science Foundation<br>under Grant IRI-9703120 via the Knowledge Discovery and<br>Dissemination (KD-D) program.</span></nobr></DIV>
<DIV style="position:absolute;top:606;left:93"><nobr><span class="ft1">References</span></nobr></DIV>
<DIV style="position:absolute;top:635;left:100"><nobr><span class="ft3">Blei, D. M., Ng, A. Y., and Jordan, M. I., (2003) Latent</span></nobr></DIV>
<DIV style="position:absolute;top:651;left:127"><nobr><span class="ft7">Dirichlet allocation, Journal of Machine Learning Re-<br>search 3, pp. 993­1022.</span></nobr></DIV>
<DIV style="position:absolute;top:696;left:100"><nobr><span class="ft3">Buntine, W.L. (1994) Operations for learning with graphi-</span></nobr></DIV>
<DIV style="position:absolute;top:712;left:127"><nobr><span class="ft7">cal models, Journal of Artificial Intelligence Research<br>2, pp. 159-225.</span></nobr></DIV>
<DIV style="position:absolute;top:757;left:100"><nobr><span class="ft3">Cutting, D., Karger, D. R., Pederson, J., and Tukey, J.</span></nobr></DIV>
<DIV style="position:absolute;top:773;left:127"><nobr><span class="ft7">W. (1992) Scatter/Gather: a cluster-based approach<br>to browsing large document collections, in Proceedings<br>of the 15th Annual International ACM SIGIR Con-<br>ference on Research and Development in Information<br>Retrieval, pp. 318­329.</span></nobr></DIV>
<DIV style="position:absolute;top:866;left:100"><nobr><span class="ft3">Deerwester, S. C., Dumais, S. T., Landauer, T. K., Furnas,</span></nobr></DIV>
<DIV style="position:absolute;top:881;left:127"><nobr><span class="ft7">G. W., and Harshman, R. A. (1990) Indexing by latent<br>semantic analysis, Journal of the American Society of<br>Information Science, 41(6), pp. 391­407.</span></nobr></DIV>
<DIV style="position:absolute;top:942;left:100"><nobr><span class="ft3">Diederich, J., Kindermann, J., Leopold, E., and Paass, G.</span></nobr></DIV>
<DIV style="position:absolute;top:958;left:127"><nobr><span class="ft7">(2003) Authorship attribution with support vector ma-<br>chines, Applied Intelligence 19 (1).</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:100"><nobr><span class="ft3">Erten, C., Harding, P. J., Kobourov, S. G., Wampler, K.,</span></nobr></DIV>
<DIV style="position:absolute;top:1019;left:127"><nobr><span class="ft7">and Yee, G. (2003) Exploring the computing literature<br>using temporal graph visualization, Technical Report,<br>Department of Computer Science, University of Ari-<br>zona.</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:495"><nobr><span class="ft3">Gray, A., Sallis, P., MacDonell, S. (1997) Software foren-</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:522"><nobr><span class="ft7">sics: Extending authorship analysis techniques to com-<br>puter programs, Proceedings of the 3rd Biannual Con-<br>ference of the International Association of Forensic<br>Linguists (IAFL), Durham NC.</span></nobr></DIV>
<DIV style="position:absolute;top:175;left:495"><nobr><span class="ft3">Griffiths, T. L., and Steyvers , M. (2004) Finding scien-</span></nobr></DIV>
<DIV style="position:absolute;top:191;left:522"><nobr><span class="ft7">tific topics, Proceedings of the National Academy of<br>Sciences, 101 (suppl. 1), 5228­5235.</span></nobr></DIV>
<DIV style="position:absolute;top:233;left:495"><nobr><span class="ft3">Hofmann, T. (1999) Probabilistic latent semantic index-</span></nobr></DIV>
<DIV style="position:absolute;top:249;left:522"><nobr><span class="ft7">ing, in Proceedings of the 22nd International Confer-<br>ence on Research and Development in Information Re-<br>trieval (SIGIR'99).</span></nobr></DIV>
<DIV style="position:absolute;top:307;left:495"><nobr><span class="ft3">Kautz, H., Selman, B., and Shah, M. (1997) Referral Web:</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:522"><nobr><span class="ft7">Combining social networks and collaborative filtering,<br>Communications of the ACM, 3, pp. 63­65.</span></nobr></DIV>
<DIV style="position:absolute;top:364;left:495"><nobr><span class="ft3">Lagus, K, Honkela, T., Kaski, S., and Kohonen, T. (1999)</span></nobr></DIV>
<DIV style="position:absolute;top:380;left:522"><nobr><span class="ft7">WEBSOM for textual data mining, Artificial Intelli-<br>gence Review, 13 (5­6), pp. 345­364.</span></nobr></DIV>
<DIV style="position:absolute;top:422;left:495"><nobr><span class="ft3">Lawrence, S., Giles, C. L., and Bollacker, K. (1999) Digi-</span></nobr></DIV>
<DIV style="position:absolute;top:438;left:522"><nobr><span class="ft7">tal libraries and autonomous citation indexing, IEEE<br>Computer, 32(6), pp. 67­71.</span></nobr></DIV>
<DIV style="position:absolute;top:480;left:495"><nobr><span class="ft3">McCallum, A., Nigam, K., and Ungar, L. (2000) Efficient</span></nobr></DIV>
<DIV style="position:absolute;top:496;left:522"><nobr><span class="ft7">clustering of high-dimensional data sets with applica-<br>tion to reference matching, in Proceedings of the Sixth<br>ACM SIGKDD Conference on Knowledge Discovery<br>and Data Mining, pp. 169­178.</span></nobr></DIV>
<DIV style="position:absolute;top:569;left:495"><nobr><span class="ft3">Mosteller, F., and Wallace, D. (1964) Applied Bayesian and</span></nobr></DIV>
<DIV style="position:absolute;top:585;left:522"><nobr><span class="ft7">Classical Inference: The Case of the Federalist Papers,<br>Springer-Verlag.</span></nobr></DIV>
<DIV style="position:absolute;top:627;left:495"><nobr><span class="ft3">Mutschke, P. (2003) Mining networks and central entities</span></nobr></DIV>
<DIV style="position:absolute;top:643;left:522"><nobr><span class="ft7">in digital libraries: a graph theoretic approach ap-<br>plied to co-author networks, Intelligent Data Analy-<br>sis 2003, Lecture Notes in Computer Science 2810,<br>Springer Verlag, pp. 155­166</span></nobr></DIV>
<DIV style="position:absolute;top:716;left:495"><nobr><span class="ft3">Newman, M. E. J. (2001) Scientific collaboration networks:</span></nobr></DIV>
<DIV style="position:absolute;top:732;left:522"><nobr><span class="ft7">I. Network construction and fundamental results, Phys-<br>ical Review E, 64, 016131.</span></nobr></DIV>
<DIV style="position:absolute;top:774;left:495"><nobr><span class="ft3">Popescul, A., Flake, G. W., Lawrence, S., Ungar, L. H., and</span></nobr></DIV>
<DIV style="position:absolute;top:790;left:522"><nobr><span class="ft7">Giles, C. L. (2000) Clustering and identifying tempo-<br>ral trends in document databases, IEEE Advances in<br>Digital Libraries, ADL 2000, pp. 173­182.</span></nobr></DIV>
<DIV style="position:absolute;top:848;left:495"><nobr><span class="ft3">Rosen-Zvi, M., Griffiths, T., Steyvers, M., Smyth, P. (2004)</span></nobr></DIV>
<DIV style="position:absolute;top:863;left:522"><nobr><span class="ft7">The author-topic model for authors and documents,<br>Proceedings of the 20th UAI Conference, July 2004.</span></nobr></DIV>
<DIV style="position:absolute;top:905;left:495"><nobr><span class="ft3">Thisted, B., and Efron, R. (1987) Did Shakespeare write a</span></nobr></DIV>
<DIV style="position:absolute;top:921;left:522"><nobr><span class="ft3">newly discovered poem?, Biometrika, pp. 445­455.</span></nobr></DIV>
<DIV style="position:absolute;top:948;left:495"><nobr><span class="ft3">White, S. and Smyth, P. (2003) Algorithms for estimating</span></nobr></DIV>
<DIV style="position:absolute;top:963;left:522"><nobr><span class="ft7">relative importance in networks, in Proceedings of the<br>Ninth ACM SIGKDD Conference on Knowledge Dis-<br>covery and Data Mining, pp. 266­275.</span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:495"><nobr><span class="ft3">Yang, Y. (1999) An evaluation of statistical approaches to</span></nobr></DIV>
<DIV style="position:absolute;top:1037;left:522"><nobr><span class="ft7">text categorization, Information Retrieval, 1, pp. 69­<br>90.</span></nobr></DIV>
<DIV style="position:absolute;top:54;left:692"><nobr><span class="ft5"><b>Research Track Paper</b></span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:460"><nobr><span class="ft6">315</span></nobr></DIV>
</DIV>
</BODY>
</HTML>
