<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
<HEAD>
<TITLE>sigir02.dvi</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<META name="generator" content="pdftohtml 0.35beta">
<META name="date" content="2002-06-20T10:45:51+00:00">
</HEAD>
<BODY bgcolor="#A0A0A0" vlink="blue" link="blue">
<!-- Page 1 -->
<a name="1"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft0{font-size:24px;font-family:Times;color:#000000;}
	.ft1{font-size:15px;font-family:Times;color:#000000;}
	.ft2{font-size:12px;font-family:Times;color:#000000;}
	.ft3{font-size:15px;font-family:Times;color:#000000;}
	.ft4{font-size:11px;font-family:Times;color:#000000;}
	.ft5{font-size:9px;font-family:Times;color:#000000;}
	.ft6{font-size:9px;font-family:Times;color:#000000;}
	.ft7{font-size:6px;font-family:Times;color:#000000;}
	.ft8{font-size:16px;font-family:Courier;color:#000000;}
	.ft9{font-size:11px;font-family:Times;color:#000000;}
	.ft10{font-size:12px;line-height:15px;font-family:Times;color:#000000;}
	.ft11{font-size:11px;line-height:15px;font-family:Times;color:#000000;}
	.ft12{font-size:9px;line-height:13px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="42001.png" alt="background image">
<DIV style="position:absolute;top:109;left:260"><nobr><span class="ft0"><b>Bayesian Online Classifiers for</b></span></nobr></DIV>
<DIV style="position:absolute;top:139;left:255"><nobr><span class="ft0"><b>Text Classification and Filtering</b></span></nobr></DIV>
<DIV style="position:absolute;top:207;left:151"><nobr><span class="ft1">Kian Ming Adam Chai</span></nobr></DIV>
<DIV style="position:absolute;top:225;left:149"><nobr><span class="ft2">DSO National Laboratories</span></nobr></DIV>
<DIV style="position:absolute;top:240;left:164"><nobr><span class="ft2">20 Science Park Drive</span></nobr></DIV>
<DIV style="position:absolute;top:256;left:177"><nobr><span class="ft2">Singapore 118230</span></nobr></DIV>
<DIV style="position:absolute;top:278;left:152"><nobr><span class="ft1">ckianmin@dso.org.sg</span></nobr></DIV>
<DIV style="position:absolute;top:207;left:404"><nobr><span class="ft1">Hwee Tou Ng</span></nobr></DIV>
<DIV style="position:absolute;top:225;left:356"><nobr><span class="ft10">Department of Computer Science<br>National University of Singapore</span></nobr></DIV>
<DIV style="position:absolute;top:256;left:399"><nobr><span class="ft2">3 Science Drive 2</span></nobr></DIV>
<DIV style="position:absolute;top:272;left:396"><nobr><span class="ft2">Singapore 117543</span></nobr></DIV>
<DIV style="position:absolute;top:294;left:363"><nobr><span class="ft1">nght@comp.nus.edu.sg</span></nobr></DIV>
<DIV style="position:absolute;top:207;left:610"><nobr><span class="ft1">Hai Leong Chieu</span></nobr></DIV>
<DIV style="position:absolute;top:225;left:587"><nobr><span class="ft2">DSO National Laboratories</span></nobr></DIV>
<DIV style="position:absolute;top:240;left:603"><nobr><span class="ft2">20 Science Park Drive</span></nobr></DIV>
<DIV style="position:absolute;top:256;left:616"><nobr><span class="ft2">Singapore 118230</span></nobr></DIV>
<DIV style="position:absolute;top:278;left:593"><nobr><span class="ft1">chaileon@dso.org.sg</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:81"><nobr><span class="ft3"><b>ABSTRACT</b></span></nobr></DIV>
<DIV style="position:absolute;top:373;left:81"><nobr><span class="ft11">This paper explores the use of Bayesian online classifiers<br>to classify text documents. Empirical results indicate that<br>these classifiers are comparable with the best text classifi-<br>cation systems. Furthermore, the online approach offers the<br>advantage of continuous learning in the batch-adaptive text<br>filtering task.</span></nobr></DIV>
<DIV style="position:absolute;top:484;left:81"><nobr><span class="ft3"><b>Categories and Subject Descriptors</b></span></nobr></DIV>
<DIV style="position:absolute;top:509;left:81"><nobr><span class="ft11">H.3.3 [Information Systems]: Information Search and Re-<br>trieval--Information filtering</span></nobr></DIV>
<DIV style="position:absolute;top:558;left:81"><nobr><span class="ft3"><b>General Terms</b></span></nobr></DIV>
<DIV style="position:absolute;top:583;left:81"><nobr><span class="ft4">Algorithms, Experimentation</span></nobr></DIV>
<DIV style="position:absolute;top:616;left:81"><nobr><span class="ft3"><b>Keywords</b></span></nobr></DIV>
<DIV style="position:absolute;top:641;left:81"><nobr><span class="ft11">Text Classification, Text Filtering, Bayesian, Online, Ma-<br>chine Learning</span></nobr></DIV>
<DIV style="position:absolute;top:689;left:81"><nobr><span class="ft3"><b>1.</b></span></nobr></DIV>
<DIV style="position:absolute;top:689;left:112"><nobr><span class="ft3"><b>INTRODUCTION</b></span></nobr></DIV>
<DIV style="position:absolute;top:712;left:94"><nobr><span class="ft4">Faced with massive information everyday, we need au-</span></nobr></DIV>
<DIV style="position:absolute;top:727;left:81"><nobr><span class="ft11">tomated means for classifying text documents. Since hand-<br>crafting text classifiers is a tedious process, machine learning<br>methods can assist in solving this problem[15, 7, 27].</span></nobr></DIV>
<DIV style="position:absolute;top:774;left:94"><nobr><span class="ft4">Yang &amp; Liu[27] provides a comprehensive comparison of</span></nobr></DIV>
<DIV style="position:absolute;top:790;left:81"><nobr><span class="ft11">supervised machine learning methods for text classification.<br>In this paper we will show that certain Bayesian classi-<br>fiers are comparable with Support Vector Machines[23], one<br>of the best methods reported in [27].</span></nobr></DIV>
<DIV style="position:absolute;top:837;left:333"><nobr><span class="ft4">In particular, we</span></nobr></DIV>
<DIV style="position:absolute;top:853;left:81"><nobr><span class="ft11">will evaluate the Bayesian online perceptron[17, 20] and the<br>Bayesian online Gaussian process[3].</span></nobr></DIV>
<DIV style="position:absolute;top:884;left:94"><nobr><span class="ft4">For text classification and filtering, where the initial train-</span></nobr></DIV>
<DIV style="position:absolute;top:900;left:81"><nobr><span class="ft11">ing set is large, online approaches are useful because they<br>allow continuous learning without storing all the previously</span></nobr></DIV>
<DIV style="position:absolute;top:977;left:81"><nobr><span class="ft12">Permission to make digital or hard copies of all or part of this work for<br>personal or classroom use is granted without fee provided that copies are<br>not made or distributed for profit or commercial advantage and that copies<br>bear this notice and the full citation on the first page. To copy otherwise, to<br>republish, to post on servers or to redistribute to lists, requires prior specific<br>permission and/or a fee.<br><i>SIGIR'02, </i>August 11-15, 2002, Tampere, Finland.<br>Copyright 2002 ACM 1-58113-561-0/02/0008 ...</span></nobr></DIV>
<DIV style="position:absolute;top:1070;left:316"><nobr><span class="ft4">$</span></nobr></DIV>
<DIV style="position:absolute;top:1071;left:323"><nobr><span class="ft5">5.00.</span></nobr></DIV>
<DIV style="position:absolute;top:351;left:475"><nobr><span class="ft11">seen data. This continuous learning allows the utilization<br>of information obtained from subsequent data after the ini-<br>tial training. Bayes' rule allows online learning to be per-<br>formed in a principled way[16, 20, 17]. We will evaluate the<br>Bayesian online perceptron, together with information gain<br>considerations, on the batch-adaptive filtering task[18].</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:475"><nobr><span class="ft3"><b>2.</b></span></nobr></DIV>
<DIV style="position:absolute;top:461;left:506"><nobr><span class="ft3"><b>CLASSIFICATION AND FILTERING</b></span></nobr></DIV>
<DIV style="position:absolute;top:484;left:489"><nobr><span class="ft4">For the text classification taskdefined by Lewis[9], we</span></nobr></DIV>
<DIV style="position:absolute;top:499;left:475"><nobr><span class="ft11">have a set of predefined categories and a set of documents.<br>For each category, the document set is partitioned into two<br>mutually exclusive sets of relevant and irrelevant documents.<br>The goal of a text classification system is to determine whether<br>a given document belongs to any of the predefined cate-<br>gories. Since the document can belong to zero, one, or more<br>categories, the system can be a collection of binary classi-<br>fiers, in which one classifier classifies for one category.</span></nobr></DIV>
<DIV style="position:absolute;top:625;left:489"><nobr><span class="ft4">In Text REtrieval Conference (TREC), the above taskis</span></nobr></DIV>
<DIV style="position:absolute;top:640;left:475"><nobr><span class="ft11">known as batch filtering. We will consider a variant of batch<br>filtering called the batch-adaptive filtering[18]. In this task,<br>during testing, if a document is retrieved by the classifier,<br>the relevance judgement is fed backto the classifier. This<br>feedbackcan be used to improve the classifier.</span></nobr></DIV>
<DIV style="position:absolute;top:727;left:475"><nobr><span class="ft3"><b>2.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:727;left:515"><nobr><span class="ft3"><b>Corpora and Data</b></span></nobr></DIV>
<DIV style="position:absolute;top:749;left:489"><nobr><span class="ft4">For text classification, we use the ModApte version of</span></nobr></DIV>
<DIV style="position:absolute;top:765;left:475"><nobr><span class="ft4">the Reuters-21578 corpus</span></nobr></DIV>
<DIV style="position:absolute;top:760;left:627"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:765;left:634"><nobr><span class="ft4">, where unlabelled documents are</span></nobr></DIV>
<DIV style="position:absolute;top:781;left:475"><nobr><span class="ft11">removed. This version has 9,603 training documents and<br>3,299 test documents. Following [7, 27], only categories that<br>have at least one document in the training and test set are<br>retained. This reduces the number of categories to 90.</span></nobr></DIV>
<DIV style="position:absolute;top:844;left:489"><nobr><span class="ft4">For batch-adaptive filtering, we attempt the taskof TREC-</span></nobr></DIV>
<DIV style="position:absolute;top:859;left:475"><nobr><span class="ft11">9[18], where the OHSUMED collection[6] is used. We will<br>evaluate on the OHSU topic-set, which consists of 63 topics.<br>The training and test material consist of 54,710 and 293,856<br>documents respectively. In addition, there is a topic state-<br>ment for each topic. For our purpose, this is treated as an<br>additional training document for that topic. We will only<br>use the title, abstract, author, and source sections of the<br>documents for training and testing.</span></nobr></DIV>
<DIV style="position:absolute;top:993;left:475"><nobr><span class="ft3"><b>2.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:993;left:515"><nobr><span class="ft3"><b>Representation</b></span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:489"><nobr><span class="ft4">There are various ways to transform a document into a</span></nobr></DIV>
<DIV style="position:absolute;top:1031;left:475"><nobr><span class="ft4">representation convenient for classification. We will use the</span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:476"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:482"><nobr><span class="ft4">Available via http://www.daviddlewis.com/resources/</span></nobr></DIV>
<DIV style="position:absolute;top:1068;left:475"><nobr><span class="ft4">testcollections/reuters21578.</span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:452"><nobr><span class="ft9">97</span></nobr></DIV>
</DIV>
<!-- Page 2 -->
<a name="2"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft13{font-size:-1px;font-family:Times;color:#000000;}
	.ft14{font-size:5px;font-family:Times;color:#000000;}
	.ft15{font-size:11px;line-height:17px;font-family:Times;color:#000000;}
	.ft16{font-size:6px;line-height:3px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="42002.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft11">bag-of-words approach, where we only retain frequencies<br>of words after tokenisation, stemming, and stop-words re-<br>moval. These frequencies can be normalized using various<br>schemes[19, 6]; we use the ltc normalization:</span></nobr></DIV>
<DIV style="position:absolute;top:159;left:153"><nobr><span class="ft4">l</span></nobr></DIV>
<DIV style="position:absolute;top:164;left:158"><nobr><span class="ft7">i,d</span></nobr></DIV>
<DIV style="position:absolute;top:159;left:185"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:159;left:209"><nobr><span class="ft4">1 + log</span></nobr></DIV>
<DIV style="position:absolute;top:163;left:251"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:159;left:259"><nobr><span class="ft4">T F</span></nobr></DIV>
<DIV style="position:absolute;top:164;left:278"><nobr><span class="ft7">i,d</span></nobr></DIV>
<DIV style="position:absolute;top:186;left:162"><nobr><span class="ft4">t</span></nobr></DIV>
<DIV style="position:absolute;top:191;left:167"><nobr><span class="ft7">i</span></nobr></DIV>
<DIV style="position:absolute;top:186;left:185"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:186;left:209"><nobr><span class="ft4">log</span></nobr></DIV>
<DIV style="position:absolute;top:190;left:227"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:177;left:238"><nobr><span class="ft15">N<br>n</span></nobr></DIV>
<DIV style="position:absolute;top:200;left:246"><nobr><span class="ft7">i</span></nobr></DIV>
<DIV style="position:absolute;top:221;left:142"><nobr><span class="ft4">ltc</span></nobr></DIV>
<DIV style="position:absolute;top:225;left:158"><nobr><span class="ft7">i,d</span></nobr></DIV>
<DIV style="position:absolute;top:221;left:185"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:212;left:273"><nobr><span class="ft4">l</span></nobr></DIV>
<DIV style="position:absolute;top:217;left:277"><nobr><span class="ft7">i,d</span></nobr></DIV>
<DIV style="position:absolute;top:209;left:294"><nobr><span class="ft4">· t</span></nobr></DIV>
<DIV style="position:absolute;top:216;left:306"><nobr><span class="ft7">i</span></nobr></DIV>
<DIV style="position:absolute;top:230;left:211"><nobr><span class="ft13">Õ</span></nobr></DIV>
<DIV style="position:absolute;top:235;left:225"><nobr><span class="ft13">È</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:239"><nobr><span class="ft7">j</span></nobr></DIV>
<DIV style="position:absolute;top:241;left:244"><nobr><span class="ft7">{terms in d}</span></nobr></DIV>
<DIV style="position:absolute;top:236;left:316"><nobr><span class="ft4">(l</span></nobr></DIV>
<DIV style="position:absolute;top:240;left:325"><nobr><span class="ft7">j,d</span></nobr></DIV>
<DIV style="position:absolute;top:232;left:343"><nobr><span class="ft4">· t</span></nobr></DIV>
<DIV style="position:absolute;top:240;left:355"><nobr><span class="ft7">j</span></nobr></DIV>
<DIV style="position:absolute;top:236;left:361"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:230;left:366"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:221;left:374"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:265;left:81"><nobr><span class="ft11">where the subscripts i and d denote the ith term and the<br>dth document respectively, T F</span></nobr></DIV>
<DIV style="position:absolute;top:285;left:265"><nobr><span class="ft7">i,d</span></nobr></DIV>
<DIV style="position:absolute;top:280;left:283"><nobr><span class="ft4">is the frequency of the ith</span></nobr></DIV>
<DIV style="position:absolute;top:296;left:81"><nobr><span class="ft4">term in the dth document, n</span></nobr></DIV>
<DIV style="position:absolute;top:301;left:255"><nobr><span class="ft7">i</span></nobr></DIV>
<DIV style="position:absolute;top:296;left:264"><nobr><span class="ft4">is the document-frequency of</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:81"><nobr><span class="ft4">the ith term, and N is the total number of documents.</span></nobr></DIV>
<DIV style="position:absolute;top:337;left:81"><nobr><span class="ft3"><b>2.3</b></span></nobr></DIV>
<DIV style="position:absolute;top:337;left:121"><nobr><span class="ft3"><b>Feature Selection Metric</b></span></nobr></DIV>
<DIV style="position:absolute;top:360;left:94"><nobr><span class="ft4">Given a set of candidate terms, we select features from</span></nobr></DIV>
<DIV style="position:absolute;top:375;left:81"><nobr><span class="ft11">the set using the likelihood ratio for binomial distribution<br>advocated by Dunning[5]:</span></nobr></DIV>
<DIV style="position:absolute;top:437;left:101"><nobr><span class="ft4"> =</span></nobr></DIV>
<DIV style="position:absolute;top:420;left:189"><nobr><span class="ft7">R</span></nobr></DIV>
<DIV style="position:absolute;top:420;left:197"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:417;left:202"><nobr><span class="ft7">+R</span></nobr></DIV>
<DIV style="position:absolute;top:420;left:219"><nobr><span class="ft14">¯</span></nobr></DIV>
<DIV style="position:absolute;top:422;left:219"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:431;left:202"><nobr><span class="ft7">N</span></nobr></DIV>
<DIV style="position:absolute;top:415;left:234"><nobr><span class="ft7">R</span></nobr></DIV>
<DIV style="position:absolute;top:415;left:242"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:412;left:247"><nobr><span class="ft7">+R</span></nobr></DIV>
<DIV style="position:absolute;top:415;left:264"><nobr><span class="ft14">¯</span></nobr></DIV>
<DIV style="position:absolute;top:417;left:264"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:420;left:282"><nobr><span class="ft7">N</span></nobr></DIV>
<DIV style="position:absolute;top:420;left:290"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:417;left:295"><nobr><span class="ft7">+N</span></nobr></DIV>
<DIV style="position:absolute;top:420;left:313"><nobr><span class="ft14">¯</span></nobr></DIV>
<DIV style="position:absolute;top:422;left:312"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:431;left:295"><nobr><span class="ft7">N</span></nobr></DIV>
<DIV style="position:absolute;top:415;left:327"><nobr><span class="ft7">N</span></nobr></DIV>
<DIV style="position:absolute;top:415;left:336"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:412;left:341"><nobr><span class="ft7">+N</span></nobr></DIV>
<DIV style="position:absolute;top:415;left:359"><nobr><span class="ft14">¯</span></nobr></DIV>
<DIV style="position:absolute;top:417;left:358"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:150"><nobr><span class="ft7">R</span></nobr></DIV>
<DIV style="position:absolute;top:452;left:158"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:139"><nobr><span class="ft7">R</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:147"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:459;left:152"><nobr><span class="ft7">+N</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:169"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:445;left:184"><nobr><span class="ft7">R</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:192"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:221"><nobr><span class="ft7">N</span></nobr></DIV>
<DIV style="position:absolute;top:452;left:230"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:211"><nobr><span class="ft7">R</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:219"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:459;left:224"><nobr><span class="ft7">+N</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:241"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:445;left:256"><nobr><span class="ft7">N</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:264"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:294"><nobr><span class="ft7">R</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:302"><nobr><span class="ft14">¯</span></nobr></DIV>
<DIV style="position:absolute;top:452;left:302"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:283"><nobr><span class="ft7">R</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:291"><nobr><span class="ft14">¯</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:291"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:459;left:296"><nobr><span class="ft7">+N</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:313"><nobr><span class="ft14">¯</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:313"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:445;left:328"><nobr><span class="ft7">R</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:336"><nobr><span class="ft14">¯</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:336"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:365"><nobr><span class="ft7">N</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:374"><nobr><span class="ft14">¯</span></nobr></DIV>
<DIV style="position:absolute;top:452;left:374"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:354"><nobr><span class="ft7">R</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:363"><nobr><span class="ft14">¯</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:363"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:459;left:367"><nobr><span class="ft7">+N</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:385"><nobr><span class="ft14">¯</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:384"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:445;left:399"><nobr><span class="ft7">N</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:408"><nobr><span class="ft14">¯</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:408"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:437;left:416"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:484;left:81"><nobr><span class="ft4">where R</span></nobr></DIV>
<DIV style="position:absolute;top:489;left:130"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:484;left:138"><nobr><span class="ft4">(N</span></nobr></DIV>
<DIV style="position:absolute;top:489;left:154"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:484;left:159"><nobr><span class="ft4">) is the number of relevant (non-relevant) train-</span></nobr></DIV>
<DIV style="position:absolute;top:500;left:81"><nobr><span class="ft4">ing documents which contain the term, R</span></nobr></DIV>
<DIV style="position:absolute;top:501;left:331"><nobr><span class="ft16">¯<br>t</span></nobr></DIV>
<DIV style="position:absolute;top:500;left:340"><nobr><span class="ft4">(N</span></nobr></DIV>
<DIV style="position:absolute;top:501;left:357"><nobr><span class="ft16">¯<br>t</span></nobr></DIV>
<DIV style="position:absolute;top:500;left:361"><nobr><span class="ft4">) is the num-</span></nobr></DIV>
<DIV style="position:absolute;top:515;left:81"><nobr><span class="ft11">ber of relevant (non-relevant) training documents which do<br>not, and N is the total number of training documents.</span></nobr></DIV>
<DIV style="position:absolute;top:547;left:94"><nobr><span class="ft4">Asymptotically,</span></nobr></DIV>
<DIV style="position:absolute;top:544;left:193"><nobr><span class="ft4">-2 ln  is </span></nobr></DIV>
<DIV style="position:absolute;top:542;left:262"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:547;left:272"><nobr><span class="ft4">distributed with 1 degree of</span></nobr></DIV>
<DIV style="position:absolute;top:563;left:81"><nobr><span class="ft4">freedom. We choose terms with</span></nobr></DIV>
<DIV style="position:absolute;top:559;left:286"><nobr><span class="ft4">-2 ln  more than 12.13,</span></nobr></DIV>
<DIV style="position:absolute;top:578;left:81"><nobr><span class="ft11">i.e. at 0.05% significance level. More details on the feature<br>selection procedures will be given in section 4.</span></nobr></DIV>
<DIV style="position:absolute;top:619;left:81"><nobr><span class="ft3"><b>2.4</b></span></nobr></DIV>
<DIV style="position:absolute;top:619;left:121"><nobr><span class="ft3"><b>Performance Measures</b></span></nobr></DIV>
<DIV style="position:absolute;top:642;left:94"><nobr><span class="ft4">To evaluate a text classification system, we use the F</span></nobr></DIV>
<DIV style="position:absolute;top:644;left:433"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:81"><nobr><span class="ft11">measure introduced by van Rijsbergen[22]. This measure<br>combines recall and precision in the following way:</span></nobr></DIV>
<DIV style="position:absolute;top:705;left:115"><nobr><span class="ft4">Recall</span></nobr></DIV>
<DIV style="position:absolute;top:705;left:165"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:696;left:192"><nobr><span class="ft4">number of correct positive predictions</span></nobr></DIV>
<DIV style="position:absolute;top:714;left:220"><nobr><span class="ft4">number of positive examples</span></nobr></DIV>
<DIV style="position:absolute;top:741;left:97"><nobr><span class="ft4">Precision</span></nobr></DIV>
<DIV style="position:absolute;top:741;left:165"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:732;left:192"><nobr><span class="ft4">number of correct positive predictions</span></nobr></DIV>
<DIV style="position:absolute;top:750;left:215"><nobr><span class="ft4">number of positive predictions</span></nobr></DIV>
<DIV style="position:absolute;top:776;left:137"><nobr><span class="ft4">F</span></nobr></DIV>
<DIV style="position:absolute;top:779;left:146"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:776;left:165"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:768;left:192"><nobr><span class="ft4">2</span></nobr></DIV>
<DIV style="position:absolute;top:764;left:201"><nobr><span class="ft4">× Recall × Precision</span></nobr></DIV>
<DIV style="position:absolute;top:786;left:203"><nobr><span class="ft4">Recall + Precision</span></nobr></DIV>
<DIV style="position:absolute;top:776;left:326"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:807;left:94"><nobr><span class="ft4">For ease of comparison, we summarize the F</span></nobr></DIV>
<DIV style="position:absolute;top:810;left:363"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:807;left:374"><nobr><span class="ft4">scores over</span></nobr></DIV>
<DIV style="position:absolute;top:823;left:81"><nobr><span class="ft11">the different categories using the micro- and macro-averages<br>of F</span></nobr></DIV>
<DIV style="position:absolute;top:841;left:105"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:839;left:116"><nobr><span class="ft4">scores[11, 27]:</span></nobr></DIV>
<DIV style="position:absolute;top:864;left:91"><nobr><span class="ft4">Micro-avg F</span></nobr></DIV>
<DIV style="position:absolute;top:867;left:165"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:864;left:184"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:864;left:208"><nobr><span class="ft4">F</span></nobr></DIV>
<DIV style="position:absolute;top:867;left:217"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:864;left:228"><nobr><span class="ft4">over categories and documents</span></nobr></DIV>
<DIV style="position:absolute;top:884;left:88"><nobr><span class="ft4">Macro-avg F</span></nobr></DIV>
<DIV style="position:absolute;top:887;left:165"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:884;left:184"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:884;left:208"><nobr><span class="ft4">average of within-category F</span></nobr></DIV>
<DIV style="position:absolute;top:887;left:381"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:884;left:392"><nobr><span class="ft4">values.</span></nobr></DIV>
<DIV style="position:absolute;top:910;left:81"><nobr><span class="ft4">The micro- and macro-average F</span></nobr></DIV>
<DIV style="position:absolute;top:912;left:290"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:910;left:303"><nobr><span class="ft4">emphasize the perfor-</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:81"><nobr><span class="ft11">mance of the system on common and rare categories re-<br>spectively. Using these averages, we can observe the effect<br>of different kinds of data on a text classification system.</span></nobr></DIV>
<DIV style="position:absolute;top:973;left:94"><nobr><span class="ft4">In addition, for comparing two text classification systems,</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:81"><nobr><span class="ft11">we use the micro sign-test (s-test) and the macro sign-test<br>(S-test), which are two significance tests first used for com-<br>paring text classification systems in [27]. The s-test com-<br>pares all the binary decisions made by the systems, while<br>the S-test compares the within-category F</span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:344"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:356"><nobr><span class="ft4">values. Simi-</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:81"><nobr><span class="ft4">lar to the F</span></nobr></DIV>
<DIV style="position:absolute;top:1069;left:156"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:168"><nobr><span class="ft4">averages, the s-test and S-test compare the</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft11">performance of two systems on common and rare categories<br>respectively.</span></nobr></DIV>
<DIV style="position:absolute;top:118;left:489"><nobr><span class="ft4">To evaluate a batch-adaptive filtering system, we use the</span></nobr></DIV>
<DIV style="position:absolute;top:135;left:475"><nobr><span class="ft4">T9P measure of TREC-9[18]:</span></nobr></DIV>
<DIV style="position:absolute;top:166;left:509"><nobr><span class="ft4">T9P =</span></nobr></DIV>
<DIV style="position:absolute;top:156;left:558"><nobr><span class="ft4">number of correct positive predictions</span></nobr></DIV>
<DIV style="position:absolute;top:174;left:551"><nobr><span class="ft4">Max(50, number of positive predictions) ,</span></nobr></DIV>
<DIV style="position:absolute;top:197;left:475"><nobr><span class="ft11">which is precision, with a penalty for not retrieving 50 doc-<br>uments.</span></nobr></DIV>
<DIV style="position:absolute;top:245;left:475"><nobr><span class="ft3"><b>3.</b></span></nobr></DIV>
<DIV style="position:absolute;top:245;left:506"><nobr><span class="ft3"><b>BAYESIAN ONLINE LEARNING</b></span></nobr></DIV>
<DIV style="position:absolute;top:267;left:489"><nobr><span class="ft4">Most of this section is based on workby Opper[17], Solla</span></nobr></DIV>
<DIV style="position:absolute;top:283;left:475"><nobr><span class="ft4">&amp; Winther[20], and Csat´</span></nobr></DIV>
<DIV style="position:absolute;top:283;left:625"><nobr><span class="ft4">o &amp; Opper[3].</span></nobr></DIV>
<DIV style="position:absolute;top:299;left:489"><nobr><span class="ft4">Suppose that each document is described by a vector x,</span></nobr></DIV>
<DIV style="position:absolute;top:314;left:475"><nobr><span class="ft11">and that the relevance indicator of x for a category is given<br>by label y  {-1, 1}, where -1 and 1 indicates irrelevant<br>and relevant respectively. Given m instances of past data</span></nobr></DIV>
<DIV style="position:absolute;top:358;left:475"><nobr><span class="ft4">D</span></nobr></DIV>
<DIV style="position:absolute;top:366;left:486"><nobr><span class="ft7">m</span></nobr></DIV>
<DIV style="position:absolute;top:361;left:501"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:358;left:517"><nobr><span class="ft4">{(y</span></nobr></DIV>
<DIV style="position:absolute;top:366;left:537"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:361;left:541"><nobr><span class="ft4">, x</span></nobr></DIV>
<DIV style="position:absolute;top:366;left:556"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:361;left:561"><nobr><span class="ft4">), t = 1...m}, the predictive probability of the</span></nobr></DIV>
<DIV style="position:absolute;top:377;left:475"><nobr><span class="ft4">relevance of a document described by x is</span></nobr></DIV>
<DIV style="position:absolute;top:408;left:543"><nobr><span class="ft4">p(y|x, D</span></nobr></DIV>
<DIV style="position:absolute;top:413;left:591"><nobr><span class="ft7">m</span></nobr></DIV>
<DIV style="position:absolute;top:408;left:602"><nobr><span class="ft4">) =</span></nobr></DIV>
<DIV style="position:absolute;top:408;left:642"><nobr><span class="ft4">da p(y|x, a)p(a|D</span></nobr></DIV>
<DIV style="position:absolute;top:413;left:747"><nobr><span class="ft7">m</span></nobr></DIV>
<DIV style="position:absolute;top:408;left:757"><nobr><span class="ft4">),</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:475"><nobr><span class="ft11">where we have introduced the classifier a to assist us in the<br>prediction. In the Bayesian approach, a is a random variable<br>with probability density p(a|D</span></nobr></DIV>
<DIV style="position:absolute;top:475;left:660"><nobr><span class="ft7">m</span></nobr></DIV>
<DIV style="position:absolute;top:470;left:670"><nobr><span class="ft4">), and we integrate over all</span></nobr></DIV>
<DIV style="position:absolute;top:486;left:475"><nobr><span class="ft4">the possible values of a to obtain the prediction.</span></nobr></DIV>
<DIV style="position:absolute;top:502;left:489"><nobr><span class="ft4">Our aim is to obtain a reasonable description of a. In</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:475"><nobr><span class="ft11">the Bayesian online learning framework[16, 20, 17], we be-<br>gin with a prior p(a|D</span></nobr></DIV>
<DIV style="position:absolute;top:535;left:616"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:623"><nobr><span class="ft4">), and perform incremental Bayes'</span></nobr></DIV>
<DIV style="position:absolute;top:549;left:475"><nobr><span class="ft4">updates to obtain the posterior as data arrives:</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:520"><nobr><span class="ft4">p(a|D</span></nobr></DIV>
<DIV style="position:absolute;top:585;left:555"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:583;left:559"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:573"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:592"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:572;left:634"><nobr><span class="ft4">p(y</span></nobr></DIV>
<DIV style="position:absolute;top:576;left:653"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:574;left:657"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:568;left:672"><nobr><span class="ft4">|x</span></nobr></DIV>
<DIV style="position:absolute;top:576;left:684"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:574;left:688"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:572;left:703"><nobr><span class="ft4">, a)p(a|D</span></nobr></DIV>
<DIV style="position:absolute;top:576;left:757"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:572;left:762"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:588;left:618"><nobr><span class="ft13">Ê</span></nobr></DIV>
<DIV style="position:absolute;top:590;left:630"><nobr><span class="ft4">da p(y</span></nobr></DIV>
<DIV style="position:absolute;top:594;left:669"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:592;left:673"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:586;left:687"><nobr><span class="ft4">|x</span></nobr></DIV>
<DIV style="position:absolute;top:594;left:700"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:592;left:704"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:590;left:719"><nobr><span class="ft4">, a)p(a|D</span></nobr></DIV>
<DIV style="position:absolute;top:594;left:773"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:590;left:778"><nobr><span class="ft4">) .</span></nobr></DIV>
<DIV style="position:absolute;top:613;left:489"><nobr><span class="ft4">To make the learning online, the explicit dependence of</span></nobr></DIV>
<DIV style="position:absolute;top:629;left:475"><nobr><span class="ft4">the posterior p(a|D</span></nobr></DIV>
<DIV style="position:absolute;top:634;left:592"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:631;left:596"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:629;left:611"><nobr><span class="ft4">) on the past data is removed by ap-</span></nobr></DIV>
<DIV style="position:absolute;top:645;left:475"><nobr><span class="ft4">proximating it with a distribution p(a|A</span></nobr></DIV>
<DIV style="position:absolute;top:649;left:728"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:647;left:732"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:645;left:747"><nobr><span class="ft4">), where A</span></nobr></DIV>
<DIV style="position:absolute;top:649;left:815"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:647;left:819"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:660;left:475"><nobr><span class="ft11">characterizes the distribution of a at time t + 1. For exam-<br>ple, if p(a|A</span></nobr></DIV>
<DIV style="position:absolute;top:681;left:548"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:678;left:552"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:676;left:567"><nobr><span class="ft4">) is a Gaussian, then A</span></nobr></DIV>
<DIV style="position:absolute;top:681;left:706"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:678;left:710"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:676;left:729"><nobr><span class="ft4">refers to its mean</span></nobr></DIV>
<DIV style="position:absolute;top:692;left:475"><nobr><span class="ft4">and covariance.</span></nobr></DIV>
<DIV style="position:absolute;top:707;left:489"><nobr><span class="ft4">Hence, starting from the prior p</span></nobr></DIV>
<DIV style="position:absolute;top:710;left:687"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:707;left:693"><nobr><span class="ft4">(a) = p(a|A</span></nobr></DIV>
<DIV style="position:absolute;top:710;left:765"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:707;left:771"><nobr><span class="ft4">), learning</span></nobr></DIV>
<DIV style="position:absolute;top:723;left:475"><nobr><span class="ft4">from a new example (y</span></nobr></DIV>
<DIV style="position:absolute;top:728;left:614"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:725;left:618"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:723;left:633"><nobr><span class="ft4">, x</span></nobr></DIV>
<DIV style="position:absolute;top:728;left:648"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:725;left:652"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:723;left:667"><nobr><span class="ft4">) comprises two steps:</span></nobr></DIV>
<DIV style="position:absolute;top:748;left:475"><nobr><span class="ft4">Update the posterior using Bayes rule</span></nobr></DIV>
<DIV style="position:absolute;top:772;left:533"><nobr><span class="ft4">p(a|A</span></nobr></DIV>
<DIV style="position:absolute;top:777;left:567"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:772;left:572"><nobr><span class="ft4">, (y</span></nobr></DIV>
<DIV style="position:absolute;top:777;left:591"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:775;left:595"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:772;left:609"><nobr><span class="ft4">, x</span></nobr></DIV>
<DIV style="position:absolute;top:777;left:624"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:775;left:628"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:772;left:643"><nobr><span class="ft4">))</span></nobr></DIV>
<DIV style="position:absolute;top:769;left:658"><nobr><span class="ft4"> p(y</span></nobr></DIV>
<DIV style="position:absolute;top:777;left:691"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:775;left:696"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:769;left:710"><nobr><span class="ft4">|x</span></nobr></DIV>
<DIV style="position:absolute;top:777;left:722"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:775;left:727"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:772;left:741"><nobr><span class="ft4">, a) p(a|A</span></nobr></DIV>
<DIV style="position:absolute;top:777;left:799"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:772;left:804"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:802;left:475"><nobr><span class="ft4">Approximate the updated posterior by parameterisation</span></nobr></DIV>
<DIV style="position:absolute;top:826;left:569"><nobr><span class="ft4">p(a|A</span></nobr></DIV>
<DIV style="position:absolute;top:831;left:604"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:826;left:608"><nobr><span class="ft4">, (y</span></nobr></DIV>
<DIV style="position:absolute;top:831;left:627"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:828;left:631"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:826;left:646"><nobr><span class="ft4">, x</span></nobr></DIV>
<DIV style="position:absolute;top:831;left:660"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:828;left:665"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:826;left:679"><nobr><span class="ft4">))</span></nobr></DIV>
<DIV style="position:absolute;top:823;left:694"><nobr><span class="ft4"> p(a|A</span></nobr></DIV>
<DIV style="position:absolute;top:831;left:746"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:828;left:750"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:826;left:764"><nobr><span class="ft4">),</span></nobr></DIV>
<DIV style="position:absolute;top:855;left:475"><nobr><span class="ft11">where the approximation step is done by minimizing the<br>Kullback-Leibler distance between the the approximating and<br>approximated distributions.</span></nobr></DIV>
<DIV style="position:absolute;top:902;left:489"><nobr><span class="ft4">The amount of information gained about a after learn-</span></nobr></DIV>
<DIV style="position:absolute;top:918;left:475"><nobr><span class="ft11">ing from a new example can be expressed as the Kullback-<br>Leibler distance between the posterior and prior distribu-<br>tions[25]:</span></nobr></DIV>
<DIV style="position:absolute;top:982;left:488"><nobr><span class="ft4">IG(y</span></nobr></DIV>
<DIV style="position:absolute;top:986;left:518"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:984;left:522"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:982;left:537"><nobr><span class="ft4">, x</span></nobr></DIV>
<DIV style="position:absolute;top:986;left:551"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:984;left:556"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:978;left:570"><nobr><span class="ft4">|D</span></nobr></DIV>
<DIV style="position:absolute;top:986;left:584"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:982;left:590"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:982;left:608"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:982;left:649"><nobr><span class="ft4">da p(a|D</span></nobr></DIV>
<DIV style="position:absolute;top:986;left:703"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:984;left:707"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:982;left:722"><nobr><span class="ft4">) log</span></nobr></DIV>
<DIV style="position:absolute;top:986;left:747"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:973;left:758"><nobr><span class="ft4">p(a|D</span></nobr></DIV>
<DIV style="position:absolute;top:978;left:792"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:975;left:797"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:973;left:811"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:991;left:764"><nobr><span class="ft4">p(a|D</span></nobr></DIV>
<DIV style="position:absolute;top:996;left:799"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:991;left:804"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:1016;left:608"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:1019;left:649"><nobr><span class="ft4">da p(a|A</span></nobr></DIV>
<DIV style="position:absolute;top:1024;left:703"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:707"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:1019;left:721"><nobr><span class="ft4">) log</span></nobr></DIV>
<DIV style="position:absolute;top:1023;left:747"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:1010;left:757"><nobr><span class="ft4">p(a|A</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:792"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:1013;left:796"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:1010;left:810"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:1028;left:764"><nobr><span class="ft4">p(a|A</span></nobr></DIV>
<DIV style="position:absolute;top:1033;left:799"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:1028;left:804"><nobr><span class="ft4">) ,</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:475"><nobr><span class="ft4">where instances of the data</span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:640"><nobr><span class="ft4">D are replaced by the summaries</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:475"><nobr><span class="ft4">A in the approximation.</span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:452"><nobr><span class="ft9">98</span></nobr></DIV>
</DIV>
<!-- Page 3 -->
<a name="3"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft17{font-size:14px;font-family:Times;color:#000000;}
	.ft18{font-size:6px;line-height:12px;font-family:Times;color:#000000;}
	.ft19{font-size:6px;line-height:8px;font-family:Times;color:#000000;}
	.ft20{font-size:6px;line-height:10px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="42003.png" alt="background image">
<DIV style="position:absolute;top:86;left:94"><nobr><span class="ft4">To simplify notation henceforth, we use p</span></nobr></DIV>
<DIV style="position:absolute;top:91;left:339"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:344"><nobr><span class="ft4">(a) and . . .</span></nobr></DIV>
<DIV style="position:absolute;top:94;left:419"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:427"><nobr><span class="ft4">to</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:81"><nobr><span class="ft4">denote p(a|A</span></nobr></DIV>
<DIV style="position:absolute;top:107;left:159"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:163"><nobr><span class="ft4">) and averages taken over p(a|A</span></nobr></DIV>
<DIV style="position:absolute;top:107;left:352"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:357"><nobr><span class="ft4">) respectively.</span></nobr></DIV>
<DIV style="position:absolute;top:118;left:81"><nobr><span class="ft4">For example, the predictive probability can be rewritten as</span></nobr></DIV>
<DIV style="position:absolute;top:148;left:81"><nobr><span class="ft4">p(y|x, D</span></nobr></DIV>
<DIV style="position:absolute;top:153;left:129"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:148;left:134"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:145;left:144"><nobr><span class="ft4"> p(y|x, A</span></nobr></DIV>
<DIV style="position:absolute;top:153;left:207"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:148;left:212"><nobr><span class="ft4">) =</span></nobr></DIV>
<DIV style="position:absolute;top:148;left:251"><nobr><span class="ft4">da p(y|x, a)p</span></nobr></DIV>
<DIV style="position:absolute;top:153;left:328"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:148;left:332"><nobr><span class="ft4">(a) = p(y|x, a)</span></nobr></DIV>
<DIV style="position:absolute;top:156;left:431"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:148;left:439"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:179;left:94"><nobr><span class="ft4">In the following sections, the scalar field h = a · x will also</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:81"><nobr><span class="ft4">be used to simplify notation and calculation.</span></nobr></DIV>
<DIV style="position:absolute;top:218;left:81"><nobr><span class="ft3"><b>3.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:218;left:121"><nobr><span class="ft3"><b>Bayesian Online Perceptron</b></span></nobr></DIV>
<DIV style="position:absolute;top:241;left:94"><nobr><span class="ft4">Consider the case where a describes a perceptron. We then</span></nobr></DIV>
<DIV style="position:absolute;top:257;left:81"><nobr><span class="ft4">define the likelihood as a probit model</span></nobr></DIV>
<DIV style="position:absolute;top:289;left:187"><nobr><span class="ft4">p(y|x, a) = </span></nobr></DIV>
<DIV style="position:absolute;top:280;left:281"><nobr><span class="ft4">ya · x</span></nobr></DIV>
<DIV style="position:absolute;top:298;left:291"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:300;left:299"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:289;left:329"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:81"><nobr><span class="ft4">where </span></nobr></DIV>
<DIV style="position:absolute;top:318;left:129"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:326;left:129"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:140"><nobr><span class="ft4">is a fixed noise variance, and  is the cumulative</span></nobr></DIV>
<DIV style="position:absolute;top:338;left:81"><nobr><span class="ft4">Gaussian distribution</span></nobr></DIV>
<DIV style="position:absolute;top:366;left:175"><nobr><span class="ft4">(u) =</span></nobr></DIV>
<DIV style="position:absolute;top:358;left:234"><nobr><span class="ft4">1</span></nobr></DIV>
<DIV style="position:absolute;top:363;left:224"><nobr><span class="ft4">2</span></nobr></DIV>
<DIV style="position:absolute;top:355;left:268"><nobr><span class="ft7">u</span></nobr></DIV>
<DIV style="position:absolute;top:380;left:262"><nobr><span class="ft7">-</span></nobr></DIV>
<DIV style="position:absolute;top:366;left:285"><nobr><span class="ft4">d e</span></nobr></DIV>
<DIV style="position:absolute;top:361;left:310"><nobr><span class="ft7">-</span></nobr></DIV>
<DIV style="position:absolute;top:358;left:324"><nobr><span class="ft14">2</span></nobr></DIV>
<DIV style="position:absolute;top:363;left:330"><nobr><span class="ft7">/</span></nobr></DIV>
<DIV style="position:absolute;top:361;left:335"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:366;left:341"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:400;left:94"><nobr><span class="ft4">If p</span></nobr></DIV>
<DIV style="position:absolute;top:402;left:116"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:400;left:122"><nobr><span class="ft4">(a) is the spherical unit Gaussian, and p</span></nobr></DIV>
<DIV style="position:absolute;top:404;left:376"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:400;left:381"><nobr><span class="ft4">(a) is the</span></nobr></DIV>
<DIV style="position:absolute;top:416;left:81"><nobr><span class="ft11">Gaussian approximation, Opper[16, 17] and Solla &amp; Winther[20]<br>obtain the following updates by equating the means and co-<br>variances of p(a|A</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:190"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:449;left:195"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:209"><nobr><span class="ft4">) and p(a|A</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:280"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:285"><nobr><span class="ft4">, (y</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:304"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:449;left:308"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:323"><nobr><span class="ft4">, x</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:337"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:449;left:341"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:356"><nobr><span class="ft4">)):</span></nobr></DIV>
<DIV style="position:absolute;top:478;left:121"><nobr><span class="ft4">a</span></nobr></DIV>
<DIV style="position:absolute;top:485;left:134"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:483;left:139"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:478;left:167"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:478;left:196"><nobr><span class="ft4">a</span></nobr></DIV>
<DIV style="position:absolute;top:485;left:209"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:478;left:217"><nobr><span class="ft4">+ s</span></nobr></DIV>
<DIV style="position:absolute;top:483;left:237"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:480;left:242"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:469;left:270"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:487;left:258"><nobr><span class="ft4"> h</span></nobr></DIV>
<DIV style="position:absolute;top:494;left:285"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:478;left:294"><nobr><span class="ft4">ln p(y</span></nobr></DIV>
<DIV style="position:absolute;top:483;left:332"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:480;left:337"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:475;left:351"><nobr><span class="ft4">|h)</span></nobr></DIV>
<DIV style="position:absolute;top:485;left:374"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:123"><nobr><span class="ft4">C</span></nobr></DIV>
<DIV style="position:absolute;top:522;left:134"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:520;left:139"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:167"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:191"><nobr><span class="ft4">C</span></nobr></DIV>
<DIV style="position:absolute;top:522;left:202"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:210"><nobr><span class="ft4">+ s</span></nobr></DIV>
<DIV style="position:absolute;top:522;left:230"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:520;left:235"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:249"><nobr><span class="ft4">s</span></nobr></DIV>
<DIV style="position:absolute;top:512;left:256"><nobr><span class="ft7">T</span></nobr></DIV>
<DIV style="position:absolute;top:523;left:256"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:521;left:260"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:509;left:286"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:504;left:294"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:528;left:276"><nobr><span class="ft4"> h</span></nobr></DIV>
<DIV style="position:absolute;top:523;left:303"><nobr><span class="ft18">2<br>t</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:313"><nobr><span class="ft4">ln p(y</span></nobr></DIV>
<DIV style="position:absolute;top:522;left:352"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:520;left:356"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:514;left:371"><nobr><span class="ft4">|h)</span></nobr></DIV>
<DIV style="position:absolute;top:525;left:393"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:401"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:81"><nobr><span class="ft4">where</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:182"><nobr><span class="ft4">s</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:188"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:193"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:221"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:245"><nobr><span class="ft4">C</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:257"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:262"><nobr><span class="ft4">x</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:270"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:274"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:289"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:603;left:142"><nobr><span class="ft4">p(y</span></nobr></DIV>
<DIV style="position:absolute;top:608;left:161"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:606;left:165"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:600;left:180"><nobr><span class="ft4">|h)</span></nobr></DIV>
<DIV style="position:absolute;top:611;left:202"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:603;left:221"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:603;left:245"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:594;left:269"><nobr><span class="ft4">y</span></nobr></DIV>
<DIV style="position:absolute;top:599;left:276"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:280"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:594;left:303"><nobr><span class="ft4">h</span></nobr></DIV>
<DIV style="position:absolute;top:601;left:316"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:613;left:282"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:617;left:290"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:615;left:294"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:603;left:335"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:635;left:181"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:629;left:189"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:640;left:188"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:638;left:193"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:635;left:221"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:635;left:245"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:629;left:253"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:638;left:253"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:635;left:263"><nobr><span class="ft4">+ x</span></nobr></DIV>
<DIV style="position:absolute;top:632;left:285"><nobr><span class="ft19">T<br>t</span></nobr></DIV>
<DIV style="position:absolute;top:638;left:289"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:635;left:304"><nobr><span class="ft4">C</span></nobr></DIV>
<DIV style="position:absolute;top:639;left:315"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:635;left:320"><nobr><span class="ft4">x</span></nobr></DIV>
<DIV style="position:absolute;top:639;left:329"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:637;left:333"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:635;left:361"><nobr><span class="ft4">and</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:189"><nobr><span class="ft4">h</span></nobr></DIV>
<DIV style="position:absolute;top:664;left:202"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:221"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:250"><nobr><span class="ft4">a</span></nobr></DIV>
<DIV style="position:absolute;top:651;left:264"><nobr><span class="ft18">T<br>t</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:274"><nobr><span class="ft4">x</span></nobr></DIV>
<DIV style="position:absolute;top:662;left:283"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:659;left:287"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:302"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:682;left:81"><nobr><span class="ft17"><i>3.1.1</i></span></nobr></DIV>
<DIV style="position:absolute;top:682;left:130"><nobr><span class="ft17"><i>Algorithm</i></span></nobr></DIV>
<DIV style="position:absolute;top:703;left:94"><nobr><span class="ft4">Training the Bayesian online perceptron on m data in-</span></nobr></DIV>
<DIV style="position:absolute;top:719;left:81"><nobr><span class="ft4">volves successive calculation of the means a</span></nobr></DIV>
<DIV style="position:absolute;top:726;left:361"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:719;left:372"><nobr><span class="ft4">and covari-</span></nobr></DIV>
<DIV style="position:absolute;top:735;left:81"><nobr><span class="ft4">ances C</span></nobr></DIV>
<DIV style="position:absolute;top:739;left:129"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:735;left:139"><nobr><span class="ft4">of the posteriors, for t  {1, ..., m}:</span></nobr></DIV>
<DIV style="position:absolute;top:758;left:97"><nobr><span class="ft4">1. Initialize a</span></nobr></DIV>
<DIV style="position:absolute;top:763;left:189"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:758;left:198"><nobr><span class="ft4">to be 0 and C</span></nobr></DIV>
<DIV style="position:absolute;top:761;left:280"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:758;left:290"><nobr><span class="ft4">to be 1 (identity matrix),</span></nobr></DIV>
<DIV style="position:absolute;top:774;left:114"><nobr><span class="ft4">i.e. a spherical unit Gaussian centred at origin.</span></nobr></DIV>
<DIV style="position:absolute;top:799;left:97"><nobr><span class="ft4">2. For t = 0, 1, ..., m - 1</span></nobr></DIV>
<DIV style="position:absolute;top:824;left:97"><nobr><span class="ft4">3.</span></nobr></DIV>
<DIV style="position:absolute;top:824;left:128"><nobr><span class="ft4">y</span></nobr></DIV>
<DIV style="position:absolute;top:828;left:135"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:826;left:139"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:824;left:158"><nobr><span class="ft4">is the relevance indicator for document x</span></nobr></DIV>
<DIV style="position:absolute;top:828;left:408"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:826;left:412"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:849;left:97"><nobr><span class="ft4">4.</span></nobr></DIV>
<DIV style="position:absolute;top:849;left:128"><nobr><span class="ft4">Calculate s</span></nobr></DIV>
<DIV style="position:absolute;top:853;left:196"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:851;left:200"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:849;left:215"><nobr><span class="ft4">, </span></nobr></DIV>
<DIV style="position:absolute;top:853;left:231"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:851;left:235"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:849;left:250"><nobr><span class="ft4">, h</span></nobr></DIV>
<DIV style="position:absolute;top:856;left:277"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:849;left:287"><nobr><span class="ft4">and p(y</span></nobr></DIV>
<DIV style="position:absolute;top:853;left:338"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:851;left:343"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:845;left:357"><nobr><span class="ft4">|h)</span></nobr></DIV>
<DIV style="position:absolute;top:856;left:380"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:97"><nobr><span class="ft4">5.</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:128"><nobr><span class="ft4">Calculate u =</span></nobr></DIV>
<DIV style="position:absolute;top:873;left:218"><nobr><span class="ft7">y</span></nobr></DIV>
<DIV style="position:absolute;top:875;left:224"><nobr><span class="ft14">t+1</span></nobr></DIV>
<DIV style="position:absolute;top:873;left:246"><nobr><span class="ft7">h</span></nobr></DIV>
<DIV style="position:absolute;top:876;left:257"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:885;left:228"><nobr><span class="ft7"></span></nobr></DIV>
<DIV style="position:absolute;top:887;left:234"><nobr><span class="ft14">t+1</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:268"><nobr><span class="ft4">and</span></nobr></DIV>
<DIV style="position:absolute;top:887;left:295"><nobr><span class="ft13">£</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:310"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:873;left:334"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:877;left:326"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:351"><nobr><span class="ft4">exp(</span></nobr></DIV>
<DIV style="position:absolute;top:874;left:378"><nobr><span class="ft4">-</span></nobr></DIV>
<DIV style="position:absolute;top:873;left:391"><nobr><span class="ft20">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:398"><nobr><span class="ft4">u</span></nobr></DIV>
<DIV style="position:absolute;top:873;left:406"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:412"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:908;left:97"><nobr><span class="ft4">6.</span></nobr></DIV>
<DIV style="position:absolute;top:908;left:128"><nobr><span class="ft4">Calculate</span></nobr></DIV>
<DIV style="position:absolute;top:906;left:200"><nobr><span class="ft7"></span></nobr></DIV>
<DIV style="position:absolute;top:916;left:190"><nobr><span class="ft7"> h</span></nobr></DIV>
<DIV style="position:absolute;top:918;left:212"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:908;left:221"><nobr><span class="ft4">ln p(y</span></nobr></DIV>
<DIV style="position:absolute;top:912;left:260"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:910;left:264"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:904;left:278"><nobr><span class="ft4">|h)</span></nobr></DIV>
<DIV style="position:absolute;top:915;left:301"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:908;left:310"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:904;left:327"><nobr><span class="ft7">y</span></nobr></DIV>
<DIV style="position:absolute;top:905;left:332"><nobr><span class="ft14">t+1</span></nobr></DIV>
<DIV style="position:absolute;top:916;left:326"><nobr><span class="ft7"></span></nobr></DIV>
<DIV style="position:absolute;top:917;left:333"><nobr><span class="ft14">t+1</span></nobr></DIV>
<DIV style="position:absolute;top:904;left:353"><nobr><span class="ft4">·</span></nobr></DIV>
<DIV style="position:absolute;top:903;left:388"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:917;left:364"><nobr><span class="ft7">p</span></nobr></DIV>
<DIV style="position:absolute;top:915;left:370"><nobr><span class="ft7">(y</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:380"><nobr><span class="ft14">t+1</span></nobr></DIV>
<DIV style="position:absolute;top:915;left:398"><nobr><span class="ft7">|h)</span></nobr></DIV>
<DIV style="position:absolute;top:922;left:417"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:904;left:424"><nobr><span class="ft4">·</span></nobr></DIV>
<DIV style="position:absolute;top:917;left:428"><nobr><span class="ft13">£</span></nobr></DIV>
<DIV style="position:absolute;top:944;left:97"><nobr><span class="ft4">7.</span></nobr></DIV>
<DIV style="position:absolute;top:944;left:128"><nobr><span class="ft4">Calculate</span></nobr></DIV>
<DIV style="position:absolute;top:942;left:199"><nobr><span class="ft7"></span></nobr></DIV>
<DIV style="position:absolute;top:937;left:206"><nobr><span class="ft14">2</span></nobr></DIV>
<DIV style="position:absolute;top:953;left:191"><nobr><span class="ft7"> h</span></nobr></DIV>
<DIV style="position:absolute;top:949;left:213"><nobr><span class="ft14">2</span></nobr></DIV>
<DIV style="position:absolute;top:955;left:213"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:944;left:223"><nobr><span class="ft4">ln p(y</span></nobr></DIV>
<DIV style="position:absolute;top:949;left:262"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:947;left:266"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:281"><nobr><span class="ft4">|h)</span></nobr></DIV>
<DIV style="position:absolute;top:952;left:303"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:944;left:312"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:983;left:151"><nobr><span class="ft4">- 1</span></nobr></DIV>
<DIV style="position:absolute;top:995;left:163"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:992;left:172"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:1002;left:171"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:1000;left:176"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:978;left:225"><nobr><span class="ft4">u ·</span></nobr></DIV>
<DIV style="position:absolute;top:987;left:243"><nobr><span class="ft13">£</span></nobr></DIV>
<DIV style="position:absolute;top:995;left:210"><nobr><span class="ft4">p(y</span></nobr></DIV>
<DIV style="position:absolute;top:1000;left:229"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:998;left:233"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:992;left:248"><nobr><span class="ft4">|h)</span></nobr></DIV>
<DIV style="position:absolute;top:1003;left:270"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:986;left:280"><nobr><span class="ft4">+</span></nobr></DIV>
<DIV style="position:absolute;top:987;left:336"><nobr><span class="ft13">£</span></nobr></DIV>
<DIV style="position:absolute;top:995;left:311"><nobr><span class="ft4">p(y</span></nobr></DIV>
<DIV style="position:absolute;top:1000;left:330"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:998;left:335"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:992;left:349"><nobr><span class="ft4">|h)</span></nobr></DIV>
<DIV style="position:absolute;top:1003;left:372"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:971;left:389"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:1028;left:97"><nobr><span class="ft4">8.</span></nobr></DIV>
<DIV style="position:absolute;top:1028;left:128"><nobr><span class="ft4">Calculate a</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:208"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:1033;left:212"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:1028;left:231"><nobr><span class="ft4">and C</span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:270"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:274"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:94"><nobr><span class="ft4">The prediction for datum (y, x) simply involves the cal-</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:81"><nobr><span class="ft4">culation of p(y|x, a)</span></nobr></DIV>
<DIV style="position:absolute;top:1074;left:211"><nobr><span class="ft7">m</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:226"><nobr><span class="ft4">= p(y|h)</span></nobr></DIV>
<DIV style="position:absolute;top:1074;left:288"><nobr><span class="ft7">m</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:298"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:83;left:475"><nobr><span class="ft3"><b>3.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:83;left:515"><nobr><span class="ft3"><b>Bayesian Online Gaussian Process</b></span></nobr></DIV>
<DIV style="position:absolute;top:106;left:489"><nobr><span class="ft4">Gaussian process (GP) has been constrained to problems</span></nobr></DIV>
<DIV style="position:absolute;top:121;left:475"><nobr><span class="ft4">with small data sets until recently when Csat´</span></nobr></DIV>
<DIV style="position:absolute;top:121;left:753"><nobr><span class="ft4">o &amp; Opper[3]</span></nobr></DIV>
<DIV style="position:absolute;top:137;left:475"><nobr><span class="ft11">and Williams &amp; Seeger[24] introduced efficient and effective<br>approximations to the full GP formulation. This section will<br>outline the approach in [3].</span></nobr></DIV>
<DIV style="position:absolute;top:184;left:489"><nobr><span class="ft4">In the GP framework, a describes a function consisting of</span></nobr></DIV>
<DIV style="position:absolute;top:200;left:475"><nobr><span class="ft4">function values</span></nobr></DIV>
<DIV style="position:absolute;top:196;left:572"><nobr><span class="ft4">{a(x)}. Using the probit model, the likeli-</span></nobr></DIV>
<DIV style="position:absolute;top:216;left:475"><nobr><span class="ft4">hood can be expressed as</span></nobr></DIV>
<DIV style="position:absolute;top:247;left:582"><nobr><span class="ft4">p(y|x, a) = </span></nobr></DIV>
<DIV style="position:absolute;top:239;left:676"><nobr><span class="ft4">ya(x)</span></nobr></DIV>
<DIV style="position:absolute;top:257;left:685"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:259;left:693"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:247;left:724"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:279;left:475"><nobr><span class="ft4">where </span></nobr></DIV>
<DIV style="position:absolute;top:281;left:523"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:279;left:534"><nobr><span class="ft4">and  are described in section 3.1.</span></nobr></DIV>
<DIV style="position:absolute;top:295;left:489"><nobr><span class="ft4">In addition, p</span></nobr></DIV>
<DIV style="position:absolute;top:297;left:570"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:295;left:576"><nobr><span class="ft4">(a) is a GP prior which specifies a Gaussian</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:475"><nobr><span class="ft11">distribution with zero mean function and covariance/kernel<br>function K</span></nobr></DIV>
<DIV style="position:absolute;top:329;left:542"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:326;left:548"><nobr><span class="ft4">(x, x ) over a function space. If p</span></nobr></DIV>
<DIV style="position:absolute;top:331;left:755"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:326;left:760"><nobr><span class="ft4">(a) is also a</span></nobr></DIV>
<DIV style="position:absolute;top:342;left:475"><nobr><span class="ft4">Gaussian process, then Csat´</span></nobr></DIV>
<DIV style="position:absolute;top:342;left:645"><nobr><span class="ft4">o &amp; Opper obtain the following</span></nobr></DIV>
<DIV style="position:absolute;top:358;left:475"><nobr><span class="ft4">updates by equating the means and covariances of p(a|A</span></nobr></DIV>
<DIV style="position:absolute;top:362;left:810"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:360;left:814"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:358;left:829"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:475"><nobr><span class="ft4">and p(a|A</span></nobr></DIV>
<DIV style="position:absolute;top:378;left:536"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:541"><nobr><span class="ft4">, (y</span></nobr></DIV>
<DIV style="position:absolute;top:378;left:560"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:376;left:564"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:579"><nobr><span class="ft4">, x</span></nobr></DIV>
<DIV style="position:absolute;top:378;left:593"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:376;left:598"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:612"><nobr><span class="ft4">)):</span></nobr></DIV>
<DIV style="position:absolute;top:404;left:516"><nobr><span class="ft4">a</span></nobr></DIV>
<DIV style="position:absolute;top:411;left:529"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:409;left:533"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:404;left:561"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:404;left:591"><nobr><span class="ft4">a</span></nobr></DIV>
<DIV style="position:absolute;top:411;left:604"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:404;left:612"><nobr><span class="ft4">+ s</span></nobr></DIV>
<DIV style="position:absolute;top:409;left:632"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:407;left:636"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:396;left:665"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:413;left:653"><nobr><span class="ft4"> h</span></nobr></DIV>
<DIV style="position:absolute;top:421;left:680"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:404;left:689"><nobr><span class="ft4">ln p(y</span></nobr></DIV>
<DIV style="position:absolute;top:409;left:727"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:407;left:731"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:401;left:746"><nobr><span class="ft4">|h)</span></nobr></DIV>
<DIV style="position:absolute;top:411;left:768"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:444;left:517"><nobr><span class="ft4">C</span></nobr></DIV>
<DIV style="position:absolute;top:448;left:529"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:533"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:444;left:561"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:444;left:585"><nobr><span class="ft4">C</span></nobr></DIV>
<DIV style="position:absolute;top:448;left:597"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:444;left:605"><nobr><span class="ft4">+ s</span></nobr></DIV>
<DIV style="position:absolute;top:448;left:625"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:629"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:444;left:644"><nobr><span class="ft4">s</span></nobr></DIV>
<DIV style="position:absolute;top:438;left:650"><nobr><span class="ft7">T</span></nobr></DIV>
<DIV style="position:absolute;top:449;left:650"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:654"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:435;left:680"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:430;left:688"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:455;left:671"><nobr><span class="ft4"> h</span></nobr></DIV>
<DIV style="position:absolute;top:449;left:698"><nobr><span class="ft18">2<br>t</span></nobr></DIV>
<DIV style="position:absolute;top:444;left:708"><nobr><span class="ft4">ln p(y</span></nobr></DIV>
<DIV style="position:absolute;top:448;left:746"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:751"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:440;left:765"><nobr><span class="ft4">|h)</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:788"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:444;left:795"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:478;left:475"><nobr><span class="ft4">where</span></nobr></DIV>
<DIV style="position:absolute;top:501;left:555"><nobr><span class="ft4">s</span></nobr></DIV>
<DIV style="position:absolute;top:506;left:561"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:504;left:566"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:501;left:594"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:501;left:618"><nobr><span class="ft4">C</span></nobr></DIV>
<DIV style="position:absolute;top:506;left:629"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:501;left:635"><nobr><span class="ft4">k</span></nobr></DIV>
<DIV style="position:absolute;top:506;left:643"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:504;left:647"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:501;left:665"><nobr><span class="ft4">+ e</span></nobr></DIV>
<DIV style="position:absolute;top:506;left:686"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:504;left:690"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:501;left:705"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:530;left:515"><nobr><span class="ft4">p(y</span></nobr></DIV>
<DIV style="position:absolute;top:534;left:534"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:532;left:538"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:526;left:553"><nobr><span class="ft4">|h)</span></nobr></DIV>
<DIV style="position:absolute;top:537;left:575"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:530;left:594"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:530;left:618"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:520;left:642"><nobr><span class="ft4">y</span></nobr></DIV>
<DIV style="position:absolute;top:525;left:649"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:523;left:653"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:520;left:676"><nobr><span class="ft4">h</span></nobr></DIV>
<DIV style="position:absolute;top:527;left:689"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:539;left:655"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:543;left:663"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:667"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:530;left:708"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:561;left:553"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:555;left:562"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:566;left:561"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:566"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:561;left:594"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:561;left:618"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:555;left:626"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:626"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:561;left:636"><nobr><span class="ft4">+ k</span></nobr></DIV>
<DIV style="position:absolute;top:555;left:657"><nobr><span class="ft7"></span></nobr></DIV>
<DIV style="position:absolute;top:566;left:657"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:661"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:561;left:679"><nobr><span class="ft4">+ k</span></nobr></DIV>
<DIV style="position:absolute;top:558;left:701"><nobr><span class="ft19">T<br>t</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:705"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:561;left:720"><nobr><span class="ft4">C</span></nobr></DIV>
<DIV style="position:absolute;top:566;left:731"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:561;left:736"><nobr><span class="ft4">k</span></nobr></DIV>
<DIV style="position:absolute;top:566;left:745"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:563;left:749"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:561;left:777"><nobr><span class="ft4">and</span></nobr></DIV>
<DIV style="position:absolute;top:583;left:562"><nobr><span class="ft4">h</span></nobr></DIV>
<DIV style="position:absolute;top:590;left:575"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:583;left:594"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:583;left:623"><nobr><span class="ft4">a(x</span></nobr></DIV>
<DIV style="position:absolute;top:588;left:645"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:585;left:649"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:583;left:663"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:590;left:674"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:583;left:688"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:583;left:712"><nobr><span class="ft4">a</span></nobr></DIV>
<DIV style="position:absolute;top:578;left:725"><nobr><span class="ft18">T<br>t</span></nobr></DIV>
<DIV style="position:absolute;top:583;left:736"><nobr><span class="ft4">k</span></nobr></DIV>
<DIV style="position:absolute;top:588;left:745"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:585;left:749"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:607;left:489"><nobr><span class="ft4">Notice the similarities to the updates in section 3.1. The</span></nobr></DIV>
<DIV style="position:absolute;top:623;left:475"><nobr><span class="ft11">main difference is the `kernel trick' introduced into the equa-<br>tions through</span></nobr></DIV>
<DIV style="position:absolute;top:662;left:522"><nobr><span class="ft4">k</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:530"><nobr><span class="ft7"></span></nobr></DIV>
<DIV style="position:absolute;top:668;left:529"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:665;left:534"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:662;left:562"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:662;left:586"><nobr><span class="ft4">K</span></nobr></DIV>
<DIV style="position:absolute;top:665;left:597"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:662;left:604"><nobr><span class="ft4">(x</span></nobr></DIV>
<DIV style="position:absolute;top:667;left:618"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:665;left:622"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:662;left:636"><nobr><span class="ft4">, x</span></nobr></DIV>
<DIV style="position:absolute;top:667;left:651"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:665;left:655"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:662;left:670"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:662;left:689"><nobr><span class="ft4">and</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:521"><nobr><span class="ft4">k</span></nobr></DIV>
<DIV style="position:absolute;top:689;left:529"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:687;left:534"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:562"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:586"><nobr><span class="ft4">(K</span></nobr></DIV>
<DIV style="position:absolute;top:687;left:603"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:609"><nobr><span class="ft4">(x</span></nobr></DIV>
<DIV style="position:absolute;top:687;left:623"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:629"><nobr><span class="ft4">, x</span></nobr></DIV>
<DIV style="position:absolute;top:689;left:644"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:687;left:648"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:663"><nobr><span class="ft4">), . . . , K</span></nobr></DIV>
<DIV style="position:absolute;top:687;left:710"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:717"><nobr><span class="ft4">(x</span></nobr></DIV>
<DIV style="position:absolute;top:689;left:730"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:735"><nobr><span class="ft4">, x</span></nobr></DIV>
<DIV style="position:absolute;top:689;left:750"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:687;left:754"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:769"><nobr><span class="ft4">))</span></nobr></DIV>
<DIV style="position:absolute;top:681;left:780"><nobr><span class="ft7">T</span></nobr></DIV>
<DIV style="position:absolute;top:708;left:489"><nobr><span class="ft4">New inputs x</span></nobr></DIV>
<DIV style="position:absolute;top:713;left:570"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:710;left:574"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:708;left:593"><nobr><span class="ft4">are added sequentially to the system via</span></nobr></DIV>
<DIV style="position:absolute;top:724;left:475"><nobr><span class="ft4">the (t + 1)th unit vector e</span></nobr></DIV>
<DIV style="position:absolute;top:728;left:639"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:726;left:643"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:724;left:658"><nobr><span class="ft4">. This results in a quadratic</span></nobr></DIV>
<DIV style="position:absolute;top:740;left:475"><nobr><span class="ft11">increase in matrix size, and is a drawbackfor large data<br>sets, such as those for text classification. Csat´</span></nobr></DIV>
<DIV style="position:absolute;top:755;left:766"><nobr><span class="ft4">o &amp; Opper</span></nobr></DIV>
<DIV style="position:absolute;top:771;left:475"><nobr><span class="ft11">overcome this by introducing sparseness into the GP. The<br>idea is to replace e</span></nobr></DIV>
<DIV style="position:absolute;top:791;left:590"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:789;left:594"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:787;left:613"><nobr><span class="ft4">by the projection</span></nobr></DIV>
<DIV style="position:absolute;top:810;left:603"><nobr><span class="ft4">^</span></nobr></DIV>
<DIV style="position:absolute;top:810;left:603"><nobr><span class="ft4">e</span></nobr></DIV>
<DIV style="position:absolute;top:815;left:610"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:813;left:615"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:810;left:633"><nobr><span class="ft4">= K</span></nobr></DIV>
<DIV style="position:absolute;top:805;left:660"><nobr><span class="ft7">-1</span></nobr></DIV>
<DIV style="position:absolute;top:816;left:660"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:810;left:675"><nobr><span class="ft4">k</span></nobr></DIV>
<DIV style="position:absolute;top:815;left:683"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:813;left:688"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:810;left:702"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:834;left:475"><nobr><span class="ft4">where</span></nobr></DIV>
<DIV style="position:absolute;top:857;left:559"><nobr><span class="ft4">K</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:572"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:857;left:581"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:853;left:595"><nobr><span class="ft4">{K</span></nobr></DIV>
<DIV style="position:absolute;top:859;left:614"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:857;left:620"><nobr><span class="ft4">(x</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:634"><nobr><span class="ft7">i</span></nobr></DIV>
<DIV style="position:absolute;top:857;left:639"><nobr><span class="ft4">, x</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:653"><nobr><span class="ft7">j</span></nobr></DIV>
<DIV style="position:absolute;top:857;left:659"><nobr><span class="ft4">), i, j = 1 . . . t}.</span></nobr></DIV>
<DIV style="position:absolute;top:879;left:475"><nobr><span class="ft4">This approximation introduces an error</span></nobr></DIV>
<DIV style="position:absolute;top:913;left:507"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:911;left:511"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:909;left:529"><nobr><span class="ft4">= (k</span></nobr></DIV>
<DIV style="position:absolute;top:903;left:557"><nobr><span class="ft7"></span></nobr></DIV>
<DIV style="position:absolute;top:914;left:557"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:912;left:561"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:905;left:578"><nobr><span class="ft4">- k</span></nobr></DIV>
<DIV style="position:absolute;top:903;left:601"><nobr><span class="ft7">T</span></nobr></DIV>
<DIV style="position:absolute;top:914;left:601"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:912;left:605"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:909;left:620"><nobr><span class="ft4">K</span></nobr></DIV>
<DIV style="position:absolute;top:903;left:632"><nobr><span class="ft7">-1</span></nobr></DIV>
<DIV style="position:absolute;top:915;left:632"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:909;left:647"><nobr><span class="ft4">k</span></nobr></DIV>
<DIV style="position:absolute;top:913;left:655"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:911;left:660"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:909;left:674"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:900;left:693"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:918;left:681"><nobr><span class="ft4"> h</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:708"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:909;left:717"><nobr><span class="ft4">ln p(y</span></nobr></DIV>
<DIV style="position:absolute;top:913;left:756"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:911;left:760"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:905;left:774"><nobr><span class="ft4">|h)</span></nobr></DIV>
<DIV style="position:absolute;top:916;left:797"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:909;left:804"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:475"><nobr><span class="ft4">which is used to decide when to employ the approximation.</span></nobr></DIV>
<DIV style="position:absolute;top:957;left:489"><nobr><span class="ft4">Hence, at any time the algorithm holds a set of basis vec-</span></nobr></DIV>
<DIV style="position:absolute;top:973;left:475"><nobr><span class="ft11">tors. It is usually desirable to limit the size of this set. To<br>accommodate this, Csat´</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:620"><nobr><span class="ft4">o &amp; Opper describe a procedure for</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:475"><nobr><span class="ft11">removing a basis vector from the set by reversing the process<br>of adding new inputs.</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:489"><nobr><span class="ft4">For lackof space, the algorithm for the Bayesian Online</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:475"><nobr><span class="ft11">Gaussian Process will not be given here. The reader is re-<br>ferred to [3] for more information.</span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:452"><nobr><span class="ft9">99</span></nobr></DIV>
</DIV>
<!-- Page 4 -->
<a name="4"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft21{font-size:11px;line-height:16px;font-family:Times;color:#000000;}
	.ft22{font-size:11px;line-height:14px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="42004.png" alt="background image">
<DIV style="position:absolute;top:83;left:81"><nobr><span class="ft3"><b>4.</b></span></nobr></DIV>
<DIV style="position:absolute;top:83;left:112"><nobr><span class="ft3"><b>EVALUATION</b></span></nobr></DIV>
<DIV style="position:absolute;top:114;left:81"><nobr><span class="ft3"><b>4.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:114;left:121"><nobr><span class="ft3"><b>Classification on Reuters-21578</b></span></nobr></DIV>
<DIV style="position:absolute;top:137;left:94"><nobr><span class="ft4">In this evaluation, we will compare Bayesian online per-</span></nobr></DIV>
<DIV style="position:absolute;top:153;left:81"><nobr><span class="ft11">ceptron, Bayesian online Gaussian process, and Support Vec-<br>tor Machines (SVM)[23]. SVM is one of the best performing<br>learning algorithms on the Reuters-21578 corpus[7, 27].</span></nobr></DIV>
<DIV style="position:absolute;top:200;left:94"><nobr><span class="ft4">The Bayesian methods are as described in section 3, while</span></nobr></DIV>
<DIV style="position:absolute;top:215;left:81"><nobr><span class="ft4">for SVM we will use the SV M</span></nobr></DIV>
<DIV style="position:absolute;top:213;left:266"><nobr><span class="ft7">light</span></nobr></DIV>
<DIV style="position:absolute;top:215;left:295"><nobr><span class="ft4">package by Joachims[8].</span></nobr></DIV>
<DIV style="position:absolute;top:231;left:81"><nobr><span class="ft11">Since SVM is a batch method, to have a fair comparison,<br>the online methods are iterated through the training data 3<br>times before testing.</span></nobr></DIV>
<DIV style="position:absolute;top:258;left:204"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:288;left:81"><nobr><span class="ft17"><i>4.1.1</i></span></nobr></DIV>
<DIV style="position:absolute;top:288;left:130"><nobr><span class="ft17"><i>Feature Selection</i></span></nobr></DIV>
<DIV style="position:absolute;top:309;left:94"><nobr><span class="ft4">For the Reuters-21578 corpus, we select as features for</span></nobr></DIV>
<DIV style="position:absolute;top:325;left:81"><nobr><span class="ft4">each category the set of all words for which</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:344"><nobr><span class="ft4">-2 ln  &gt; 12.13.</span></nobr></DIV>
<DIV style="position:absolute;top:341;left:81"><nobr><span class="ft11">We further prune these by using only the top 300 features.<br>This reduces the computation time required for the calcula-<br>tion of the covariances of the Bayesian classifiers.</span></nobr></DIV>
<DIV style="position:absolute;top:388;left:94"><nobr><span class="ft4">Since SVM is known to perform well for many features,</span></nobr></DIV>
<DIV style="position:absolute;top:403;left:81"><nobr><span class="ft11">for the SVM classifiers we also use the set of words which<br>occur in at least 3 training documents[7]. This gives us 8,362<br>words. Note that these words are non-category specific.</span></nobr></DIV>
<DIV style="position:absolute;top:460;left:81"><nobr><span class="ft17"><i>4.1.2</i></span></nobr></DIV>
<DIV style="position:absolute;top:460;left:130"><nobr><span class="ft17"><i>Thresholding</i></span></nobr></DIV>
<DIV style="position:absolute;top:482;left:94"><nobr><span class="ft4">The probabilistic outputs from the Bayesian classifiers can</span></nobr></DIV>
<DIV style="position:absolute;top:497;left:81"><nobr><span class="ft11">be used in various ways. The most direct way is to use the<br>Bayes decision rule, p(y = 1|x, D</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:292"><nobr><span class="ft7">m</span></nobr></DIV>
<DIV style="position:absolute;top:513;left:302"><nobr><span class="ft4">) &gt; 0.5, to determine</span></nobr></DIV>
<DIV style="position:absolute;top:529;left:81"><nobr><span class="ft4">the relevance of the document described by x.</span></nobr></DIV>
<DIV style="position:absolute;top:524;left:368"><nobr><span class="ft7">3</span></nobr></DIV>
<DIV style="position:absolute;top:529;left:384"><nobr><span class="ft4">However,</span></nobr></DIV>
<DIV style="position:absolute;top:544;left:81"><nobr><span class="ft11">as discussed in [10, 26], this is not optimal for the chosen<br>evaluation measure.</span></nobr></DIV>
<DIV style="position:absolute;top:576;left:94"><nobr><span class="ft4">Therefore, in addition to 0.5 thresholding, we also empir-</span></nobr></DIV>
<DIV style="position:absolute;top:591;left:81"><nobr><span class="ft4">ically optimise the threshold for each category for the F</span></nobr></DIV>
<DIV style="position:absolute;top:594;left:433"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:607;left:81"><nobr><span class="ft11">measure on the training documents. This scheme, which we<br>shall call MaxF1, has also been employed in [27] for thresh-<br>olding kNN and LLSF classifiers. The difference from our<br>approach is that the threshold in [27] is calculated over a<br>validation set. We do not use a validation set because we<br>feel that, for very rare categories, it is hard to obtain a rea-<br>sonable validation set from the training documents.</span></nobr></DIV>
<DIV style="position:absolute;top:717;left:94"><nobr><span class="ft4">For the Bayesian classifiers, we also perform an analyti-</span></nobr></DIV>
<DIV style="position:absolute;top:733;left:81"><nobr><span class="ft11">cal threshold optimisation suggested by Lewis[10]. In this<br>scheme, which we shall call ExpectedF1, the threshold for<br>each category is selected to optimise the expected F</span></nobr></DIV>
<DIV style="position:absolute;top:766;left:395"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:764;left:402"><nobr><span class="ft4">:</span></nobr></DIV>
<DIV style="position:absolute;top:804;left:143"><nobr><span class="ft4">E [F</span></nobr></DIV>
<DIV style="position:absolute;top:807;left:168"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:804;left:174"><nobr><span class="ft4">]</span></nobr></DIV>
<DIV style="position:absolute;top:812;left:178"><nobr><span class="ft7"></span></nobr></DIV>
<DIV style="position:absolute;top:801;left:188"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:790;left:215"><nobr><span class="ft13">É</span></nobr></DIV>
<DIV style="position:absolute;top:798;left:228"><nobr><span class="ft7">i</span></nobr></DIV>
<DIV style="position:absolute;top:795;left:232"><nobr><span class="ft7">D</span></nobr></DIV>
<DIV style="position:absolute;top:790;left:249"><nobr><span class="ft4">(1</span></nobr></DIV>
<DIV style="position:absolute;top:787;left:265"><nobr><span class="ft4">- p</span></nobr></DIV>
<DIV style="position:absolute;top:795;left:285"><nobr><span class="ft7">i</span></nobr></DIV>
<DIV style="position:absolute;top:790;left:290"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:790;left:309"><nobr><span class="ft4">if</span></nobr></DIV>
<DIV style="position:absolute;top:787;left:322"><nobr><span class="ft4">|D</span></nobr></DIV>
<DIV style="position:absolute;top:793;left:336"><nobr><span class="ft7">+</span></nobr></DIV>
<DIV style="position:absolute;top:787;left:346"><nobr><span class="ft4">| = 0</span></nobr></DIV>
<DIV style="position:absolute;top:804;left:226"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:805;left:233"><nobr><span class="ft13">È</span></nobr></DIV>
<DIV style="position:absolute;top:808;left:244"><nobr><span class="ft14">iD+</span></nobr></DIV>
<DIV style="position:absolute;top:806;left:274"><nobr><span class="ft7">p</span></nobr></DIV>
<DIV style="position:absolute;top:807;left:280"><nobr><span class="ft14">i</span></nobr></DIV>
<DIV style="position:absolute;top:818;left:217"><nobr><span class="ft4">|</span></nobr></DIV>
<DIV style="position:absolute;top:821;left:221"><nobr><span class="ft7">D</span></nobr></DIV>
<DIV style="position:absolute;top:824;left:229"><nobr><span class="ft14">+</span></nobr></DIV>
<DIV style="position:absolute;top:818;left:238"><nobr><span class="ft4">|</span></nobr></DIV>
<DIV style="position:absolute;top:821;left:242"><nobr><span class="ft7">+</span></nobr></DIV>
<DIV style="position:absolute;top:823;left:250"><nobr><span class="ft13">È</span></nobr></DIV>
<DIV style="position:absolute;top:825;left:261"><nobr><span class="ft14">iD</span></nobr></DIV>
<DIV style="position:absolute;top:823;left:283"><nobr><span class="ft7">p</span></nobr></DIV>
<DIV style="position:absolute;top:824;left:289"><nobr><span class="ft14">i</span></nobr></DIV>
<DIV style="position:absolute;top:814;left:309"><nobr><span class="ft4">otherwise,</span></nobr></DIV>
<DIV style="position:absolute;top:845;left:81"><nobr><span class="ft4">where  is the threshold, p</span></nobr></DIV>
<DIV style="position:absolute;top:849;left:248"><nobr><span class="ft7">i</span></nobr></DIV>
<DIV style="position:absolute;top:845;left:259"><nobr><span class="ft4">is the probability assigned to</span></nobr></DIV>
<DIV style="position:absolute;top:860;left:81"><nobr><span class="ft11">document i by the classifier, D is the set of all test docu-<br>ments, and</span></nobr></DIV>
<DIV style="position:absolute;top:873;left:149"><nobr><span class="ft4">D</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:160"><nobr><span class="ft7">+</span></nobr></DIV>
<DIV style="position:absolute;top:876;left:172"><nobr><span class="ft4">is the set of test documents with probabilities</span></nobr></DIV>
<DIV style="position:absolute;top:892;left:81"><nobr><span class="ft4">higher than the threshold .</span></nobr></DIV>
<DIV style="position:absolute;top:907;left:94"><nobr><span class="ft4">Note that ExpectedF1 can only be applied after the prob-</span></nobr></DIV>
<DIV style="position:absolute;top:923;left:81"><nobr><span class="ft11">abilities for all the test documents are assigned. Hence the<br>classification can only be done in batch. This is unlike the<br>first two schemes, where classification can be done online.</span></nobr></DIV>
<DIV style="position:absolute;top:980;left:81"><nobr><span class="ft17"><i>4.1.3</i></span></nobr></DIV>
<DIV style="position:absolute;top:980;left:130"><nobr><span class="ft17"><i>Results and Discussion</i></span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:81"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:1009;left:88"><nobr><span class="ft4">See section A.2 for discussion on the number of passes.</span></nobr></DIV>
<DIV style="position:absolute;top:1019;left:81"><nobr><span class="ft7">3</span></nobr></DIV>
<DIV style="position:absolute;top:1024;left:88"><nobr><span class="ft4">For SVM, to minimise structural risks, we would classify</span></nobr></DIV>
<DIV style="position:absolute;top:1038;left:81"><nobr><span class="ft4">the document as relevant if w</span></nobr></DIV>
<DIV style="position:absolute;top:1034;left:270"><nobr><span class="ft4">· x + b &gt; 0, where w is the</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:81"><nobr><span class="ft4">hyperplane, and b is the bias.</span></nobr></DIV>
<DIV style="position:absolute;top:1062;left:81"><nobr><span class="ft7">4</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:88"><nobr><span class="ft4">See section A.3 for discussion on the jitter terms </span></nobr></DIV>
<DIV style="position:absolute;top:1071;left:393"><nobr><span class="ft7">ij</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:402"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:96;left:541"><nobr><span class="ft4">Table 1: Description of Methods</span></nobr></DIV>
<DIV style="position:absolute;top:111;left:565"><nobr><span class="ft4">Description</span></nobr></DIV>
<DIV style="position:absolute;top:106;left:634"><nobr><span class="ft7">4</span></nobr></DIV>
<DIV style="position:absolute;top:128;left:483"><nobr><span class="ft4">SVM-1</span></nobr></DIV>
<DIV style="position:absolute;top:128;left:565"><nobr><span class="ft4">K</span></nobr></DIV>
<DIV style="position:absolute;top:130;left:577"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:128;left:587"><nobr><span class="ft4">= x</span></nobr></DIV>
<DIV style="position:absolute;top:132;left:610"><nobr><span class="ft7">i</span></nobr></DIV>
<DIV style="position:absolute;top:124;left:618"><nobr><span class="ft4">· x</span></nobr></DIV>
<DIV style="position:absolute;top:132;left:633"><nobr><span class="ft7">j</span></nobr></DIV>
<DIV style="position:absolute;top:128;left:642"><nobr><span class="ft4">+ 1</span></nobr></DIV>
<DIV style="position:absolute;top:144;left:483"><nobr><span class="ft4">SVM-2</span></nobr></DIV>
<DIV style="position:absolute;top:144;left:565"><nobr><span class="ft4">K</span></nobr></DIV>
<DIV style="position:absolute;top:146;left:577"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:144;left:587"><nobr><span class="ft4">= (x</span></nobr></DIV>
<DIV style="position:absolute;top:148;left:616"><nobr><span class="ft7">i</span></nobr></DIV>
<DIV style="position:absolute;top:140;left:623"><nobr><span class="ft4">· x</span></nobr></DIV>
<DIV style="position:absolute;top:148;left:639"><nobr><span class="ft7">j</span></nobr></DIV>
<DIV style="position:absolute;top:144;left:647"><nobr><span class="ft4">+ 1)</span></nobr></DIV>
<DIV style="position:absolute;top:139;left:674"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:483"><nobr><span class="ft4">SVM-R1</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:565"><nobr><span class="ft4">K</span></nobr></DIV>
<DIV style="position:absolute;top:162;left:577"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:587"><nobr><span class="ft4">= exp(</span></nobr></DIV>
<DIV style="position:absolute;top:157;left:628"><nobr><span class="ft4">-</span></nobr></DIV>
<DIV style="position:absolute;top:155;left:641"><nobr><span class="ft20">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:157;left:648"><nobr><span class="ft4">|x</span></nobr></DIV>
<DIV style="position:absolute;top:164;left:660"><nobr><span class="ft7">i</span></nobr></DIV>
<DIV style="position:absolute;top:157;left:668"><nobr><span class="ft4">- x</span></nobr></DIV>
<DIV style="position:absolute;top:164;left:690"><nobr><span class="ft7">j</span></nobr></DIV>
<DIV style="position:absolute;top:157;left:696"><nobr><span class="ft4">|</span></nobr></DIV>
<DIV style="position:absolute;top:155;left:700"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:706"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:176;left:483"><nobr><span class="ft4">Perceptron</span></nobr></DIV>
<DIV style="position:absolute;top:176;left:565"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:178;left:573"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:176;left:583"><nobr><span class="ft4">= 0.5, one fixed feature (for bias)</span></nobr></DIV>
<DIV style="position:absolute;top:192;left:483"><nobr><span class="ft4">GP-1</span></nobr></DIV>
<DIV style="position:absolute;top:192;left:565"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:194;left:573"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:192;left:583"><nobr><span class="ft4">= 0.5, K</span></nobr></DIV>
<DIV style="position:absolute;top:194;left:636"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:192;left:646"><nobr><span class="ft4">= x</span></nobr></DIV>
<DIV style="position:absolute;top:197;left:669"><nobr><span class="ft7">i</span></nobr></DIV>
<DIV style="position:absolute;top:189;left:677"><nobr><span class="ft4">· x</span></nobr></DIV>
<DIV style="position:absolute;top:197;left:692"><nobr><span class="ft7">j</span></nobr></DIV>
<DIV style="position:absolute;top:192;left:701"><nobr><span class="ft4">+ 1 + 10</span></nobr></DIV>
<DIV style="position:absolute;top:187;left:752"><nobr><span class="ft7">-4</span></nobr></DIV>
<DIV style="position:absolute;top:192;left:767"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:197;left:773"><nobr><span class="ft7">ij</span></nobr></DIV>
<DIV style="position:absolute;top:208;left:483"><nobr><span class="ft4">GP-2</span></nobr></DIV>
<DIV style="position:absolute;top:208;left:565"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:210;left:573"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:208;left:583"><nobr><span class="ft4">= 0.5, K</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:636"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:208;left:646"><nobr><span class="ft4">= (x</span></nobr></DIV>
<DIV style="position:absolute;top:213;left:674"><nobr><span class="ft7">i</span></nobr></DIV>
<DIV style="position:absolute;top:205;left:682"><nobr><span class="ft4">· x</span></nobr></DIV>
<DIV style="position:absolute;top:213;left:697"><nobr><span class="ft7">j</span></nobr></DIV>
<DIV style="position:absolute;top:208;left:706"><nobr><span class="ft4">+ 1)</span></nobr></DIV>
<DIV style="position:absolute;top:203;left:732"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:208;left:742"><nobr><span class="ft4">+ 10</span></nobr></DIV>
<DIV style="position:absolute;top:203;left:769"><nobr><span class="ft7">-4</span></nobr></DIV>
<DIV style="position:absolute;top:208;left:784"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:213;left:790"><nobr><span class="ft7">ij</span></nobr></DIV>
<DIV style="position:absolute;top:224;left:483"><nobr><span class="ft4">GP-R1</span></nobr></DIV>
<DIV style="position:absolute;top:224;left:565"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:227;left:573"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:224;left:583"><nobr><span class="ft4">= 0.5, K</span></nobr></DIV>
<DIV style="position:absolute;top:227;left:636"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:224;left:646"><nobr><span class="ft4">= exp(</span></nobr></DIV>
<DIV style="position:absolute;top:221;left:687"><nobr><span class="ft4">-</span></nobr></DIV>
<DIV style="position:absolute;top:220;left:699"><nobr><span class="ft20">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:221;left:707"><nobr><span class="ft4">|x</span></nobr></DIV>
<DIV style="position:absolute;top:229;left:719"><nobr><span class="ft7">i</span></nobr></DIV>
<DIV style="position:absolute;top:221;left:727"><nobr><span class="ft4">- x</span></nobr></DIV>
<DIV style="position:absolute;top:229;left:749"><nobr><span class="ft7">j</span></nobr></DIV>
<DIV style="position:absolute;top:221;left:755"><nobr><span class="ft4">|</span></nobr></DIV>
<DIV style="position:absolute;top:219;left:759"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:224;left:765"><nobr><span class="ft4">) + 10</span></nobr></DIV>
<DIV style="position:absolute;top:219;left:801"><nobr><span class="ft7">-4</span></nobr></DIV>
<DIV style="position:absolute;top:224;left:816"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:229;left:822"><nobr><span class="ft7">ij</span></nobr></DIV>
<DIV style="position:absolute;top:269;left:535"><nobr><span class="ft4">Table 2: Micro-/Macro-average F</span></nobr></DIV>
<DIV style="position:absolute;top:271;left:768"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:286;left:594"><nobr><span class="ft4">0.5</span></nobr></DIV>
<DIV style="position:absolute;top:286;left:683"><nobr><span class="ft4">MaxF1</span></nobr></DIV>
<DIV style="position:absolute;top:286;left:760"><nobr><span class="ft4">ExpectedF1</span></nobr></DIV>
<DIV style="position:absolute;top:301;left:483"><nobr><span class="ft4">SVM</span></nobr></DIV>
<DIV style="position:absolute;top:306;left:514"><nobr><span class="ft7">a</span></nobr></DIV>
<DIV style="position:absolute;top:301;left:521"><nobr><span class="ft4">-1</span></nobr></DIV>
<DIV style="position:absolute;top:301;left:565"><nobr><span class="ft4">86.15 / 42.63</span></nobr></DIV>
<DIV style="position:absolute;top:301;left:661"><nobr><span class="ft4">86.35 / 56.92</span></nobr></DIV>
<DIV style="position:absolute;top:317;left:483"><nobr><span class="ft4">SVM</span></nobr></DIV>
<DIV style="position:absolute;top:321;left:514"><nobr><span class="ft7">a</span></nobr></DIV>
<DIV style="position:absolute;top:317;left:521"><nobr><span class="ft4">-2</span></nobr></DIV>
<DIV style="position:absolute;top:317;left:565"><nobr><span class="ft4">85.44 / 40.13</span></nobr></DIV>
<DIV style="position:absolute;top:317;left:661"><nobr><span class="ft4">86.19 / 56.42</span></nobr></DIV>
<DIV style="position:absolute;top:332;left:483"><nobr><span class="ft4">SVM</span></nobr></DIV>
<DIV style="position:absolute;top:337;left:514"><nobr><span class="ft7">a</span></nobr></DIV>
<DIV style="position:absolute;top:332;left:521"><nobr><span class="ft4">-R1</span></nobr></DIV>
<DIV style="position:absolute;top:332;left:565"><nobr><span class="ft4">84.99 / 37.61</span></nobr></DIV>
<DIV style="position:absolute;top:332;left:661"><nobr><span class="ft4">86.63 / 53.14</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:483"><nobr><span class="ft4">SVM</span></nobr></DIV>
<DIV style="position:absolute;top:353;left:514"><nobr><span class="ft7">b</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:520"><nobr><span class="ft4">-1</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:565"><nobr><span class="ft4">85.60 / 52.03</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:661"><nobr><span class="ft4">85.05 / 52.43</span></nobr></DIV>
<DIV style="position:absolute;top:364;left:483"><nobr><span class="ft4">SVM</span></nobr></DIV>
<DIV style="position:absolute;top:369;left:514"><nobr><span class="ft7">b</span></nobr></DIV>
<DIV style="position:absolute;top:364;left:520"><nobr><span class="ft4">-2</span></nobr></DIV>
<DIV style="position:absolute;top:364;left:565"><nobr><span class="ft4">85.60 / 50.53</span></nobr></DIV>
<DIV style="position:absolute;top:364;left:661"><nobr><span class="ft4">84.50 / 50.49</span></nobr></DIV>
<DIV style="position:absolute;top:380;left:483"><nobr><span class="ft4">SVM</span></nobr></DIV>
<DIV style="position:absolute;top:384;left:514"><nobr><span class="ft7">b</span></nobr></DIV>
<DIV style="position:absolute;top:380;left:520"><nobr><span class="ft4">-R1</span></nobr></DIV>
<DIV style="position:absolute;top:380;left:565"><nobr><span class="ft4">85.75 / 50.52</span></nobr></DIV>
<DIV style="position:absolute;top:380;left:661"><nobr><span class="ft4">84.65 / 51.27</span></nobr></DIV>
<DIV style="position:absolute;top:395;left:483"><nobr><span class="ft4">Perceptron</span></nobr></DIV>
<DIV style="position:absolute;top:395;left:565"><nobr><span class="ft4">85.12 / 45.23</span></nobr></DIV>
<DIV style="position:absolute;top:395;left:661"><nobr><span class="ft4">86.69 / 52.16</span></nobr></DIV>
<DIV style="position:absolute;top:395;left:756"><nobr><span class="ft4">86.44 / 53.08</span></nobr></DIV>
<DIV style="position:absolute;top:411;left:483"><nobr><span class="ft4">GP-1</span></nobr></DIV>
<DIV style="position:absolute;top:411;left:565"><nobr><span class="ft4">85.08 / 45.20</span></nobr></DIV>
<DIV style="position:absolute;top:411;left:661"><nobr><span class="ft4">86.73 / 52.12</span></nobr></DIV>
<DIV style="position:absolute;top:411;left:756"><nobr><span class="ft4">86.54 / 53.12</span></nobr></DIV>
<DIV style="position:absolute;top:426;left:483"><nobr><span class="ft4">GP-2</span></nobr></DIV>
<DIV style="position:absolute;top:426;left:565"><nobr><span class="ft4">85.58 / 47.90</span></nobr></DIV>
<DIV style="position:absolute;top:426;left:661"><nobr><span class="ft4">86.60 / 52.19</span></nobr></DIV>
<DIV style="position:absolute;top:426;left:756"><nobr><span class="ft4">86.77 / 55.04</span></nobr></DIV>
<DIV style="position:absolute;top:442;left:483"><nobr><span class="ft4">GP-R1</span></nobr></DIV>
<DIV style="position:absolute;top:442;left:565"><nobr><span class="ft4">85.18 / 44.88</span></nobr></DIV>
<DIV style="position:absolute;top:442;left:661"><nobr><span class="ft4">86.76 / 52.61</span></nobr></DIV>
<DIV style="position:absolute;top:442;left:756"><nobr><span class="ft4">86.93 / 53.35</span></nobr></DIV>
<DIV style="position:absolute;top:486;left:489"><nobr><span class="ft4">Table 1 lists the parameters for the algorithms used in our</span></nobr></DIV>
<DIV style="position:absolute;top:501;left:475"><nobr><span class="ft11">evaluation, while Table 2 and 3 tabulate the results. There<br>are two sets of results for SVM, and they are labeled SVM</span></nobr></DIV>
<DIV style="position:absolute;top:522;left:827"><nobr><span class="ft7">a</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:475"><nobr><span class="ft4">and SVM</span></nobr></DIV>
<DIV style="position:absolute;top:538;left:533"><nobr><span class="ft7">b</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:539"><nobr><span class="ft4">. The latter uses the same set of features as the</span></nobr></DIV>
<DIV style="position:absolute;top:549;left:475"><nobr><span class="ft4">Bayesian classifiers (i.e. using the</span></nobr></DIV>
<DIV style="position:absolute;top:545;left:690"><nobr><span class="ft4">-2 ln  measure), while</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:475"><nobr><span class="ft4">the former uses the set of 8,362 words as features.</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:489"><nobr><span class="ft4">Table 2 summarizes the results using F</span></nobr></DIV>
<DIV style="position:absolute;top:582;left:728"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:739"><nobr><span class="ft4">averages. Table</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:475"><nobr><span class="ft11">3 compares the classifiers using s-test and S-test. Here, the<br>MaxF1 thresholds are used for the classification decisions.<br>Each row in these tables compares the method listed in the<br>first column with the other methods. The significance levels<br>from [27] are used.</span></nobr></DIV>
<DIV style="position:absolute;top:674;left:489"><nobr><span class="ft4">Several observations can be made:</span></nobr></DIV>
<DIV style="position:absolute;top:694;left:495"><nobr><span class="ft4">· Generally, MaxF1 thresholding increases the performance</span></nobr></DIV>
<DIV style="position:absolute;top:713;left:509"><nobr><span class="ft4">of all the systems, especially for rare categories.</span></nobr></DIV>
<DIV style="position:absolute;top:735;left:495"><nobr><span class="ft4">· For the Bayesian classifiers, ExpectedF1 thresholding</span></nobr></DIV>
<DIV style="position:absolute;top:754;left:509"><nobr><span class="ft11">improves the performance of the systems on rare cat-<br>egories.</span></nobr></DIV>
<DIV style="position:absolute;top:791;left:495"><nobr><span class="ft4">· Perceptron implicitly implements the kernel used by</span></nobr></DIV>
<DIV style="position:absolute;top:810;left:509"><nobr><span class="ft4">GP-1, hence their similar results.</span></nobr></DIV>
<DIV style="position:absolute;top:832;left:495"><nobr><span class="ft4">· With MaxF1 thresholding, feature selection impedes</span></nobr></DIV>
<DIV style="position:absolute;top:851;left:509"><nobr><span class="ft4">the performance of SVM.</span></nobr></DIV>
<DIV style="position:absolute;top:872;left:495"><nobr><span class="ft4">· In Table 2, SVM with 8,362 features have slightly lower</span></nobr></DIV>
<DIV style="position:absolute;top:891;left:509"><nobr><span class="ft4">micro-average F</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:605"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:891;left:616"><nobr><span class="ft4">to the Bayesian classifiers. However,</span></nobr></DIV>
<DIV style="position:absolute;top:907;left:509"><nobr><span class="ft11">the s-tests in Table 3 show that Bayesian classifiers<br>outperform SVM for significantly many common cat-<br>egories. Hence, in addition to computing average F</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:828"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:954;left:509"><nobr><span class="ft4">measures, it is useful to perform sign tests.</span></nobr></DIV>
<DIV style="position:absolute;top:976;left:495"><nobr><span class="ft4">· As shown in Table 3, for limited features, Bayesian</span></nobr></DIV>
<DIV style="position:absolute;top:995;left:509"><nobr><span class="ft11">classifiers outperform SVM for both common and rare<br>categories.</span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:495"><nobr><span class="ft4">· Based on the sign tests, the Bayesian classifiers outper-</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:509"><nobr><span class="ft11">form SVM (using 8,362 words) for common categories,<br>and vice versa for rare categories.</span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:449"><nobr><span class="ft9">100</span></nobr></DIV>
</DIV>
<!-- Page 5 -->
<a name="5"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="42005.png" alt="background image">
<DIV style="position:absolute;top:96;left:296"><nobr><span class="ft4">Table 3: s-test/S-test using MaxF1 thresholding</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:176"><nobr><span class="ft4">SVM</span></nobr></DIV>
<DIV style="position:absolute;top:117;left:207"><nobr><span class="ft7">a</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:213"><nobr><span class="ft4">-1</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:241"><nobr><span class="ft4">SVM</span></nobr></DIV>
<DIV style="position:absolute;top:117;left:272"><nobr><span class="ft7">a</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:279"><nobr><span class="ft4">-2</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:306"><nobr><span class="ft4">SVM</span></nobr></DIV>
<DIV style="position:absolute;top:117;left:337"><nobr><span class="ft7">a</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:344"><nobr><span class="ft4">-R1</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:382"><nobr><span class="ft4">SVM</span></nobr></DIV>
<DIV style="position:absolute;top:117;left:412"><nobr><span class="ft7">b</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:418"><nobr><span class="ft4">-1</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:446"><nobr><span class="ft4">SVM</span></nobr></DIV>
<DIV style="position:absolute;top:117;left:476"><nobr><span class="ft7">b</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:482"><nobr><span class="ft4">-2</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:510"><nobr><span class="ft4">SVM</span></nobr></DIV>
<DIV style="position:absolute;top:117;left:541"><nobr><span class="ft7">b</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:546"><nobr><span class="ft4">-R1</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:585"><nobr><span class="ft4">Pptron</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:650"><nobr><span class="ft4">GP-1</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:710"><nobr><span class="ft4">GP-2</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:773"><nobr><span class="ft4">GP-R1</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:91"><nobr><span class="ft4">SVM</span></nobr></DIV>
<DIV style="position:absolute;top:136;left:122"><nobr><span class="ft7">a</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:129"><nobr><span class="ft4">-1</span></nobr></DIV>
<DIV style="position:absolute;top:128;left:247"><nobr><span class="ft4"> / </span></nobr></DIV>
<DIV style="position:absolute;top:131;left:317"><nobr><span class="ft4">&lt; / </span></nobr></DIV>
<DIV style="position:absolute;top:131;left:402"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:466"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:535"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:602"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:662"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:722"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:790"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:147;left:91"><nobr><span class="ft4">SVM</span></nobr></DIV>
<DIV style="position:absolute;top:152;left:122"><nobr><span class="ft7">a</span></nobr></DIV>
<DIV style="position:absolute;top:147;left:129"><nobr><span class="ft4">-2</span></nobr></DIV>
<DIV style="position:absolute;top:144;left:182"><nobr><span class="ft4"> / </span></nobr></DIV>
<DIV style="position:absolute;top:147;left:334"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:144;left:345"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:147;left:385"><nobr><span class="ft4">&gt; /</span></nobr></DIV>
<DIV style="position:absolute;top:147;left:466"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:147;left:535"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:147;left:602"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:147;left:662"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:147;left:724"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:144;left:735"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:147;left:792"><nobr><span class="ft4">/ &gt;</span></nobr></DIV>
<DIV style="position:absolute;top:163;left:91"><nobr><span class="ft4">SVM</span></nobr></DIV>
<DIV style="position:absolute;top:167;left:122"><nobr><span class="ft7">a</span></nobr></DIV>
<DIV style="position:absolute;top:163;left:129"><nobr><span class="ft4">-R1</span></nobr></DIV>
<DIV style="position:absolute;top:163;left:182"><nobr><span class="ft4">&gt; / </span></nobr></DIV>
<DIV style="position:absolute;top:163;left:264"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:159;left:275"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:163;left:404"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:159;left:415"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:163;left:466"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:163;left:535"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:163;left:587"><nobr><span class="ft4">&lt; / &gt;</span></nobr></DIV>
<DIV style="position:absolute;top:163;left:647"><nobr><span class="ft4">&lt; / &gt;</span></nobr></DIV>
<DIV style="position:absolute;top:159;left:707"><nobr><span class="ft4"> / </span></nobr></DIV>
<DIV style="position:absolute;top:163;left:775"><nobr><span class="ft4">&lt; / </span></nobr></DIV>
<DIV style="position:absolute;top:179;left:91"><nobr><span class="ft4">SVM</span></nobr></DIV>
<DIV style="position:absolute;top:184;left:122"><nobr><span class="ft7">b</span></nobr></DIV>
<DIV style="position:absolute;top:179;left:128"><nobr><span class="ft4">-1</span></nobr></DIV>
<DIV style="position:absolute;top:179;left:197"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:179;left:245"><nobr><span class="ft4">&lt; /</span></nobr></DIV>
<DIV style="position:absolute;top:179;left:334"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:176;left:345"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:179;left:468"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:176;left:479"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:179;left:520"><nobr><span class="ft4">&gt; / &gt;</span></nobr></DIV>
<DIV style="position:absolute;top:179;left:604"><nobr><span class="ft4">/ &lt;</span></nobr></DIV>
<DIV style="position:absolute;top:179;left:664"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:176;left:675"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:179;left:724"><nobr><span class="ft4">/ &lt;</span></nobr></DIV>
<DIV style="position:absolute;top:179;left:792"><nobr><span class="ft4">/ &lt;</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:91"><nobr><span class="ft4">SVM</span></nobr></DIV>
<DIV style="position:absolute;top:199;left:122"><nobr><span class="ft7">b</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:128"><nobr><span class="ft4">-2</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:197"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:262"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:332"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:404"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:191;left:415"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:191;left:520"><nobr><span class="ft4"> / </span></nobr></DIV>
<DIV style="position:absolute;top:195;left:604"><nobr><span class="ft4">/ &lt;</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:664"><nobr><span class="ft4">/ &lt;</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:722"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:790"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:91"><nobr><span class="ft4">SVM</span></nobr></DIV>
<DIV style="position:absolute;top:215;left:122"><nobr><span class="ft7">b</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:128"><nobr><span class="ft4">-R1</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:197"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:262"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:332"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:387"><nobr><span class="ft4">&lt; / &lt;</span></nobr></DIV>
<DIV style="position:absolute;top:207;left:451"><nobr><span class="ft4"> / </span></nobr></DIV>
<DIV style="position:absolute;top:210;left:604"><nobr><span class="ft4">/ &lt;</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:662"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:722"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:790"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:227;left:91"><nobr><span class="ft4">Perceptron</span></nobr></DIV>
<DIV style="position:absolute;top:227;left:197"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:227;left:262"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:227;left:317"><nobr><span class="ft4">&gt; / &lt;</span></nobr></DIV>
<DIV style="position:absolute;top:227;left:404"><nobr><span class="ft4">/ &gt;</span></nobr></DIV>
<DIV style="position:absolute;top:227;left:468"><nobr><span class="ft4">/ &gt;</span></nobr></DIV>
<DIV style="position:absolute;top:227;left:537"><nobr><span class="ft4">/ &gt;</span></nobr></DIV>
<DIV style="position:absolute;top:223;left:647"><nobr><span class="ft4"> / </span></nobr></DIV>
<DIV style="position:absolute;top:223;left:707"><nobr><span class="ft4"> / </span></nobr></DIV>
<DIV style="position:absolute;top:223;left:775"><nobr><span class="ft4"> / </span></nobr></DIV>
<DIV style="position:absolute;top:243;left:91"><nobr><span class="ft4">GP-1</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:197"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:262"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:317"><nobr><span class="ft4">&gt; / &lt;</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:404"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:239;left:415"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:243;left:468"><nobr><span class="ft4">/ &gt;</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:535"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:239;left:587"><nobr><span class="ft4"> / </span></nobr></DIV>
<DIV style="position:absolute;top:239;left:707"><nobr><span class="ft4"> / </span></nobr></DIV>
<DIV style="position:absolute;top:239;left:775"><nobr><span class="ft4"> / </span></nobr></DIV>
<DIV style="position:absolute;top:259;left:91"><nobr><span class="ft4">GP-2</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:197"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:264"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:255;left:275"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:255;left:317"><nobr><span class="ft4"> / </span></nobr></DIV>
<DIV style="position:absolute;top:259;left:404"><nobr><span class="ft4">/ &gt;</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:466"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:535"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:255;left:587"><nobr><span class="ft4"> / </span></nobr></DIV>
<DIV style="position:absolute;top:255;left:647"><nobr><span class="ft4"> / </span></nobr></DIV>
<DIV style="position:absolute;top:255;left:775"><nobr><span class="ft4"> / </span></nobr></DIV>
<DIV style="position:absolute;top:274;left:91"><nobr><span class="ft4">GP-R1</span></nobr></DIV>
<DIV style="position:absolute;top:274;left:197"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:274;left:264"><nobr><span class="ft4">/ &lt;</span></nobr></DIV>
<DIV style="position:absolute;top:274;left:317"><nobr><span class="ft4">&gt; / </span></nobr></DIV>
<DIV style="position:absolute;top:274;left:404"><nobr><span class="ft4">/ &gt;</span></nobr></DIV>
<DIV style="position:absolute;top:274;left:466"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:274;left:535"><nobr><span class="ft4">/</span></nobr></DIV>
<DIV style="position:absolute;top:271;left:587"><nobr><span class="ft4"> / </span></nobr></DIV>
<DIV style="position:absolute;top:271;left:647"><nobr><span class="ft4"> / </span></nobr></DIV>
<DIV style="position:absolute;top:271;left:707"><nobr><span class="ft4"> / </span></nobr></DIV>
<DIV style="position:absolute;top:291;left:91"><nobr><span class="ft4">"</span></nobr></DIV>
<DIV style="position:absolute;top:291;left:112"><nobr><span class="ft4">" or "</span></nobr></DIV>
<DIV style="position:absolute;top:291;left:161"><nobr><span class="ft4">" means P-value</span></nobr></DIV>
<DIV style="position:absolute;top:287;left:265"><nobr><span class="ft4"> 0.01;</span></nobr></DIV>
<DIV style="position:absolute;top:291;left:355"><nobr><span class="ft4">"&gt;" or "&lt;" means 0.01 &lt; P-value  0.05;</span></nobr></DIV>
<DIV style="position:absolute;top:291;left:658"><nobr><span class="ft4">"</span></nobr></DIV>
<DIV style="position:absolute;top:287;left:665"><nobr><span class="ft4">" means P-value &gt; 0.05.</span></nobr></DIV>
<DIV style="position:absolute;top:337;left:94"><nobr><span class="ft4">The last observation suggests that one can use Bayesian</span></nobr></DIV>
<DIV style="position:absolute;top:353;left:81"><nobr><span class="ft4">classifiers for common categories, and SVM for rare ones.</span></nobr></DIV>
<DIV style="position:absolute;top:380;left:81"><nobr><span class="ft3"><b>4.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:380;left:121"><nobr><span class="ft3"><b>Filtering on OHSUMED</b></span></nobr></DIV>
<DIV style="position:absolute;top:403;left:94"><nobr><span class="ft4">In this section, only the Bayesian online perceptron will</span></nobr></DIV>
<DIV style="position:absolute;top:418;left:81"><nobr><span class="ft11">be considered. In order to avoid numerical integration of<br>the information gain measure, instead of the probit model<br>of section 3.1, here we use a simpler likelihood model in<br>which the outputs are flipped with fixed probability :</span></nobr></DIV>
<DIV style="position:absolute;top:493;left:156"><nobr><span class="ft4">p(y|x, a) =  + (1 - 2) (ya · x) ,</span></nobr></DIV>
<DIV style="position:absolute;top:520;left:81"><nobr><span class="ft4">where</span></nobr></DIV>
<DIV style="position:absolute;top:554;left:189"><nobr><span class="ft4">(x) =</span></nobr></DIV>
<DIV style="position:absolute;top:540;left:237"><nobr><span class="ft13">´</span></nobr></DIV>
<DIV style="position:absolute;top:545;left:248"><nobr><span class="ft4">1</span></nobr></DIV>
<DIV style="position:absolute;top:545;left:269"><nobr><span class="ft4">x &gt; 0</span></nobr></DIV>
<DIV style="position:absolute;top:563;left:248"><nobr><span class="ft4">0</span></nobr></DIV>
<DIV style="position:absolute;top:563;left:269"><nobr><span class="ft4">otherwise.</span></nobr></DIV>
<DIV style="position:absolute;top:590;left:81"><nobr><span class="ft4">The update equations will also change accordingly, e.g.</span></nobr></DIV>
<DIV style="position:absolute;top:626;left:126"><nobr><span class="ft4">p(y</span></nobr></DIV>
<DIV style="position:absolute;top:630;left:145"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:628;left:149"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:622;left:164"><nobr><span class="ft4">|h)</span></nobr></DIV>
<DIV style="position:absolute;top:633;left:186"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:626;left:205"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:626;left:229"><nobr><span class="ft4"> + (1 - 2)</span></nobr></DIV>
<DIV style="position:absolute;top:616;left:328"><nobr><span class="ft4">y</span></nobr></DIV>
<DIV style="position:absolute;top:621;left:334"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:618;left:339"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:616;left:361"><nobr><span class="ft4">h</span></nobr></DIV>
<DIV style="position:absolute;top:623;left:374"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:635;left:340"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:639;left:348"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:637;left:352"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:626;left:393"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:165"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:651;left:173"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:662;left:172"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:660;left:177"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:205"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:229"><nobr><span class="ft4">x</span></nobr></DIV>
<DIV style="position:absolute;top:654;left:237"><nobr><span class="ft19">T<br>t</span></nobr></DIV>
<DIV style="position:absolute;top:660;left:242"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:256"><nobr><span class="ft4">C</span></nobr></DIV>
<DIV style="position:absolute;top:661;left:268"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:273"><nobr><span class="ft4">x</span></nobr></DIV>
<DIV style="position:absolute;top:661;left:281"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:659;left:285"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:314"><nobr><span class="ft4">and</span></nobr></DIV>
<DIV style="position:absolute;top:679;left:173"><nobr><span class="ft4">h</span></nobr></DIV>
<DIV style="position:absolute;top:686;left:186"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:679;left:205"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:679;left:234"><nobr><span class="ft4">a</span></nobr></DIV>
<DIV style="position:absolute;top:673;left:248"><nobr><span class="ft18">T<br>t</span></nobr></DIV>
<DIV style="position:absolute;top:679;left:258"><nobr><span class="ft4">x</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:267"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:681;left:271"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:679;left:286"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:706;left:94"><nobr><span class="ft4">Using this likelihood measure, we can express the infor-</span></nobr></DIV>
<DIV style="position:absolute;top:722;left:81"><nobr><span class="ft4">mation gained from datum (y</span></nobr></DIV>
<DIV style="position:absolute;top:727;left:260"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:724;left:264"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:722;left:279"><nobr><span class="ft4">, x</span></nobr></DIV>
<DIV style="position:absolute;top:727;left:293"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:724;left:298"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:722;left:312"><nobr><span class="ft4">) as</span></nobr></DIV>
<DIV style="position:absolute;top:754;left:96"><nobr><span class="ft4">IG(y</span></nobr></DIV>
<DIV style="position:absolute;top:758;left:126"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:756;left:130"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:754;left:145"><nobr><span class="ft4">, x</span></nobr></DIV>
<DIV style="position:absolute;top:758;left:159"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:756;left:164"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:750;left:178"><nobr><span class="ft4">|D</span></nobr></DIV>
<DIV style="position:absolute;top:758;left:192"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:754;left:198"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:750;left:207"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:790;left:83"><nobr><span class="ft4">log</span></nobr></DIV>
<DIV style="position:absolute;top:794;left:101"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:790;left:109"><nobr><span class="ft4">+</span></nobr></DIV>
<DIV style="position:absolute;top:779;left:153"><nobr><span class="ft4">y</span></nobr></DIV>
<DIV style="position:absolute;top:783;left:160"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:781;left:164"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:779;left:184"><nobr><span class="ft4">h</span></nobr></DIV>
<DIV style="position:absolute;top:786;left:197"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:784;left:202"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:799;left:171"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:803;left:179"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:801;left:184"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:790;left:231"><nobr><span class="ft4">log</span></nobr></DIV>
<DIV style="position:absolute;top:794;left:249"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:781;left:270"><nobr><span class="ft4">1</span></nobr></DIV>
<DIV style="position:absolute;top:777;left:280"><nobr><span class="ft4">- </span></nobr></DIV>
<DIV style="position:absolute;top:799;left:282"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:786;left:314"><nobr><span class="ft4">-log</span></nobr></DIV>
<DIV style="position:absolute;top:794;left:342"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:790;left:356"><nobr><span class="ft4">p(y</span></nobr></DIV>
<DIV style="position:absolute;top:794;left:375"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:792;left:380"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:786;left:394"><nobr><span class="ft4">|h)</span></nobr></DIV>
<DIV style="position:absolute;top:797;left:417"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:790;left:424"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:829;left:81"><nobr><span class="ft4">where</span></nobr></DIV>
<DIV style="position:absolute;top:856;left:173"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:850;left:181"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:181"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:859;left:185"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:856;left:213"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:856;left:237"><nobr><span class="ft4">x</span></nobr></DIV>
<DIV style="position:absolute;top:853;left:246"><nobr><span class="ft19">T<br>t</span></nobr></DIV>
<DIV style="position:absolute;top:859;left:250"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:856;left:264"><nobr><span class="ft4">C</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:276"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:858;left:280"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:856;left:295"><nobr><span class="ft4">x</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:303"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:858;left:308"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:856;left:336"><nobr><span class="ft4">and</span></nobr></DIV>
<DIV style="position:absolute;top:880;left:167"><nobr><span class="ft4">h</span></nobr></DIV>
<DIV style="position:absolute;top:887;left:181"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:885;left:185"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:880;left:213"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:880;left:242"><nobr><span class="ft4">a</span></nobr></DIV>
<DIV style="position:absolute;top:874;left:256"><nobr><span class="ft18">T<br>t</span></nobr></DIV>
<DIV style="position:absolute;top:885;left:260"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:880;left:277"><nobr><span class="ft4">x</span></nobr></DIV>
<DIV style="position:absolute;top:884;left:285"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:882;left:290"><nobr><span class="ft7">+1</span></nobr></DIV>
<DIV style="position:absolute;top:880;left:304"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:907;left:94"><nobr><span class="ft4">We use  = 0.1 in this evaluation. The following sections</span></nobr></DIV>
<DIV style="position:absolute;top:923;left:81"><nobr><span class="ft11">will describe the algorithm in detail. To simplify presen-<br>tation, we will divide the batch-adaptive filtering taskinto<br>batch and adaptive phases.</span></nobr></DIV>
<DIV style="position:absolute;top:982;left:81"><nobr><span class="ft17"><i>4.2.1</i></span></nobr></DIV>
<DIV style="position:absolute;top:982;left:130"><nobr><span class="ft17"><i>Feature Selection and Adaptation</i></span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:94"><nobr><span class="ft4">During the batch phase, words for which</span></nobr></DIV>
<DIV style="position:absolute;top:1001;left:347"><nobr><span class="ft4">-2 ln  &gt; 12.13</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:81"><nobr><span class="ft4">are selected as features.</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:94"><nobr><span class="ft4">During the adaptive phase, when we obtain a feedback, we</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:81"><nobr><span class="ft4">update the features by adding any new words with</span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:383"><nobr><span class="ft4">-2 ln  &gt;</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:81"><nobr><span class="ft4">12.13. When a feature is added, the distribution of the per-</span></nobr></DIV>
<DIV style="position:absolute;top:337;left:475"><nobr><span class="ft4">ceptron a is extended by one dimension:</span></nobr></DIV>
<DIV style="position:absolute;top:396;left:520"><nobr><span class="ft4">a</span></nobr></DIV>
<DIV style="position:absolute;top:393;left:537"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:366;left:554"><nobr><span class="ft13">¼</span></nobr></DIV>
<DIV style="position:absolute;top:386;left:575"><nobr><span class="ft4">a</span></nobr></DIV>
<DIV style="position:absolute;top:426;left:575"><nobr><span class="ft4">0</span></nobr></DIV>
<DIV style="position:absolute;top:366;left:591"><nobr><span class="ft13">½</span></nobr></DIV>
<DIV style="position:absolute;top:396;left:661"><nobr><span class="ft4">C</span></nobr></DIV>
<DIV style="position:absolute;top:393;left:676"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:374;left:694"><nobr><span class="ft13">¼</span></nobr></DIV>
<DIV style="position:absolute;top:389;left:726"><nobr><span class="ft4">C</span></nobr></DIV>
<DIV style="position:absolute;top:389;left:764"><nobr><span class="ft4">0</span></nobr></DIV>
<DIV style="position:absolute;top:420;left:728"><nobr><span class="ft4">0</span></nobr></DIV>
<DIV style="position:absolute;top:420;left:764"><nobr><span class="ft4">1</span></nobr></DIV>
<DIV style="position:absolute;top:374;left:776"><nobr><span class="ft13">½</span></nobr></DIV>
<DIV style="position:absolute;top:396;left:791"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:458;left:475"><nobr><span class="ft17"><i>4.2.2</i></span></nobr></DIV>
<DIV style="position:absolute;top:458;left:524"><nobr><span class="ft17"><i>Training the classifier</i></span></nobr></DIV>
<DIV style="position:absolute;top:479;left:489"><nobr><span class="ft4">During the batch phase, the classifier is iterated through</span></nobr></DIV>
<DIV style="position:absolute;top:495;left:475"><nobr><span class="ft11">the training documents 3 times. In addition, the relevant<br>documents are collected for use during the adaptive phase.</span></nobr></DIV>
<DIV style="position:absolute;top:526;left:489"><nobr><span class="ft4">During the adaptive phase, retrieved relevant documents</span></nobr></DIV>
<DIV style="position:absolute;top:542;left:475"><nobr><span class="ft11">are added to this collection. When a document is retrieved,<br>the classifier is trained on that document and its given rel-<br>evance judgement.</span></nobr></DIV>
<DIV style="position:absolute;top:589;left:489"><nobr><span class="ft4">The classifier will be trained on irrelevant documents most</span></nobr></DIV>
<DIV style="position:absolute;top:605;left:475"><nobr><span class="ft11">of the time. To prevent it from "forgetting" relevant docu-<br>ments due to its limited capacity, whenever we train on an<br>irrelevant document, we would also train on a past relevant<br>document. This past relevant document is chosen succes-<br>sively from the collection of relevant documents.</span></nobr></DIV>
<DIV style="position:absolute;top:683;left:489"><nobr><span class="ft4">This is needed also because new features might have been</span></nobr></DIV>
<DIV style="position:absolute;top:699;left:475"><nobr><span class="ft11">added since a relevant document was last trained on. Hence<br>the classifier would be able to gather new information from<br>the same document again due to the additional features.</span></nobr></DIV>
<DIV style="position:absolute;top:746;left:489"><nobr><span class="ft4">Note that the past relevant document does not need to be</span></nobr></DIV>
<DIV style="position:absolute;top:762;left:475"><nobr><span class="ft11">chosen in successive order. Instead, it can be chosen using<br>a probability distribution over the collection. This will be<br>desirable when handling topic-drifts.</span></nobr></DIV>
<DIV style="position:absolute;top:809;left:489"><nobr><span class="ft4">We will evaluate the effectiveness of this strategy of re-</span></nobr></DIV>
<DIV style="position:absolute;top:824;left:475"><nobr><span class="ft11">training on past retrieved relevant documents, and denote<br>its use by +rel. Though its use means that the algorithm<br>is no longer online, asymptotic efficiency is unaffected, since<br>only one past document is used for training at any instance.</span></nobr></DIV>
<DIV style="position:absolute;top:900;left:475"><nobr><span class="ft17"><i>4.2.3</i></span></nobr></DIV>
<DIV style="position:absolute;top:900;left:524"><nobr><span class="ft17"><i>Information Gain</i></span></nobr></DIV>
<DIV style="position:absolute;top:922;left:489"><nobr><span class="ft4">During testing, there are two reasons why we retrieve</span></nobr></DIV>
<DIV style="position:absolute;top:938;left:475"><nobr><span class="ft4">a document.</span></nobr></DIV>
<DIV style="position:absolute;top:938;left:565"><nobr><span class="ft4">The first is that it is relevant, i.e.</span></nobr></DIV>
<DIV style="position:absolute;top:938;left:796"><nobr><span class="ft4">p(y =</span></nobr></DIV>
<DIV style="position:absolute;top:953;left:475"><nobr><span class="ft4">1</span></nobr></DIV>
<DIV style="position:absolute;top:950;left:482"><nobr><span class="ft4">|x, D</span></nobr></DIV>
<DIV style="position:absolute;top:958;left:511"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:953;left:516"><nobr><span class="ft4">) &gt; 0.5, where x represents the document. The sec-</span></nobr></DIV>
<DIV style="position:absolute;top:969;left:475"><nobr><span class="ft11">ond is that, although the document is deemed irrelevant<br>by the classifier, the classifier would gain useful information<br>from the document. Using the measure IG(y, x|D</span></nobr></DIV>
<DIV style="position:absolute;top:1005;left:774"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:1000;left:779"><nobr><span class="ft4">), we cal-</span></nobr></DIV>
<DIV style="position:absolute;top:1016;left:475"><nobr><span class="ft4">culate the expected information gain</span></nobr></DIV>
<DIV style="position:absolute;top:1047;left:494"><nobr><span class="ft4">IG(x|D</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:540"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:1047;left:545"><nobr><span class="ft4">) =</span></nobr></DIV>
<DIV style="position:absolute;top:1066;left:574"><nobr><span class="ft7"></span></nobr></DIV>
<DIV style="position:absolute;top:1064;left:581"><nobr><span class="ft7">{-1,1}</span></nobr></DIV>
<DIV style="position:absolute;top:1047;left:625"><nobr><span class="ft4">p(y = |x, D</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:700"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:1047;left:705"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:1043;left:714"><nobr><span class="ft4">· IG(y = , x|D</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:806"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:1047;left:811"><nobr><span class="ft4">).</span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:449"><nobr><span class="ft9">101</span></nobr></DIV>
</DIV>
<!-- Page 6 -->
<a name="6"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft23{font-size:4px;font-family:Times;color:#000000;}
	.ft24{font-size:10px;font-family:Times;color:#000000;}
	.ft25{font-size:8px;font-family:Times;color:#000000;}
	.ft26{font-size:10px;font-family:Times;color:#000000;}
	.ft27{font-size:8px;font-family:Times;color:#000000;}
	.ft28{font-size:8px;font-family:Times;color:#000000;}
	.ft29{font-size:8px;line-height:11px;font-family:Times;color:#000000;}
	.ft30{font-size:8px;line-height:11px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="42006.png" alt="background image">
<DIV style="position:absolute;top:311;left:123"><nobr><span class="ft23">0</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:149"><nobr><span class="ft23">10</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:177"><nobr><span class="ft23">20</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:205"><nobr><span class="ft23">30</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:233"><nobr><span class="ft23">40</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:261"><nobr><span class="ft23">50</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:289"><nobr><span class="ft23">60</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:317"><nobr><span class="ft23">70</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:345"><nobr><span class="ft23">80</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:373"><nobr><span class="ft23">90</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:400"><nobr><span class="ft23">100</span></nobr></DIV>
<DIV style="position:absolute;top:306;left:119"><nobr><span class="ft23">0</span></nobr></DIV>
<DIV style="position:absolute;top:262;left:114"><nobr><span class="ft23">0.2</span></nobr></DIV>
<DIV style="position:absolute;top:217;left:114"><nobr><span class="ft23">0.4</span></nobr></DIV>
<DIV style="position:absolute;top:173;left:114"><nobr><span class="ft23">0.6</span></nobr></DIV>
<DIV style="position:absolute;top:129;left:114"><nobr><span class="ft23">0.8</span></nobr></DIV>
<DIV style="position:absolute;top:85;left:119"><nobr><span class="ft23">1</span></nobr></DIV>
<DIV style="position:absolute;top:318;left:255"><nobr><span class="ft24"><i>N</i></span></nobr></DIV>
<DIV style="position:absolute;top:326;left:263"><nobr><span class="ft25"><i>ret</i></span></nobr></DIV>
<DIV style="position:absolute;top:186;left:108"><nobr><span class="ft26"></span></nobr></DIV>
<DIV style="position:absolute;top:190;left:315"><nobr><span class="ft29">Target number of <br>documents = 50 </span></nobr></DIV>
<DIV style="position:absolute;top:357;left:133"><nobr><span class="ft4">Figure 1:  versus N</span></nobr></DIV>
<DIV style="position:absolute;top:359;left:274"><nobr><span class="ft7">ret</span></nobr></DIV>
<DIV style="position:absolute;top:357;left:296"><nobr><span class="ft4">tuned for T9P</span></nobr></DIV>
<DIV style="position:absolute;top:402;left:94"><nobr><span class="ft4">A document is then deemed useful if its expected infor-</span></nobr></DIV>
<DIV style="position:absolute;top:417;left:81"><nobr><span class="ft11">mation gain is at least . Optimizing for the T9P measure<br>(i.e. targeting 50 documents), we choose  to be</span></nobr></DIV>
<DIV style="position:absolute;top:468;left:113"><nobr><span class="ft4"> = 0.999 1 + exp - N</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:263"><nobr><span class="ft7">ret</span></nobr></DIV>
<DIV style="position:absolute;top:456;left:280"><nobr><span class="ft4">- 50.0</span></nobr></DIV>
<DIV style="position:absolute;top:478;left:278"><nobr><span class="ft4">10</span></nobr></DIV>
<DIV style="position:absolute;top:454;left:341"><nobr><span class="ft7">-1</span></nobr></DIV>
<DIV style="position:absolute;top:468;left:359"><nobr><span class="ft4">+ 0.001,</span></nobr></DIV>
<DIV style="position:absolute;top:501;left:81"><nobr><span class="ft4">where N</span></nobr></DIV>
<DIV style="position:absolute;top:503;left:131"><nobr><span class="ft7">ret</span></nobr></DIV>
<DIV style="position:absolute;top:501;left:148"><nobr><span class="ft4">is the total number of documents that the system</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:81"><nobr><span class="ft4">has retrieved. Figure 1 plots  against N</span></nobr></DIV>
<DIV style="position:absolute;top:519;left:329"><nobr><span class="ft7">ret</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:343"><nobr><span class="ft4">. Note that this</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:81"><nobr><span class="ft11">is a kind of active learning, where the willingness to tradeoff<br>precision for learning decreases with N</span></nobr></DIV>
<DIV style="position:absolute;top:550;left:320"><nobr><span class="ft7">ret</span></nobr></DIV>
<DIV style="position:absolute;top:548;left:334"><nobr><span class="ft4">. The use of this</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:81"><nobr><span class="ft4">information gain criteria will be denoted by +ig.</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:94"><nobr><span class="ft4">We will test the effectiveness of the information gain strat-</span></nobr></DIV>
<DIV style="position:absolute;top:595;left:81"><nobr><span class="ft22">egy, against an alternative one. The alternative, denoted by<br>+rnd, will randomly select documents to retrieve based on<br>the probability</span></nobr></DIV>
<DIV style="position:absolute;top:663;left:169"><nobr><span class="ft4">U =</span></nobr></DIV>
<DIV style="position:absolute;top:650;left:198"><nobr><span class="ft13">´</span></nobr></DIV>
<DIV style="position:absolute;top:654;left:209"><nobr><span class="ft4">0</span></nobr></DIV>
<DIV style="position:absolute;top:654;left:268"><nobr><span class="ft4">if N</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:292"><nobr><span class="ft7">ret</span></nobr></DIV>
<DIV style="position:absolute;top:654;left:310"><nobr><span class="ft4">&gt;= 50</span></nobr></DIV>
<DIV style="position:absolute;top:668;left:211"><nobr><span class="ft7">50-N</span></nobr></DIV>
<DIV style="position:absolute;top:671;left:239"><nobr><span class="ft14">ret</span></nobr></DIV>
<DIV style="position:absolute;top:679;left:215"><nobr><span class="ft7">293856</span></nobr></DIV>
<DIV style="position:absolute;top:673;left:268"><nobr><span class="ft4">otherwise,</span></nobr></DIV>
<DIV style="position:absolute;top:700;left:81"><nobr><span class="ft4">where 293,856 is the number of test documents.</span></nobr></DIV>
<DIV style="position:absolute;top:726;left:81"><nobr><span class="ft17"><i>4.2.4</i></span></nobr></DIV>
<DIV style="position:absolute;top:726;left:130"><nobr><span class="ft17"><i>Results and Discussion</i></span></nobr></DIV>
<DIV style="position:absolute;top:747;left:94"><nobr><span class="ft4">Table 4 lists the results of seven systems. The first two are</span></nobr></DIV>
<DIV style="position:absolute;top:763;left:81"><nobr><span class="ft11">of Microsoft Research Cambridge and Fudan University re-<br>spectively. These are the only runs in TREC-9 for the task.<br>The third is of the system as described in full, i.e. Bayesian<br>online perceptron, with retraining on past retrieved relevant<br>documents, and with the use of information gain. The rest<br>are of the Bayesian online perceptron with different combi-<br>nations of strategies.</span></nobr></DIV>
<DIV style="position:absolute;top:873;left:94"><nobr><span class="ft4">Besides the T9P measure, for the sake of completeness, Ta-</span></nobr></DIV>
<DIV style="position:absolute;top:888;left:81"><nobr><span class="ft11">ble 4 also lists the other measures used in TREC-9. Taken<br>together, the measures show that Bayesian online percep-<br>tron, together with the consideration for information gain,<br>is a very competitive method.</span></nobr></DIV>
<DIV style="position:absolute;top:951;left:94"><nobr><span class="ft4">For the systems with +rel, the collection of past known</span></nobr></DIV>
<DIV style="position:absolute;top:967;left:81"><nobr><span class="ft11">relevant documents is kept. Although Microsoft uses this<br>same collection for its query reformulation, another collec-<br>tion of all previously seen documents is used for threshold<br>adaptation. Fudan maintains a collection of past retrieved<br>documents and uses this collection for query adaptation.</span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:81"><nobr><span class="ft7">5</span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:88"><nobr><span class="ft4">[18] reports results from run ok9bfr2po, while we report</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:81"><nobr><span class="ft4">results from the slightly better run ok9bf2po.</span></nobr></DIV>
<DIV style="position:absolute;top:315;left:523"><nobr><span class="ft23">0</span></nobr></DIV>
<DIV style="position:absolute;top:315;left:552"><nobr><span class="ft23">2</span></nobr></DIV>
<DIV style="position:absolute;top:315;left:580"><nobr><span class="ft23">4</span></nobr></DIV>
<DIV style="position:absolute;top:315;left:608"><nobr><span class="ft23">6</span></nobr></DIV>
<DIV style="position:absolute;top:315;left:637"><nobr><span class="ft23">8</span></nobr></DIV>
<DIV style="position:absolute;top:315;left:664"><nobr><span class="ft23">10</span></nobr></DIV>
<DIV style="position:absolute;top:315;left:692"><nobr><span class="ft23">12</span></nobr></DIV>
<DIV style="position:absolute;top:315;left:721"><nobr><span class="ft23">14</span></nobr></DIV>
<DIV style="position:absolute;top:315;left:749"><nobr><span class="ft23">16</span></nobr></DIV>
<DIV style="position:absolute;top:315;left:777"><nobr><span class="ft23">18</span></nobr></DIV>
<DIV style="position:absolute;top:315;left:806"><nobr><span class="ft23">20</span></nobr></DIV>
<DIV style="position:absolute;top:309;left:516"><nobr><span class="ft23">40</span></nobr></DIV>
<DIV style="position:absolute;top:284;left:516"><nobr><span class="ft23">50</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:516"><nobr><span class="ft23">60</span></nobr></DIV>
<DIV style="position:absolute;top:234;left:516"><nobr><span class="ft23">70</span></nobr></DIV>
<DIV style="position:absolute;top:209;left:516"><nobr><span class="ft23">80</span></nobr></DIV>
<DIV style="position:absolute;top:185;left:516"><nobr><span class="ft23">90</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:512"><nobr><span class="ft23">100</span></nobr></DIV>
<DIV style="position:absolute;top:135;left:512"><nobr><span class="ft23">110</span></nobr></DIV>
<DIV style="position:absolute;top:110;left:512"><nobr><span class="ft23">120</span></nobr></DIV>
<DIV style="position:absolute;top:85;left:512"><nobr><span class="ft23">130</span></nobr></DIV>
<DIV style="position:absolute;top:326;left:567"><nobr><span class="ft27">Average number of relevant documents retrieved</span></nobr></DIV>
<DIV style="position:absolute;top:249;left:503"><nobr><span class="ft27">Average number of features</span></nobr></DIV>
<DIV style="position:absolute;top:263;left:740"><nobr><span class="ft30">Pptron+rel+ig<br>Pptron+ig<br>Pptron+rnd<br>Pptron</span></nobr></DIV>
<DIV style="position:absolute;top:357;left:475"><nobr><span class="ft11">Figure 2: Variation of the number of features as<br>relevant documents are retrieved.</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:736"><nobr><span class="ft4">The plots for</span></nobr></DIV>
<DIV style="position:absolute;top:390;left:475"><nobr><span class="ft22">Pptron+rel+ig and Pptron+ig are very close. So are<br>the plots for Pptron+rnd and Pptron.</span></nobr></DIV>
<DIV style="position:absolute;top:470;left:489"><nobr><span class="ft4">In a typical operational system, retrieved relevant docu-</span></nobr></DIV>
<DIV style="position:absolute;top:486;left:475"><nobr><span class="ft11">ments are usually retained, while irrelevant documents are<br>usually discarded. Therefore +rel is a practical strategy to<br>adopt.</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:489"><nobr><span class="ft4">Figure 2 plots the average number of features during the</span></nobr></DIV>
<DIV style="position:absolute;top:549;left:475"><nobr><span class="ft4">adaptive phase.</span></nobr></DIV>
<DIV style="position:absolute;top:549;left:583"><nobr><span class="ft4">We can see that features are constantly</span></nobr></DIV>
<DIV style="position:absolute;top:565;left:475"><nobr><span class="ft11">added as relevant documents are seen. When the classifier<br>is retrained on past documents, the new features enable the<br>classifier to gain new information from these documents. If<br>we compare the results for Pptron+rel and Pptron in Ta-<br>ble 4, we find that not training on past documents causes<br>the number of relevant documents retrieved to drop by 5%.<br>Similarly, for Pptron+rel+ig and Pptron+ig, the drop is<br>8%.</span></nobr></DIV>
<DIV style="position:absolute;top:690;left:489"><nobr><span class="ft4">Table 5 breaks down the retrieved documents into those</span></nobr></DIV>
<DIV style="position:absolute;top:706;left:475"><nobr><span class="ft11">that the classifier deems relevant and those that the clas-<br>sifier is actually querying for information, for Pptron+ig<br>and Pptron+rnd. The table shows that none of the doc-<br>uments randomly queried are relevant documents. This is<br>not surprising, since only an average of 0.017% of the test<br>documents are relevant. In contrast, the information gain<br>strategy is able to retrieve 313 relevant documents, which is<br>26.1% of the documents queried. This is a significant result.</span></nobr></DIV>
<DIV style="position:absolute;top:831;left:489"><nobr><span class="ft4">Consider Pptron+ig. Table 4 shows that for Pptron, when</span></nobr></DIV>
<DIV style="position:absolute;top:847;left:475"><nobr><span class="ft11">the information gain strategy is removed, only 731 relevant<br>documents will be retrieved. Hence, although most of the<br>documents queried are irrelevant, information gained from<br>these queries helps recall by the classifier (i.e. 815 docu-<br>ments versus 731 documents), which is important for reach-<br>ing the target of 50 documents.</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:489"><nobr><span class="ft4">MacKay[13] has noted the phenomenon of querying for</span></nobr></DIV>
<DIV style="position:absolute;top:957;left:475"><nobr><span class="ft11">irrelevant documents which are at the edges of the input<br>space, and suggested maximizing information in a defined<br>region of interest instead.</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:647"><nobr><span class="ft4">Finding this region for batch-</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:475"><nobr><span class="ft4">adaptive filtering remains a subject for further research.</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:489"><nobr><span class="ft4">Comparing the four plots in Figure 2, we find that, on</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:475"><nobr><span class="ft11">average, the information gain strategy causes about 3% more<br>features to be discovered for the same number of relevant<br>documents retrieved. A consequence of this is better recall.</span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:449"><nobr><span class="ft9">102</span></nobr></DIV>
</DIV>
<!-- Page 7 -->
<a name="7"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="42007.png" alt="background image">
<DIV style="position:absolute;top:96;left:207"><nobr><span class="ft4">Table 4: Results for Batch-adaptive filtering optimized for T9P measure.</span></nobr></DIV>
<DIV style="position:absolute;top:111;left:270"><nobr><span class="ft4">Microsoft</span></nobr></DIV>
<DIV style="position:absolute;top:106;left:326"><nobr><span class="ft7">5</span></nobr></DIV>
<DIV style="position:absolute;top:111;left:349"><nobr><span class="ft4">Fudan</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:403"><nobr><span class="ft4">Pptron+rel+ig</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:511"><nobr><span class="ft4">Pptron+ig</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:591"><nobr><span class="ft4">Pptron+rnd</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:677"><nobr><span class="ft4">Pptron+rel</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:764"><nobr><span class="ft4">Pptron</span></nobr></DIV>
<DIV style="position:absolute;top:128;left:108"><nobr><span class="ft4">Total retrieved</span></nobr></DIV>
<DIV style="position:absolute;top:128;left:305"><nobr><span class="ft4">3562</span></nobr></DIV>
<DIV style="position:absolute;top:128;left:359"><nobr><span class="ft4">3251</span></nobr></DIV>
<DIV style="position:absolute;top:128;left:467"><nobr><span class="ft4">2716</span></nobr></DIV>
<DIV style="position:absolute;top:128;left:547"><nobr><span class="ft4">2391</span></nobr></DIV>
<DIV style="position:absolute;top:128;left:633"><nobr><span class="ft4">2533</span></nobr></DIV>
<DIV style="position:absolute;top:128;left:720"><nobr><span class="ft4">1157</span></nobr></DIV>
<DIV style="position:absolute;top:128;left:779"><nobr><span class="ft4">1057</span></nobr></DIV>
<DIV style="position:absolute;top:143;left:108"><nobr><span class="ft4">Relevant retrieved</span></nobr></DIV>
<DIV style="position:absolute;top:143;left:305"><nobr><span class="ft4">1095</span></nobr></DIV>
<DIV style="position:absolute;top:143;left:359"><nobr><span class="ft4">1061</span></nobr></DIV>
<DIV style="position:absolute;top:143;left:467"><nobr><span class="ft4">1227</span></nobr></DIV>
<DIV style="position:absolute;top:143;left:547"><nobr><span class="ft4">1128</span></nobr></DIV>
<DIV style="position:absolute;top:143;left:640"><nobr><span class="ft4">732</span></nobr></DIV>
<DIV style="position:absolute;top:143;left:727"><nobr><span class="ft4">772</span></nobr></DIV>
<DIV style="position:absolute;top:143;left:786"><nobr><span class="ft4">731</span></nobr></DIV>
<DIV style="position:absolute;top:159;left:108"><nobr><span class="ft4">Macro-average recall</span></nobr></DIV>
<DIV style="position:absolute;top:159;left:308"><nobr><span class="ft4">39.5</span></nobr></DIV>
<DIV style="position:absolute;top:159;left:362"><nobr><span class="ft4">37.9</span></nobr></DIV>
<DIV style="position:absolute;top:159;left:470"><nobr><span class="ft4">36.2</span></nobr></DIV>
<DIV style="position:absolute;top:159;left:550"><nobr><span class="ft4">33.3</span></nobr></DIV>
<DIV style="position:absolute;top:159;left:636"><nobr><span class="ft4">20.0</span></nobr></DIV>
<DIV style="position:absolute;top:159;left:723"><nobr><span class="ft4">20.8</span></nobr></DIV>
<DIV style="position:absolute;top:159;left:782"><nobr><span class="ft4">20.0</span></nobr></DIV>
<DIV style="position:absolute;top:175;left:108"><nobr><span class="ft4">Macro-average precision</span></nobr></DIV>
<DIV style="position:absolute;top:175;left:308"><nobr><span class="ft4">30.5</span></nobr></DIV>
<DIV style="position:absolute;top:175;left:362"><nobr><span class="ft4">32.2</span></nobr></DIV>
<DIV style="position:absolute;top:175;left:470"><nobr><span class="ft4">35.8</span></nobr></DIV>
<DIV style="position:absolute;top:175;left:550"><nobr><span class="ft4">35.8</span></nobr></DIV>
<DIV style="position:absolute;top:175;left:636"><nobr><span class="ft4">21.6</span></nobr></DIV>
<DIV style="position:absolute;top:175;left:723"><nobr><span class="ft4">61.9</span></nobr></DIV>
<DIV style="position:absolute;top:175;left:782"><nobr><span class="ft4">62.3</span></nobr></DIV>
<DIV style="position:absolute;top:190;left:108"><nobr><span class="ft4">Mean T9P</span></nobr></DIV>
<DIV style="position:absolute;top:190;left:305"><nobr><span class="ft4">30.5</span></nobr></DIV>
<DIV style="position:absolute;top:190;left:359"><nobr><span class="ft4">31.7</span></nobr></DIV>
<DIV style="position:absolute;top:190;left:466"><nobr><span class="ft4">31.3</span></nobr></DIV>
<DIV style="position:absolute;top:190;left:546"><nobr><span class="ft4">29.8</span></nobr></DIV>
<DIV style="position:absolute;top:190;left:633"><nobr><span class="ft4">19.2</span></nobr></DIV>
<DIV style="position:absolute;top:190;left:720"><nobr><span class="ft4">21.5</span></nobr></DIV>
<DIV style="position:absolute;top:190;left:778"><nobr><span class="ft4">20.8</span></nobr></DIV>
<DIV style="position:absolute;top:206;left:108"><nobr><span class="ft4">Mean Utility</span></nobr></DIV>
<DIV style="position:absolute;top:206;left:297"><nobr><span class="ft4">-4.397</span></nobr></DIV>
<DIV style="position:absolute;top:206;left:351"><nobr><span class="ft4">-1.079</span></nobr></DIV>
<DIV style="position:absolute;top:206;left:456"><nobr><span class="ft4">15.318</span></nobr></DIV>
<DIV style="position:absolute;top:206;left:536"><nobr><span class="ft4">15.762</span></nobr></DIV>
<DIV style="position:absolute;top:206;left:625"><nobr><span class="ft4">-5.349</span></nobr></DIV>
<DIV style="position:absolute;top:206;left:710"><nobr><span class="ft4">18.397</span></nobr></DIV>
<DIV style="position:absolute;top:206;left:768"><nobr><span class="ft4">17.730</span></nobr></DIV>
<DIV style="position:absolute;top:222;left:108"><nobr><span class="ft4">Mean T9U</span></nobr></DIV>
<DIV style="position:absolute;top:222;left:297"><nobr><span class="ft4">-4.397</span></nobr></DIV>
<DIV style="position:absolute;top:222;left:351"><nobr><span class="ft4">-1.079</span></nobr></DIV>
<DIV style="position:absolute;top:222;left:456"><nobr><span class="ft4">15.318</span></nobr></DIV>
<DIV style="position:absolute;top:222;left:536"><nobr><span class="ft4">15.762</span></nobr></DIV>
<DIV style="position:absolute;top:222;left:625"><nobr><span class="ft4">-5.349</span></nobr></DIV>
<DIV style="position:absolute;top:222;left:710"><nobr><span class="ft4">18.397</span></nobr></DIV>
<DIV style="position:absolute;top:222;left:768"><nobr><span class="ft4">17.730</span></nobr></DIV>
<DIV style="position:absolute;top:237;left:108"><nobr><span class="ft4">Mean scaled utility</span></nobr></DIV>
<DIV style="position:absolute;top:237;left:297"><nobr><span class="ft4">-0.596</span></nobr></DIV>
<DIV style="position:absolute;top:237;left:351"><nobr><span class="ft4">-0.461</span></nobr></DIV>
<DIV style="position:absolute;top:237;left:459"><nobr><span class="ft4">-0.025</span></nobr></DIV>
<DIV style="position:absolute;top:237;left:543"><nobr><span class="ft4">0.016</span></nobr></DIV>
<DIV style="position:absolute;top:237;left:625"><nobr><span class="ft4">-0.397</span></nobr></DIV>
<DIV style="position:absolute;top:237;left:716"><nobr><span class="ft4">0.141</span></nobr></DIV>
<DIV style="position:absolute;top:237;left:775"><nobr><span class="ft4">0.138</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:108"><nobr><span class="ft4">Zero returns</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:326"><nobr><span class="ft4">0</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:380"><nobr><span class="ft4">0</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:488"><nobr><span class="ft4">0</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:568"><nobr><span class="ft4">0</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:654"><nobr><span class="ft4">0</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:741"><nobr><span class="ft4">8</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:800"><nobr><span class="ft4">0</span></nobr></DIV>
<DIV style="position:absolute;top:299;left:81"><nobr><span class="ft11">Table 5: Breakdown of documents retrieved for Pptron+ig and Pptron+rnd. The numbers for the latter are in<br>brackets.</span></nobr></DIV>
<DIV style="position:absolute;top:327;left:519"><nobr><span class="ft4">Relevant</span></nobr></DIV>
<DIV style="position:absolute;top:327;left:599"><nobr><span class="ft4">Not Relevant</span></nobr></DIV>
<DIV style="position:absolute;top:327;left:723"><nobr><span class="ft4">Total</span></nobr></DIV>
<DIV style="position:absolute;top:343;left:203"><nobr><span class="ft4"># docs retrieved by perceptron classifier proper</span></nobr></DIV>
<DIV style="position:absolute;top:343;left:514"><nobr><span class="ft4">815</span></nobr></DIV>
<DIV style="position:absolute;top:343;left:551"><nobr><span class="ft4">(732)</span></nobr></DIV>
<DIV style="position:absolute;top:343;left:606"><nobr><span class="ft4">378</span></nobr></DIV>
<DIV style="position:absolute;top:343;left:650"><nobr><span class="ft4">(345)</span></nobr></DIV>
<DIV style="position:absolute;top:343;left:697"><nobr><span class="ft4">1193</span></nobr></DIV>
<DIV style="position:absolute;top:343;left:741"><nobr><span class="ft4">(1077)</span></nobr></DIV>
<DIV style="position:absolute;top:359;left:135"><nobr><span class="ft4"># docs retrieved by information gain (or random strategy)</span></nobr></DIV>
<DIV style="position:absolute;top:359;left:514"><nobr><span class="ft4">313</span></nobr></DIV>
<DIV style="position:absolute;top:359;left:565"><nobr><span class="ft4">(0)</span></nobr></DIV>
<DIV style="position:absolute;top:359;left:606"><nobr><span class="ft4">885</span></nobr></DIV>
<DIV style="position:absolute;top:359;left:643"><nobr><span class="ft4">(1456)</span></nobr></DIV>
<DIV style="position:absolute;top:359;left:697"><nobr><span class="ft4">1198</span></nobr></DIV>
<DIV style="position:absolute;top:359;left:741"><nobr><span class="ft4">(1456)</span></nobr></DIV>
<DIV style="position:absolute;top:375;left:460"><nobr><span class="ft4">Total</span></nobr></DIV>
<DIV style="position:absolute;top:375;left:508"><nobr><span class="ft4">1128</span></nobr></DIV>
<DIV style="position:absolute;top:375;left:551"><nobr><span class="ft4">(732)</span></nobr></DIV>
<DIV style="position:absolute;top:375;left:599"><nobr><span class="ft4">1263</span></nobr></DIV>
<DIV style="position:absolute;top:375;left:643"><nobr><span class="ft4">(1801)</span></nobr></DIV>
<DIV style="position:absolute;top:375;left:697"><nobr><span class="ft4">2391</span></nobr></DIV>
<DIV style="position:absolute;top:375;left:741"><nobr><span class="ft4">(2533)</span></nobr></DIV>
<DIV style="position:absolute;top:418;left:81"><nobr><span class="ft3"><b>5.</b></span></nobr></DIV>
<DIV style="position:absolute;top:418;left:112"><nobr><span class="ft3"><b>CONCLUSIONS AND FURTHER WORK</b></span></nobr></DIV>
<DIV style="position:absolute;top:441;left:94"><nobr><span class="ft4">We have implemented and tested Bayesian online percep-</span></nobr></DIV>
<DIV style="position:absolute;top:457;left:81"><nobr><span class="ft11">tron and Gaussian processes on the text classification prob-<br>lem, and have shown that their performance is compara-<br>ble to that of SVM, one of the best learning algorithms on<br>text classification in the published literature. We have also<br>demonstrated the effectiveness of online learning with infor-<br>mation gain on the TREC-9 batch-adaptive filtering task.</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:94"><nobr><span class="ft4">Our results on text classification suggest that one can use</span></nobr></DIV>
<DIV style="position:absolute;top:567;left:81"><nobr><span class="ft11">Bayesian classifiers for common categories, and maximum<br>margin classifiers for rare categories. The partitioning of the<br>categories into common and rare ones in an optimal way is<br>an interesting problem.</span></nobr></DIV>
<DIV style="position:absolute;top:629;left:94"><nobr><span class="ft4">SVM has been employed to use relevance feedbackby</span></nobr></DIV>
<DIV style="position:absolute;top:645;left:81"><nobr><span class="ft11">Drucker et al [4], where the retrieval is in groups of 10 doc-<br>uments. In essence, this is a form of adaptive routing. It<br>would be instructive to see how Bayesian classifiers perform<br>here, without storing too many previously seen documents.</span></nobr></DIV>
<DIV style="position:absolute;top:708;left:94"><nobr><span class="ft4">It would also be interesting to compare the merits of in-</span></nobr></DIV>
<DIV style="position:absolute;top:723;left:81"><nobr><span class="ft4">cremental SVM[21, 1] with the Bayesian online classifiers.</span></nobr></DIV>
<DIV style="position:absolute;top:754;left:81"><nobr><span class="ft3"><b>Acknowledgments</b></span></nobr></DIV>
<DIV style="position:absolute;top:779;left:81"><nobr><span class="ft4">We would like to thank Lehel Csat´</span></nobr></DIV>
<DIV style="position:absolute;top:779;left:301"><nobr><span class="ft4">o for providing details</span></nobr></DIV>
<DIV style="position:absolute;top:795;left:81"><nobr><span class="ft11">on the implementation of the Gaussian process, Wee Meng<br>Soon for assisting in the data preparation, Yiming Yang<br>for clarifying the representation used in [27], and Loo Nin<br>Teow for proof-reading the manuscript. We would also like<br>to thankthe reviewers for their many helpful comments in<br>improving the paper.</span></nobr></DIV>
<DIV style="position:absolute;top:904;left:81"><nobr><span class="ft3"><b>6.</b></span></nobr></DIV>
<DIV style="position:absolute;top:904;left:112"><nobr><span class="ft3"><b>REFERENCES</b></span></nobr></DIV>
<DIV style="position:absolute;top:922;left:88"><nobr><span class="ft4">[1] G. Cauwenberghs and T. Poggio. Incremental and</span></nobr></DIV>
<DIV style="position:absolute;top:938;left:109"><nobr><span class="ft11">decremental support vector machine learning. In T. K.<br>Leen, T. G. Dietterich, and V. Tresp, editors, NIPS<br>2000, volume 13. The MIT Press, 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:987;left:88"><nobr><span class="ft4">[2] D. Cox and E. Snell. Analysis of Binary Data.</span></nobr></DIV>
<DIV style="position:absolute;top:1002;left:109"><nobr><span class="ft4">Chapman &amp; Hall, London, 2nd edition, 1989.</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:88"><nobr><span class="ft4">[3] L. Csat´</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:154"><nobr><span class="ft4">o and M. Opper. Sparse representation for</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:109"><nobr><span class="ft11">Gaussian process models. In T. K. Leen, T. G.<br>Dietterich, and V. Tresp, editors, NIPS 2000,<br>volume 13. The MIT Press, 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:421;left:482"><nobr><span class="ft4">[4] H. Drucker, B. Shahrary, and D. C. Gibbon.</span></nobr></DIV>
<DIV style="position:absolute;top:437;left:503"><nobr><span class="ft11">Relevance feedbackusing support vector machines. In<br>Proceedings of the 2001 International Conference on<br>Machine Learning, 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:486;left:482"><nobr><span class="ft4">[5] T. E. Dunning. Accurate methods for the statistics of</span></nobr></DIV>
<DIV style="position:absolute;top:502;left:503"><nobr><span class="ft11">surprise and coincidence. Computational Linguistics,<br>19(1):61­74, 1993.</span></nobr></DIV>
<DIV style="position:absolute;top:534;left:482"><nobr><span class="ft4">[6] W. Hersh, C. Buckley, T. Leone, and D. Hickam.</span></nobr></DIV>
<DIV style="position:absolute;top:550;left:503"><nobr><span class="ft11">OHSUMED: An interactive retrieval evaluation and<br>new large test collection for research. In Proceedings of<br>the 17th Annual International ACM SIGIR<br>Conference on Research and Development in<br>Information Retrieval, pages 192­201, 1994.</span></nobr></DIV>
<DIV style="position:absolute;top:630;left:482"><nobr><span class="ft4">[7] T. Joachims. Text categorization with support vector</span></nobr></DIV>
<DIV style="position:absolute;top:646;left:503"><nobr><span class="ft11">machines: Learning with many relevant features. In<br>Proceedings of the European Conference on Machine<br>Learning (ECML), pages 137­142, 1998.</span></nobr></DIV>
<DIV style="position:absolute;top:694;left:482"><nobr><span class="ft4">[8] T. Joachims. Making large-scale SVM learning</span></nobr></DIV>
<DIV style="position:absolute;top:710;left:503"><nobr><span class="ft4">practical. In B. Sch´</span></nobr></DIV>
<DIV style="position:absolute;top:710;left:621"><nobr><span class="ft4">olkopf, C. Burges, and A. Smola,</span></nobr></DIV>
<DIV style="position:absolute;top:726;left:503"><nobr><span class="ft11">editors, Advances in Kernel Methods -- Support<br>Vector Learning, chapter 11. The MIT Press, 1999.</span></nobr></DIV>
<DIV style="position:absolute;top:759;left:482"><nobr><span class="ft4">[9] D. D. Lewis. Representation and Learning in</span></nobr></DIV>
<DIV style="position:absolute;top:774;left:503"><nobr><span class="ft11">Information Retrieval. PhD thesis, Department of<br>Computer and Information Science, University of<br>Massachusetts at Amherst, 1992.</span></nobr></DIV>
<DIV style="position:absolute;top:823;left:475"><nobr><span class="ft4">[10] D. D. Lewis. Evaluating and optimizing automomous</span></nobr></DIV>
<DIV style="position:absolute;top:839;left:503"><nobr><span class="ft11">text classification systems. In Proceedings of the 18th<br>Annual International ACM SIGIR Conference on<br>Research and Development in Information Retrieval,<br>pages 246­254, 1995.</span></nobr></DIV>
<DIV style="position:absolute;top:903;left:475"><nobr><span class="ft4">[11] D. D. Lewis, R. E. Schapire, J. P. Callan, and</span></nobr></DIV>
<DIV style="position:absolute;top:918;left:503"><nobr><span class="ft11">R. Papka. Training algorithms for linear text<br>classifiers. In Proceedings of the 19th Annual<br>International ACM SIGIR Conference on Research<br>and Development in Information Retrieval, pages<br>298­306, 1996.</span></nobr></DIV>
<DIV style="position:absolute;top:998;left:475"><nobr><span class="ft4">[12] D. J. Mackay. Bayesian interpolation. Neural</span></nobr></DIV>
<DIV style="position:absolute;top:1014;left:503"><nobr><span class="ft4">Computation, 4(3):415­447, 1991.</span></nobr></DIV>
<DIV style="position:absolute;top:1031;left:475"><nobr><span class="ft4">[13] D. J. Mackay. Information-based objective functions</span></nobr></DIV>
<DIV style="position:absolute;top:1047;left:503"><nobr><span class="ft11">for active data selection. Neural Computation,<br>4(4):590­604, 1992.</span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:449"><nobr><span class="ft9">103</span></nobr></DIV>
</DIV>
<!-- Page 8 -->
<a name="8"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="42008.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft4">[14] R. M. Neal. Monte Carlo implementation of Gaussian</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:109"><nobr><span class="ft11">process models for Bayesian regression and<br>classification. Technical Report CRG-TR-97-2,<br>Department of Computer Science, University of<br>Toronto, January 1997.</span></nobr></DIV>
<DIV style="position:absolute;top:166;left:81"><nobr><span class="ft4">[15] H. T. Ng, W. B. Goh, and K. L. Low. Feature</span></nobr></DIV>
<DIV style="position:absolute;top:182;left:109"><nobr><span class="ft11">selection, perceptron learning, and a usability case<br>study for text categorization. In Proceedings of the<br>20th Annual International ACM SIGIR Conference on<br>Research and Development in Information Retrieval,<br>pages 67­73, 1997.</span></nobr></DIV>
<DIV style="position:absolute;top:262;left:81"><nobr><span class="ft4">[16] M. Opper. Online versus offline learning from random</span></nobr></DIV>
<DIV style="position:absolute;top:278;left:109"><nobr><span class="ft11">examples: General results. Physical Review Letters,<br>77:4671­4674, 1996.</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:81"><nobr><span class="ft4">[17] M. Opper. A Bayesian approach to online learning. In</span></nobr></DIV>
<DIV style="position:absolute;top:326;left:109"><nobr><span class="ft11">D. Saad, editor, On-Line Learning in Neural<br>Networks. Combridge University Press, 1998.</span></nobr></DIV>
<DIV style="position:absolute;top:359;left:81"><nobr><span class="ft4">[18] S. Robertson and D. A. Hull. The TREC-9 filtering</span></nobr></DIV>
<DIV style="position:absolute;top:375;left:109"><nobr><span class="ft11">trackfinal report. In Proceedings of the 9th Text<br>REtrieval Conference (TREC-9), pages 25­40, 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:408;left:81"><nobr><span class="ft4">[19] G. Salton and C. Buckley. Term-weighting approaches</span></nobr></DIV>
<DIV style="position:absolute;top:423;left:109"><nobr><span class="ft11">in automatic text retrieval. Information Processing<br>and Management, 24(5):513­523, 1988.</span></nobr></DIV>
<DIV style="position:absolute;top:456;left:81"><nobr><span class="ft4">[20] S. A. Solla and O. Winther. Optimal perceptron</span></nobr></DIV>
<DIV style="position:absolute;top:472;left:109"><nobr><span class="ft11">learning: an online Bayesian approach. In D. Saad,<br>editor, On-Line Learning in Neural Networks.<br>Combridge University Press, 1998.</span></nobr></DIV>
<DIV style="position:absolute;top:520;left:81"><nobr><span class="ft4">[21] N. A. Syed, H. Liu, and K. K. Sung. Incremental</span></nobr></DIV>
<DIV style="position:absolute;top:536;left:109"><nobr><span class="ft11">learning with support vector machines. In Proceedings<br>of the Workshop on Support Vector Machines at the<br>International Joint Conference on Artificial<br>Intelligence (IJCAI-99), 1999.</span></nobr></DIV>
<DIV style="position:absolute;top:600;left:81"><nobr><span class="ft4">[22] C. van Rijsbergen. Information Retrieval.</span></nobr></DIV>
<DIV style="position:absolute;top:616;left:109"><nobr><span class="ft4">Butterworths, London, 1979.</span></nobr></DIV>
<DIV style="position:absolute;top:633;left:81"><nobr><span class="ft4">[23] V. N. Vapnik. The Nature of Statistical Learning</span></nobr></DIV>
<DIV style="position:absolute;top:649;left:109"><nobr><span class="ft4">Theory. Springer, New York, 1995.</span></nobr></DIV>
<DIV style="position:absolute;top:666;left:81"><nobr><span class="ft4">[24] C. K. Williams and M. Seeger. Using the Nystr¨</span></nobr></DIV>
<DIV style="position:absolute;top:666;left:396"><nobr><span class="ft4">om</span></nobr></DIV>
<DIV style="position:absolute;top:682;left:109"><nobr><span class="ft11">method to speed up kernel machines. In T. K. Leen,<br>T. G. Dietterich, and V. Tresp, editors, NIPS 2000,<br>volume 13. The MIT Press, 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:731;left:81"><nobr><span class="ft4">[25] O. Winther. Bayesian Mean Field Algorithms for</span></nobr></DIV>
<DIV style="position:absolute;top:746;left:109"><nobr><span class="ft11">Neural Networks and Gaussian Processes. PhD thesis,<br>University of Copenhagen, CONNECT, The Niels Bohr<br>Institute, 1998.</span></nobr></DIV>
<DIV style="position:absolute;top:795;left:81"><nobr><span class="ft4">[26] Y. Yang. A study on thresholding strategies for text</span></nobr></DIV>
<DIV style="position:absolute;top:810;left:109"><nobr><span class="ft11">categorization. In Proceedings of the 24th Annual<br>International ACM SIGIR Conference on Research<br>and Development in Information Retrieval, pages<br>137­145, 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:875;left:81"><nobr><span class="ft4">[27] Y. Yang and X. Liu. A re-examination of text</span></nobr></DIV>
<DIV style="position:absolute;top:890;left:109"><nobr><span class="ft11">categorization methods. In Proceedings of the 22nd<br>Annual International ACM SIGIR Conference on<br>Research and Development in Information Retrieval,<br>pages 42­49, 1999.</span></nobr></DIV>
<DIV style="position:absolute;top:970;left:81"><nobr><span class="ft3"><b>APPENDIX</b></span></nobr></DIV>
<DIV style="position:absolute;top:997;left:81"><nobr><span class="ft3"><b>A.</b></span></nobr></DIV>
<DIV style="position:absolute;top:997;left:116"><nobr><span class="ft3"><b>ON THE CHOICE OF PARAMETERS</b></span></nobr></DIV>
<DIV style="position:absolute;top:1028;left:81"><nobr><span class="ft3"><b>A.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:1028;left:125"><nobr><span class="ft3"><b>Likelihood model</b></span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:94"><nobr><span class="ft4">MacKay[12] has suggested the evidence frameworkfor model</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:81"><nobr><span class="ft4">selection. Here, we calculate the evidence on the training</span></nobr></DIV>
<DIV style="position:absolute;top:96;left:475"><nobr><span class="ft4">Table 6:</span></nobr></DIV>
<DIV style="position:absolute;top:96;left:547"><nobr><span class="ft4">Micro-/Macro-avg F</span></nobr></DIV>
<DIV style="position:absolute;top:99;left:692"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:96;left:706"><nobr><span class="ft4">(MaxF1 thresholds)</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:475"><nobr><span class="ft11">and Avg log-evidence on Reuters-21578 for different<br>likelihood models, using Bayesian online perceptron.</span></nobr></DIV>
<DIV style="position:absolute;top:143;left:558"><nobr><span class="ft4">Micro-/Macro-avg F</span></nobr></DIV>
<DIV style="position:absolute;top:145;left:681"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:143;left:703"><nobr><span class="ft4">Avg log-evidence</span></nobr></DIV>
<DIV style="position:absolute;top:159;left:503"><nobr><span class="ft4">Logit</span></nobr></DIV>
<DIV style="position:absolute;top:159;left:583"><nobr><span class="ft4">86.48 / 52.75</span></nobr></DIV>
<DIV style="position:absolute;top:159;left:737"><nobr><span class="ft4">-45.02</span></nobr></DIV>
<DIV style="position:absolute;top:175;left:503"><nobr><span class="ft4">Probit</span></nobr></DIV>
<DIV style="position:absolute;top:175;left:583"><nobr><span class="ft4">86.69 / 52.16</span></nobr></DIV>
<DIV style="position:absolute;top:175;left:737"><nobr><span class="ft4">-34.32</span></nobr></DIV>
<DIV style="position:absolute;top:191;left:503"><nobr><span class="ft4">Flip</span></nobr></DIV>
<DIV style="position:absolute;top:191;left:583"><nobr><span class="ft4">85.94 / 53.00</span></nobr></DIV>
<DIV style="position:absolute;top:191;left:737"><nobr><span class="ft4">-368.8</span></nobr></DIV>
<DIV style="position:absolute;top:237;left:475"><nobr><span class="ft4">Table 7:</span></nobr></DIV>
<DIV style="position:absolute;top:237;left:547"><nobr><span class="ft4">Micro-/Macro-avg F</span></nobr></DIV>
<DIV style="position:absolute;top:239;left:692"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:237;left:706"><nobr><span class="ft4">(MaxF1 thresholds)</span></nobr></DIV>
<DIV style="position:absolute;top:252;left:475"><nobr><span class="ft11">and Avg log-evidence on Reuters-21578 for different<br>passes over the training data, using Bayesian online<br>perceptron.</span></nobr></DIV>
<DIV style="position:absolute;top:299;left:503"><nobr><span class="ft4">Passes</span></nobr></DIV>
<DIV style="position:absolute;top:299;left:558"><nobr><span class="ft4">Micro-/Macro-avg F</span></nobr></DIV>
<DIV style="position:absolute;top:301;left:681"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:299;left:703"><nobr><span class="ft4">Avg log-evidence</span></nobr></DIV>
<DIV style="position:absolute;top:315;left:503"><nobr><span class="ft4">1</span></nobr></DIV>
<DIV style="position:absolute;top:315;left:583"><nobr><span class="ft4">87.08 / 52.87</span></nobr></DIV>
<DIV style="position:absolute;top:315;left:737"><nobr><span class="ft4">-35.56</span></nobr></DIV>
<DIV style="position:absolute;top:331;left:503"><nobr><span class="ft4">2</span></nobr></DIV>
<DIV style="position:absolute;top:331;left:583"><nobr><span class="ft4">86.92 / 52.63</span></nobr></DIV>
<DIV style="position:absolute;top:331;left:737"><nobr><span class="ft4">-34.36</span></nobr></DIV>
<DIV style="position:absolute;top:347;left:503"><nobr><span class="ft4">3</span></nobr></DIV>
<DIV style="position:absolute;top:347;left:583"><nobr><span class="ft4">86.69 / 52.16</span></nobr></DIV>
<DIV style="position:absolute;top:347;left:737"><nobr><span class="ft4">-34.32</span></nobr></DIV>
<DIV style="position:absolute;top:362;left:503"><nobr><span class="ft4">4</span></nobr></DIV>
<DIV style="position:absolute;top:362;left:583"><nobr><span class="ft4">86.62 / 52.75</span></nobr></DIV>
<DIV style="position:absolute;top:362;left:737"><nobr><span class="ft4">-34.54</span></nobr></DIV>
<DIV style="position:absolute;top:378;left:503"><nobr><span class="ft4">5</span></nobr></DIV>
<DIV style="position:absolute;top:378;left:583"><nobr><span class="ft4">85.22 / 46.93</span></nobr></DIV>
<DIV style="position:absolute;top:378;left:737"><nobr><span class="ft4">-34.69</span></nobr></DIV>
<DIV style="position:absolute;top:425;left:475"><nobr><span class="ft4">data using the final posterior for a:</span></nobr></DIV>
<DIV style="position:absolute;top:460;left:572"><nobr><span class="ft4">p(D</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:595"><nobr><span class="ft7">m</span></nobr></DIV>
<DIV style="position:absolute;top:460;left:605"><nobr><span class="ft4">) =</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:633"><nobr><span class="ft7">m</span></nobr></DIV>
<DIV style="position:absolute;top:478;left:629"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:476;left:633"><nobr><span class="ft7">=1</span></nobr></DIV>
<DIV style="position:absolute;top:460;left:655"><nobr><span class="ft4">p(y</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:674"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:456;left:679"><nobr><span class="ft4">|x</span></nobr></DIV>
<DIV style="position:absolute;top:464;left:691"><nobr><span class="ft7">t</span></nobr></DIV>
<DIV style="position:absolute;top:460;left:696"><nobr><span class="ft4">, a)</span></nobr></DIV>
<DIV style="position:absolute;top:467;left:721"><nobr><span class="ft7">m</span></nobr></DIV>
<DIV style="position:absolute;top:460;left:734"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:497;left:489"><nobr><span class="ft4">Table 6 illustrates this for selecting the likelihood mea-</span></nobr></DIV>
<DIV style="position:absolute;top:512;left:475"><nobr><span class="ft11">sure for the text classification task, using the Bayesian on-<br>line perceptron. In the table, the probit model follows the<br>formulation in section 3.1 with </span></nobr></DIV>
<DIV style="position:absolute;top:546;left:672"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:544;left:682"><nobr><span class="ft4">= 0.5, logit model is esti-</span></nobr></DIV>
<DIV style="position:absolute;top:559;left:475"><nobr><span class="ft4">mated by the probit model with </span></nobr></DIV>
<DIV style="position:absolute;top:562;left:679"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:559;left:689"><nobr><span class="ft4">= 1.6474[2], and the flip</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:475"><nobr><span class="ft11">noise model is as described in section 4.2. Although their<br>F</span></nobr></DIV>
<DIV style="position:absolute;top:593;left:484"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:591;left:495"><nobr><span class="ft4">averages are similar, the evidences show that the probit</span></nobr></DIV>
<DIV style="position:absolute;top:606;left:475"><nobr><span class="ft4">model with </span></nobr></DIV>
<DIV style="position:absolute;top:609;left:556"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:606;left:566"><nobr><span class="ft4">= 0.5 is a more likely model. The small evi-</span></nobr></DIV>
<DIV style="position:absolute;top:622;left:475"><nobr><span class="ft11">dence for the flip noise model is because much information<br>is lost through the threshold function .</span></nobr></DIV>
<DIV style="position:absolute;top:662;left:475"><nobr><span class="ft3"><b>A.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:662;left:519"><nobr><span class="ft3"><b>Effects of multiple passes over data</b></span></nobr></DIV>
<DIV style="position:absolute;top:685;left:489"><nobr><span class="ft4">Using the evidence measure defined in section A.1, Table</span></nobr></DIV>
<DIV style="position:absolute;top:701;left:475"><nobr><span class="ft11">7 illustrates the effects of different number of passes over<br>training data for Bayesian online perceptron. Treating the<br>number of passes as a parameter for the algorithm, we see<br>that having 3 passes over the data gives the highest average<br>evidence, although there is no significant difference between<br>2, 3, or 4 passes. Similar results hold for the Gaussian pro-<br>cess for the 3 different kernels. Hence, in section 4.1, we<br>choose to use 3 passes for all the Bayesian algorithms.</span></nobr></DIV>
<DIV style="position:absolute;top:835;left:475"><nobr><span class="ft3"><b>A.3</b></span></nobr></DIV>
<DIV style="position:absolute;top:835;left:519"><nobr><span class="ft3"><b>Jitter term</b></span></nobr></DIV>
<DIV style="position:absolute;top:858;left:489"><nobr><span class="ft4">The addition of the jitter term 10</span></nobr></DIV>
<DIV style="position:absolute;top:853;left:703"><nobr><span class="ft7">-4</span></nobr></DIV>
<DIV style="position:absolute;top:858;left:718"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:862;left:724"><nobr><span class="ft7">ij</span></nobr></DIV>
<DIV style="position:absolute;top:858;left:740"><nobr><span class="ft4">(where </span></nobr></DIV>
<DIV style="position:absolute;top:862;left:793"><nobr><span class="ft7">ij</span></nobr></DIV>
<DIV style="position:absolute;top:858;left:810"><nobr><span class="ft4">= 1</span></nobr></DIV>
<DIV style="position:absolute;top:873;left:475"><nobr><span class="ft11">if i = j, and 0 otherwise) for Gaussian process for classi-<br>fication is recommended by Neal[14]. This term improves<br>the conditioning of the matrix computations while having<br>a small effect on the model. From our preliminary exper-<br>iments, without the jitter term, the matrix operations in<br>Bayesian online Gaussian process become ill-conditioned.</span></nobr></DIV>
<DIV style="position:absolute;top:976;left:475"><nobr><span class="ft3"><b>A.4</b></span></nobr></DIV>
<DIV style="position:absolute;top:976;left:519"><nobr><span class="ft3"><b>Sizes of the basis vectors sets</b></span></nobr></DIV>
<DIV style="position:absolute;top:999;left:489"><nobr><span class="ft4">The sizes of the sets of basis vectors for GP in section 4.1</span></nobr></DIV>
<DIV style="position:absolute;top:1014;left:475"><nobr><span class="ft11">are limited to less than or equal to the number of features<br>selected. This is because, as noted by Csat´</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:748"><nobr><span class="ft4">o &amp; Opper[3],</span></nobr></DIV>
<DIV style="position:absolute;top:1046;left:475"><nobr><span class="ft11">for a feature space of finite dimension M, no more than M<br>basis vectors are needed, due to linear dependence.</span></nobr></DIV>
<DIV style="position:absolute;top:1122;left:449"><nobr><span class="ft9">104</span></nobr></DIV>
</DIV>
</BODY>
</HTML>
