<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
<HEAD>
<TITLE>p18-2-ziv.dvi</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<META name="generator" content="pdftohtml 0.35beta">
<META name="date" content="2003-04-21T16:56:47+00:00">
</HEAD>
<BODY bgcolor="#A0A0A0" vlink="blue" link="blue">
<!-- Page 1 -->
<a name="1"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft0{font-size:24px;font-family:Times;color:#000000;}
	.ft1{font-size:15px;font-family:Times;color:#000000;}
	.ft2{font-size:12px;font-family:Times;color:#000000;}
	.ft3{font-size:11px;font-family:Times;color:#000000;}
	.ft4{font-size:9px;font-family:Times;color:#000000;}
	.ft5{font-size:19px;font-family:Helvetica;color:#000000;}
	.ft6{font-size:11px;font-family:Times;color:#000000;}
	.ft7{font-size:11px;line-height:15px;font-family:Times;color:#000000;}
	.ft8{font-size:9px;line-height:13px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="61001.png" alt="background image">
<DIV style="position:absolute;top:108;left:140"><nobr><span class="ft0"><b>Coverage Directed Test Generation for Functional</b></span></nobr></DIV>
<DIV style="position:absolute;top:138;left:219"><nobr><span class="ft0"><b>Verification using Bayesian Networks</b></span></nobr></DIV>
<DIV style="position:absolute;top:205;left:316"><nobr><span class="ft1">Shai Fine</span></nobr></DIV>
<DIV style="position:absolute;top:205;left:546"><nobr><span class="ft1">Avi Ziv</span></nobr></DIV>
<DIV style="position:absolute;top:228;left:345"><nobr><span class="ft2">IBM Research Laboratory in Haifa</span></nobr></DIV>
<DIV style="position:absolute;top:244;left:393"><nobr><span class="ft2">Haifa, 31905, Israel</span></nobr></DIV>
<DIV style="position:absolute;top:258;left:376"><nobr><span class="ft3">{</span></nobr></DIV>
<DIV style="position:absolute;top:260;left:383"><nobr><span class="ft2">fshai, aziv</span></nobr></DIV>
<DIV style="position:absolute;top:258;left:449"><nobr><span class="ft3">}</span></nobr></DIV>
<DIV style="position:absolute;top:260;left:456"><nobr><span class="ft2">@il.ibm.com</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:81"><nobr><span class="ft1">ABSTRACT</span></nobr></DIV>
<DIV style="position:absolute;top:337;left:81"><nobr><span class="ft7">Functional verification is widely acknowledged as the bottleneck<br>in the hardware design cycle. This paper addresses one of the<br>main challenges of simulation based verification (or dynamic veri-<br>fication), by providing a new approach for Coverage Directed Test<br>Generation (CDG). This approach is based on Bayesian networks<br>and computer learning techniques. It provides an efficient way for<br>closing a feedback loop from the coverage domain back to a gener-<br>ator that produces new stimuli to the tested design. In this paper, we<br>show how to apply Bayesian networks to the CDG problem. Ap-<br>plying Bayesian networks to the CDG framework has been tested in<br>several experiments, exhibiting encouraging results and indicating<br>that the suggested approach can be used to achieve CDG goals.</span></nobr></DIV>
<DIV style="position:absolute;top:540;left:81"><nobr><span class="ft1">Categories and Subject Descriptors</span></nobr></DIV>
<DIV style="position:absolute;top:565;left:81"><nobr><span class="ft3">B.6.3 [Logic Design]: Design Aids--Verification</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:81"><nobr><span class="ft1">General Terms</span></nobr></DIV>
<DIV style="position:absolute;top:621;left:81"><nobr><span class="ft3">Verification, Measurement, Algorithms, Experimentation</span></nobr></DIV>
<DIV style="position:absolute;top:652;left:81"><nobr><span class="ft1">Keywords</span></nobr></DIV>
<DIV style="position:absolute;top:677;left:81"><nobr><span class="ft3">Functional Verification, Coverage Analysis, Bayesian Networks</span></nobr></DIV>
<DIV style="position:absolute;top:708;left:81"><nobr><span class="ft1">1.</span></nobr></DIV>
<DIV style="position:absolute;top:708;left:112"><nobr><span class="ft1">INTRODUCTION</span></nobr></DIV>
<DIV style="position:absolute;top:731;left:94"><nobr><span class="ft3">Functional verification is widely acknowledged as the bottleneck</span></nobr></DIV>
<DIV style="position:absolute;top:746;left:81"><nobr><span class="ft7">in the hardware design cycle [1]. To date, up to 70% of the design<br>development time and resources are spent on functional verifica-<br>tion. The increasing complexity of hardware designs raises the<br>need for the development of new techniques and methodologies<br>that can provide the verification team with the means to achieve its<br>goals quickly and with limited resources.</span></nobr></DIV>
<DIV style="position:absolute;top:840;left:94"><nobr><span class="ft3">The current practice for functional verification of complex de-</span></nobr></DIV>
<DIV style="position:absolute;top:856;left:81"><nobr><span class="ft7">signs starts with a definition of a test plan, comprised of a large<br>set of events that the verification team would like to observe dur-<br>ing the verification process. The test plan is usually implemented<br>using random test generators that produce a large number of test-<br>cases, and coverage tools that detect the occurrence of events in</span></nobr></DIV>
<DIV style="position:absolute;top:977;left:81"><nobr><span class="ft8">Permission to make digital or hard copies of all or part of this work for<br>personal or classroom use is granted without fee provided that copies are<br>not made or distributed for profit or commercial advantage and that copies<br>bear this notice and the full citation on the first page. To copy otherwise, to<br>republish, to post on servers or to redistribute to lists, requires prior specific<br>permission and/or a fee.<br>DAC 2003, June 2­6, 2003, Anaheim, California, USA.<br>Copyright 2003 ACM 1-58113-688-9/03/0006 ...</span></nobr></DIV>
<DIV style="position:absolute;top:1070;left:315"><nobr><span class="ft3">$</span></nobr></DIV>
<DIV style="position:absolute;top:1071;left:322"><nobr><span class="ft4">5.00.</span></nobr></DIV>
<DIV style="position:absolute;top:315;left:475"><nobr><span class="ft7">the test plan, and provide information related to the progress of the<br>test plan. Analysis of the coverage reports allows the verification<br>team to modify the directives for the test generators and to better<br>hit areas or specific tasks in the design that are not covered well [5].</span></nobr></DIV>
<DIV style="position:absolute;top:378;left:489"><nobr><span class="ft3">The analysis of coverage reports, and their translation to a set</span></nobr></DIV>
<DIV style="position:absolute;top:393;left:475"><nobr><span class="ft7">of test generator directives to guide and enhance the implementa-<br>tion of the test plan, result in major manual bottlenecks in the oth-<br>erwise highly automated verification process. Considerable effort<br>is invested in finding ways to close the loop of coverage analysis<br>and test generation. Coverage directed test generation (CDG) is<br>a technique to automate the feedback from coverage analysis to<br>test generation. The main goals of CDG are to improve the cover-<br>age progress rate, to help reaching uncovered tasks, and to provide<br>many different ways to reach a given coverage task. Achieving<br>these goals should increase the efficiency and quality of the verifi-<br>cation process and reduce the time and effort needed to implement<br>a test plan.</span></nobr></DIV>
<DIV style="position:absolute;top:582;left:489"><nobr><span class="ft3">In this paper, we propose a new approach for coverage directed</span></nobr></DIV>
<DIV style="position:absolute;top:597;left:475"><nobr><span class="ft7">test generation. Our approach is to cast CDG in a statistical infer-<br>ence framework, and apply computer learning techniques to achieve<br>the CDG goals. Specifically, our approach is based on modeling the<br>relationship between the coverage information and the directives to<br>the test generator using Bayesian networks [9]. A Bayesian net-<br>work is a directed graph whose nodes are random variables and<br>whose edges represent direct dependency between their sink and<br>source nodes. Each node in the Bayesian network is associated with<br>a set of parameters specifying its conditional probability given the<br>state of its parents.</span></nobr></DIV>
<DIV style="position:absolute;top:754;left:489"><nobr><span class="ft3">Simply stated, the CDG process is performed in two main steps.</span></nobr></DIV>
<DIV style="position:absolute;top:770;left:475"><nobr><span class="ft7">In the first step, a training set is used to learn the parameters of<br>a Bayesian network that models the relationship between the cov-<br>erage information and the test directives. In the second step, the<br>Bayesian network is used to provide the most probable directives<br>that would lead to a given coverage task (or set of tasks).</span></nobr></DIV>
<DIV style="position:absolute;top:848;left:489"><nobr><span class="ft3">Bayesian networks are well suited to the kind of modeling re-</span></nobr></DIV>
<DIV style="position:absolute;top:864;left:475"><nobr><span class="ft7">quired for CDG, because they offer a natural and compact rep-<br>resentation of the rather complex relationship between the CDG<br>ingredients, together with the ability to encode essential domain<br>knowledge. Moreover, adaptive tuning of the Bayesian network<br>parameters provides a mean to focus on the rare coverage cases.</span></nobr></DIV>
<DIV style="position:absolute;top:943;left:489"><nobr><span class="ft3">We describe two experiments in which we tested the the abil-</span></nobr></DIV>
<DIV style="position:absolute;top:958;left:475"><nobr><span class="ft7">ity of Bayesian networks to handle aspects of the CDG problem<br>in various settings. The goals of the experiments were to increase<br>the hitting rates in hard-to-reach coverage cases; design directives<br>aimed at reaching uncovered tasks; and provide many different di-<br>rectives for a given coverage task. We used two settings for our<br>experiments. In the first setting, we used a Bayesian network to<br>generate instruction streams to an abstract model of the pipeline of</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft6">286</span></nobr></DIV>
<DIV style="position:absolute;top:54;left:80"><nobr><span class="ft5">18.2</span></nobr></DIV>
</DIV>
<!-- Page 2 -->
<a name="2"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft9{font-size:5px;font-family:Times;color:#000000;}
	.ft10{font-size:3px;font-family:Times;color:#000000;}
	.ft11{font-size:15px;line-height:20px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="61002.png" alt="background image">
<DIV style="position:absolute;top:88;left:247"><nobr><span class="ft9">Random</span></nobr></DIV>
<DIV style="position:absolute;top:96;left:253"><nobr><span class="ft9">Test</span></nobr></DIV>
<DIV style="position:absolute;top:104;left:245"><nobr><span class="ft9">Generator</span></nobr></DIV>
<DIV style="position:absolute;top:92;left:107"><nobr><span class="ft9">Test Plan</span></nobr></DIV>
<DIV style="position:absolute;top:103;left:409"><nobr><span class="ft9">Fail</span></nobr></DIV>
<DIV style="position:absolute;top:90;left:409"><nobr><span class="ft9">Pass</span></nobr></DIV>
<DIV style="position:absolute;top:127;left:378"><nobr><span class="ft9">Information</span></nobr></DIV>
<DIV style="position:absolute;top:96;left:185"><nobr><span class="ft9">Directives</span></nobr></DIV>
<DIV style="position:absolute;top:89;left:307"><nobr><span class="ft10">Test</span></nobr></DIV>
<DIV style="position:absolute;top:118;left:378"><nobr><span class="ft9">Coverage</span></nobr></DIV>
<DIV style="position:absolute;top:145;left:360"><nobr><span class="ft9">Coverage</span></nobr></DIV>
<DIV style="position:absolute;top:154;left:354"><nobr><span class="ft9">Analysis Tool</span></nobr></DIV>
<DIV style="position:absolute;top:154;left:301"><nobr><span class="ft9">Reports</span></nobr></DIV>
<DIV style="position:absolute;top:145;left:298"><nobr><span class="ft9">Coverage</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:360"><nobr><span class="ft9">Simulator</span></nobr></DIV>
<DIV style="position:absolute;top:92;left:366"><nobr><span class="ft9">DUT</span></nobr></DIV>
<DIV style="position:absolute;top:191;left:87"><nobr><span class="ft3">Figure 1: Verification process with automatic test generation</span></nobr></DIV>
<DIV style="position:absolute;top:236;left:81"><nobr><span class="ft7">an advanced super-scalar PowerPC processor. In the second set-<br>ting, we used a Bayesian network to generate directives to an ex-<br>isting test generator of a storage control unit of a mainframe with a<br>goal to cover all possible transactions from the CPUs connected to<br>this unit. In both experiments we reached our goals. The encour-<br>aging results suggests that Bayesian networks may well be used to<br>achieve the primary goals of CDG.</span></nobr></DIV>
<DIV style="position:absolute;top:346;left:94"><nobr><span class="ft3">The remainder of this paper is as follows. In Section 2, we briefly</span></nobr></DIV>
<DIV style="position:absolute;top:362;left:81"><nobr><span class="ft7">present the CDG framework and review related work. In Section 3,<br>we describe Bayesian networks and their application to CDG. Sec-<br>tions 4 and 5 provide detailed descriptions of the experiments. We<br>conclude with a few remarks and suggestions for future study.</span></nobr></DIV>
<DIV style="position:absolute;top:443;left:81"><nobr><span class="ft1">2.</span></nobr></DIV>
<DIV style="position:absolute;top:443;left:112"><nobr><span class="ft11">COVERAGE DIRECTED TEST GENER-<br>ATION (CDG)</span></nobr></DIV>
<DIV style="position:absolute;top:486;left:94"><nobr><span class="ft3">In current industry practice, verification by simulation, or dy-</span></nobr></DIV>
<DIV style="position:absolute;top:502;left:81"><nobr><span class="ft7">namic verification, is the leading technique for functional verifica-<br>tion. Coverage is used to ensure that the verification of the design is<br>thorough, and the definition of coverage events or testing require-<br>ments is a major part in the definition of the verification plan of the<br>design. Often, a family of coverage events that share common prop-<br>erties are grouped together to form a coverage model [7]. Members<br>of the coverage model are called coverage tasks and are considered<br>part of the test plan. Cross-product coverage models [7] are of spe-<br>cial interest. These models are defined by a basic event and a set of<br>parameters or attributes, where the list of coverage tasks comprises<br>all possible combinations of values for the attributes.</span></nobr></DIV>
<DIV style="position:absolute;top:674;left:94"><nobr><span class="ft3">Figure 1 illustrates the verification process with an automatic</span></nobr></DIV>
<DIV style="position:absolute;top:690;left:81"><nobr><span class="ft7">random test generation. A test plan is translated by the verifica-<br>tion team to a set of directives for the random test generator. Based<br>on these directives and embedded domain knowledge, the test gen-<br>erator produces many test-cases. The design under test (DUT) is<br>then simulated using the generated test-cases, and its behavior is<br>monitored to make sure that it meets its specification. In addition,<br>coverage tools are used to detect the occurrence of coverage tasks<br>during simulation. Analysis of the reports provided by the cover-<br>age tools allows the verification team to modify the directives to<br>the test generator to overcome weaknesses in the implementation<br>of the test plan. This process is repeated until the exit criteria in the<br>test plan are met.</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:94"><nobr><span class="ft3">The use of automatic test generators can dramatically reduce the</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:81"><nobr><span class="ft7">amount of manual labor required to implement the test plan. Even<br>so, the manual work needed for analyzing the coverage reports and<br>translating them to directives for the test generator, can constitute a<br>bottleneck in the verification process. Therefore, considerable ef-<br>fort is spent on finding ways to automate this procedure, and close<br>the loop of coverage analysis and test generation. This automated<br>feedback from coverage analysis to test generation, known as Cov-<br>erage Directed test Generation (CDG), can reduce the manual work<br>in the verification process and increase its efficiency.</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:94"><nobr><span class="ft3">In general, the goal of CDG is to automatically provide directives</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:81"><nobr><span class="ft7">that are based on coverage analysis to the test generator. This can<br>be further divided into two sub-goals: First, to provide directives to</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft7">the test generator that help in reaching hard cases, namely uncov-<br>ered or rarely covered tasks. Achieving this sub-goal can shorten<br>the time needed to fulfill the test plan and reduce the number of<br>manually written directives. Second, to provide directives that al-<br>low easier reach for any coverage task, using a different set of direc-<br>tives when possible. Achieving this sub-goal makes the verification<br>process more robust, because it increases the number of times a task<br>has been covered during verification. Moreover, if a coverage task<br>is reached via different directions, the chances to discover hidden<br>bugs related to this task are increased [8].</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:489"><nobr><span class="ft3">In the past, two general approaches for CDG have been pro-</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:475"><nobr><span class="ft7">posed: feedback-based CDG and CDG by construction. Feedback-<br>based CDG relies on feedback from the coverage analysis to auto-<br>matically modify the directives to the test generator. For example,<br>in [2], a genetic algorithm is used to select and modify test-cases to<br>increase coverage. In [13], coverage analysis data is used to mod-<br>ify the parameters of a Markov Chain that represents the DUT. The<br>Markov Chain is then used to generate test-cases for the design.<br>In [11], the coverage analysis results trigger a set of generation<br>rules that modify the testing directives. In contrast, in CDG by<br>construction, an external model of the DUT is used to generate test<br>directives designed to accurately hit the coverage tasks. For exam-<br>ple, in [14] an FSM model of pipelines is used to generate tests that<br>cover instruction interdependencies in the pipes.</span></nobr></DIV>
<DIV style="position:absolute;top:486;left:475"><nobr><span class="ft1">3.</span></nobr></DIV>
<DIV style="position:absolute;top:486;left:507"><nobr><span class="ft11">COVERAGE DIRECTED TEST GENER-<br>ATION USING BAYESIAN NETWORKS</span></nobr></DIV>
<DIV style="position:absolute;top:530;left:489"><nobr><span class="ft3">The random nature of automatic test-case generators imposes a</span></nobr></DIV>
<DIV style="position:absolute;top:546;left:475"><nobr><span class="ft7">considerable amount of uncertainty in the relationship between test<br>directives and coverage tasks, e.g., the same set of directives can<br>be used to generate many different test-cases, each leading to dif-<br>ferent coverage tasks. This inherent uncertainty suggests to cast<br>the CDG setup in a statistical inference framework. To this end,<br>Bayesian networks offer an efficient modeling scheme by provid-<br>ing a compact representation of the complex (possibly stochastic)<br>relationships among the CDG ingredients, together with the pos-<br>sibility to encode essential domain knowledge. It should be noted<br>that we do not suggest modeling the behavior of the design, typi-<br>cally a large and complicated (deterministic) finite state machine.<br>Rather, we model the CDG process itself, namely the trial-and-<br>error procedure governed by the verification team, which controls<br>the test generation at one end and traces the progress of covering<br>the test plan at the other.</span></nobr></DIV>
<DIV style="position:absolute;top:793;left:475"><nobr><span class="ft1">3.1</span></nobr></DIV>
<DIV style="position:absolute;top:793;left:516"><nobr><span class="ft1">A Brief Introduction to Bayesian Networks</span></nobr></DIV>
<DIV style="position:absolute;top:816;left:489"><nobr><span class="ft3">A Bayesian network is a graphical representation of the joint</span></nobr></DIV>
<DIV style="position:absolute;top:831;left:475"><nobr><span class="ft7">probability distribution for a set of variables. This representation<br>was originally designed to encode the uncertain knowledge of an<br>expert and can be dated back to the geneticist Sewall Wright [15].<br>Their initial development in the late 1970s was motivated by the<br>need to model the top-down (semantic) and bottom-up (perceptual)<br>combinations of evidence (observations/findings). Their capability<br>for bidirectional inferences, combined with a rigorous probabilistic<br>foundation, led to the rapid emergence of Bayesian networks as the<br>method of choice for uncertain reasoning in AI and expert systems,<br>replacing ad hoc rule-based schemes. Bayesian networks also play<br>a crucial role in diagnosis and decision support systems [10].</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:489"><nobr><span class="ft3">Obviously, there's a computational problem in dealing with many</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:475"><nobr><span class="ft7">sources of uncertainty, i.e. the ability to perform probabilistic ma-<br>nipulations in high dimensions (the "curse of dimensionality"). The<br>main breakthrough emerged in the late 1980s and can be attributed<br>to Judea Pearl [12], who introduced 'modularity', thus enabling</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft6">287</span></nobr></DIV>
</DIV>
<!-- Page 3 -->
<a name="3"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft12{font-size:8px;font-family:Times;color:#000000;}
	.ft13{font-size:17px;font-family:Times;color:#000000;}
	.ft14{font-size:7px;font-family:Times;color:#000000;}
	.ft15{font-size:11px;line-height:13px;font-family:Times;color:#000000;}
	.ft16{font-size:7px;line-height:11px;font-family:Times;color:#000000;}
	.ft17{font-size:7px;line-height:10px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="61003.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft7">large and complex models and theirs associated calculations, to be<br>split up into small manageable pieces. The best way to do this is<br>via the imposition of meaningfully simplified conditional indepen-<br>dence assumptions. These, in turn, can be expressed by means of a<br>powerful and appealing graphical representation.</span></nobr></DIV>
<DIV style="position:absolute;top:165;left:94"><nobr><span class="ft3">A Bayesian network consists of two components. The first is a</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:81"><nobr><span class="ft7">directed acyclic graph in which each vertex corresponds to a ran-<br>dom variable. This graph represents a set of conditional indepen-<br>dence properties of the represented distribution: each variable is<br>probabilistically independent of its non-descendants in the graph<br>given the state of its parents. The graph captures the qualitative<br>structure of the probability distribution, and is exploited for effi-<br>cient inference and decision making. The second component is a<br>collection of local interaction models that describe the conditional<br>probability p</span></nobr></DIV>
<DIV style="position:absolute;top:303;left:151"><nobr><span class="ft3">(X</span></nobr></DIV>
<DIV style="position:absolute;top:310;left:164"><nobr><span class="ft12"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:303;left:168"><nobr><span class="ft3">|Pa</span></nobr></DIV>
<DIV style="position:absolute;top:310;left:185"><nobr><span class="ft12"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:303;left:189"><nobr><span class="ft3">) of each variable X</span></nobr></DIV>
<DIV style="position:absolute;top:310;left:296"><nobr><span class="ft12"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:306;left:303"><nobr><span class="ft3">given its parents Pa</span></nobr></DIV>
<DIV style="position:absolute;top:310;left:409"><nobr><span class="ft12"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:306;left:413"><nobr><span class="ft3">. To-</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:81"><nobr><span class="ft7">gether, these two components represent a unique joint probability<br>distribution over the complete set of variables X [12]. The joint<br>probability distribution is given by the following equation:</span></nobr></DIV>
<DIV style="position:absolute;top:387;left:205"><nobr><span class="ft3">p</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:211"><nobr><span class="ft3">(X) =</span></nobr></DIV>
<DIV style="position:absolute;top:375;left:253"><nobr><span class="ft12"><i>n</i></span></nobr></DIV>
<DIV style="position:absolute;top:381;left:248"><nobr><span class="ft13"></span></nobr></DIV>
<DIV style="position:absolute;top:403;left:248"><nobr><span class="ft12"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:400;left:251"><nobr><span class="ft12"><i>=1</i></span></nobr></DIV>
<DIV style="position:absolute;top:387;left:266"><nobr><span class="ft3">p</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:273"><nobr><span class="ft3">(X</span></nobr></DIV>
<DIV style="position:absolute;top:391;left:286"><nobr><span class="ft12"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:383;left:290"><nobr><span class="ft3">|Pa</span></nobr></DIV>
<DIV style="position:absolute;top:391;left:308"><nobr><span class="ft12"><i>i</i></span></nobr></DIV>
<DIV style="position:absolute;top:383;left:311"><nobr><span class="ft3">)</span></nobr></DIV>
<DIV style="position:absolute;top:387;left:424"><nobr><span class="ft3">(1)</span></nobr></DIV>
<DIV style="position:absolute;top:422;left:81"><nobr><span class="ft7">It can be shown that this equation actually implies the conditional<br>independence semantics of the graphical structure given earlier.<br>Eq. 1 shows that the joint distribution specified by a Bayesian net-<br>work has a factored representation as the product of individual local<br>interaction models. Thus, while Bayesian networks can represent<br>arbitrary probability distributions, they provide a computational ad-<br>vantage for those distributions that can be represented with a simple<br>structure.</span></nobr></DIV>
<DIV style="position:absolute;top:548;left:94"><nobr><span class="ft3">The characterization given by Eq. 1 is a purely formal charac-</span></nobr></DIV>
<DIV style="position:absolute;top:563;left:81"><nobr><span class="ft7">terization in terms of probabilities and conditional independence.<br>An informal connection can be made between this characterization<br>and the intuitive notion of direct causal influence. It has been noted<br>that if the edges in the network structure correspond to causal re-<br>lationships, where a variable's parents represent the direct causal<br>influences on that variable, then resulting networks are often very<br>concise and accurate descriptions of the domain. Thus it appears<br>that in many practical situations, a Bayesian network provides a<br>natural way to encode causal information. Nonetheless, it is often<br>difficult and time consuming to construct Bayesian networks from<br>expert knowledge alone, particularly because of the need to provide<br>numerical parameters. This observation, together with the fact that<br>data is becoming increasingly available and cheaper to acquire, has<br>led to a growing interest in using data to learn both the structure<br>and probabilities of a Bayesian network (cf. [3, 9, 12]).</span></nobr></DIV>
<DIV style="position:absolute;top:799;left:94"><nobr><span class="ft3">Typical types of queries that can be efficiently answered by the</span></nobr></DIV>
<DIV style="position:absolute;top:814;left:81"><nobr><span class="ft7">Bayesian network model are derived from applying the Bayes rule<br>to yield posterior probabilities for the values of a node (or set of<br>nodes), X , given some evidence, E, i.e. assignment of specific val-<br>ues to other nodes:</span></nobr></DIV>
<DIV style="position:absolute;top:891;left:191"><nobr><span class="ft3">p</span></nobr></DIV>
<DIV style="position:absolute;top:888;left:198"><nobr><span class="ft3">(X|E) = p(E|X)  p(X)</span></nobr></DIV>
<DIV style="position:absolute;top:900;left:276"><nobr><span class="ft3">p</span></nobr></DIV>
<DIV style="position:absolute;top:897;left:283"><nobr><span class="ft3">(E)</span></nobr></DIV>
<DIV style="position:absolute;top:924;left:81"><nobr><span class="ft7">Thus, a statistical inference can be made in the form of either select-<br>ing the Maximal A Posteriori (MAP) probability, max p</span></nobr></DIV>
<DIV style="position:absolute;top:936;left:387"><nobr><span class="ft3">(X|E), or</span></nobr></DIV>
<DIV style="position:absolute;top:955;left:81"><nobr><span class="ft3">obtaining the Most Probable Explanation (MPE), arg max p</span></nobr></DIV>
<DIV style="position:absolute;top:952;left:401"><nobr><span class="ft3">(X|E).</span></nobr></DIV>
<DIV style="position:absolute;top:971;left:94"><nobr><span class="ft3">The sophisticated yet efficient methods that have been developed</span></nobr></DIV>
<DIV style="position:absolute;top:986;left:81"><nobr><span class="ft7">for using Bayesian networks provide the means for predictive and<br>diagnostic inference</span></nobr></DIV>
<DIV style="position:absolute;top:999;left:189"><nobr><span class="ft12"><i>1</i></span></nobr></DIV>
<DIV style="position:absolute;top:1002;left:195"><nobr><span class="ft3">. A diagnostic query is such that the evidence</span></nobr></DIV>
<DIV style="position:absolute;top:1024;left:81"><nobr><span class="ft12"><i>1</i></span></nobr></DIV>
<DIV style="position:absolute;top:1026;left:87"><nobr><span class="ft3">This is in contrast to standard regression and classification meth-</span></nobr></DIV>
<DIV style="position:absolute;top:1040;left:81"><nobr><span class="ft15">ods (e.g., feed forward neural networks and decision trees) that<br>encode only the probability distribution of a target variable given<br>several input variables.</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:714"><nobr><span class="ft14">State</span></nobr></DIV>
<DIV style="position:absolute;top:121;left:718"><nobr><span class="ft14">Int</span></nobr></DIV>
<DIV style="position:absolute;top:245;left:778"><nobr><span class="ft16">Covearge<br>Variables</span></nobr></DIV>
<DIV style="position:absolute;top:257;left:534"><nobr><span class="ft14">Directives</span></nobr></DIV>
<DIV style="position:absolute;top:245;left:525"><nobr><span class="ft14">Test Generator</span></nobr></DIV>
<DIV style="position:absolute;top:193;left:648"><nobr><span class="ft14">Core</span></nobr></DIV>
<DIV style="position:absolute;top:203;left:641"><nobr><span class="ft14">Enbable</span></nobr></DIV>
<DIV style="position:absolute;top:121;left:648"><nobr><span class="ft14">Cmd</span></nobr></DIV>
<DIV style="position:absolute;top:130;left:647"><nobr><span class="ft14">Type</span></nobr></DIV>
<DIV style="position:absolute;top:88;left:506"><nobr><span class="ft17">cp_cmd_type =<br>{// val  weight<br>   {read,  20},<br>   {write, 20},<br>   {RMW,    5},<br>   ...<br>};</span></nobr></DIV>
<DIV style="position:absolute;top:171;left:506"><nobr><span class="ft17">cp_core_enable =<br>{// val  weight</span></nobr></DIV>
<DIV style="position:absolute;top:201;left:506"><nobr><span class="ft14">  {Core 1, 10},</span></nobr></DIV>
<DIV style="position:absolute;top:222;left:506"><nobr><span class="ft14">};</span></nobr></DIV>
<DIV style="position:absolute;top:207;left:718"><nobr><span class="ft14">Op</span></nobr></DIV>
<DIV style="position:absolute;top:197;left:712"><nobr><span class="ft14">Mode</span></nobr></DIV>
<DIV style="position:absolute;top:212;left:787"><nobr><span class="ft14">Core</span></nobr></DIV>
<DIV style="position:absolute;top:163;left:787"><nobr><span class="ft14">Cmd</span></nobr></DIV>
<DIV style="position:absolute;top:115;left:787"><nobr><span class="ft14">Resp</span></nobr></DIV>
<DIV style="position:absolute;top:191;left:506"><nobr><span class="ft14">  {Core 0, 10},</span></nobr></DIV>
<DIV style="position:absolute;top:212;left:506"><nobr><span class="ft14">  {Both,  100}</span></nobr></DIV>
<DIV style="position:absolute;top:285;left:550"><nobr><span class="ft3">Figure 2: Bayesian Network of CDG</span></nobr></DIV>
<DIV style="position:absolute;top:333;left:475"><nobr><span class="ft7">nodes E represent a cause, while the queried nodes, X , represent<br>an effect. The reversed direction, i.e. evidence on the effect nodes<br>which serves to determine the possible cause, is called abductive.<br>These methods also allow Bayesian networks to reason efficiently<br>with missing values, by computing the marginal probability of the<br>query given the observed values.</span></nobr></DIV>
<DIV style="position:absolute;top:427;left:489"><nobr><span class="ft3">There are two important extensions of Bayesian networks: Dy-</span></nobr></DIV>
<DIV style="position:absolute;top:442;left:475"><nobr><span class="ft7">namic Bayesian networks and influence diagrams. The first exten-<br>sion (see [6]) enables the incorporation of time, thus modeling tem-<br>poral dependencies in a stochastic process. The second extension<br>(see [3]) enriches the Bayesian network paradigm with decision<br>making and utility considerations which create a powerful mecha-<br>nism for dealing with decisions under uncertainty constraints.</span></nobr></DIV>
<DIV style="position:absolute;top:549;left:475"><nobr><span class="ft1">3.2</span></nobr></DIV>
<DIV style="position:absolute;top:549;left:516"><nobr><span class="ft1">A Bayesian Network for CDG</span></nobr></DIV>
<DIV style="position:absolute;top:572;left:489"><nobr><span class="ft3">The CDG process begins with the construction of a Bayesian net-</span></nobr></DIV>
<DIV style="position:absolute;top:587;left:475"><nobr><span class="ft7">work model that describes the relations between the test directives<br>and the coverage space. Figure 2 illustrates a simple, yet typical,<br>Bayesian network, which models a small excerpt of the CDG setup.<br>The network describes the relationship between the directives that<br>influence the type of command that is generated (cp cmd type)<br>and the active cores inside a CPU (cp core enable), and the<br>coverage attributes of a generated command (cmd), its response<br>(resp), and the core that generated it (core). The network is<br>comprised of input nodes (the white circles on the left) that re-<br>late to test directives that appear to their left and coverage nodes<br>(the white squares on the right) that define the coverage space. In<br>addition to these nodes, for which we have physical observations,<br>the network may also contain hidden nodes, namely variables for<br>which we don't have any physical evidence (observations) for their<br>interactions. These variables are represented as shaded ovals in<br>the figure. Hidden nodes are added to the Bayesian network struc-<br>ture primarily to reflect expert domain knowledge regarding hidden<br>causes and functionalities which impose some structure on the in-<br>teraction between the interface (observed) nodes</span></nobr></DIV>
<DIV style="position:absolute;top:867;left:736"><nobr><span class="ft12"><i>2</i></span></nobr></DIV>
<DIV style="position:absolute;top:870;left:742"><nobr><span class="ft3">.</span></nobr></DIV>
<DIV style="position:absolute;top:885;left:489"><nobr><span class="ft3">The Bayesian network at Fig. 2 describes the causal relationships</span></nobr></DIV>
<DIV style="position:absolute;top:901;left:475"><nobr><span class="ft7">from the test generation directives (causes) to the coverage model<br>space (effects). For example, it encodes the expert knowledge that<br>indicates that there is an internal mode of operation for which we<br>do not have any direct physical observation, yet it is determined<br>by the combined values of the test generation attributes. On the<br>other hand, the (hidden) mode of operation directly influences the<br>choice of the resulting command and core, which are attributes of</span></nobr></DIV>
<DIV style="position:absolute;top:1024;left:476"><nobr><span class="ft12"><i>2</i></span></nobr></DIV>
<DIV style="position:absolute;top:1026;left:482"><nobr><span class="ft3">Introducing hidden nodes to the network structure has the sec-</span></nobr></DIV>
<DIV style="position:absolute;top:1040;left:475"><nobr><span class="ft15">ondary impact of reducing the computational complexity by dimen-<br>sionality reduction, and as a means for capturing non-trivial (higher<br>order) correlations between observed events.</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft6">288</span></nobr></DIV>
</DIV>
<!-- Page 4 -->
<a name="4"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft18{font-size:10px;font-family:Times;color:#000000;}
	.ft19{font-size:10px;font-family:Times;color:#ffffff;}
-->
</STYLE>
<IMG width="918" height="1188" src="61004.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft7">the coverage model. Note the absence of a direct link between the<br>requested core (via the directive cp core enable) and the ob-<br>served one (at Core), which captures our understanding that there<br>is no direct influence between the directives and the coverage at-<br>tribute. Another assumption encoded in the CDG Bayesian net-<br>work structure at Fig. 2, is that the only information that governs<br>the response for the command is the generated command itself, and<br>this is encoded via the direct link from Cmd to Resp.</span></nobr></DIV>
<DIV style="position:absolute;top:212;left:94"><nobr><span class="ft3">In a nutshell, the design of the Bayesian network starts with iden-</span></nobr></DIV>
<DIV style="position:absolute;top:228;left:81"><nobr><span class="ft7">tifying the ingredients (attributes) that will constitute the directives<br>to the test generator on one hand, and to the coverage model on the<br>other. These attributes are dictated by the interface to the simulation<br>environment, to the coverage analysis tool, and by the specification<br>of the coverage model in the test plan. These ingredients are used<br>as the first guess about the nodes in the graph structure. Connect-<br>ing these nodes with edges is our technique for expert knowledge<br>encoding, as demonstrated in Fig. 2. Obviously, using a fully con-<br>nected graph, i.e. with an edge between every pair of nodes, rep-<br>resents absolutely no knowledge about the possible dependencies<br>and functionalities within the model. Hence, as the graph structure<br>becomes sparser, it represents deeper domain knowledge. We dis-<br>covered that a good practice in specifying a dependency graph is<br>to remove edges for which we have strong belief that the detached<br>nodes are not directly influencing one another. At this point, hid-<br>den nodes can be added to the structure, either to represent hidden<br>causes, which contribute to a better description of the functional-<br>ities of the model, or to take on a role from the complexity stand<br>point, by breaking the barges cliques in the graph (see [4]).</span></nobr></DIV>
<DIV style="position:absolute;top:526;left:94"><nobr><span class="ft3">After the Bayesian network structure is specified, it is trained</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:81"><nobr><span class="ft7">using a sample of directives and the respective coverage tasks. To<br>this end, we activate the simulation environment and construct a<br>training set out of the directives used and the resulting coverage<br>tasks. We then use one of the many known learning algorithms (cf.<br>[3]) to estimate the Bayesian network's parameters (i.e. the set of<br>conditional probability distributions). This completes the design<br>and training of the Bayesian network model.</span></nobr></DIV>
<DIV style="position:absolute;top:651;left:94"><nobr><span class="ft3">In the evaluation phase, the trained Bayesian network can be</span></nobr></DIV>
<DIV style="position:absolute;top:667;left:81"><nobr><span class="ft7">used to determine directives for a desired coverage task, via pos-<br>terior probabilities, MAP and MPE queries, which use the cov-<br>erage task attributes as evidence. For example, in a model for<br>which the directives are weights of possible outcomes for inter-<br>nal draws in the test generator (e.g. the directive cp cmd type<br>in Fig. 2 specifies a preference to read commands, write com-<br>mands, etc.), we can specify a desired coverage task assignment<br>(evidence) for the coverage nodes (e.g. Resp = ACK) and calcu-<br>late the posterior probability distribution for directive nodes (e.g.</span></nobr></DIV>
<DIV style="position:absolute;top:808;left:82"><nobr><span class="ft3">p</span></nobr></DIV>
<DIV style="position:absolute;top:805;left:88"><nobr><span class="ft3">(Cmd Type|Resp = ACK)), which directly translates to the set of</span></nobr></DIV>
<DIV style="position:absolute;top:824;left:81"><nobr><span class="ft7">weights to be written in the test generator's parameter file. Note, as<br>the example demonstrates, we can specify partial evidence and/or<br>determine a partial set of directives.</span></nobr></DIV>
<DIV style="position:absolute;top:898;left:81"><nobr><span class="ft1">4.</span></nobr></DIV>
<DIV style="position:absolute;top:898;left:112"><nobr><span class="ft11">INSTRUCTION STREAM GENERATION<br>USING A DYNAMIC NETWORK</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:94"><nobr><span class="ft3">To evaluate the feasibility of the suggested modeling approach</span></nobr></DIV>
<DIV style="position:absolute;top:957;left:81"><nobr><span class="ft7">to the CDG problem, we designed a controlled study that acts in<br>a simple domain (small state space), where we have a deep un-<br>derstanding of the DUT's logic, direct control on the input, and a<br>`ground truth' reference to evaluate performance.</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:94"><nobr><span class="ft3">We conducted the experiment on a model of the pipeline of North-</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:81"><nobr><span class="ft7">Star, an advanced PowerPC processor. The pipeline of NorthStar<br>contains four execution units and a dispatch unit that dispatches in-<br>structions to the execution units. Figure 3 illustrates the general</span></nobr></DIV>
<DIV style="position:absolute;top:88;left:659"><nobr><span class="ft18">Dispatch</span></nobr></DIV>
<DIV style="position:absolute;top:185;left:692"><nobr><span class="ft19">0000</span></nobr></DIV>
<DIV style="position:absolute;top:173;left:692"><nobr><span class="ft19">0000</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:692"><nobr><span class="ft19">0000</span></nobr></DIV>
<DIV style="position:absolute;top:148;left:692"><nobr><span class="ft19">0000</span></nobr></DIV>
<DIV style="position:absolute;top:135;left:692"><nobr><span class="ft19">0000</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:692"><nobr><span class="ft19">0000</span></nobr></DIV>
<DIV style="position:absolute;top:185;left:692"><nobr><span class="ft18">1111</span></nobr></DIV>
<DIV style="position:absolute;top:173;left:692"><nobr><span class="ft18">1111</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:692"><nobr><span class="ft18">1111</span></nobr></DIV>
<DIV style="position:absolute;top:148;left:692"><nobr><span class="ft18">1111</span></nobr></DIV>
<DIV style="position:absolute;top:135;left:692"><nobr><span class="ft18">1111</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:692"><nobr><span class="ft18">1111</span></nobr></DIV>
<DIV style="position:absolute;top:200;left:704"><nobr><span class="ft12"><i>Branch</i></span></nobr></DIV>
<DIV style="position:absolute;top:212;left:702"><nobr><span class="ft12"><i>Pipe (B)</i></span></nobr></DIV>
<DIV style="position:absolute;top:177;left:505"><nobr><span class="ft12"><i>Write Back</i></span></nobr></DIV>
<DIV style="position:absolute;top:153;left:520"><nobr><span class="ft12"><i>Execute</i></span></nobr></DIV>
<DIV style="position:absolute;top:130;left:508"><nobr><span class="ft12"><i>Data Fetch</i></span></nobr></DIV>
<DIV style="position:absolute;top:177;left:581"><nobr><span class="ft12"><i>S3</i></span></nobr></DIV>
<DIV style="position:absolute;top:153;left:581"><nobr><span class="ft12"><i>S2</i></span></nobr></DIV>
<DIV style="position:absolute;top:130;left:581"><nobr><span class="ft12"><i>S1</i></span></nobr></DIV>
<DIV style="position:absolute;top:200;left:558"><nobr><span class="ft12"><i>Simple Arith</i></span></nobr></DIV>
<DIV style="position:absolute;top:212;left:569"><nobr><span class="ft12"><i>Pipe (S)</i></span></nobr></DIV>
<DIV style="position:absolute;top:154;left:652"><nobr><span class="ft14">C2</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:652"><nobr><span class="ft14">C1</span></nobr></DIV>
<DIV style="position:absolute;top:177;left:651"><nobr><span class="ft12"><i>C3</i></span></nobr></DIV>
<DIV style="position:absolute;top:200;left:625"><nobr><span class="ft12"><i>Complex Arith</i></span></nobr></DIV>
<DIV style="position:absolute;top:212;left:639"><nobr><span class="ft12"><i>Pipe (C)</i></span></nobr></DIV>
<DIV style="position:absolute;top:185;left:751"><nobr><span class="ft19">0000</span></nobr></DIV>
<DIV style="position:absolute;top:173;left:751"><nobr><span class="ft19">0000</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:751"><nobr><span class="ft19">0000</span></nobr></DIV>
<DIV style="position:absolute;top:148;left:751"><nobr><span class="ft19">0000</span></nobr></DIV>
<DIV style="position:absolute;top:135;left:751"><nobr><span class="ft19">0000</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:751"><nobr><span class="ft19">0000</span></nobr></DIV>
<DIV style="position:absolute;top:185;left:751"><nobr><span class="ft18">1111</span></nobr></DIV>
<DIV style="position:absolute;top:173;left:751"><nobr><span class="ft18">1111</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:751"><nobr><span class="ft18">1111</span></nobr></DIV>
<DIV style="position:absolute;top:148;left:751"><nobr><span class="ft18">1111</span></nobr></DIV>
<DIV style="position:absolute;top:135;left:751"><nobr><span class="ft18">1111</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:751"><nobr><span class="ft18">1111</span></nobr></DIV>
<DIV style="position:absolute;top:200;left:755"><nobr><span class="ft12"><i>Load/Store</i></span></nobr></DIV>
<DIV style="position:absolute;top:212;left:761"><nobr><span class="ft12"><i>Pipe (L)</i></span></nobr></DIV>
<DIV style="position:absolute;top:244;left:513"><nobr><span class="ft3">Figure 3: The structure of the NorthStar pipeline</span></nobr></DIV>
<DIV style="position:absolute;top:298;left:475"><nobr><span class="ft7">structure of the NorthStar pipeline. For reasons of simplicity, our<br>model contains only the simple arithmetic unit that executes simple<br>arithmetic instructions such as add, and the complex arithmetic unit<br>that can execute both simple and complex arithmetic instructions.<br>Each execution unit consists of three pipeline stages: (1) Data fetch<br>stage, in which the data of the instruction is fetched; (2) Execute<br>stage, in which the instruction is executed; (3) Write back stage,<br>where the result is written back to the target register. The flow of<br>instructions in the pipeline is governed by a simple set of rules.<br>For example, in-order dispatching of instructions to the execution<br>units, and rules for stalling because of data dependency. Note, the<br>complete set of rules is omitted to simplify the description.</span></nobr></DIV>
<DIV style="position:absolute;top:486;left:489"><nobr><span class="ft3">We developed a simple abstract model of the dispatch unit and</span></nobr></DIV>
<DIV style="position:absolute;top:502;left:475"><nobr><span class="ft7">two pipelines and used it to simulate the behavior of the pipeline.<br>The input to our NorthStar model is a simplified subset of the Pow-<br>erPC instruction set. Each instruction is modeled by four input<br>variables. The first variable indicates the type of the instruction.<br>There are five possible types: S - simple arithmetic; C1, C2, C3<br>- complex arithmetic; and NOP - instructions that are executed in<br>other execution units. The second and third input variables consti-<br>tute the source and target register of the instructions. For simplicity<br>and in order to increase the possibility of register interdependency,<br>we used only eight registers instead of the 32 registers available in<br>PowerPC. The last input variable indicates whether the instruction<br>uses the condition register. Due to restrictions on the legal com-<br>binations of the input variables (e.g., NOP instruction is not using<br>registers), there are 449 possible instructions.</span></nobr></DIV>
<DIV style="position:absolute;top:721;left:489"><nobr><span class="ft3">We used a coverage model that examines the state of the two</span></nobr></DIV>
<DIV style="position:absolute;top:737;left:475"><nobr><span class="ft7">pipelines, and properties of the instructions in them. The coverage<br>model consists of five attributes, the type of instruction at stage 1 of<br>the simple and complex arithmetic pipelines (S1Type and C1Type,<br>resp.), flags indicating whether stage 2 of the pipelines are occu-<br>pied (S2Valid and C2Valid, resp.), and a flag indicating whether<br>the instruction at stage 2 of the simple arithmetic pipeline uses the<br>condition register (S2CR). The total number of legal coverage tasks<br>in the model is 54 (out of 80 possible cases).</span></nobr></DIV>
<DIV style="position:absolute;top:863;left:489"><nobr><span class="ft3">The goal of the experiment was to generate instruction streams</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:475"><nobr><span class="ft7">that cover the coverage model described above. Specifically, we<br>concentrated on the ability to reach the desired coverage cases with<br>many, yet relatively short, instruction sequences.</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:489"><nobr><span class="ft3">We modeled the temporal dependencies between the instructions</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:475"><nobr><span class="ft7">and coverage tasks and among the instructions using a two-slice<br>Dynamic Bayesian Network (DBN) [6]. Rather than an accurate<br>mapping of the specific state machine structure, the DBN encoded<br>the general knowledge of an expert on the modus operandi of this<br>type of DUT. Using an expert's domain knowledge proved to be vi-<br>tal in this setup because it provided essential information needed<br>for the generation of instruction streams. Moreover, it enabled<br>the use of hidden nodes, which effectively reduced the complex-<br>ity through dimensionality reduction. The resulting DBN has 19</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft6">289</span></nobr></DIV>
</DIV>
<!-- Page 5 -->
<a name="5"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft20{font-size:6px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="61005.png" alt="background image">
<DIV style="position:absolute;top:86;left:141"><nobr><span class="ft12"><i>Time slice (cycle) t</i></span></nobr></DIV>
<DIV style="position:absolute;top:86;left:283"><nobr><span class="ft12"><i>Time slice (cycle) t+1</i></span></nobr></DIV>
<DIV style="position:absolute;top:324;left:134"><nobr><span class="ft20">Input Node</span></nobr></DIV>
<DIV style="position:absolute;top:324;left:235"><nobr><span class="ft20">Coverage Node</span></nobr></DIV>
<DIV style="position:absolute;top:324;left:352"><nobr><span class="ft20">Hidden Node</span></nobr></DIV>
<DIV style="position:absolute;top:297;left:222"><nobr><span class="ft20">type1</span></nobr></DIV>
<DIV style="position:absolute;top:264;left:195"><nobr><span class="ft20">sr1</span></nobr></DIV>
<DIV style="position:absolute;top:225;left:195"><nobr><span class="ft20">tg1</span></nobr></DIV>
<DIV style="position:absolute;top:185;left:195"><nobr><span class="ft20">cr1</span></nobr></DIV>
<DIV style="position:absolute;top:146;left:192"><nobr><span class="ft20">type2</span></nobr></DIV>
<DIV style="position:absolute;top:287;left:165"><nobr><span class="ft20">sr2</span></nobr></DIV>
<DIV style="position:absolute;top:248;left:165"><nobr><span class="ft20">tg2</span></nobr></DIV>
<DIV style="position:absolute;top:209;left:165"><nobr><span class="ft20">cr2</span></nobr></DIV>
<DIV style="position:absolute;top:297;left:370"><nobr><span class="ft20">type1</span></nobr></DIV>
<DIV style="position:absolute;top:264;left:343"><nobr><span class="ft20">sr1</span></nobr></DIV>
<DIV style="position:absolute;top:225;left:343"><nobr><span class="ft20">tg1</span></nobr></DIV>
<DIV style="position:absolute;top:185;left:343"><nobr><span class="ft20">cr1</span></nobr></DIV>
<DIV style="position:absolute;top:146;left:340"><nobr><span class="ft20">type2</span></nobr></DIV>
<DIV style="position:absolute;top:287;left:313"><nobr><span class="ft20">sr2</span></nobr></DIV>
<DIV style="position:absolute;top:248;left:313"><nobr><span class="ft20">tg2</span></nobr></DIV>
<DIV style="position:absolute;top:209;left:313"><nobr><span class="ft20">cr2</span></nobr></DIV>
<DIV style="position:absolute;top:225;left:135"><nobr><span class="ft20">im0</span></nobr></DIV>
<DIV style="position:absolute;top:146;left:137"><nobr><span class="ft20">ir0</span></nobr></DIV>
<DIV style="position:absolute;top:268;left:223"><nobr><span class="ft20">mv1</span></nobr></DIV>
<DIV style="position:absolute;top:107;left:195"><nobr><span class="ft20">rv1</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:164"><nobr><span class="ft20">rcr1</span></nobr></DIV>
<DIV style="position:absolute;top:225;left:283"><nobr><span class="ft20">im0</span></nobr></DIV>
<DIV style="position:absolute;top:146;left:285"><nobr><span class="ft20">ir0</span></nobr></DIV>
<DIV style="position:absolute;top:268;left:371"><nobr><span class="ft20">mv1</span></nobr></DIV>
<DIV style="position:absolute;top:107;left:343"><nobr><span class="ft20">rv1</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:312"><nobr><span class="ft20">rcr1</span></nobr></DIV>
<DIV style="position:absolute;top:358;left:105"><nobr><span class="ft3">Figure 4: two-slice DBN for the NorthStar experiment</span></nobr></DIV>
<DIV style="position:absolute;top:391;left:221"><nobr><span class="ft3">Rare</span></nobr></DIV>
<DIV style="position:absolute;top:391;left:337"><nobr><span class="ft3">Uncovered</span></nobr></DIV>
<DIV style="position:absolute;top:407;left:177"><nobr><span class="ft3">Instructions</span></nobr></DIV>
<DIV style="position:absolute;top:407;left:257"><nobr><span class="ft3">Cycles</span></nobr></DIV>
<DIV style="position:absolute;top:407;left:309"><nobr><span class="ft3">Instructions</span></nobr></DIV>
<DIV style="position:absolute;top:407;left:389"><nobr><span class="ft3">Cycles</span></nobr></DIV>
<DIV style="position:absolute;top:423;left:94"><nobr><span class="ft3">Training Set</span></nobr></DIV>
<DIV style="position:absolute;top:423;left:205"><nobr><span class="ft3">6</span></nobr></DIV>
<DIV style="position:absolute;top:423;left:272"><nobr><span class="ft3">7</span></nobr></DIV>
<DIV style="position:absolute;top:423;left:339"><nobr><span class="ft3">-</span></nobr></DIV>
<DIV style="position:absolute;top:423;left:405"><nobr><span class="ft3">-</span></nobr></DIV>
<DIV style="position:absolute;top:440;left:94"><nobr><span class="ft3">DBN</span></nobr></DIV>
<DIV style="position:absolute;top:440;left:205"><nobr><span class="ft3">4</span></nobr></DIV>
<DIV style="position:absolute;top:440;left:272"><nobr><span class="ft3">5</span></nobr></DIV>
<DIV style="position:absolute;top:440;left:338"><nobr><span class="ft3">4</span></nobr></DIV>
<DIV style="position:absolute;top:440;left:404"><nobr><span class="ft3">5</span></nobr></DIV>
<DIV style="position:absolute;top:456;left:94"><nobr><span class="ft3">Text Book</span></nobr></DIV>
<DIV style="position:absolute;top:456;left:205"><nobr><span class="ft3">3</span></nobr></DIV>
<DIV style="position:absolute;top:456;left:272"><nobr><span class="ft3">4</span></nobr></DIV>
<DIV style="position:absolute;top:456;left:338"><nobr><span class="ft3">3</span></nobr></DIV>
<DIV style="position:absolute;top:456;left:404"><nobr><span class="ft3">4</span></nobr></DIV>
<DIV style="position:absolute;top:501;left:151"><nobr><span class="ft3">Table 1: NorthStar experiment results</span></nobr></DIV>
<DIV style="position:absolute;top:549;left:81"><nobr><span class="ft7">nodes per slice, 13 of which are observed, 15 intra (within a slice)<br>edges, and 37 inter (between slices) edges (see Fig 4).</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:94"><nobr><span class="ft3">The training set is composed of 1000 sequences of random in-</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:81"><nobr><span class="ft7">structions. The length of each sequence is 10 cycles. Note, the<br>model the we used for the Bayesian network made it easier to mea-<br>sure length in terms of cycles instead of instructions. The training<br>set contained 385 different instructions. During its simulation, 49<br>(out of 54) coverage cases were observed. The average number of<br>instructions per sequence in the training set was 9.7 out of the 20<br>possible dispatches in 10 cycles (i.e., more than half of the dispatch<br>slots in the sequence are empty).</span></nobr></DIV>
<DIV style="position:absolute;top:721;left:94"><nobr><span class="ft3">After training the Bayesian network, we tried to generate instruc-</span></nobr></DIV>
<DIV style="position:absolute;top:737;left:81"><nobr><span class="ft7">tion sequences for all 54 coverage tasks in the coverage model.<br>Each sequence was generated using the DBN, by solving the Most<br>Probable Explanation (MPE) problem for the requested coverage<br>task. All 49 coverage cases of the training set plus three addi-<br>tional uncovered cases were reached using instruction sequences<br>designed by the DBN. In addition, we generated many different in-<br>struction sequences for each coverage task that was covered by the<br>Bayesian network. The average number of cycles in a generated se-<br>quence dropped to 2.9, while the average number of instructions in<br>a sequence reduced to 3.7. This reflects the fact that the generated<br>instruction sequences cause less stall states en-route to reaching the<br>desired coverage cases. Table 1 illustrates the details of reaching<br>two difficult coverage cases--the rarest coverage task, which was<br>seen only once in the training set, and an uncovered task. The ta-<br>ble shows the number of cycles and instructions required to reach<br>these tasks in the training set, the instruction sequences generated<br>by the trained DBN, and the `text book' solution--the best pos-<br>sible sequence. The table indicates that the instruction sequences<br>generated by the DBN are shorter, both in instructions and cycles,<br>than the sequences in the training set. Overall, the results indicate<br>that the trained DBN is able to generate many compact instruction<br>sequences that are not far from the best possible solution.</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:773"><nobr><span class="ft14">Resp</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:731"><nobr><span class="ft14">Cmd</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:654"><nobr><span class="ft14">Resp</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:612"><nobr><span class="ft14">Cmd</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:560"><nobr><span class="ft14">Resp</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:518"><nobr><span class="ft14">Cmd</span></nobr></DIV>
<DIV style="position:absolute;top:187;left:548"><nobr><span class="ft14">Pipe 0</span></nobr></DIV>
<DIV style="position:absolute;top:187;left:737"><nobr><span class="ft14">Pipe 1</span></nobr></DIV>
<DIV style="position:absolute;top:234;left:516"><nobr><span class="ft14">Core 0</span></nobr></DIV>
<DIV style="position:absolute;top:234;left:556"><nobr><span class="ft14">Core 1</span></nobr></DIV>
<DIV style="position:absolute;top:234;left:611"><nobr><span class="ft14">Core 0</span></nobr></DIV>
<DIV style="position:absolute;top:234;left:650"><nobr><span class="ft14">Core 1</span></nobr></DIV>
<DIV style="position:absolute;top:234;left:729"><nobr><span class="ft14">Core 0</span></nobr></DIV>
<DIV style="position:absolute;top:234;left:768"><nobr><span class="ft14">Core 1</span></nobr></DIV>
<DIV style="position:absolute;top:147;left:611"><nobr><span class="ft18">Storage Control</span></nobr></DIV>
<DIV style="position:absolute;top:165;left:632"><nobr><span class="ft18">Element</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:638"><nobr><span class="ft18">(SCE)</span></nobr></DIV>
<DIV style="position:absolute;top:94;left:601"><nobr><span class="ft18">Memory Subsystem</span></nobr></DIV>
<DIV style="position:absolute;top:247;left:537"><nobr><span class="ft18">CP0</span></nobr></DIV>
<DIV style="position:absolute;top:247;left:632"><nobr><span class="ft18">CP1</span></nobr></DIV>
<DIV style="position:absolute;top:247;left:750"><nobr><span class="ft18">CP7</span></nobr></DIV>
<DIV style="position:absolute;top:283;left:495"><nobr><span class="ft3">Figure 5: The structure of SCE simulation environment</span></nobr></DIV>
<DIV style="position:absolute;top:333;left:475"><nobr><span class="ft1">5.</span></nobr></DIV>
<DIV style="position:absolute;top:333;left:507"><nobr><span class="ft11">STORAGE CONTROL EXPERIMENT US-<br>ING A STATIC NETWORK</span></nobr></DIV>
<DIV style="position:absolute;top:376;left:489"><nobr><span class="ft3">The second experiment was conducted in a real-life setting. The</span></nobr></DIV>
<DIV style="position:absolute;top:392;left:475"><nobr><span class="ft7">design under test in the experiment is the Storage Control Element<br>(SCE) of an IBM z-series system. Figure 5 shows the structure of<br>the SCE and its simulation environment. The SCE handles com-<br>mands from eight CPUs (CP0 ­ CP7). Each CPU consists of two<br>cores that generate commands to the SCE independently. The SCE<br>handles incoming commands using two internal pipelines. When<br>the SCE finishes handling a command, it sends a response to the<br>commanding CPU.</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:489"><nobr><span class="ft3">The simulation environment for the SCE contains, in addition to</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:475"><nobr><span class="ft7">the SCE itself, behavioral models for the eight CPUs that it ser-<br>vices, and a behavioral model for the memory subsystem. The be-<br>havioral models of the CPUs generate commands to the SCE based<br>on their internal state and a directive file provided by the user. The<br>directive file contains a set of parameters that affect the behavior<br>of the system. Some of these parameters control the entire sys-<br>tem while others are specific to certain components of the system,<br>such as a specific CPU. Figure 2 shows an example of some pa-<br>rameters that are used in the simulation environment of the SCE.<br>Each parameter contains a set of possible values that the parameter<br>can receive. Each value has a weight associated with it. When<br>the value of a parameter is needed, it is randomly chosen from<br>the set of possible values according the weights of these values.<br>For example, when a CPU generates a new command, it first uses<br>the cp cmd type parameter to determine the type of command to<br>generate, and then a specific parameter for that command type to<br>determine the exact command to be used.</span></nobr></DIV>
<DIV style="position:absolute;top:800;left:489"><nobr><span class="ft3">In the experiment, we tried to cover all the possible transactions</span></nobr></DIV>
<DIV style="position:absolute;top:816;left:475"><nobr><span class="ft7">between the CPUs and the SCE. The coverage model contained five<br>attributes: The CPU (8 possible values) and the core (2 values) in<br>it that initiated the command, the command itself (31 values), its<br>response (14 values), and the pipeline in the SCE that handled it (2<br>values). Overall, the cross product contains 13,888 cases and the<br>coverage model contains 1968 legal coverage tasks.</span></nobr></DIV>
<DIV style="position:absolute;top:910;left:489"><nobr><span class="ft3">This experiment added many new challenges over the controlled</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:475"><nobr><span class="ft7">experiment described in the previous section. First, our knowledge<br>about the DUT in this experiment was very limited compared to<br>the full understanding of the design in the first experiment. In addi-<br>tion, we were less able to observe and control the input and output<br>nodes of the Bayesian network. For the test parameters, we could<br>only specify the distribution of each parameter and we could not<br>observe the values that were actually used, only their distribution.<br>Moreover, in some cases the behavioral models ignored the param-<br>eters and generated commands based on their internal state. Thus,<br>the actual distribution used was not exactly the provided distribu-</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft6">290</span></nobr></DIV>
</DIV>
<!-- Page 6 -->
<a name="6"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft21{font-size:4px;font-family:Times;color:#000000;}
	.ft22{font-size:4px;line-height:-4px;font-family:Times;color:#000000;}
	.ft23{font-size:4px;line-height:-3px;font-family:Times;color:#000000;}
	.ft24{font-size:3px;line-height:5px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="61006.png" alt="background image">
<DIV style="position:absolute;top:256;left:157"><nobr><span class="ft10">0</span></nobr></DIV>
<DIV style="position:absolute;top:256;left:180"><nobr><span class="ft10">50</span></nobr></DIV>
<DIV style="position:absolute;top:256;left:202"><nobr><span class="ft10">100</span></nobr></DIV>
<DIV style="position:absolute;top:256;left:226"><nobr><span class="ft10">150</span></nobr></DIV>
<DIV style="position:absolute;top:256;left:250"><nobr><span class="ft10">200</span></nobr></DIV>
<DIV style="position:absolute;top:256;left:274"><nobr><span class="ft10">250</span></nobr></DIV>
<DIV style="position:absolute;top:256;left:298"><nobr><span class="ft10">300</span></nobr></DIV>
<DIV style="position:absolute;top:256;left:321"><nobr><span class="ft10">350</span></nobr></DIV>
<DIV style="position:absolute;top:256;left:345"><nobr><span class="ft10">400</span></nobr></DIV>
<DIV style="position:absolute;top:256;left:369"><nobr><span class="ft10">450</span></nobr></DIV>
<DIV style="position:absolute;top:252;left:153"><nobr><span class="ft10">0</span></nobr></DIV>
<DIV style="position:absolute;top:218;left:151"><nobr><span class="ft10">50</span></nobr></DIV>
<DIV style="position:absolute;top:185;left:148"><nobr><span class="ft10">100</span></nobr></DIV>
<DIV style="position:absolute;top:151;left:148"><nobr><span class="ft10">150</span></nobr></DIV>
<DIV style="position:absolute;top:117;left:148"><nobr><span class="ft10">200</span></nobr></DIV>
<DIV style="position:absolute;top:83;left:148"><nobr><span class="ft10">250</span></nobr></DIV>
<DIV style="position:absolute;top:264;left:251"><nobr><span class="ft21">Test-cases</span></nobr></DIV>
<DIV style="position:absolute;top:185;left:146"><nobr><span class="ft22">C<br>overe</span></nobr></DIV>
<DIV style="position:absolute;top:163;left:146"><nobr><span class="ft22">d<br> <br>T<br>as</span></nobr></DIV>
<DIV style="position:absolute;top:146;left:146"><nobr><span class="ft23">k<br>s</span></nobr></DIV>
<DIV style="position:absolute;top:241;left:347"><nobr><span class="ft24">CDG<br>Baseline</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:148"><nobr><span class="ft10">223</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:121"><nobr><span class="ft3">Figure 6: Coverage progress of the CDG process</span></nobr></DIV>
<DIV style="position:absolute;top:349;left:81"><nobr><span class="ft7">tion of the parameters. This type of observation (distribution in-<br>stead of specific value) is known as a soft evidence. The coverage<br>data that we got out of the simulation environment was a summary<br>of all the coverage tasks that occurred during the simulation of a<br>test-case. Therefore, it was hard to correlate between the observed<br>coverage tasks and the parameters' values that caused them and be-<br>tween the different observed coverage tasks.</span></nobr></DIV>
<DIV style="position:absolute;top:459;left:94"><nobr><span class="ft3">Because we had limited knowledge about the DUT and the cor-</span></nobr></DIV>
<DIV style="position:absolute;top:475;left:81"><nobr><span class="ft7">relation between the parameters in the test directives and the cov-<br>erage tasks, the first Bayesian network we constructed contained<br>arcs between each of the coverage variables and each of the test<br>parameters. We trained this network with 160 test-cases (each tak-<br>ing more than 30 minutes to execute). After the initial training, we<br>analyzed the Bayesian network and found out that most of the test<br>parameters were strongly correlated either to the command and re-<br>sponse coverage variables or the pipe and core variables, but only<br>a single variable was strongly correlated to all coverage variables.<br>Therefore, we partitioned the Bayesian network into two networks,<br>one for command and response and the other for core and pipe.<br>The result of the inference on the common parameter from the first<br>network was used as input for the second one. We trained the sec-<br>ond network with the same training set of 160 test-cases. During<br>the training, 1745 out of the 1968 tasks in the model were covered,<br>while 223 remained uncovered.</span></nobr></DIV>
<DIV style="position:absolute;top:726;left:94"><nobr><span class="ft3">We checked the performance of the trained network and its abil-</span></nobr></DIV>
<DIV style="position:absolute;top:742;left:81"><nobr><span class="ft7">ity to increase the coverage rate for the uncovered tasks in the train-<br>ing set. The baseline for comparison was the progress achieved by<br>the best test directive file created by an expert user.</span></nobr></DIV>
<DIV style="position:absolute;top:789;left:94"><nobr><span class="ft3">We tried to maximize the coverage progress rate using a large</span></nobr></DIV>
<DIV style="position:absolute;top:804;left:81"><nobr><span class="ft7">number of test directive files aimed at specific sets of uncovered<br>tasks. This approach is not realistic for a human user due the ef-<br>fort needed to create each set of directives. However, it is useful<br>for the automatic creation of directives, because the inference time<br>from the trained network is negligible. Our method to maximize<br>the coverage progress rate was to randomly partition the uncov-<br>ered tasks, use the trained network to create a test directive file<br>for each partition, and simulate a single test-case for each directive<br>file. This process was repeated until all the tasks were covered.<br>The CDG process was able to cover all uncovered tasks after 250<br>test-cases, while the baseline case of the user defined test directives<br>file covered only two thirds of them after over 400 test-cases (see<br>Figure 6).</span></nobr></DIV>
<DIV style="position:absolute;top:1028;left:81"><nobr><span class="ft1">6.</span></nobr></DIV>
<DIV style="position:absolute;top:1028;left:112"><nobr><span class="ft1">CONCLUSIONS AND FUTURE WORK</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:94"><nobr><span class="ft3">In this paper we demonstrated how Bayesian networks can be</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:81"><nobr><span class="ft3">used to close the loop between coverage data and directives to test</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft7">generators. The experiments described in the paper show that this<br>modeling technique can be efficiently used to achieve the CDG<br>goals of easier reach for hard coverage cases, diverse reach for av-<br>erage cases, and improved coverage progress rate. It should be<br>noted that the suggested CDG method is not limited to the types<br>of simulation environments handled in this paper (i.e., parameters-<br>based test generation and direct stimuli generation). It can be used<br>in other types of environments, such as test generators in which the<br>control on the stimuli is embedded in the generator itself.</span></nobr></DIV>
<DIV style="position:absolute;top:228;left:489"><nobr><span class="ft3">Our future work has two distinct aspects: enhancing the learning</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:475"><nobr><span class="ft7">capabilities and effectively applying the suggested framework to<br>the verification process. From the learning perspective, we plan<br>to explore other techniques that may increase our capabilities. For<br>example, incremental structure learning as a means for encoding<br>richer domain knowledge, and the efficient construction of good<br>queries to boost targeting rare cases using selective sampling. To<br>effectively deploy the CDG framework, we need to gain a better<br>understanding of the type of knowledge that should be encoded in<br>the model, and to identify in which areas the suggested approach<br>may prove most beneficial to the verification process.</span></nobr></DIV>
<DIV style="position:absolute;top:417;left:475"><nobr><span class="ft1">7.</span></nobr></DIV>
<DIV style="position:absolute;top:417;left:507"><nobr><span class="ft1">REFERENCES</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:484"><nobr><span class="ft4">[1] J. Bergeron. Writing Testbenches: Functional Verification of HDL</span></nobr></DIV>
<DIV style="position:absolute;top:452;left:504"><nobr><span class="ft4">Models. Kluwer Academic Publishers, January 2000.</span></nobr></DIV>
<DIV style="position:absolute;top:467;left:484"><nobr><span class="ft4">[2] M. Bose, J. Shin, E. M. Rudnick, T. Dukes, and M. Abadir. A</span></nobr></DIV>
<DIV style="position:absolute;top:481;left:504"><nobr><span class="ft8">genetic approach to automatic bias generation for biased random<br>instruction generation. In Proceedings of the 2001 Congress on<br>Evolutionary Computation CEC2001, pages 442­448, May 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:523;left:484"><nobr><span class="ft4">[3] R. G. Cowell, A. P. Dawid, S. L. Lauritzen, and D. J. Spiegelhalter.</span></nobr></DIV>
<DIV style="position:absolute;top:536;left:504"><nobr><span class="ft4">Probabilistic Networks and Expert Systems. Springer-Verlag, 1999.</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:484"><nobr><span class="ft4">[4] G. Elidan, N. Lotner, N. Friedman, and D. Koller. Discovering</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:504"><nobr><span class="ft8">hidden variables: A structure-based approach. In Proceedings of the<br>13th Annual Conference on Neural Information Processing Systems,<br>pages 479­485, 2000.</span></nobr></DIV>
<DIV style="position:absolute;top:606;left:484"><nobr><span class="ft4">[5] L. Fournier, Y. Arbetman, and M. Levinger. Functional verification</span></nobr></DIV>
<DIV style="position:absolute;top:620;left:504"><nobr><span class="ft8">methodology for microprocessors using the Genesys test-program<br>generator. In Proceedings of the 1999 Design, Automation and Test<br>in Europe Conference (DATE), pages 434­441, March 1999.</span></nobr></DIV>
<DIV style="position:absolute;top:662;left:484"><nobr><span class="ft4">[6] Z. Ghahramani. Learning dynamic Bayesian networks. In Adaptive</span></nobr></DIV>
<DIV style="position:absolute;top:675;left:504"><nobr><span class="ft8">Processing of Sequences and Data Structures, Lecture Notes in<br>Artificial Intelligence, pages 168­197. Springer-Verlag, 1998.</span></nobr></DIV>
<DIV style="position:absolute;top:703;left:484"><nobr><span class="ft4">[7] R. Grinwald, E. Harel, M. Orgad, S. Ur, and A. Ziv. User defined</span></nobr></DIV>
<DIV style="position:absolute;top:717;left:504"><nobr><span class="ft8">coverage - a tool supported methodology for design verification. In<br>Proceedings of the 35th Design Automation Conference, pages<br>158­165, June 1998.</span></nobr></DIV>
<DIV style="position:absolute;top:759;left:484"><nobr><span class="ft4">[8] A. Hartman, S. Ur, and A. Ziv. Short vs long size does make a</span></nobr></DIV>
<DIV style="position:absolute;top:772;left:504"><nobr><span class="ft8">difference. In Proceedings of the High-Level Design Validation and<br>Test Workshop, pages 23­28, November 1999.</span></nobr></DIV>
<DIV style="position:absolute;top:800;left:484"><nobr><span class="ft4">[9] D. Heckerman. A tutorial on learning with Bayesian networks.</span></nobr></DIV>
<DIV style="position:absolute;top:814;left:504"><nobr><span class="ft4">Technical report, Microsoft Research, 1996.</span></nobr></DIV>
<DIV style="position:absolute;top:829;left:478"><nobr><span class="ft4">[10] D. Heckerman, A. Mamdani, and M. Wellman. Real-world</span></nobr></DIV>
<DIV style="position:absolute;top:842;left:504"><nobr><span class="ft8">applications of Bayesian networks. Communications of the ACM,<br>38(3):24­30, 1995.</span></nobr></DIV>
<DIV style="position:absolute;top:871;left:478"><nobr><span class="ft4">[11] G. Nativ, S. Mittermaier, S. Ur, and A. Ziv. Cost evaluation of</span></nobr></DIV>
<DIV style="position:absolute;top:884;left:504"><nobr><span class="ft8">coverage directed test generation for the IBM mainframe. In<br>Proceedings of the 2001 International Test Conference, pages<br>793­802, October 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:926;left:478"><nobr><span class="ft4">[12] J. Pearl. Probabilistic Reasoning in Intelligent Systems: Network of</span></nobr></DIV>
<DIV style="position:absolute;top:939;left:504"><nobr><span class="ft4">Plausible Inference. Morgan Kaufmann, 1988.</span></nobr></DIV>
<DIV style="position:absolute;top:954;left:478"><nobr><span class="ft4">[13] S. Tasiran, F. Fallah, D. G. Chinnery, S. J. Weber, and K. Keutzer. A</span></nobr></DIV>
<DIV style="position:absolute;top:968;left:504"><nobr><span class="ft8">functional validation technique: biased-random simulation guided<br>by observability-based coverage. In Proceedings of the International<br>Conference on Computer Design, pages 82­88, September 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:1010;left:478"><nobr><span class="ft4">[14] S. Ur and Y. Yadin. Micro-architecture coverage directed generation</span></nobr></DIV>
<DIV style="position:absolute;top:1023;left:504"><nobr><span class="ft8">of test programs. In Proceedings of the 36th Design Automation<br>Conference, pages 175­180, June 1999.</span></nobr></DIV>
<DIV style="position:absolute;top:1052;left:478"><nobr><span class="ft4">[15] S. Wright. Correlation and causation. Journal of Agricultural</span></nobr></DIV>
<DIV style="position:absolute;top:1065;left:504"><nobr><span class="ft4">Research, 1921.</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft6">291</span></nobr></DIV>
</DIV>
</BODY>
</HTML>
