<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
<HEAD>
<TITLE>D:\Paper\HTML\150</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<META name="generator" content="pdftohtml 0.35beta">
<META name="date" content="2005-11-23T21:57:50+00:00">
</HEAD>
<BODY bgcolor="#A0A0A0" vlink="blue" link="blue">
<!-- Page 1 -->
<a name="1"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft0{font-size:24px;font-family:Helvetica;color:#000000;}
	.ft1{font-size:15px;font-family:Helvetica;color:#000000;}
	.ft2{font-size:12px;font-family:Helvetica;color:#000000;}
	.ft3{font-size:15px;font-family:Times;color:#000000;}
	.ft4{font-size:11px;font-family:Times;color:#000000;}
	.ft5{font-size:9px;font-family:Times;color:#000000;}
	.ft6{font-size:9px;font-family:Times;color:#000000;}
	.ft7{font-size:16px;font-family:Courier;color:#000000;}
	.ft8{font-size:11px;font-family:Times;color:#000000;}
	.ft9{font-size:11px;line-height:15px;font-family:Times;color:#000000;}
	.ft10{font-size:9px;line-height:13px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="150001.png" alt="background image">
<DIV style="position:absolute;top:108;left:104"><nobr><span class="ft0"><b>Preventing Attribute Information Leakage in Automated</b></span></nobr></DIV>
<DIV style="position:absolute;top:138;left:347"><nobr><span class="ft0"><b>Trust Negotiation</b></span></nobr></DIV>
<DIV style="position:absolute;top:207;left:235"><nobr><span class="ft1">Keith Irwin</span></nobr></DIV>
<DIV style="position:absolute;top:225;left:174"><nobr><span class="ft2">North Carolina State University</span></nobr></DIV>
<DIV style="position:absolute;top:240;left:217"><nobr><span class="ft2">Raleigh, NC, USA</span></nobr></DIV>
<DIV style="position:absolute;top:262;left:208"><nobr><span class="ft1">kirwin@ncsu.edu</span></nobr></DIV>
<DIV style="position:absolute;top:207;left:608"><nobr><span class="ft1">Ting Yu</span></nobr></DIV>
<DIV style="position:absolute;top:225;left:535"><nobr><span class="ft2">North Carolina State University</span></nobr></DIV>
<DIV style="position:absolute;top:240;left:578"><nobr><span class="ft2">Raleigh, NC, USA</span></nobr></DIV>
<DIV style="position:absolute;top:262;left:567"><nobr><span class="ft1">yu@csc.ncsu.edu</span></nobr></DIV>
<DIV style="position:absolute;top:317;left:81"><nobr><span class="ft3"><b>ABSTRACT</b></span></nobr></DIV>
<DIV style="position:absolute;top:341;left:81"><nobr><span class="ft9">Automated trust negotiation is an approach which estab-<br>lishes trust between strangers through the bilateral, itera-<br>tive disclosure of digital credentials. Sensitive credentials<br>are protected by access control policies which may also be<br>communicated to the other party. Ideally, sensitive informa-<br>tion should not be known by others unless its access control<br>policy has been satisfied. However, due to bilateral informa-<br>tion exchange, information may flow to others in a variety<br>of forms, many of which cannot be protected by access con-<br>trol policies alone. In particular, sensitive information may<br>be inferred by observing negotiation participants' behavior<br>even when access control policies are strictly enforced.</span></nobr></DIV>
<DIV style="position:absolute;top:530;left:94"><nobr><span class="ft4">In this paper, we propose a general framework for the</span></nobr></DIV>
<DIV style="position:absolute;top:545;left:81"><nobr><span class="ft9">safety of trust negotiation systems. Compared to the ex-<br>isting safety model, our framework focuses on the actual<br>information gain during trust negotiation instead of the ex-<br>changed messages. Thus, it directly reflects the essence of<br>safety in sensitive information protection. Based on the pro-<br>posed framework, we develop policy databases as a mecha-<br>nism to help prevent unauthorized information inferences<br>during trust negotiation. We show that policy databases<br>achieve the same protection of sensitive information as ex-<br>isting solutions without imposing additional complications<br>to the interaction between negotiation participants or re-<br>stricting users' autonomy in defining their own policies.</span></nobr></DIV>
<DIV style="position:absolute;top:738;left:81"><nobr><span class="ft3">Categories and Subject Descriptors</span></nobr></DIV>
<DIV style="position:absolute;top:738;left:81"><nobr><span class="ft9">K.6.5 [Manage-<br>ment of Computing and Information Systems]: Security and<br>Protection</span></nobr></DIV>
<DIV style="position:absolute;top:790;left:81"><nobr><span class="ft3">General Terms</span></nobr></DIV>
<DIV style="position:absolute;top:790;left:81"><nobr><span class="ft4">Security, Theory</span></nobr></DIV>
<DIV style="position:absolute;top:811;left:81"><nobr><span class="ft9">Keywords: Privacy, Trust Negotiation, Attribute-based<br>Access Control</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:81"><nobr><span class="ft3"><b>1.</b></span></nobr></DIV>
<DIV style="position:absolute;top:861;left:117"><nobr><span class="ft3"><b>INTRODUCTION</b></span></nobr></DIV>
<DIV style="position:absolute;top:883;left:94"><nobr><span class="ft4">Automated trust negotiation (ATN) is an approach to</span></nobr></DIV>
<DIV style="position:absolute;top:899;left:81"><nobr><span class="ft9">access control and authentication in open, flexible systems<br>such as the Internet. ATN enables open computing by as-</span></nobr></DIV>
<DIV style="position:absolute;top:977;left:81"><nobr><span class="ft10">Permission to make digital or hard copies of all or part of this work for<br>personal or classroom use is granted without fee provided that copies are<br>not made or distributed for profit or commercial advantage and that copies<br>bear this notice and the full citation on the first page. To copy otherwise, to<br>republish, to post on servers or to redistribute to lists, requires prior specific<br>permission and/or a fee.<br><i>CCS'05, </i>November 7­11, 2005, Alexandria, Virginia, USA.<br>Copyright 2005 ACM 1-59593-226-7/05/0011 ...</span></nobr></DIV>
<DIV style="position:absolute;top:1070;left:315"><nobr><span class="ft4">$</span></nobr></DIV>
<DIV style="position:absolute;top:1071;left:322"><nobr><span class="ft5">5.00.</span></nobr></DIV>
<DIV style="position:absolute;top:320;left:475"><nobr><span class="ft9">signing an access control policy to each resource that is to<br>be made available to entities from different domains. An<br>access control policy describes the attributes of the entities<br>allowed to access that resource, in contrast to the traditional<br>approach of listing their identities. To satisfy an access con-<br>trol policy, a user has to demonstrate that they have the<br>attributes named in the policy through the use of digital<br>credentials. Since one's attributes may also be sensitive, the<br>disclosure of digital credentials is also protected by access<br>control policies.</span></nobr></DIV>
<DIV style="position:absolute;top:477;left:489"><nobr><span class="ft4">A trust negotiation is triggered when one party requests</span></nobr></DIV>
<DIV style="position:absolute;top:492;left:475"><nobr><span class="ft9">access to a resource owned by another party. Since each<br>party may have policies that the other needs to satisfy, trust<br>is established incrementally through bilateral disclosures of<br>credentials and requests for credentials, a characteristic that<br>distinguishes trust negotiation from other trust establish-<br>ment approaches [2, 11].</span></nobr></DIV>
<DIV style="position:absolute;top:587;left:489"><nobr><span class="ft4">Access control policies play a central role in protecting</span></nobr></DIV>
<DIV style="position:absolute;top:602;left:475"><nobr><span class="ft9">privacy during trust negotiation. Ideally, an entity's sensi-<br>tive information should not be known by others unless they<br>have satisfied the corresponding access control policy. How-<br>ever, depending on the way two parties interact with each<br>other, one's private information may flow to others in vari-<br>ous forms, which are not always controlled by access control<br>policies. In particular, the different behaviors of a negoti-<br>ation participant may be exploited to infer sensitive infor-<br>mation, even if credentials containing that information are<br>never directly disclosed.</span></nobr></DIV>
<DIV style="position:absolute;top:759;left:489"><nobr><span class="ft4">For example, suppose a resource's policy requires Alice to</span></nobr></DIV>
<DIV style="position:absolute;top:775;left:475"><nobr><span class="ft9">prove a sensitive attribute such as employment by the CIA.<br>If Alice has this attribute, then she likely protects it with an<br>access control policy. Thus, as a response, Alice will ask the<br>resource provider to satisfy her policy. On the other hand,<br>if Alice does not have the attribute, then a natural response<br>would be for her to terminate the negotiation since there is<br>no way that she can access the resource. Thus, merely from<br>Alice's response, the resource provider may infer with high<br>confidence whether or not Alice is working for the CIA, even<br>though her access control policy is strictly enforced.</span></nobr></DIV>
<DIV style="position:absolute;top:932;left:489"><nobr><span class="ft4">The problem of unauthorized information flow in ATN has</span></nobr></DIV>
<DIV style="position:absolute;top:947;left:475"><nobr><span class="ft9">been noted by several groups of researchers [20, 22, 27]. A<br>variety of approaches have been proposed, which mainly fall<br>into two categories. Approaches in the first category try to<br>"break" the correlation between different information. Intu-<br>itively, if the disclosed policy for an attribute is independent<br>from the possession of the attribute, then the above inference<br>is impossible. A representative approach in this category is<br>by Seamons et al. [20], where an entity possessing a sensi-</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:452"><nobr><span class="ft8">36</span></nobr></DIV>
</DIV>
<!-- Page 2 -->
<a name="2"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft11{font-size:6px;font-family:Times;color:#000000;}
	.ft12{font-size:6px;line-height:10px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="150002.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft9">tive credential always responds with a cover policy of f alse<br>to pretend the opposite. Only when the actual policy is sat-<br>isfied by the credentials disclosed by the opponent will the<br>entity disclose the credential. Clearly, since the disclosed<br>policy is always f alse, it is not correlated to the possession<br>of the credential. One obvious problem with this approach,<br>however, is that a potentially successful negotiation may fail<br>because an entity pretends to not have the credential.</span></nobr></DIV>
<DIV style="position:absolute;top:212;left:94"><nobr><span class="ft4">Approaches in the second category aim to make the cor-</span></nobr></DIV>
<DIV style="position:absolute;top:228;left:81"><nobr><span class="ft9">relation between different information "safe", i.e., when an<br>opponent is able to infer some sensitive information through<br>the correlation, it is already entitled to know that informa-<br>tion. For example, Winsborough and Li [23] proposed the<br>use of acknowledgement policies ("Ack policies" for short) as<br>a solution. Their approach is based on the principle "discuss<br>sensitive topics only with appropriate parties". Therefore,<br>besides an access control policy P , Alice also associates an<br>Ack policy P</span></nobr></DIV>
<DIV style="position:absolute;top:358;left:161"><nobr><span class="ft11">Ack</span></nobr></DIV>
<DIV style="position:absolute;top:353;left:187"><nobr><span class="ft4">with a sensitive attribute A. Intuitively,</span></nobr></DIV>
<DIV style="position:absolute;top:369;left:81"><nobr><span class="ft4">P</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:90"><nobr><span class="ft11">Ack</span></nobr></DIV>
<DIV style="position:absolute;top:369;left:115"><nobr><span class="ft4">determines when Alice can tell others whether or not</span></nobr></DIV>
<DIV style="position:absolute;top:384;left:81"><nobr><span class="ft9">she has attribute A. During a negotiation, when the at-<br>tribute is requested, the Ack policy P</span></nobr></DIV>
<DIV style="position:absolute;top:405;left:313"><nobr><span class="ft11">Ack</span></nobr></DIV>
<DIV style="position:absolute;top:400;left:338"><nobr><span class="ft4">is first sent back</span></nobr></DIV>
<DIV style="position:absolute;top:416;left:81"><nobr><span class="ft4">as a reply. Only when P</span></nobr></DIV>
<DIV style="position:absolute;top:421;left:231"><nobr><span class="ft11">Ack</span></nobr></DIV>
<DIV style="position:absolute;top:416;left:256"><nobr><span class="ft4">is satisfied by the other party,</span></nobr></DIV>
<DIV style="position:absolute;top:432;left:81"><nobr><span class="ft9">will Alice disclose whether or not she has A and may then<br>ask the other party to satisfy the access control policy P .<br>In order to prevent additional correlation introduced by Ack<br>policies, it is required that all entities use the same Ack pol-<br>icy to protect a given attribute regardless of whether or not<br>they have A. In [23], Winsborough and Li also formally de-<br>fined the safety requirements in trust negotiation based on<br>Ack policies.</span></nobr></DIV>
<DIV style="position:absolute;top:557;left:94"><nobr><span class="ft4">Though the approach of Ack policies can provide protec-</span></nobr></DIV>
<DIV style="position:absolute;top:573;left:81"><nobr><span class="ft9">tion against unauthorized inferences, it has a significant dis-<br>advantage. One benefit of automated trust negotiation is<br>that it gives each entity the autonomy to determine the ap-<br>propriate protection for its own resources and credentials.<br>The perceived sensitivity of possessing an attribute may be<br>very different for different entities. For example, some may<br>consider the possession of a certificate showing eligibility for<br>food stamps highly sensitive, and thus would like to have a<br>very strict Ack policy for it. Some others may not care as<br>much, and have a less strict Ack policy, because they are<br>more concerned with their ability to get services than their<br>privacy. The Ack Policy system, however, requires that all<br>entities use the same Ack policy for a given attribute, which.<br>deprives entities of the autonomy to make their own deci-<br>sions. This will inevitably be over-protective for some and<br>under-protective for others. And either situation will result<br>in users preferring not to participate in the system.</span></nobr></DIV>
<DIV style="position:absolute;top:839;left:94"><nobr><span class="ft4">In this paper, we first propose a general framework for safe</span></nobr></DIV>
<DIV style="position:absolute;top:855;left:81"><nobr><span class="ft9">information flow in automated trust negotiation. Compared<br>with that proposed by Winsborough and Li, our framework<br>focuses on modeling the actual information gain caused by<br>information flow instead of the messages exchanged. There-<br>fore it directly reflects the essence of safety in sensitive in-<br>formation protection. Based on this framework, we propose<br>policy databases as a solution to the above problem. Policy<br>databases not only prevent unauthorized inferences as de-<br>scribed above but also preserve users' autonomy in deciding<br>their own policies. In order to do this, we focus on sever-<br>ing the correlation between attributes and policies by intro-<br>ducing randomness, rather than adding additional layers or<br>fixed policies as in the Ack Policy system. In our approach,<br>there is a central database of policies for each possession</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft9">sensitive attribute. Users who possess the attribute submit<br>their policies to the database anonymously. Users who do<br>not possess the attribute can then draw a policy at random<br>from the database. The result of this process is that the<br>distributions of policies for a given possession sensitive at-<br>tribute are identical for users who have the attribute and<br>users who do not. Thus, an opponent cannot infer whether<br>or not users possess the attribute by looking at their policies.</span></nobr></DIV>
<DIV style="position:absolute;top:212;left:489"><nobr><span class="ft4">The rest of the paper is organized as follows. In section</span></nobr></DIV>
<DIV style="position:absolute;top:228;left:475"><nobr><span class="ft9">2, we propose a formal definition of safety for automated<br>trust negotiation. In section 3, we discuss the specifics of<br>our approach, including what assumptions underlie it, how<br>well it satisfies our safety principle, both theoretically and<br>in practical situations, and what practical concerns to im-<br>plementing it exist. Closely related work to this paper is<br>reported in section 4. We conclude this paper in section 5</span></nobr></DIV>
<DIV style="position:absolute;top:356;left:475"><nobr><span class="ft3"><b>2.</b></span></nobr></DIV>
<DIV style="position:absolute;top:356;left:511"><nobr><span class="ft3"><b>SAFETY IN TRUST NEGOTIATION</b></span></nobr></DIV>
<DIV style="position:absolute;top:378;left:489"><nobr><span class="ft4">In [23], Winsborough and Li put forth several definitions</span></nobr></DIV>
<DIV style="position:absolute;top:394;left:475"><nobr><span class="ft9">of safety in trust negotiation based on an underlying notion<br>of indistinguishability. The essence of indistinguishability is<br>that if an opponent is given the opportunity to interact with<br>a user in two states corresponding to two different potential<br>sets of attributes, the opponent cannot detect a difference<br>in those sets of attributes based on the messages sent. In<br>the definition of deterministic indistinguishability, the mes-<br>sages sent in the two states must be precisely the same. In<br>the definition of probabilistic indistinguishability, they must<br>have precisely the same distribution.</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:489"><nobr><span class="ft4">These definitions, however, are overly strict. To determine</span></nobr></DIV>
<DIV style="position:absolute;top:567;left:475"><nobr><span class="ft9">whether or not a given user has a credential, it is not suffi-<br>cient for an opponent to know that the user acts differently<br>depending on whether or not that user has the credential:<br>the opponent also has to be able to figure out which behavior<br>corresponds to having the credential and which corresponds<br>to lacking the credential. Otherwise, the opponent has not<br>actually gained any information about the user.</span></nobr></DIV>
<DIV style="position:absolute;top:693;left:490"><nobr><span class="ft4">Example 1. Suppose we have a system in which there</span></nobr></DIV>
<DIV style="position:absolute;top:707;left:475"><nobr><span class="ft4">is only one attribute and two policies, p</span></nobr></DIV>
<DIV style="position:absolute;top:711;left:723"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:707;left:736"><nobr><span class="ft4">and p</span></nobr></DIV>
<DIV style="position:absolute;top:711;left:771"><nobr><span class="ft11">2</span></nobr></DIV>
<DIV style="position:absolute;top:707;left:777"><nobr><span class="ft4">. Half of</span></nobr></DIV>
<DIV style="position:absolute;top:722;left:475"><nobr><span class="ft4">the users use p</span></nobr></DIV>
<DIV style="position:absolute;top:727;left:567"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:722;left:579"><nobr><span class="ft4">when they have the attribute and p</span></nobr></DIV>
<DIV style="position:absolute;top:727;left:792"><nobr><span class="ft11">2</span></nobr></DIV>
<DIV style="position:absolute;top:722;left:804"><nobr><span class="ft4">when</span></nobr></DIV>
<DIV style="position:absolute;top:738;left:475"><nobr><span class="ft4">they do not. The other half of the users use p</span></nobr></DIV>
<DIV style="position:absolute;top:743;left:761"><nobr><span class="ft11">2</span></nobr></DIV>
<DIV style="position:absolute;top:738;left:773"><nobr><span class="ft4">when they</span></nobr></DIV>
<DIV style="position:absolute;top:754;left:475"><nobr><span class="ft4">have the attribute and p</span></nobr></DIV>
<DIV style="position:absolute;top:758;left:624"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:754;left:637"><nobr><span class="ft4">when they do not. Every user's</span></nobr></DIV>
<DIV style="position:absolute;top:770;left:475"><nobr><span class="ft9">messages would be distinguishable under the definition of in-<br>distinguishability presented in [23] because for each user the<br>distribution of messages is different. However, if a fraction<br>r of the users have the attribute and a fraction 1 - r do not,<br>then</span></nobr></DIV>
<DIV style="position:absolute;top:830;left:507"><nobr><span class="ft12">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:832;left:517"><nobr><span class="ft4">· r +</span></nobr></DIV>
<DIV style="position:absolute;top:830;left:547"><nobr><span class="ft12">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:832;left:557"><nobr><span class="ft4">· (1 - r) =</span></nobr></DIV>
<DIV style="position:absolute;top:830;left:623"><nobr><span class="ft12">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:832;left:635"><nobr><span class="ft4">of the users display policy p</span></nobr></DIV>
<DIV style="position:absolute;top:837;left:801"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:832;left:812"><nobr><span class="ft4">and</span></nobr></DIV>
<DIV style="position:absolute;top:848;left:475"><nobr><span class="ft4">the other half of the users display policy p</span></nobr></DIV>
<DIV style="position:absolute;top:853;left:740"><nobr><span class="ft11">2</span></nobr></DIV>
<DIV style="position:absolute;top:848;left:746"><nobr><span class="ft4">. As such the</span></nobr></DIV>
<DIV style="position:absolute;top:864;left:475"><nobr><span class="ft4">number of users displaying p</span></nobr></DIV>
<DIV style="position:absolute;top:868;left:653"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:864;left:666"><nobr><span class="ft4">or p</span></nobr></DIV>
<DIV style="position:absolute;top:868;left:692"><nobr><span class="ft11">2</span></nobr></DIV>
<DIV style="position:absolute;top:864;left:704"><nobr><span class="ft4">does not change as r</span></nobr></DIV>
<DIV style="position:absolute;top:879;left:475"><nobr><span class="ft9">changes. Hence, they are independent. Since the policy dis-<br>played is independent of the attribute when users are viewed<br>as a whole, seeing either policy does not reveal any infor-<br>mation about whether or not the user in question has the<br>attribute.</span></nobr></DIV>
<DIV style="position:absolute;top:972;left:489"><nobr><span class="ft4">As such, Winsborough and Li's definitions of indistin-</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:475"><nobr><span class="ft9">guishability restrict a number of valid systems where a given<br>user will act differently in the two cases, but an opponent<br>cannot actually distinguish which case is which. In fact,<br>their definitions allow only systems greatly similar to the<br>Ack Policy system that they proposed in [22]. Instead we<br>propose a definition of safety based directly on information</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:452"><nobr><span class="ft8">37</span></nobr></DIV>
</DIV>
<!-- Page 3 -->
<a name="3"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft13{font-size:14px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="150003.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft9">gain instead of the message exchange sequences between the<br>two parties.</span></nobr></DIV>
<DIV style="position:absolute;top:118;left:94"><nobr><span class="ft4">Before we formally define safety, we first discuss what</span></nobr></DIV>
<DIV style="position:absolute;top:133;left:81"><nobr><span class="ft9">safety means informally. In any trust negotiation system,<br>there is some set of objects which are protected by poli-<br>cies. Usually this includes credentials, information about<br>attribute possession, and sometimes even some of the poli-<br>cies in the system. All of these can be structured as digital<br>information, and the aim of the system is to disclose that<br>information only to appropriate parties.</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:94"><nobr><span class="ft4">The straight-forward part of the idea of safety is that an</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:81"><nobr><span class="ft9">object's value should not be revealed unless its policy has<br>been satisfied. However, we do not want to simply avoid<br>an object's value being known with complete certainty, but<br>also the value being guessed with significant likelihood.</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:94"><nobr><span class="ft4">As such, we can define the change in safety as the change</span></nobr></DIV>
<DIV style="position:absolute;top:337;left:81"><nobr><span class="ft4">in the probability of guessing the value of an object.</span></nobr></DIV>
<DIV style="position:absolute;top:337;left:430"><nobr><span class="ft4">If</span></nobr></DIV>
<DIV style="position:absolute;top:353;left:81"><nobr><span class="ft4">there are two secrets, s</span></nobr></DIV>
<DIV style="position:absolute;top:358;left:225"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:353;left:237"><nobr><span class="ft4">and s</span></nobr></DIV>
<DIV style="position:absolute;top:358;left:272"><nobr><span class="ft11">2</span></nobr></DIV>
<DIV style="position:absolute;top:353;left:278"><nobr><span class="ft4">, we can define the condi-</span></nobr></DIV>
<DIV style="position:absolute;top:369;left:81"><nobr><span class="ft4">tional safety of s</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:186"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:369;left:198"><nobr><span class="ft4">upon the disclosure of s</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:347"><nobr><span class="ft11">2</span></nobr></DIV>
<DIV style="position:absolute;top:369;left:359"><nobr><span class="ft4">as the condi-</span></nobr></DIV>
<DIV style="position:absolute;top:384;left:81"><nobr><span class="ft4">tional probability of guessing s</span></nobr></DIV>
<DIV style="position:absolute;top:389;left:270"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:384;left:282"><nobr><span class="ft4">given s</span></nobr></DIV>
<DIV style="position:absolute;top:389;left:325"><nobr><span class="ft11">2</span></nobr></DIV>
<DIV style="position:absolute;top:384;left:331"><nobr><span class="ft4">. Thus, we define</span></nobr></DIV>
<DIV style="position:absolute;top:400;left:81"><nobr><span class="ft9">absolute safety in a system as being the property that no<br>disclosure of objects whose policies have been satisfied re-<br>sults in any change in the probability of guessing the value<br>of any object whose policy has not been satisfied regardless<br>of what inferences might be possible.</span></nobr></DIV>
<DIV style="position:absolute;top:479;left:94"><nobr><span class="ft4">There exists a simple system which can satisfy this level of</span></nobr></DIV>
<DIV style="position:absolute;top:494;left:81"><nobr><span class="ft9">safety, which is the all-or-nothing system, a system in which<br>all of every user's objects are required to be protected by<br>a single policy which is the same for all users. Clearly in<br>such a system there are only two states, all objects revealed<br>or no objects revealed. As such, there can be no inferences<br>between objects which are revealed and objects which are<br>not. This system, however, has undesirable properties which<br>outweigh its safety guarantees, namely the lack of autonomy,<br>flexibility, and fine-grained access control. Because of the<br>necessity of protecting against every possible inference which<br>could occur, it is like that any system which achieves ideal<br>safety would be similarly inflexible.</span></nobr></DIV>
<DIV style="position:absolute;top:683;left:94"><nobr><span class="ft4">Since there have been no practical systems proposed which</span></nobr></DIV>
<DIV style="position:absolute;top:698;left:81"><nobr><span class="ft9">meet the ideal safety condition, describing ideal safety is not<br>sufficient unto itself. We wish to explore not just ideal safety,<br>but also safety relative to certain types of attacks. This will<br>help us develop a more complete view of safety in the likely<br>event that no useful system which is ideally safe is found.</span></nobr></DIV>
<DIV style="position:absolute;top:777;left:94"><nobr><span class="ft4">If a system does not have ideal safety, then there must</span></nobr></DIV>
<DIV style="position:absolute;top:792;left:81"><nobr><span class="ft9">be some inferences which can cause a leakage of informa-<br>tion between revealed objects and protected objects. But<br>this does not mean that every single object revealed leaks<br>information about every protected object. As such, we can<br>potentially describe what sort of inferences a system does<br>protect against. For example, Ack Policy systems are moti-<br>vated by a desire to prevent inferences from a policy to the<br>possession of the attribute that it protects. Inferences from<br>one attribute to another are not prevented by such a system<br>(for example, users who are AARP members are more likely<br>to be retired than ones who are not). Hence, it is desirable<br>to describe what it means for a system to be safe relative to<br>certain types of inferences.</span></nobr></DIV>
<DIV style="position:absolute;top:996;left:94"><nobr><span class="ft4">Next we present a formal framework to model safety in</span></nobr></DIV>
<DIV style="position:absolute;top:1012;left:81"><nobr><span class="ft9">trust negotiation. The formalism which we are using in this<br>paper is based on that used by Winsborough and Li, but is<br>substantially revised.</span></nobr></DIV>
<DIV style="position:absolute;top:84;left:479"><nobr><span class="ft13"><i>2.0.1</i></span></nobr></DIV>
<DIV style="position:absolute;top:84;left:529"><nobr><span class="ft13"><i>Trust Negotiation Systems</i></span></nobr></DIV>
<DIV style="position:absolute;top:106;left:489"><nobr><span class="ft4">A Trust Negotiation System is comprised of the following</span></nobr></DIV>
<DIV style="position:absolute;top:121;left:475"><nobr><span class="ft4">elements:</span></nobr></DIV>
<DIV style="position:absolute;top:140;left:462"><nobr><span class="ft4">· A finite set, K, of principals, uniquely identified by a ran-</span></nobr></DIV>
<DIV style="position:absolute;top:156;left:475"><nobr><span class="ft4">domly chosen public key, P ub</span></nobr></DIV>
<DIV style="position:absolute;top:161;left:659"><nobr><span class="ft11">k</span></nobr></DIV>
<DIV style="position:absolute;top:156;left:666"><nobr><span class="ft4">. Each principal knows the</span></nobr></DIV>
<DIV style="position:absolute;top:172;left:475"><nobr><span class="ft4">associated private key, and can produce a proof of identity.</span></nobr></DIV>
<DIV style="position:absolute;top:193;left:462"><nobr><span class="ft4">· A finite set, T , of attributes. An attribute is something</span></nobr></DIV>
<DIV style="position:absolute;top:209;left:475"><nobr><span class="ft9">which each user either possesses or lacks. An example would<br>be status as a licensed driver or enrollment at a university.</span></nobr></DIV>
<DIV style="position:absolute;top:246;left:462"><nobr><span class="ft4">· A set, G, of configurations, each of which is a subset of T .</span></nobr></DIV>
<DIV style="position:absolute;top:262;left:475"><nobr><span class="ft9">If a principal k is in a configuration g  G, then k possesses<br>the attributes in g and no other attributes.</span></nobr></DIV>
<DIV style="position:absolute;top:299;left:462"><nobr><span class="ft4">· A set, P, of possible policies, each of which is a logical propo-</span></nobr></DIV>
<DIV style="position:absolute;top:315;left:475"><nobr><span class="ft9">sition comprised of a combination of and, or, and attributes<br>in T . We define an attribute in a policy to be true with re-<br>spect to a principal k if k has that attribute. We consider<br>all logically equivalent policies to be the same policy.</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:462"><nobr><span class="ft4">· Objects. Every principal k has objects which may be pro-</span></nobr></DIV>
<DIV style="position:absolute;top:399;left:475"><nobr><span class="ft4">tected which include the following:</span></nobr></DIV>
<DIV style="position:absolute;top:424;left:464"><nobr><span class="ft4">- A set, S, of services provided by a principal. Every princi-</span></nobr></DIV>
<DIV style="position:absolute;top:440;left:475"><nobr><span class="ft9">pal offers some set of services to all other principals. These<br>services are each protected by some policy, as we will de-<br>scribe later. A simple service which each principal offers is<br>a proof of attribute possession. If another principal satisfies<br>the appropriate policy, the principal will offer some proof<br>that he holds the attribute. This service is denoted s</span></nobr></DIV>
<DIV style="position:absolute;top:523;left:807"><nobr><span class="ft11">t</span></nobr></DIV>
<DIV style="position:absolute;top:518;left:817"><nobr><span class="ft4">for</span></nobr></DIV>
<DIV style="position:absolute;top:534;left:475"><nobr><span class="ft4">any attribute t  T .</span></nobr></DIV>
<DIV style="position:absolute;top:553;left:464"><nobr><span class="ft4">- A set, A, of attribute status objects. Since the set of all</span></nobr></DIV>
<DIV style="position:absolute;top:568;left:475"><nobr><span class="ft9">attributes is already known, we want to protect the infor-<br>mation about whether or not a given user has an attribute.<br>As such we formally define A as a set of boolean valued ran-<br>dom variables, a</span></nobr></DIV>
<DIV style="position:absolute;top:620;left:575"><nobr><span class="ft11">t</span></nobr></DIV>
<DIV style="position:absolute;top:616;left:581"><nobr><span class="ft4">. The value of a</span></nobr></DIV>
<DIV style="position:absolute;top:620;left:681"><nobr><span class="ft11">t</span></nobr></DIV>
<DIV style="position:absolute;top:616;left:691"><nobr><span class="ft4">for a principal k, which</span></nobr></DIV>
<DIV style="position:absolute;top:631;left:475"><nobr><span class="ft4">we denote a</span></nobr></DIV>
<DIV style="position:absolute;top:636;left:550"><nobr><span class="ft11">t</span></nobr></DIV>
<DIV style="position:absolute;top:631;left:555"><nobr><span class="ft4">(k) is defined to be true if k possesses t  T</span></nobr></DIV>
<DIV style="position:absolute;top:647;left:475"><nobr><span class="ft4">and false otherwise. Thus A = {a</span></nobr></DIV>
<DIV style="position:absolute;top:652;left:679"><nobr><span class="ft11">t</span></nobr></DIV>
<DIV style="position:absolute;top:646;left:684"><nobr><span class="ft4">|t  T }.</span></nobr></DIV>
<DIV style="position:absolute;top:666;left:464"><nobr><span class="ft4">- A set, Q of policy mapping objects. A system may desire</span></nobr></DIV>
<DIV style="position:absolute;top:681;left:475"><nobr><span class="ft9">to protect an object's policy either because of correlations<br>between policies and sensitive attributes or because in some<br>systems the policies themselves may be considered sensitive.<br>Similar to attribute status objects, we do not protect a pol-<br>icy, per se, but instead the pairing of a policy with what<br>it is protecting. As such, each policy mapping object is a<br>random variable q</span></nobr></DIV>
<DIV style="position:absolute;top:780;left:584"><nobr><span class="ft11">o</span></nobr></DIV>
<DIV style="position:absolute;top:775;left:595"><nobr><span class="ft4">with range P where o is an object. The</span></nobr></DIV>
<DIV style="position:absolute;top:791;left:475"><nobr><span class="ft4">value of q</span></nobr></DIV>
<DIV style="position:absolute;top:796;left:531"><nobr><span class="ft11">o</span></nobr></DIV>
<DIV style="position:absolute;top:791;left:540"><nobr><span class="ft4">for a given principal k, denoted q</span></nobr></DIV>
<DIV style="position:absolute;top:796;left:734"><nobr><span class="ft11">o</span></nobr></DIV>
<DIV style="position:absolute;top:791;left:741"><nobr><span class="ft4">(k) is the policy</span></nobr></DIV>
<DIV style="position:absolute;top:807;left:475"><nobr><span class="ft4">that k has chosen to protect object o.</span></nobr></DIV>
<DIV style="position:absolute;top:825;left:475"><nobr><span class="ft9">Every system should define which objects are protected. It<br>is expected that all systems should protect the services, S,<br>and the attribute status objects, A. In some systems, there<br>will also be policies which protect policies. Thus protected<br>objects may also include a subset of Q. We call the set of<br>protected objects O, where O  S  A  Q. If an object is<br>not protected, this is equivalent to it having a policy equal<br>to true.</span></nobr></DIV>
<DIV style="position:absolute;top:954;left:475"><nobr><span class="ft4">For convenience, we define Q</span></nobr></DIV>
<DIV style="position:absolute;top:958;left:661"><nobr><span class="ft11">X</span></nobr></DIV>
<DIV style="position:absolute;top:954;left:678"><nobr><span class="ft4">to be the members of Q</span></nobr></DIV>
<DIV style="position:absolute;top:970;left:475"><nobr><span class="ft9">which are policies protecting members of X , where X is a<br>set of objects. Formally, Q</span></nobr></DIV>
<DIV style="position:absolute;top:989;left:637"><nobr><span class="ft11">X</span></nobr></DIV>
<DIV style="position:absolute;top:985;left:651"><nobr><span class="ft4">= {q</span></nobr></DIV>
<DIV style="position:absolute;top:990;left:679"><nobr><span class="ft11">o</span></nobr></DIV>
<DIV style="position:absolute;top:984;left:689"><nobr><span class="ft4"> Q|o  X }.</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:475"><nobr><span class="ft9">Some subset of the information objects are considered to<br>be sensitive objects. These are the objects about which we<br>want an opponent to gain no information unless they have<br>satisfied that object's policy. Full information about any<br>object, sensitive or insensitive, is not released by the system</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:452"><nobr><span class="ft8">38</span></nobr></DIV>
</DIV>
<!-- Page 4 -->
<a name="4"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft14{font-size:5px;font-family:Times;color:#000000;}
	.ft15{font-size:11px;line-height:13px;font-family:Times;color:#000000;}
	.ft16{font-size:11px;line-height:14px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="150004.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft9">until its policy has been satisfied, but it is acceptable for<br>inferences to cause the leakage of information which is not<br>considered sensitive.</span></nobr></DIV>
<DIV style="position:absolute;top:141;left:67"><nobr><span class="ft4">· A set, N , of negotiation strategies. A negotiation strategy</span></nobr></DIV>
<DIV style="position:absolute;top:158;left:81"><nobr><span class="ft9">is the means that a principal uses to interact with other<br>principals. Established strategies include the eager strategy<br>[24] and the trust-target graph strategy [22].</span></nobr></DIV>
<DIV style="position:absolute;top:189;left:374"><nobr><span class="ft4">A negotia-</span></nobr></DIV>
<DIV style="position:absolute;top:205;left:81"><nobr><span class="ft9">tion strategy, n, is defined as an interactive, deterministic,<br>Turing-equivalent computational machine augmented by a<br>random tape. The random tape serves as a random oracle<br>which allows us to discuss randomized strategies.</span></nobr></DIV>
<DIV style="position:absolute;top:273;left:81"><nobr><span class="ft9">A negotiation strategy takes as initial input the public knowl-<br>edge needed to operate in a system, the principal's attributes,<br>its services, and the policies which protect its objects. It<br>then produces additional inputs and outputs by interacting<br>with other strategies. It can output policies, credentials,<br>and any additional information which is useful. We do not<br>further define the specifics of the information communicated<br>between strategies except to note that all the strategies in a<br>system should have compatible input and output protocols.<br>We refrain from further specifics of strategies since they are<br>not required in our later discussion.</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:67"><nobr><span class="ft4">· An adversary, M , is defined as a set of principals coordinat-</span></nobr></DIV>
<DIV style="position:absolute;top:467;left:81"><nobr><span class="ft9">ing to discover the value of sensitive information objects<br>belonging to some k  M .</span></nobr></DIV>
<DIV style="position:absolute;top:483;left:266"><nobr><span class="ft4">Preventing this discovery is</span></nobr></DIV>
<DIV style="position:absolute;top:499;left:81"><nobr><span class="ft9">the security goal of a trust negotiation system. We assume<br>that adversaries may only interact with principals through<br>trust negotiation and are limited to proving possession of<br>attributes which they actually possess. In other words, the<br>trust negotiation system provides a means of proof which is<br>resistant to attempts at forgery.</span></nobr></DIV>
<DIV style="position:absolute;top:598;left:67"><nobr><span class="ft4">· A set, I, of all inferences. Each inference is a minimal subset</span></nobr></DIV>
<DIV style="position:absolute;top:614;left:81"><nobr><span class="ft9">of information objects such that the joint distribution of the<br>set differs from the product of the individual distributions<br>of the items in the set.</span></nobr></DIV>
<DIV style="position:absolute;top:643;left:224"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:667;left:81"><nobr><span class="ft9">These then allow a partitioning, C, of the information ob-<br>jects into inference components. We define a relation  such<br>that o</span></nobr></DIV>
<DIV style="position:absolute;top:703;left:118"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:698;left:128"><nobr><span class="ft4"> o</span></nobr></DIV>
<DIV style="position:absolute;top:703;left:145"><nobr><span class="ft11">2</span></nobr></DIV>
<DIV style="position:absolute;top:698;left:156"><nobr><span class="ft4">iff i  I|o</span></nobr></DIV>
<DIV style="position:absolute;top:703;left:223"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:698;left:229"><nobr><span class="ft4">, o</span></nobr></DIV>
<DIV style="position:absolute;top:703;left:242"><nobr><span class="ft11">2</span></nobr></DIV>
<DIV style="position:absolute;top:698;left:253"><nobr><span class="ft4"> i. C is the transitive closure</span></nobr></DIV>
<DIV style="position:absolute;top:714;left:81"><nobr><span class="ft4">of .</span></nobr></DIV>
<DIV style="position:absolute;top:733;left:94"><nobr><span class="ft4">In general, we assume that all of the information objects</span></nobr></DIV>
<DIV style="position:absolute;top:749;left:81"><nobr><span class="ft9">in our framework are static. We do not model changes in a<br>principal's attribute status or policies. If such is necessary,<br>the model would need to be adapted.</span></nobr></DIV>
<DIV style="position:absolute;top:796;left:94"><nobr><span class="ft4">It should also be noted that there is an additional con-</span></nobr></DIV>
<DIV style="position:absolute;top:811;left:81"><nobr><span class="ft9">straint on policies that protect policies which we have not<br>described.</span></nobr></DIV>
<DIV style="position:absolute;top:827;left:155"><nobr><span class="ft4">This is because in most systems there is a way</span></nobr></DIV>
<DIV style="position:absolute;top:843;left:81"><nobr><span class="ft9">to gain information about what a policy is, which is to sat-<br>isfy it. When a policy is satisfied, this generally results in<br>some service being rendered or information being released.<br>As such, this will let the other party know that they have<br>satisfied the policy for that object. Therefore, the effective<br>policy protecting a policy status object must be the logical<br>or of the policy in the policy status object and the policy<br>which protects it.</span></nobr></DIV>
<DIV style="position:absolute;top:979;left:85"><nobr><span class="ft13"><i>2.0.2</i></span></nobr></DIV>
<DIV style="position:absolute;top:979;left:134"><nobr><span class="ft13"><i>The Ack Policy System</i></span></nobr></DIV>
<DIV style="position:absolute;top:1000;left:94"><nobr><span class="ft4">To help illustrate the model, let us describe how the Ack</span></nobr></DIV>
<DIV style="position:absolute;top:1016;left:81"><nobr><span class="ft4">Policy system maps onto the model. The mapping of oppo-</span></nobr></DIV>
<DIV style="position:absolute;top:1037;left:81"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:1040;left:88"><nobr><span class="ft4">A system need not define the particulars of inferences, but</span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:81"><nobr><span class="ft15">should discuss what sort of inferences it can deal with, and<br>hence what sort of inferences are assumed to exist.</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft9">nents, the sets of principals, attributes, configurations, and<br>policies in the Ack Policy system is straightforward.</span></nobr></DIV>
<DIV style="position:absolute;top:118;left:489"><nobr><span class="ft4">In an Ack Policy system, any mutually compatible set of</span></nobr></DIV>
<DIV style="position:absolute;top:133;left:475"><nobr><span class="ft9">negotiation strategies is acceptable. There are policies for<br>protecting services, protecting attribute status objects, and<br>protecting policies which protect attribute proving services.<br>As such, the set of protected objects, O = S  A  Q</span></nobr></DIV>
<DIV style="position:absolute;top:185;left:797"><nobr><span class="ft11">S</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:805"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:196;left:489"><nobr><span class="ft4">According to the definition of the Ack Policy system, for</span></nobr></DIV>
<DIV style="position:absolute;top:212;left:475"><nobr><span class="ft16">a given attribute, the policy that protects the proof service<br>for that attribute is protected by the same policy that pro-<br>tects the attribute status object. Formally, t  T , k <br>K, q</span></nobr></DIV>
<DIV style="position:absolute;top:264;left:498"><nobr><span class="ft11">a</span></nobr></DIV>
<DIV style="position:absolute;top:266;left:504"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:510"><nobr><span class="ft4">(k) = q</span></nobr></DIV>
<DIV style="position:absolute;top:264;left:553"><nobr><span class="ft11">q</span></nobr></DIV>
<DIV style="position:absolute;top:266;left:558"><nobr><span class="ft14">st</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:569"><nobr><span class="ft4">(k). Further, the Ack policy for an attribute</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:475"><nobr><span class="ft16">is required to be the same for all principals. Thus we know<br>t  T p  Pk  K|q</span></nobr></DIV>
<DIV style="position:absolute;top:295;left:611"><nobr><span class="ft11">a</span></nobr></DIV>
<DIV style="position:absolute;top:297;left:617"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:623"><nobr><span class="ft4">(k) = p.</span></nobr></DIV>
<DIV style="position:absolute;top:306;left:489"><nobr><span class="ft4">Two basic assumptions about the set of inferences, I, ex-</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:475"><nobr><span class="ft9">ist in Ack Policy systems, which also lead us to conclusions<br>about the inference components, C. It is assumed that infer-<br>ences between the policy which protects the attribute prov-<br>ing service, q</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:557"><nobr><span class="ft11">s</span></nobr></DIV>
<DIV style="position:absolute;top:376;left:562"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:369;left:568"><nobr><span class="ft4">(k), and the attribute status object, a</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:807"><nobr><span class="ft11">t</span></nobr></DIV>
<DIV style="position:absolute;top:369;left:812"><nobr><span class="ft4">(k),</span></nobr></DIV>
<DIV style="position:absolute;top:384;left:475"><nobr><span class="ft9">exist. As such, those two objects should always be in the<br>same inference component. Because Ack Policies are uni-<br>form for all principals, they are uncorrelated to any other<br>information object and they cannot be part of any inference.<br>Hence, each Ack Policy is in an inference component of its<br>own.</span></nobr></DIV>
<DIV style="position:absolute;top:496;left:479"><nobr><span class="ft13"><i>2.0.3</i></span></nobr></DIV>
<DIV style="position:absolute;top:496;left:529"><nobr><span class="ft13"><i>Safety in Trust Negotiation Systems</i></span></nobr></DIV>
<DIV style="position:absolute;top:517;left:489"><nobr><span class="ft4">In order to formally define safety in trust negotiation, we</span></nobr></DIV>
<DIV style="position:absolute;top:533;left:475"><nobr><span class="ft9">need to define the specifics of the opponent. We need to<br>model the potential capabilities of an opponent and the in-<br>formation initially available to the opponent. Obviously, no<br>system is safe against an opponent with unlimited capabili-<br>ties or unlimited knowledge.</span></nobr></DIV>
<DIV style="position:absolute;top:612;left:489"><nobr><span class="ft4">As such, we restrict the opponent to having some tactic,</span></nobr></DIV>
<DIV style="position:absolute;top:627;left:475"><nobr><span class="ft9">for forming trust negotiation messages, processing responses<br>to those messages, and, finally, forming a guess about the<br>values of unrevealed information objects. We model the tac-<br>tic as an interactive, deterministic, Turing-equivalent com-<br>putational machine. This model is a very powerful model,<br>and we argue that it describes any reasonable opponent.<br>This model, however, restricts the opponent to calculating<br>things which are computable from its input and implies that<br>the opponent behaves in a deterministic fashion.</span></nobr></DIV>
<DIV style="position:absolute;top:769;left:489"><nobr><span class="ft4">The input available to the machine at the start is the</span></nobr></DIV>
<DIV style="position:absolute;top:784;left:475"><nobr><span class="ft9">knowledge available to the opponent before any trust ne-<br>gotiation has taken place. What this knowledge is varies<br>depending on the particulars of a trust negotiation system.<br>However, in every system this should include the knowl-<br>edge available to the principals who are a part of the op-<br>ponent, such as their public and private keys and their cre-<br>dentials. And it should also include public information such<br>as how the system works, the public keys of the attribute<br>authorities, and other information that every user knows.<br>In most systems, information about the distribution of at-<br>tributes and credentials and knowledge of inference rules<br>should also be considered as public information.</span></nobr></DIV>
<DIV style="position:absolute;top:957;left:793"><nobr><span class="ft4">All re-</span></nobr></DIV>
<DIV style="position:absolute;top:972;left:475"><nobr><span class="ft9">sponses from principals in different configurations become<br>available as input to the tactic as they are made. The tactic<br>must output both a sequence of responses and, at the end,<br>guesses about the unknown objects of all users.</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:489"><nobr><span class="ft4">We observe that an opponent will have probabilistic knowl-</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:475"><nobr><span class="ft9">edge about information objects in a system. Initially, the<br>probabilities will be based only on publicly available knowl-</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:452"><nobr><span class="ft8">39</span></nobr></DIV>
</DIV>
<!-- Page 5 -->
<a name="5"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="150005.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft9">edge, so we can use the publicly available knowledge to de-<br>scribe the a priori probabilities.</span></nobr></DIV>
<DIV style="position:absolute;top:118;left:94"><nobr><span class="ft4">For instance, in most systems, it would be reasonable to</span></nobr></DIV>
<DIV style="position:absolute;top:133;left:81"><nobr><span class="ft9">assume that the opponent will have knowledge of the odds<br>that any particular member of the population has a given at-<br>tribute. Thus, if a fraction h</span></nobr></DIV>
<DIV style="position:absolute;top:169;left:254"><nobr><span class="ft11">t</span></nobr></DIV>
<DIV style="position:absolute;top:165;left:264"><nobr><span class="ft4">of the population is expected</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:81"><nobr><span class="ft9">to possess attribute t  T , the opponent should begin with<br>an assumption that some given principal has a h</span></nobr></DIV>
<DIV style="position:absolute;top:201;left:374"><nobr><span class="ft11">t</span></nobr></DIV>
<DIV style="position:absolute;top:196;left:383"><nobr><span class="ft4">chance of</span></nobr></DIV>
<DIV style="position:absolute;top:212;left:81"><nobr><span class="ft4">having attribute t. Hence, h</span></nobr></DIV>
<DIV style="position:absolute;top:216;left:256"><nobr><span class="ft11">t</span></nobr></DIV>
<DIV style="position:absolute;top:212;left:266"><nobr><span class="ft4">represents the a priori prob-</span></nobr></DIV>
<DIV style="position:absolute;top:228;left:81"><nobr><span class="ft9">ability of any given principal possessing t. Note that we<br>assume that the opponent only knows the odds of a given<br>principal having an attribute, but does not know for certain<br>that a fixed percentage of the users have a given attribute.<br>As such, knowledge about the value of an object belonging<br>to some set of users does not imply any knowledge about<br>the value of objects belonging to some other user.</span></nobr></DIV>
<DIV style="position:absolute;top:350;left:96"><nobr><span class="ft4">Definition 1. A trust negotiation system is safe relative</span></nobr></DIV>
<DIV style="position:absolute;top:363;left:81"><nobr><span class="ft9">to a set of possible inferences if for all allowed mappings be-<br>tween principals and configurations there exists no opponent<br>which can guess the value of sensitive information objects<br>whose security policies have not been met with odds better<br>than the a priori odds over all principals which are not in<br>the opponent, over all values of all random tapes, and over<br>all mappings between public key values and principals.</span></nobr></DIV>
<DIV style="position:absolute;top:482;left:94"><nobr><span class="ft4">Definition 1 differs from Winsborough and Li's definitions</span></nobr></DIV>
<DIV style="position:absolute;top:498;left:81"><nobr><span class="ft9">in several ways. The first is that it is concerned with multi-<br>ple users. It both requires that the opponent form guesses<br>over all users and allows the opponent to interact with all<br>users. Instead of simply having a sequence of messages sent<br>to a single principal, the tactic we have defined may interact<br>with a variety of users, analyzing incoming messages, and<br>then use them to form new messages. It is allowed to talk<br>to the users in any order and to interleave communications<br>with multiple users, thus it is more general than those in [23].<br>The second is that we are concerned only with the informa-<br>tion which the opponent can glean from the communication,<br>not the distribution of the communication itself. As such,<br>our definition more clearly reflects the fundamental idea of<br>safety.</span></nobr></DIV>
<DIV style="position:absolute;top:718;left:94"><nobr><span class="ft4">We next introduce a theorem which will be helpful in prov-</span></nobr></DIV>
<DIV style="position:absolute;top:733;left:81"><nobr><span class="ft4">ing the safety of systems.</span></nobr></DIV>
<DIV style="position:absolute;top:761;left:96"><nobr><span class="ft4">Theorem 1. There exists no opponent which can beat the</span></nobr></DIV>
<DIV style="position:absolute;top:774;left:81"><nobr><span class="ft9">a priori odds of guessing the value of an object, o, given<br>only information about objects which are not in the same<br>inference component as o, over all principals not in M and<br>whose policy for o M cannot satisfy, over all random tapes,<br>and over all mappings between public keys and principals.</span></nobr></DIV>
<DIV style="position:absolute;top:863;left:94"><nobr><span class="ft4">The formal proof for this theorem can be found in Ap-</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:81"><nobr><span class="ft9">pendix A. Intuitively, since the opponent only gains infor-<br>mation about objects not correlated to o, its guess of the<br>value of o is not affected.</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:94"><nobr><span class="ft4">With theorem 1, let us take a brief moment to prove</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:81"><nobr><span class="ft9">the safety of the Ack Policy systems under our framework.<br>Specifically, we examine Ack Policy systems in which the<br>distribution of strategies is independent of the distributions<br>of attributes, an assumption implicitly made in [23]. In Ack<br>Policy systems the Ack Policy is a policy which protects<br>two objects in our model: an attribute's status object and<br>its policy for that attribute's proof service. Ack Policies are<br>required to be uniform for all users, which ensures that they<br>are independent of all objects.</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:489"><nobr><span class="ft4">Ack Policy systems are designed to prevent inferences</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:475"><nobr><span class="ft9">from an attribute's policy to an attribute's status for at-<br>tributes which are sensitive. So, let us assume an appropri-<br>ate set of inference components in order to prove that Ack<br>Policy systems are safe relative to that form of inference.<br>As we described earlier, each attribute status object should<br>be in the same inference component with the policy which<br>protects that attribute's proof service, and the Ack policy<br>for each attribute should be in its own inference component.<br>The Ack Policy system also assumes that different attributes<br>are independent of each other. As such, each attribute sta-<br>tus object should be in a different inference group.</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:489"><nobr><span class="ft4">This set of inference components excludes all other pos-</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:475"><nobr><span class="ft9">sible types of inferences. The set of sensitive objects is the<br>set of attribute status objects whose value is true. Due to<br>Theorem 1, we know then that no opponent will be able to<br>gain any information based on objects in different inference<br>components. So the only potential source of inference for<br>whether or not a given attribute's status object, a</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:787"><nobr><span class="ft11">t</span></nobr></DIV>
<DIV style="position:absolute;top:369;left:792"><nobr><span class="ft4">, has a</span></nobr></DIV>
<DIV style="position:absolute;top:384;left:475"><nobr><span class="ft9">value of true or f alse is the policy protecting the attribute<br>proof service, s</span></nobr></DIV>
<DIV style="position:absolute;top:405;left:567"><nobr><span class="ft11">t</span></nobr></DIV>
<DIV style="position:absolute;top:400;left:572"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:416;left:489"><nobr><span class="ft4">However, we know that the same policy, P , protects both</span></nobr></DIV>
<DIV style="position:absolute;top:432;left:475"><nobr><span class="ft9">of these objects. As such unauthorized inference between<br>them is impossible without satisfying P .</span></nobr></DIV>
<DIV style="position:absolute;top:445;left:729"><nobr><span class="ft11">2</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:742"><nobr><span class="ft4">Thus, the odds</span></nobr></DIV>
<DIV style="position:absolute;top:463;left:475"><nobr><span class="ft4">for a</span></nobr></DIV>
<DIV style="position:absolute;top:468;left:505"><nobr><span class="ft11">t</span></nobr></DIV>
<DIV style="position:absolute;top:463;left:515"><nobr><span class="ft4">do not change. Therefore, the Ack Policy system is</span></nobr></DIV>
<DIV style="position:absolute;top:479;left:475"><nobr><span class="ft9">secure against inferences from an attribute's policy to its<br>attribute status.</span></nobr></DIV>
<DIV style="position:absolute;top:531;left:475"><nobr><span class="ft3"><b>3.</b></span></nobr></DIV>
<DIV style="position:absolute;top:531;left:507"><nobr><span class="ft3"><b>POLICY DATABASE</b></span></nobr></DIV>
<DIV style="position:absolute;top:553;left:489"><nobr><span class="ft4">We propose a new trust negotiation system designed to</span></nobr></DIV>
<DIV style="position:absolute;top:569;left:475"><nobr><span class="ft9">be safe under the definition we proposed, but to also allow<br>the users who have sensitive attributes complete freedom to<br>determine their own policies. It also does not rely on any<br>particular strategy being used. Potentially, a combination of<br>strategies could even be used so long as the strategy chosen<br>is not in any way correlated to the attributes possessed.</span></nobr></DIV>
<DIV style="position:absolute;top:663;left:489"><nobr><span class="ft4">This system is based on the observation that there is more</span></nobr></DIV>
<DIV style="position:absolute;top:679;left:475"><nobr><span class="ft9">than one way to deal with a correlation. A simple ideal sys-<br>tem which prevents the inference from policies to attribute<br>possession information is to have each user draw a random<br>policy. This system obviously does not allow users the free-<br>dom to create their own policies. Instead we propose a sys-<br>tem which looks like the policies are random even though<br>they are not.</span></nobr></DIV>
<DIV style="position:absolute;top:788;left:489"><nobr><span class="ft4">This system is similar to the existing trust negotiation</span></nobr></DIV>
<DIV style="position:absolute;top:804;left:475"><nobr><span class="ft9">systems except for the addition of a new element: the policy<br>database. The policy database is a database run by a trusted<br>third party which collects anonymized information about the<br>policies which are in use. In the policy database system, a</span></nobr></DIV>
<DIV style="position:absolute;top:876;left:476"><nobr><span class="ft11">2</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:482"><nobr><span class="ft4">Except that one of these is a policy mapping object which</span></nobr></DIV>
<DIV style="position:absolute;top:892;left:475"><nobr><span class="ft15">is being protected by a policy. As such, we have to keep<br>in mind that there exists a possibility that the opponent<br>could gain information about the policy without satisfy-<br>ing it. Specifically, the opponent can figure out what at-<br>tributes do not satisfy it by proving that he possesses those<br>attributes. However, in an Ack Policy system, the policy<br>protecting an attribute proof object of an attribute which a<br>user does not hold is always f alse. No opponent can distin-<br>guish between two policies which they cannot satisfy since<br>all they know is that they have failed to satisfy them. And<br>we are unconcerned with policies which they have satisfied.<br>Thus, we know that the opponent cannot gain any useful in-<br>formation about the policies which they have not satisfied,<br>and hence cannot beat the a priori odds for those policies.</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:452"><nobr><span class="ft8">40</span></nobr></DIV>
</DIV>
<!-- Page 6 -->
<a name="6"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="150006.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft9">user who has a given sensitive attribute chooses their own<br>policy and submits it anonymously to the policy database<br>for that attribute. The policy database uses pseudonymous<br>certificates to verify that users who submit policies actually<br>have the attribute, in a manner that will be discussed later<br>in section 3.2. Then users who do not have the attribute<br>will pull policies at random from the database to use as<br>their own. The contents of the policy database are public,<br>so any user who wishes to can draw a random policy from<br>the database.</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:94"><nobr><span class="ft4">In our system, each user uses a single policy to protect all</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:81"><nobr><span class="ft9">the information objects associated with an attribute. They<br>neither acknowledge that they have the attribute nor prove<br>that they do until the policy has been satisfied. This means<br>that users are allowed to have policies which protect at-<br>tributes which they do not hold. The policy in our system<br>may be seen as the combination of the Ack policy and a<br>traditional access control policy for attribute proofs.</span></nobr></DIV>
<DIV style="position:absolute;top:369;left:94"><nobr><span class="ft4">The goal of this system is to ensure that the policy is in</span></nobr></DIV>
<DIV style="position:absolute;top:384;left:81"><nobr><span class="ft9">a separate inference component from the attribute status<br>object, thus guaranteeing that inferences between policies<br>and attribute status objects cannot be made.</span></nobr></DIV>
<DIV style="position:absolute;top:432;left:94"><nobr><span class="ft4">This system is workable because of the following.</span></nobr></DIV>
<DIV style="position:absolute;top:432;left:420"><nobr><span class="ft4">We</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:81"><nobr><span class="ft9">know that policies cannot require a lack of an attribute, thus<br>users who do not have a given attribute will never suffer from<br>their policy for that attribute being too strong. Changes<br>in the policy which protects an attribute that they do not<br>have may vary the length of the trust negotiation, but it<br>will never cause them to be unable to complete transactions<br>which they would otherwise be able to complete. Also, we<br>deal only with possession sensitive attributes. We do not<br>deal with attributes where it is at all sensitive to lack them.<br>As such, users who do not have the attribute cannot have<br>their policies be too weak. Since there is no penalty for those<br>users for their policies being either too weak or too strong,<br>they can have whatever policy is most helpful for helping<br>disguise the users who do possess the attribute.</span></nobr></DIV>
<DIV style="position:absolute;top:667;left:94"><nobr><span class="ft4">This also means that users who do not have the attribute</span></nobr></DIV>
<DIV style="position:absolute;top:683;left:81"><nobr><span class="ft9">do not need to trust the policy database since no policy<br>which the database gives them would be unacceptable to<br>them. Users who have the attribute, however, do need to<br>trust that the policy database will actually randomly dis-<br>tribute policies to help camouflage their policies. They do<br>not, however, need to trust the policy database to act ap-<br>propriately with their sensitive information because all in-<br>formation is anonymized.</span></nobr></DIV>
<DIV style="position:absolute;top:825;left:81"><nobr><span class="ft3"><b>3.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:825;left:121"><nobr><span class="ft3"><b>Safety of the Approach of Policy Databases</b></span></nobr></DIV>
<DIV style="position:absolute;top:847;left:94"><nobr><span class="ft4">Let us describe the Policy Database system in terms of</span></nobr></DIV>
<DIV style="position:absolute;top:863;left:81"><nobr><span class="ft9">our model. Again the opponent and the sets of principals,<br>attributes, configurations, and policies need no special com-<br>ment.</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:135"><nobr><span class="ft4">Because we only have policies protecting the ser-</span></nobr></DIV>
<DIV style="position:absolute;top:910;left:81"><nobr><span class="ft16">vices and attribute status objects, the set of protected ob-<br>jects, O = S  A. Also, each attribute proving service and<br>attribute status object are protected by the same policy.<br>t  T , k  K, q</span></nobr></DIV>
<DIV style="position:absolute;top:961;left:183"><nobr><span class="ft11">a</span></nobr></DIV>
<DIV style="position:absolute;top:964;left:189"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:957;left:194"><nobr><span class="ft4">(k) = q</span></nobr></DIV>
<DIV style="position:absolute;top:961;left:237"><nobr><span class="ft11">s</span></nobr></DIV>
<DIV style="position:absolute;top:964;left:243"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:957;left:248"><nobr><span class="ft4">(k).</span></nobr></DIV>
<DIV style="position:absolute;top:972;left:94"><nobr><span class="ft4">This system is only designed to deal with inferences from</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:81"><nobr><span class="ft9">policies to attribute possession, so we assume that every at-<br>tribute status object is in a different inference component.<br>If the policies do actually appear to be completely random,<br>then policies and attribute status objects should be in sep-<br>arate inference components as well.</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:94"><nobr><span class="ft4">The obvious question is whether Policy Database systems</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft9">actually guarantee that this occurs. The answer is that they<br>do not guarantee it with any finite number of users due to<br>the distribution of policies being unlikely to be absolutely,<br>precisely the same. This is largely due to a combination of<br>rounding issues and the odds being against things coming<br>out precisely evenly distributed. However, as the number<br>of users in the system approaches infinity, the system ap-<br>proaches this condition.</span></nobr></DIV>
<DIV style="position:absolute;top:212;left:489"><nobr><span class="ft4">In an ideal system, the distribution of policies would be</span></nobr></DIV>
<DIV style="position:absolute;top:228;left:475"><nobr><span class="ft9">completely random. If an opponent observes that some num-<br>ber of principals had a given policy for some attribute, this<br>would give them no information about whether or not any<br>of those users had the attribute. However, in the Policy<br>Database system, every policy which is held is known to be<br>held by at least one user who has the attribute. As such, we<br>need to worry about how even the distributions of different<br>policies are.</span></nobr></DIV>
<DIV style="position:absolute;top:353;left:489"><nobr><span class="ft4">We can describe and quantify the difference which exists</span></nobr></DIV>
<DIV style="position:absolute;top:369;left:475"><nobr><span class="ft9">between a real implementation of our system and the ideal.<br>There are two reasons for a difference to exist. The first is<br>difference due to distributions being discrete. For example,<br>let us say that there are five users in our system, two of<br>which have some attribute and three who do not. Let us<br>also say that the two users with the attribute each have<br>different policies. For the distributions to be identical, each<br>of those policies would need to be selected by one and a<br>half of the remaining three users. This, obviously, cannot<br>happen. We refer to this difference as rounding error.</span></nobr></DIV>
<DIV style="position:absolute;top:526;left:489"><nobr><span class="ft4">The second is difference due to the natural unevenness of</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:475"><nobr><span class="ft4">random selection.</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:604"><nobr><span class="ft4">The distributions tend towards even-</span></nobr></DIV>
<DIV style="position:absolute;top:557;left:475"><nobr><span class="ft9">ness as the number of samples increases, but with any finite<br>number of users, the distributions are quite likely to vary<br>some from the ideal.</span></nobr></DIV>
<DIV style="position:absolute;top:604;left:489"><nobr><span class="ft4">These differences can both be quantified the same way:</span></nobr></DIV>
<DIV style="position:absolute;top:620;left:475"><nobr><span class="ft9">as a difference between the expected number of principals<br>who have a policy and the actual number. If the opponent<br>knows that one half of the principals have an attribute and<br>one half do not, and they observe that among four users,<br>there are two policies, one of which is held by three users<br>and the other by one user, then they can know that the user<br>with the unique policy holds the attribute. In general, any<br>time the number of users who share a policy is less than the<br>expectation, it is more likely that a user who has that policy<br>also has the attribute. Information is leaked when there is<br>a difference between the expected number of principals who<br>have a policy and the actual number of principals who have<br>that policy in proportion to the ratio between them.</span></nobr></DIV>
<DIV style="position:absolute;top:844;left:490"><nobr><span class="ft4">Theorem 2. The limit of the difference between the ex-</span></nobr></DIV>
<DIV style="position:absolute;top:857;left:475"><nobr><span class="ft9">pected number of principals who have a policy and the actual<br>number of principals who have the policy as the number of<br>users goes to infinity is 0.</span></nobr></DIV>
<DIV style="position:absolute;top:923;left:489"><nobr><span class="ft4">The proof of Theorem 2 can be found in Appendix B. The</span></nobr></DIV>
<DIV style="position:absolute;top:938;left:475"><nobr><span class="ft9">intuition behind it is that as the number of samples grows<br>very large, the actual distribution approaches the ideal dis-<br>tribution and the rounding errors shrink towards zero.</span></nobr></DIV>
<DIV style="position:absolute;top:997;left:475"><nobr><span class="ft3"><b>3.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:997;left:516"><nobr><span class="ft3"><b>Attacks and Countermeasures</b></span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:489"><nobr><span class="ft4">Until now, we have only proven things about a system</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:475"><nobr><span class="ft9">which is assumed to be in some instantaneous unchanging<br>state. In the real world we have to deal with issues related<br>to how policies change over time and multiple interactions.</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:452"><nobr><span class="ft8">41</span></nobr></DIV>
</DIV>
<!-- Page 7 -->
<a name="7"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="150007.png" alt="background image">
<DIV style="position:absolute;top:86;left:94"><nobr><span class="ft4">Therefore, we also want the policy which a given user ran-</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:81"><nobr><span class="ft9">domly selects from the database to be persistent. Otherwise<br>an adversary would simply make multiple requests to the<br>same user over time and see if the policy changed. If it did,<br>especially if it changed erratically, it would indicate that the<br>user was repeatedly drawing random policies. Instead, the<br>user should hold some value which designates which policy<br>the user has.</span></nobr></DIV>
<DIV style="position:absolute;top:212;left:94"><nobr><span class="ft4">An obvious answer would be to have the user hold onto</span></nobr></DIV>
<DIV style="position:absolute;top:228;left:81"><nobr><span class="ft9">the policy itself, but this would open the user up to a new at-<br>tack. If users lacking a given attribute simply grabbed onto<br>a policy and never changed it, this itself could be a tell. If<br>there were some event which occurred which made having a<br>given attribute suddenly more sensitive than it used to be,<br>then rational users who have the attribute would increase<br>the stringency of their policies.</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:290"><nobr><span class="ft4">For example, if a coun-</span></nobr></DIV>
<DIV style="position:absolute;top:337;left:81"><nobr><span class="ft9">try undertook an action which was politically unpopular on<br>a global scale, holders of passports issued by that country<br>would likely consider that more sensitive information now<br>and would increase their policies appropriately. The result<br>would then be that the average policy for people who had<br>cached a previously fetched policy would then be less strin-<br>gent than those who were making their own policies.</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:94"><nobr><span class="ft4">Instead of a permanent policy, it would be more sensible</span></nobr></DIV>
<DIV style="position:absolute;top:463;left:81"><nobr><span class="ft9">for a principal to receive a cookie which could get it the<br>policy from a particular principal so that when principals<br>who posses the attribute changed their policies, principals<br>who do not possess it would too.</span></nobr></DIV>
<DIV style="position:absolute;top:526;left:94"><nobr><span class="ft4">We also need to guard against stacking the deck. Obvi-</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:81"><nobr><span class="ft9">ously we can restrict the database to users who actually have<br>the attribute by requiring the presentation of a pseudony-<br>mous certificate [6, 7, 8, 9, 10, 18] which proves that they<br>have the attribute. However, we also need to assure that a<br>legitimate attribute holder cannot submit multiple policies<br>in order to skew the set of policies. To this end, we require<br>that each policy be submitted initially with a one-time-show<br>pseudonymous credential [8]. The attribute authorities can<br>be restricted so that they will only issue each user a sin-<br>gle one-time-show pseudonymous credential for each Policy<br>Database use. Then we can accept the policy, knowing it to<br>come from a unique user who holds the attribute, and issue<br>them a secret key which they can later use to verify that<br>they were the submitter of a given policy and to replace it<br>with an updated policy.</span></nobr></DIV>
<DIV style="position:absolute;top:777;left:94"><nobr><span class="ft4">This does not prevent a user who has the attribute from</span></nobr></DIV>
<DIV style="position:absolute;top:792;left:81"><nobr><span class="ft9">submitting a single false policy, perhaps one which is dis-<br>tinctly different from normal policies. The result would be<br>that users who draw that policy would be known to not have<br>the attribute. However, under the assumptions of our sys-<br>tem, not having the attribute is not sensitive, so this does<br>not compromise safety.</span></nobr></DIV>
<DIV style="position:absolute;top:903;left:81"><nobr><span class="ft3"><b>3.3</b></span></nobr></DIV>
<DIV style="position:absolute;top:903;left:121"><nobr><span class="ft3"><b>Limitations</b></span></nobr></DIV>
<DIV style="position:absolute;top:925;left:94"><nobr><span class="ft4">We assume that for the attribute being protected, it is not</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:81"><nobr><span class="ft9">significantly sensitive to lack the attribute. This assumption<br>means that our system likely cannot be used in practice to<br>protect all attributes. Most notably it fails when lacking an<br>attribute implies having or being highly likely to have some<br>other attribute. For example, not having a valid passport<br>probably means that you are a permanent resident of the<br>country you are currently in (although users could be an<br>illegal immigrants or citizens of a defunct nation).</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:94"><nobr><span class="ft4">It also fails when the lack of an attribute is more sensitive</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft9">than having it. For instance, few people are going to wish<br>to prevent people from knowing that they have graduated<br>from high school, but many would consider their lack of a<br>high school graduation attribute to be sensitive. However,<br>we argue that no system can adequately handle such a case<br>because those who do have the attribute would likely be<br>unwilling to accept any system which would result in them<br>having to not disclose the attribute when it was useful for<br>them to do so. And if they still easily disclose their attribute,<br>then it becomes impossible for those without to disguise<br>their lack.</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:489"><nobr><span class="ft4">Similarly to the Ack Policy system, policy databases also</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:475"><nobr><span class="ft9">do not generally handle any form of probabilistic inference<br>rule between attributes. The existence of such a rule would<br>likely imply certain relationships between policies which most<br>users would enforce. If the possession of a city library card<br>suggested with strong probability that the user was a city<br>resident, then perhaps all users who have both would have<br>a policy protecting their library card which is stricter than<br>the policy protecting their city residency. However, as there<br>is variety in the policies of individuals, a user could pick a<br>random pair of policies which did not have this property.<br>That would then be a sure tell that he did not actually have<br>both of those attributes.</span></nobr></DIV>
<DIV style="position:absolute;top:463;left:489"><nobr><span class="ft4">Another drawback of the system is that it requires a pol-</span></nobr></DIV>
<DIV style="position:absolute;top:479;left:475"><nobr><span class="ft4">icy database service be available on-line.</span></nobr></DIV>
<DIV style="position:absolute;top:479;left:745"><nobr><span class="ft4">This decreases</span></nobr></DIV>
<DIV style="position:absolute;top:494;left:475"><nobr><span class="ft9">the decentralized nature of trust negotiation. However, our<br>approach is still less centralized than Ack Policies, which<br>require that users cooperate to determine a universally ac-<br>cepted Ack policy. And this centralization may be able to be<br>decreased by decentralizing the database itself. Although we<br>discuss the database as if it were a single monolithic entity,<br>it could be made of a number of different entities acting<br>together. The only requirement is that it accepts policies<br>from unique users who have the attribute and distributes<br>them randomly.</span></nobr></DIV>
<DIV style="position:absolute;top:668;left:475"><nobr><span class="ft3"><b>4.</b></span></nobr></DIV>
<DIV style="position:absolute;top:668;left:507"><nobr><span class="ft3"><b>RELATED WORK</b></span></nobr></DIV>
<DIV style="position:absolute;top:690;left:489"><nobr><span class="ft4">The framework of automated trust negotiation was first</span></nobr></DIV>
<DIV style="position:absolute;top:706;left:475"><nobr><span class="ft4">proposed by Winsborough et al.</span></nobr></DIV>
<DIV style="position:absolute;top:706;left:690"><nobr><span class="ft4">[24].</span></nobr></DIV>
<DIV style="position:absolute;top:706;left:727"><nobr><span class="ft4">Since then, great</span></nobr></DIV>
<DIV style="position:absolute;top:721;left:475"><nobr><span class="ft9">efforts have been put forward to address challenges in a va-<br>riety of aspects of trust negotiation.</span></nobr></DIV>
<DIV style="position:absolute;top:737;left:716"><nobr><span class="ft4">An introduction to</span></nobr></DIV>
<DIV style="position:absolute;top:753;left:475"><nobr><span class="ft9">trust negotiation and related trust management issues can<br>be found in [25]. As described in detail there, a number of<br>trust negotiation systems and supporting middleware have<br>been proposed and/or implemented in a variety of contexts<br>(e.g., [3, 4, 11, 12, 14, 17, 19]). Information leakage dur-<br>ing trust negotiation is studied in [13, 5, 15, 20, 21, 22,<br>23]. The work by Winsborough and Li has been discussed<br>in detail in previous sections. Next, we discuss several other<br>approaches.</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:489"><nobr><span class="ft4">In [20], non-response is proposed as a way to protect</span></nobr></DIV>
<DIV style="position:absolute;top:910;left:475"><nobr><span class="ft4">possession-sensitive attributes.</span></nobr></DIV>
<DIV style="position:absolute;top:910;left:674"><nobr><span class="ft4">The basic idea is to have</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:475"><nobr><span class="ft9">Alice, the owner of a sensitive attribute, act as if she does<br>not have the attribute. Only later when the other party<br>accidentally satisfies her policy for that attribute will Alice<br>disclose that attribute. This approach is easy to deploy in<br>trust negotiation. But clearly it will often cause a potentially<br>successful negotiation to fail because of Alice's conservative<br>response.</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:489"><nobr><span class="ft4">Yu and Winslett [26] introduce a technique called policy</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:475"><nobr><span class="ft9">migration to mitigate the problem of unauthorized inference.<br>In policy migration, Alice dynamically integrates her poli-</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:452"><nobr><span class="ft8">42</span></nobr></DIV>
</DIV>
<!-- Page 8 -->
<a name="8"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft17{font-size:8px;font-family:Times;color:#000000;}
	.ft18{font-size:8px;line-height:11px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="150008.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft9">cies for sensitive attributes with those of other attributes, so<br>that she does not need to explicitly disclose policies for sen-<br>sitive attributes. Meanwhile, policy migration makes sure<br>that "migrated" policies are logically equivalent to original<br>policies, and thus guarantees the success of the negotiation<br>whenever possible. On the other hand, policy migration is<br>not a universal solution, in the sense that it may not be ap-<br>plicable to all the possible configurations of a negotiation.<br>Further, it is subject to a variety of attacks. In other words,<br>it only seeks to make unauthorized inference harder instead<br>of preventing it completely.</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:94"><nobr><span class="ft4">Most existing trust negotiation frameworks [16, 17, 28]</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:81"><nobr><span class="ft9">assume that the appropriate access control policies can be<br>shown to Bob when he requests access to Alice's resource.<br>However, realistic access control policies also tend to contain<br>sensitive information, because the details of Alice's policy<br>for the disclosure of a credential C tends to give hints about<br>C's contents. More generally, a company's internal and ex-<br>ternal policies are part of its corporate assets, and it will<br>not wish to indiscriminately broadcast its policies in their<br>entirety. Several schemes have been proposed to protect the<br>disclosure of sensitive policies. In [4], Bonatti and Samarati<br>suggests dividing a policy into two parts ­ prerequisite rules<br>and requisite rules. The constraints in a requisite rule will<br>not be disclosed until those in prerequisite rules are satisfied.<br>In [19], Seamons et al. proposed organizing a policy into a<br>directed graph so that constraints in a policy can be dis-<br>closed gradually. In [26], access control policies are treated<br>as first-class resources, thus can be protected in the same<br>manner as services and credentials.</span></nobr></DIV>
<DIV style="position:absolute;top:557;left:94"><nobr><span class="ft4">Recently, much work has been done on mutual authenti-</span></nobr></DIV>
<DIV style="position:absolute;top:573;left:81"><nobr><span class="ft9">cation and authorization through the use of cryptographic<br>techniques that offer improved privacy guarantees. For ex-<br>ample, Balfanz et al. [1] designed a secret-handshake scheme<br>where two parties reveal their memberships in a group to<br>each other if and only if they belong to the same group. Li<br>et al. [15] proposed a mutual signature verification scheme<br>to solve the problem of cyclic policy interdependency in trust<br>negotiation. Under their scheme, Alice can see the content<br>of Bob's credential signed by a certification authority CA<br>only if she herself has a valid certificate also signed by CA<br>and containing the content she sent to Bob earlier. A sim-<br>ilar idea was independently explored by researchers [5, 13]<br>to handle more complex access control policies. Note that<br>approaches based on cryptographic techniques usually im-<br>pose more constraints on access control policies. Therefore,<br>policy databases are complementary to the above work.</span></nobr></DIV>
<DIV style="position:absolute;top:841;left:81"><nobr><span class="ft3"><b>5.</b></span></nobr></DIV>
<DIV style="position:absolute;top:841;left:112"><nobr><span class="ft3"><b>CONCLUSION AND FUTURE WORK</b></span></nobr></DIV>
<DIV style="position:absolute;top:863;left:94"><nobr><span class="ft4">In this paper, we have proposed a general framework for</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:81"><nobr><span class="ft9">safety in automated trust negotiation. The framework is<br>based strictly on information gain, instead of on communi-<br>cation. It thus more directly reflects the essence of safe infor-<br>mation flow in trust negotiation. We have also shown that<br>Ack policy systems are safe under our framework. Based<br>on the framework, we have presented policy databases, a<br>new, safe trust negotiation system. Compared with existing<br>systems, policy databases do not introduce extra layers of<br>policies or other complications to the negotiation between<br>users. Further, policy databases preserve user's autonomy<br>in defining their own policies instead of imposing uniform<br>policies across all users. Therefore they are more flexible<br>and easier to deploy than other systems.</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:489"><nobr><span class="ft4">Further, we have discussed a number of practical issues</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:475"><nobr><span class="ft9">which would be involved in implementing our system. In<br>the future, we plan to address how our system can be used<br>in the presence of delegated credentials. And we plan to<br>attempt to broaden the system to account for probabilistic<br>inferences rules which are publicly known.</span></nobr></DIV>
<DIV style="position:absolute;top:185;left:475"><nobr><span class="ft9">Acknowledgments This research was sponsored by NSF<br>through IIS CyberTrust grant number 0430166 (NCSU). We<br>also thank anonymous reviewers for their helpful comments.</span></nobr></DIV>
<DIV style="position:absolute;top:255;left:475"><nobr><span class="ft3"><b>6.</b></span></nobr></DIV>
<DIV style="position:absolute;top:255;left:507"><nobr><span class="ft3"><b>REFERENCES</b></span></nobr></DIV>
<DIV style="position:absolute;top:277;left:481"><nobr><span class="ft17">[1] D. Balfanz, G. Durfee, N. Shankar, D. Smetters, J. Staddon,</span></nobr></DIV>
<DIV style="position:absolute;top:289;left:501"><nobr><span class="ft18">and H. Wong. Secret Handshakes from Pairing-Based Key<br>Agreements. In IEEE Symposium on Security and Privacy,<br>Berkeley, CA, May 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:326;left:481"><nobr><span class="ft17">[2] M. Blaze, J. Feigenbaum, J. Ioannidis, and A. Keromytis. The</span></nobr></DIV>
<DIV style="position:absolute;top:338;left:501"><nobr><span class="ft18">KeyNote Trust Management System Version 2. In Internet<br>Draft RFC 2704, September 1999.</span></nobr></DIV>
<DIV style="position:absolute;top:363;left:481"><nobr><span class="ft17">[3] M. Blaze, J. Feigenbaum, and A. D. Keromytis. KeyNote:</span></nobr></DIV>
<DIV style="position:absolute;top:375;left:501"><nobr><span class="ft18">Trust Management for Public-Key Infrastructures. In Security<br>Protocols Workshop, Cambridge, UK, 1998.</span></nobr></DIV>
<DIV style="position:absolute;top:401;left:481"><nobr><span class="ft17">[4] P. Bonatti and P. Samarati. Regulating Service Access and</span></nobr></DIV>
<DIV style="position:absolute;top:413;left:501"><nobr><span class="ft18">Information Release on the Web. In Conference on Computer<br>and Communications Security, Athens, November 2000.</span></nobr></DIV>
<DIV style="position:absolute;top:438;left:481"><nobr><span class="ft17">[5] R.W. Bradshaw, J.E. Holt, and K.E. Seamons. Concealing</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:501"><nobr><span class="ft18">Complex Policies in Hidden Credentials. In ACM Conference<br>on Computer and Communications Security, Washington,<br>DC, October 2004.</span></nobr></DIV>
<DIV style="position:absolute;top:487;left:481"><nobr><span class="ft17">[6] S. Brands. Rethinking Public Key Infrastructures and Digital</span></nobr></DIV>
<DIV style="position:absolute;top:499;left:501"><nobr><span class="ft17">Certificates: Building in Privacy. The MIT Press, 2000.</span></nobr></DIV>
<DIV style="position:absolute;top:513;left:481"><nobr><span class="ft17">[7] J. Camenisch and E.V. Herreweghen. Design and</span></nobr></DIV>
<DIV style="position:absolute;top:525;left:501"><nobr><span class="ft18">Implementation of the Idemix Anonymous Credential System.<br>In ACM Conference on Computer and Communications<br>Security, Washington D.C., November 2002.</span></nobr></DIV>
<DIV style="position:absolute;top:562;left:481"><nobr><span class="ft17">[8] J. Camenisch and A. Lysyanskaya. Efficient Non-Transferable</span></nobr></DIV>
<DIV style="position:absolute;top:574;left:501"><nobr><span class="ft18">Anonymous Multi-Show Credential System with Optional<br>Anonymity Revocation. In EUROCRYPT 2001, volume 2045<br>of Lecture Notes in Computer Science. Springer, 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:611;left:481"><nobr><span class="ft17">[9] D. Chaum. Security without Identification: Transactions</span></nobr></DIV>
<DIV style="position:absolute;top:623;left:501"><nobr><span class="ft18">Systems to Make Big Brother Obsolete. Communications of<br>the ACM, 24(2), 1985.</span></nobr></DIV>
<DIV style="position:absolute;top:649;left:475"><nobr><span class="ft17">[10] I.B. Damg°</span></nobr></DIV>
<DIV style="position:absolute;top:649;left:555"><nobr><span class="ft17">ard. Payment Systems and Credential Mechanism</span></nobr></DIV>
<DIV style="position:absolute;top:661;left:501"><nobr><span class="ft18">with Provable Security Against Abuse by Individuals. In<br>CRYPTO'88, volume 403 of Lecture Notes in Computer<br>Science. Springer, 1990.</span></nobr></DIV>
<DIV style="position:absolute;top:698;left:475"><nobr><span class="ft17">[11] A. Herzberg, J. Mihaeli, Y. Mass, D. Naor, and Y. Ravid.</span></nobr></DIV>
<DIV style="position:absolute;top:710;left:501"><nobr><span class="ft18">Access Control Meets Public Key Infrastructure, Or: Assigning<br>Roles to Strangers. In IEEE Symposium on Security and<br>Privacy, Oakland, CA, May 2000.</span></nobr></DIV>
<DIV style="position:absolute;top:747;left:475"><nobr><span class="ft17">[12] A. Hess, J. Jacobson, H. Mills, R. Wamsley, K. Seamons, and</span></nobr></DIV>
<DIV style="position:absolute;top:759;left:501"><nobr><span class="ft18">B. Smith. Advanced Client/Server Authentication in TLS. In<br>Network and Distributed System Security Symposium, San<br>Diego, CA, February 2002.</span></nobr></DIV>
<DIV style="position:absolute;top:797;left:475"><nobr><span class="ft17">[13] J. Holt, R. bradshaw, K.E. Seamons, and H. Orman. Hidden</span></nobr></DIV>
<DIV style="position:absolute;top:809;left:501"><nobr><span class="ft18">Credentials. In ACM Workshop on Privacy in the Electronic<br>Society, Washington, DC, October 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:834;left:475"><nobr><span class="ft17">[14] W. Johnson, S. Mudumbai, and M. Thompson. Authorization</span></nobr></DIV>
<DIV style="position:absolute;top:846;left:501"><nobr><span class="ft18">and Attribute Certificates for Widely Distributed Access<br>Control. In IEEE International Workshop on Enabling<br>Technologies: Infrastructure for Collaborative Enterprises,<br>1998.</span></nobr></DIV>
<DIV style="position:absolute;top:895;left:475"><nobr><span class="ft17">[15] N. Li, W. Du, and D. Boneh. Oblivious Signature-Based</span></nobr></DIV>
<DIV style="position:absolute;top:907;left:501"><nobr><span class="ft18">Envelope. In ACM Symposium on Principles of Distributed<br>Computing, New York City, NY, July 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:933;left:475"><nobr><span class="ft17">[16] N. Li, J.C. Mitchell, and W. Winsborough. Design of a</span></nobr></DIV>
<DIV style="position:absolute;top:945;left:501"><nobr><span class="ft18">Role-based Trust-management Framework. In IEEE<br>Symposium on Security and Privacy, Berkeley, California,<br>May 2002.</span></nobr></DIV>
<DIV style="position:absolute;top:982;left:475"><nobr><span class="ft17">[17] N. Li, W. Winsborough, and J.C. Mitchell. Distributed</span></nobr></DIV>
<DIV style="position:absolute;top:994;left:501"><nobr><span class="ft18">Credential Chain Discovery in Trust Management. Journal of<br>Computer Security, 11(1), February 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:1019;left:475"><nobr><span class="ft17">[18] A. Lysyanskaya, R. Rivest, A. Sahai, and S. Wolf. Pseudonym</span></nobr></DIV>
<DIV style="position:absolute;top:1031;left:501"><nobr><span class="ft18">Systems. In Selected Areas in Cryptography, 1999, volume<br>1758 of Lecture Notes in Computer Science. Springer, 2000.</span></nobr></DIV>
<DIV style="position:absolute;top:1057;left:475"><nobr><span class="ft17">[19] K. Seamons, M. Winslett, and T. Yu. Limiting the Disclosure</span></nobr></DIV>
<DIV style="position:absolute;top:1069;left:501"><nobr><span class="ft17">of Access Control Policies during Automated Trust</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:452"><nobr><span class="ft8">43</span></nobr></DIV>
</DIV>
<!-- Page 9 -->
<a name="9"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="150009.png" alt="background image">
<DIV style="position:absolute;top:88;left:106"><nobr><span class="ft18">Negotiation. In Network and Distributed System Security<br>Symposium, San Diego, CA, February 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:114;left:81"><nobr><span class="ft17">[20] K. Seamons, M. Winslett, T. Yu, L. Yu, and R. Jarvis.</span></nobr></DIV>
<DIV style="position:absolute;top:126;left:106"><nobr><span class="ft18">Protecting Privacy during On-line Trust Negotiation. In 2nd<br>Workshop on Privacy Enhancing Technologies, San Francisco,<br>CA, April 2002.</span></nobr></DIV>
<DIV style="position:absolute;top:163;left:81"><nobr><span class="ft17">[21] W. Winsborough and N. Li. Protecting Sensitive Attributes in</span></nobr></DIV>
<DIV style="position:absolute;top:175;left:106"><nobr><span class="ft18">Automated Trust Negotiation. In ACM Workshop on Privacy<br>in the Electronic Society, Washington, DC, November 2002.</span></nobr></DIV>
<DIV style="position:absolute;top:200;left:81"><nobr><span class="ft17">[22] W. Winsborough and N. Li. Towards Practical Automated</span></nobr></DIV>
<DIV style="position:absolute;top:212;left:106"><nobr><span class="ft18">Trust Negotiation. In 3rd International Workshop on Policies<br>for Distributed Systems and Networks, Monterey, California,<br>June 2002.</span></nobr></DIV>
<DIV style="position:absolute;top:250;left:81"><nobr><span class="ft17">[23] W. Winsborough and N. Li. Safety in Automated Trust</span></nobr></DIV>
<DIV style="position:absolute;top:262;left:106"><nobr><span class="ft18">Negotiation. In IEEE Symposium on Security and Privacy,<br>Oakland, CA, May 2004.</span></nobr></DIV>
<DIV style="position:absolute;top:287;left:81"><nobr><span class="ft17">[24] W. Winsborough, K. Seamons, and V. Jones. Automated Trust</span></nobr></DIV>
<DIV style="position:absolute;top:299;left:106"><nobr><span class="ft18">Negotiation. In DARPA Information Survivability Conference<br>and Exposition, Hilton Head Island, SC, January 2000.</span></nobr></DIV>
<DIV style="position:absolute;top:324;left:81"><nobr><span class="ft17">[25] M. Winslett, T. Yu, K.E. Seamons, A. Hess, J. Jarvis,</span></nobr></DIV>
<DIV style="position:absolute;top:336;left:106"><nobr><span class="ft18">B. Smith, and L. Yu. Negotiating Trust on the Web. IEEE<br>Internet Computing, special issue on trust management, 6(6),<br>November 2002.</span></nobr></DIV>
<DIV style="position:absolute;top:374;left:81"><nobr><span class="ft17">[26] T. Yu and M. Winslett. A Unified Scheme for Resource</span></nobr></DIV>
<DIV style="position:absolute;top:386;left:106"><nobr><span class="ft18">Protection in Automated Trust Negotiation. In IEEE<br>Symposium on Security and Privacy, Oakland, CA, May 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:411;left:81"><nobr><span class="ft17">[27] T. Yu and M. Winslett. Policy Migration for Sensitive</span></nobr></DIV>
<DIV style="position:absolute;top:423;left:106"><nobr><span class="ft18">Credentials in Trust Negotiation. In ACM Workshop on<br>Privacy in the Electronic Society, Washington, DC, October<br>2003.</span></nobr></DIV>
<DIV style="position:absolute;top:460;left:81"><nobr><span class="ft17">[28] T. Yu, M. Winslett, and K. Seamons. Supporting Structured</span></nobr></DIV>
<DIV style="position:absolute;top:472;left:106"><nobr><span class="ft18">Credentials and Sensitive Policies through Interoperable<br>Strategies in Automated Trust Negotiation. ACM Transactions<br>on Information and System Security, 6(1), February 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:527;left:81"><nobr><span class="ft3"><b>APPENDIX</b></span></nobr></DIV>
<DIV style="position:absolute;top:554;left:81"><nobr><span class="ft3"><b>A.</b></span></nobr></DIV>
<DIV style="position:absolute;top:554;left:116"><nobr><span class="ft3"><b>PROOF OF THEOREM 1</b></span></nobr></DIV>
<DIV style="position:absolute;top:576;left:94"><nobr><span class="ft4">Our goal is to prove the following theorem:</span></nobr></DIV>
<DIV style="position:absolute;top:597;left:110"><nobr><span class="ft9">There exists no opponent which can beat the a<br>priori odds of guessing the value of an object, o<br>given only information about objects which are<br>not in the same inference component as o, over<br>all principals not in M and whose policy for o M<br>cannot satisfy, over all random tapes, and over all<br>mappings of public key values to principals.</span></nobr></DIV>
<DIV style="position:absolute;top:712;left:94"><nobr><span class="ft4">Now it follows that if the opponent can beat the a priori</span></nobr></DIV>
<DIV style="position:absolute;top:728;left:81"><nobr><span class="ft9">odds of guessing the value of an object, o, then the opponent<br>can beat the a priori odds of guessing the parity of o. Hence,<br>if no opponent can beat the a priori odds of guessing the<br>parity of an object, then none can beat the odds of guessing<br>the value of the object.</span></nobr></DIV>
<DIV style="position:absolute;top:821;left:96"><nobr><span class="ft4">Lemma 1. There exists no opponent which can beat the</span></nobr></DIV>
<DIV style="position:absolute;top:834;left:81"><nobr><span class="ft9">a priori odds of guessing the parity of an object, o given<br>only information about objects which are not in the same<br>inference component as o, over all principals not in M and<br>whose policy for o M cannot satisfy, over all random tapes,<br>and over all mappings of public key values to principals.</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:94"><nobr><span class="ft4">To prove this, we begin with an assumption that there</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:81"><nobr><span class="ft9">exists some tactic which can successfully guess the parity of<br>o with odds better than the a priori odds for at least some<br>public key mappings. We are going to prove that any such<br>tactic cannot beat the a priori odds on average across all<br>mappings because there must be more mappings where it<br>fails to beat the a priori odds than where it beats them.</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:94"><nobr><span class="ft4">Just to be clear, the tactic is allowed to interact with</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:81"><nobr><span class="ft9">principals whose policy for o it can satisfy. It just does not<br>get to guess about the value of o for those principals, as it</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft9">is entitled to beat the a priori odds for them. Hence, doing<br>so is not considered a leakage in the system.</span></nobr></DIV>
<DIV style="position:absolute;top:118;left:489"><nobr><span class="ft4">Because the tactic is a deterministic Turing-equivalent</span></nobr></DIV>
<DIV style="position:absolute;top:133;left:475"><nobr><span class="ft9">computational machine, when it outputs its final guesses,<br>it must output them in some order. We will define n to<br>be the number of users, |K|. We will number the series of<br>principals k</span></nobr></DIV>
<DIV style="position:absolute;top:185;left:546"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:552"><nobr><span class="ft4">, k</span></nobr></DIV>
<DIV style="position:absolute;top:185;left:568"><nobr><span class="ft11">2</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:574"><nobr><span class="ft4">, ..., k</span></nobr></DIV>
<DIV style="position:absolute;top:185;left:610"><nobr><span class="ft11">n</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:618"><nobr><span class="ft4">. Without loss of generality, we can</span></nobr></DIV>
<DIV style="position:absolute;top:196;left:475"><nobr><span class="ft9">assume that every principal's strategy's random tape has<br>some fixed value, resulting in them behaving in a strictly<br>deterministic manner. Therefore, as the tactic and strate-<br>gies are deterministic, the only remaining variable is the<br>mapping of public keys to principals.</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:489"><nobr><span class="ft4">Next we will fix the sequence of public keys.</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:786"><nobr><span class="ft4">Because</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:475"><nobr><span class="ft9">public keys are randomly chosen to begin with, and we are<br>varying over the set of all public-key to user mappings, we<br>can do this without loss of generality. The order in which<br>guesses are made must in some way depend only on the a<br>priori knowledge, the public keys, and the communications<br>which the tactic has with the strategies. So, if all of these<br>things are kept constant, the guesses will not change.</span></nobr></DIV>
<DIV style="position:absolute;top:400;left:489"><nobr><span class="ft4">Let us suppose that a fraction h of the population whose</span></nobr></DIV>
<DIV style="position:absolute;top:416;left:475"><nobr><span class="ft9">policy for o has not been satisfied has one parity value, and<br>a fraction 1 - h of the population has the other. Without<br>loss of generality, we assume that h  1 - h. We determine<br>h by calculating the relative a priori probabilities given the<br>distribution of the values of the object.</span></nobr></DIV>
<DIV style="position:absolute;top:494;left:489"><nobr><span class="ft4">The a priori probability of successfully guessing which par-</span></nobr></DIV>
<DIV style="position:absolute;top:510;left:475"><nobr><span class="ft9">ity a given user's object has is h. Now, if there exists some<br>order of interaction, i which beats the a priori odds, then<br>its number of correct guesses must be expressible as hn + <br>for some  &gt; 0.</span></nobr></DIV>
<DIV style="position:absolute;top:573;left:489"><nobr><span class="ft4">We can break the set of users whose policies for o M can-</span></nobr></DIV>
<DIV style="position:absolute;top:588;left:475"><nobr><span class="ft9">not meet down into a group of sets according to the values<br>of the objects which are in inference components other than<br>the one which contains o. We will define a set of sets, V G<br>such that vg  V G is a set of users all of which have the<br>same values for all objects in all inference components other<br>than the one which contains o.</span></nobr></DIV>
<DIV style="position:absolute;top:683;left:489"><nobr><span class="ft4">Now, let us consider the possibility of rearranging the pub-</span></nobr></DIV>
<DIV style="position:absolute;top:698;left:475"><nobr><span class="ft9">lic keys of members of this group. Because the strategies<br>in use are defined to be deterministic with respect to the<br>policies governing the attributes which distinguish the two<br>configurations and because the opponent is defined to be<br>deterministic: it follows that if we were to rearrange user's<br>public keys from the original mapping to create a new map-<br>ping, the communication would be the same in both. Since<br>the communication would be the same, it follows that the<br>tactic would make the same guesses relative to the order of<br>users because it is a deterministic machine and must pro-<br>duce the same output given the same input, the end result<br>of which is that switching two users both of whom are mem-<br>bers of the same value group will result in the guesses of the<br>parity of those two users switching as well.</span></nobr></DIV>
<DIV style="position:absolute;top:918;left:489"><nobr><span class="ft4">We can then consider the set of all arrangements of pub-</span></nobr></DIV>
<DIV style="position:absolute;top:934;left:475"><nobr><span class="ft9">lic keys formed by switching principals around within their<br>value groups, which we shall call I. So the question at hand,<br>then, is whether or not the expected value of  across all<br>members of I is positive. If we can demonstrate that it is<br>not, then no successful opponent can exist.</span></nobr></DIV>
<DIV style="position:absolute;top:1012;left:489"><nobr><span class="ft4">Here we introduce another lemma. Proof of this lemma is</span></nobr></DIV>
<DIV style="position:absolute;top:1028;left:475"><nobr><span class="ft4">now sufficient to establish our earlier lemma.</span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:490"><nobr><span class="ft4">Lemma 2. The expected value of  across all public key</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:475"><nobr><span class="ft4">mappings is less than or equal to zero.</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:452"><nobr><span class="ft8">44</span></nobr></DIV>
</DIV>
<!-- Page 10 -->
<a name="10"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft19{font-size:5px;line-height:7px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="150010.png" alt="background image">
<DIV style="position:absolute;top:86;left:94"><nobr><span class="ft4">If we have some quantity of extra correct guesses, , for</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:81"><nobr><span class="ft9">some public key mapping i, then these guesses must be dis-<br>tributed over some set of value groups. If  is to be positive<br>on average, then at least some value groups must average<br>a number of correct guesses above the a priori probability<br>over all arrangements in I.</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:94"><nobr><span class="ft4">Let us assume that we have one such group vg. Because</span></nobr></DIV>
<DIV style="position:absolute;top:196;left:81"><nobr><span class="ft9">the distributions of values of items in other inference com-<br>ponents are defined to be precisely independent of o, we can<br>know that in each group, there must be a fraction h of the<br>members which have one parity and 1 - h which have the<br>other. So, in vg there will be x = h|vg| principals with the<br>first parity and y = (1 - h)|vg| principals with the second,<br>and the a priori expected number of correct guesses would<br>be x.</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:94"><nobr><span class="ft4">If, for some mapping, i, the tactic is successful, then there</span></nobr></DIV>
<DIV style="position:absolute;top:337;left:81"><nobr><span class="ft9">must be some number of correct guesses x +  where  &gt; 0.<br>We also know that   y simply because the tactic is limited<br>in total correct guesses to |vg| = x + y. As the number of<br>correct guesses is x + , it must follow that the number of<br>incorrect guesses is y - .</span></nobr></DIV>
<DIV style="position:absolute;top:416;left:94"><nobr><span class="ft4">Further, we need to note that the tactic must make some</span></nobr></DIV>
<DIV style="position:absolute;top:432;left:81"><nobr><span class="ft9">quantity of first parity guesses and some quantity of second<br>parity guesses. Obviously, these quantities need to add up<br>to |vg|, but need not match up with x and y. Every extra<br>first parity or second parity guess guarantees at least one<br>mistake, but even with several mistakes, it is quite possible<br>to beat the a priori odds for some arrangements. So we<br>define x + c to be the number of first parity guesses and<br>y - c to be the number of second parity guesses.</span></nobr></DIV>
<DIV style="position:absolute;top:557;left:94"><nobr><span class="ft4">Now, we know that each increase of one in |c| guarantees</span></nobr></DIV>
<DIV style="position:absolute;top:573;left:81"><nobr><span class="ft9">at least one wrong guess, so we have a bound of  + |c|  y.<br>Further, we know that since c is fixed (as it is not dependent<br>on the arrangement, only the guesses which are unchang-<br>ing), the only way to gain a wrong guess is to swap a first<br>parity principal with a second parity principal, which must<br>necessarily create two wrong guesses. So we can quantify<br>the number of wrong first parity guesses and the number of<br>wrong second parity guesses using the terms we have set up.<br>Specifically, there must be</span></nobr></DIV>
<DIV style="position:absolute;top:696;left:244"><nobr><span class="ft12">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:698;left:252"><nobr><span class="ft4">(y -  + c) incorrect first parity</span></nobr></DIV>
<DIV style="position:absolute;top:716;left:81"><nobr><span class="ft4">guesses, and</span></nobr></DIV>
<DIV style="position:absolute;top:713;left:161"><nobr><span class="ft12">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:716;left:168"><nobr><span class="ft4">(y -  - c) incorrect second parity guesses.</span></nobr></DIV>
<DIV style="position:absolute;top:731;left:94"><nobr><span class="ft4">Now we can determine the number of arrangements of</span></nobr></DIV>
<DIV style="position:absolute;top:747;left:81"><nobr><span class="ft15">principals which will create x +  correct guesses. Specifi-<br>cally, we look at the total number of principals which are<br>first parity and choose a way to arrange them to match up<br>with incorrect second parity guesses and we look at the to-<br>tal number of principals which are second parity and choose<br>a way to arrange them to match up with incorrect first<br>parity guesses. Then we multiply that by the number of<br>permutations of first parity principals and the number of<br>permutations of second parity principals. And we arrive at<br>`</span></nobr></DIV>
<DIV style="position:absolute;top:885;left:109"><nobr><span class="ft11">x</span></nobr></DIV>
<DIV style="position:absolute;top:893;left:89"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:896;left:96"><nobr><span class="ft11">(y--c)</span></nobr></DIV>
<DIV style="position:absolute;top:886;left:138"><nobr><span class="ft4">´`</span></nobr></DIV>
<DIV style="position:absolute;top:885;left:173"><nobr><span class="ft11">y</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:152"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:896;left:159"><nobr><span class="ft11">(y-+c)</span></nobr></DIV>
<DIV style="position:absolute;top:886;left:201"><nobr><span class="ft4">´x!y!.</span></nobr></DIV>
<DIV style="position:absolute;top:908;left:94"><nobr><span class="ft4">Now, similarly, we can calculate the number of arrange-</span></nobr></DIV>
<DIV style="position:absolute;top:924;left:81"><nobr><span class="ft9">ments which will result in x -  correct answers. And if<br>for all  there are at least as many arrangements which<br>produce x -  correct answers as produce x +  of them<br>then the average of  cannot exceed 0. Now, if there are<br>x -  correct answers, then there must be y +  incorrect<br>ones. And we can use the same reasoning to establish that<br>there must be</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:178"><nobr><span class="ft12">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:1018;left:185"><nobr><span class="ft4">(y +  + c) incorrect first parity guesses</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:81"><nobr><span class="ft4">and</span></nobr></DIV>
<DIV style="position:absolute;top:1033;left:109"><nobr><span class="ft12">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:117"><nobr><span class="ft4">(y +  - c) incorrect second parity guesses, and hence</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:81"><nobr><span class="ft4">`</span></nobr></DIV>
<DIV style="position:absolute;top:1050;left:109"><nobr><span class="ft11">x</span></nobr></DIV>
<DIV style="position:absolute;top:1058;left:89"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:1060;left:96"><nobr><span class="ft11">(y+-c)</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:138"><nobr><span class="ft4">´`</span></nobr></DIV>
<DIV style="position:absolute;top:1049;left:173"><nobr><span class="ft11">y</span></nobr></DIV>
<DIV style="position:absolute;top:1058;left:152"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:1061;left:159"><nobr><span class="ft11">(y++c)</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:201"><nobr><span class="ft4">´x!y! arrangements which result in x - </span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft4">correct guesses.</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:585"><nobr><span class="ft4">So if we can prove that this is no less</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:475"><nobr><span class="ft15">than the previous quantity then our proof will be complete.<br>`</span></nobr></DIV>
<DIV style="position:absolute;top:115;left:504"><nobr><span class="ft11">x</span></nobr></DIV>
<DIV style="position:absolute;top:123;left:483"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:125;left:490"><nobr><span class="ft11">(y--c)</span></nobr></DIV>
<DIV style="position:absolute;top:116;left:533"><nobr><span class="ft4">´`</span></nobr></DIV>
<DIV style="position:absolute;top:114;left:568"><nobr><span class="ft11">y</span></nobr></DIV>
<DIV style="position:absolute;top:123;left:547"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:126;left:554"><nobr><span class="ft11">(y-+c)</span></nobr></DIV>
<DIV style="position:absolute;top:116;left:596"><nobr><span class="ft4">´x!y!  `</span></nobr></DIV>
<DIV style="position:absolute;top:115;left:673"><nobr><span class="ft11">x</span></nobr></DIV>
<DIV style="position:absolute;top:123;left:652"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:125;left:659"><nobr><span class="ft11">(y+-c)</span></nobr></DIV>
<DIV style="position:absolute;top:116;left:701"><nobr><span class="ft4">´`</span></nobr></DIV>
<DIV style="position:absolute;top:114;left:736"><nobr><span class="ft11">y</span></nobr></DIV>
<DIV style="position:absolute;top:123;left:716"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:126;left:723"><nobr><span class="ft11">(y++c)</span></nobr></DIV>
<DIV style="position:absolute;top:116;left:764"><nobr><span class="ft4">´x!y! </span></nobr></DIV>
<DIV style="position:absolute;top:138;left:489"><nobr><span class="ft4">`</span></nobr></DIV>
<DIV style="position:absolute;top:137;left:517"><nobr><span class="ft11">x</span></nobr></DIV>
<DIV style="position:absolute;top:145;left:497"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:147;left:504"><nobr><span class="ft11">(y--c)</span></nobr></DIV>
<DIV style="position:absolute;top:138;left:546"><nobr><span class="ft4">´`</span></nobr></DIV>
<DIV style="position:absolute;top:136;left:581"><nobr><span class="ft11">y</span></nobr></DIV>
<DIV style="position:absolute;top:145;left:560"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:148;left:567"><nobr><span class="ft11">(y-+c)</span></nobr></DIV>
<DIV style="position:absolute;top:138;left:609"><nobr><span class="ft4">´  `</span></nobr></DIV>
<DIV style="position:absolute;top:137;left:663"><nobr><span class="ft11">x</span></nobr></DIV>
<DIV style="position:absolute;top:145;left:643"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:147;left:650"><nobr><span class="ft11">(y+-c)</span></nobr></DIV>
<DIV style="position:absolute;top:138;left:692"><nobr><span class="ft4">´`</span></nobr></DIV>
<DIV style="position:absolute;top:136;left:727"><nobr><span class="ft11">y</span></nobr></DIV>
<DIV style="position:absolute;top:145;left:706"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:148;left:713"><nobr><span class="ft11">(y++c)</span></nobr></DIV>
<DIV style="position:absolute;top:138;left:755"><nobr><span class="ft4">´ </span></nobr></DIV>
<DIV style="position:absolute;top:160;left:556"><nobr><span class="ft11">x!</span></nobr></DIV>
<DIV style="position:absolute;top:171;left:490"><nobr><span class="ft11">(</span></nobr></DIV>
<DIV style="position:absolute;top:169;left:497"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:171;left:503"><nobr><span class="ft11">(y--c))!(x-</span></nobr></DIV>
<DIV style="position:absolute;top:169;left:574"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:171;left:581"><nobr><span class="ft11">(y--c))!</span></nobr></DIV>
<DIV style="position:absolute;top:159;left:700"><nobr><span class="ft11">y!</span></nobr></DIV>
<DIV style="position:absolute;top:171;left:634"><nobr><span class="ft11">(</span></nobr></DIV>
<DIV style="position:absolute;top:169;left:641"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:171;left:647"><nobr><span class="ft11">(y-+c))!(y-</span></nobr></DIV>
<DIV style="position:absolute;top:169;left:718"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:171;left:725"><nobr><span class="ft11">(y-+c))!</span></nobr></DIV>
<DIV style="position:absolute;top:162;left:780"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:183;left:556"><nobr><span class="ft11">x!</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:490"><nobr><span class="ft11">(</span></nobr></DIV>
<DIV style="position:absolute;top:192;left:497"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:503"><nobr><span class="ft11">(y+-c))!(x-</span></nobr></DIV>
<DIV style="position:absolute;top:192;left:574"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:581"><nobr><span class="ft11">(y+-c))!</span></nobr></DIV>
<DIV style="position:absolute;top:183;left:699"><nobr><span class="ft11">y!</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:634"><nobr><span class="ft11">(</span></nobr></DIV>
<DIV style="position:absolute;top:192;left:640"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:647"><nobr><span class="ft11">(y++c))!(y-</span></nobr></DIV>
<DIV style="position:absolute;top:192;left:717"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:724"><nobr><span class="ft11">(y++c))!</span></nobr></DIV>
<DIV style="position:absolute;top:185;left:779"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:206;left:558"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:217;left:490"><nobr><span class="ft11">(</span></nobr></DIV>
<DIV style="position:absolute;top:215;left:497"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:217;left:503"><nobr><span class="ft11">(y--c))!(x-</span></nobr></DIV>
<DIV style="position:absolute;top:215;left:574"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:217;left:581"><nobr><span class="ft11">(y--c))!</span></nobr></DIV>
<DIV style="position:absolute;top:206;left:694"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:217;left:634"><nobr><span class="ft11">(</span></nobr></DIV>
<DIV style="position:absolute;top:215;left:641"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:217;left:647"><nobr><span class="ft11">(y-+c))!(</span></nobr></DIV>
<DIV style="position:absolute;top:215;left:703"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:217;left:710"><nobr><span class="ft11">(y+-c))!</span></nobr></DIV>
<DIV style="position:absolute;top:207;left:765"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:228;left:558"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:239;left:490"><nobr><span class="ft11">(</span></nobr></DIV>
<DIV style="position:absolute;top:237;left:497"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:239;left:503"><nobr><span class="ft11">(y+-c))!(x-</span></nobr></DIV>
<DIV style="position:absolute;top:237;left:574"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:239;left:581"><nobr><span class="ft11">(y+-c))!</span></nobr></DIV>
<DIV style="position:absolute;top:228;left:694"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:239;left:634"><nobr><span class="ft11">(</span></nobr></DIV>
<DIV style="position:absolute;top:237;left:640"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:239;left:647"><nobr><span class="ft11">(y++c))!(</span></nobr></DIV>
<DIV style="position:absolute;top:237;left:702"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:239;left:709"><nobr><span class="ft11">(y--c))!</span></nobr></DIV>
<DIV style="position:absolute;top:230;left:765"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:251;left:558"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:262;left:490"><nobr><span class="ft11">(x-</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:511"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:262;left:518"><nobr><span class="ft11">(y--c))!(</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:574"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:262;left:581"><nobr><span class="ft11">(y-+c))!</span></nobr></DIV>
<DIV style="position:absolute;top:252;left:636"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:251;left:720"><nobr><span class="ft11">1</span></nobr></DIV>
<DIV style="position:absolute;top:262;left:653"><nobr><span class="ft11">(x-</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:674"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:262;left:681"><nobr><span class="ft11">(y+-c))!(</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:736"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:262;left:743"><nobr><span class="ft11">(y++c))!</span></nobr></DIV>
<DIV style="position:absolute;top:252;left:798"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:275;left:489"><nobr><span class="ft4">(x -</span></nobr></DIV>
<DIV style="position:absolute;top:273;left:517"><nobr><span class="ft12">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:525"><nobr><span class="ft4">(y -  - c))!(</span></nobr></DIV>
<DIV style="position:absolute;top:273;left:599"><nobr><span class="ft12">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:606"><nobr><span class="ft4">(y -  + c))!  (x -</span></nobr></DIV>
<DIV style="position:absolute;top:273;left:720"><nobr><span class="ft12">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:727"><nobr><span class="ft4">(y +  - c))!(</span></nobr></DIV>
<DIV style="position:absolute;top:273;left:802"><nobr><span class="ft12">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:809"><nobr><span class="ft4">(y +</span></nobr></DIV>
<DIV style="position:absolute;top:298;left:475"><nobr><span class="ft4"> + c))! </span></nobr></DIV>
<DIV style="position:absolute;top:293;left:539"><nobr><span class="ft11">(x-</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:560"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:293;left:567"><nobr><span class="ft11">(y--c))!</span></nobr></DIV>
<DIV style="position:absolute;top:307;left:539"><nobr><span class="ft11">(x-</span></nobr></DIV>
<DIV style="position:absolute;top:304;left:560"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:307;left:567"><nobr><span class="ft11">(y+-c))!</span></nobr></DIV>
<DIV style="position:absolute;top:297;left:622"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:293;left:639"><nobr><span class="ft11">(</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:645"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:293;left:651"><nobr><span class="ft11">(y++c))!</span></nobr></DIV>
<DIV style="position:absolute;top:307;left:638"><nobr><span class="ft11">(</span></nobr></DIV>
<DIV style="position:absolute;top:304;left:644"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:307;left:651"><nobr><span class="ft11">(y-+c))!</span></nobr></DIV>
<DIV style="position:absolute;top:297;left:707"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:293;left:733"><nobr><span class="ft11">(x-</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:754"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:293;left:761"><nobr><span class="ft11">(y--c))!</span></nobr></DIV>
<DIV style="position:absolute;top:307;left:726"><nobr><span class="ft11">(x-</span></nobr></DIV>
<DIV style="position:absolute;top:304;left:747"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:307;left:754"><nobr><span class="ft11">(y--c)-)!</span></nobr></DIV>
<DIV style="position:absolute;top:297;left:823"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:321;left:484"><nobr><span class="ft11">(</span></nobr></DIV>
<DIV style="position:absolute;top:318;left:490"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:321;left:497"><nobr><span class="ft11">(y++c))!</span></nobr></DIV>
<DIV style="position:absolute;top:334;left:477"><nobr><span class="ft11">(</span></nobr></DIV>
<DIV style="position:absolute;top:332;left:483"><nobr><span class="ft19">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:334;left:490"><nobr><span class="ft11">(y++c)-)!</span></nobr></DIV>
<DIV style="position:absolute;top:347;left:489"><nobr><span class="ft4">We define a function f (a, k) = a!/(a-k)!, i.e. the product</span></nobr></DIV>
<DIV style="position:absolute;top:362;left:475"><nobr><span class="ft9">starting from a going down k integers. And obviously a <br>b  f (a, k)  f (b, k), b  k  0.</span></nobr></DIV>
<DIV style="position:absolute;top:394;left:489"><nobr><span class="ft4">Then we can rewrite the last inequality as f (x -</span></nobr></DIV>
<DIV style="position:absolute;top:391;left:799"><nobr><span class="ft12">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:394;left:807"><nobr><span class="ft4">(y -</span></nobr></DIV>
<DIV style="position:absolute;top:411;left:475"><nobr><span class="ft4"> - c), )  f (</span></nobr></DIV>
<DIV style="position:absolute;top:409;left:562"><nobr><span class="ft12">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:411;left:569"><nobr><span class="ft4">(y +  + c), ), which, noting that   0 and</span></nobr></DIV>
<DIV style="position:absolute;top:429;left:475"><nobr><span class="ft4">y   + |c|  y   - c  y + c +   2 </span></nobr></DIV>
<DIV style="position:absolute;top:426;left:737"><nobr><span class="ft12">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:429;left:745"><nobr><span class="ft4">(y + c + )  ,</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:475"><nobr><span class="ft4">is implied by x-</span></nobr></DIV>
<DIV style="position:absolute;top:443;left:577"><nobr><span class="ft12">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:584"><nobr><span class="ft4">(y - -c) </span></nobr></DIV>
<DIV style="position:absolute;top:443;left:660"><nobr><span class="ft12">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:668"><nobr><span class="ft4">(y + +c)  x-</span></nobr></DIV>
<DIV style="position:absolute;top:443;left:767"><nobr><span class="ft12">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:774"><nobr><span class="ft4">y </span></nobr></DIV>
<DIV style="position:absolute;top:443;left:802"><nobr><span class="ft12">1<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:809"><nobr><span class="ft4">y </span></nobr></DIV>
<DIV style="position:absolute;top:462;left:475"><nobr><span class="ft9">x  y  h|vg|  (1 - h)|vg|  h  (1 - h) which we know<br>to be true from our assumption at the start of the proof.</span></nobr></DIV>
<DIV style="position:absolute;top:493;left:489"><nobr><span class="ft4">So we have proven lemma 2, and this completes the proof.</span></nobr></DIV>
<DIV style="position:absolute;top:525;left:475"><nobr><span class="ft3"><b>B.</b></span></nobr></DIV>
<DIV style="position:absolute;top:525;left:510"><nobr><span class="ft3"><b>PROOF OF THEOREM 2</b></span></nobr></DIV>
<DIV style="position:absolute;top:548;left:489"><nobr><span class="ft4">We define n to be the number of users, |K|. Because we</span></nobr></DIV>
<DIV style="position:absolute;top:563;left:475"><nobr><span class="ft9">assume that this system is in a fixed state, every user k is in<br>some configuration g</span></nobr></DIV>
<DIV style="position:absolute;top:584;left:600"><nobr><span class="ft11">k</span></nobr></DIV>
<DIV style="position:absolute;top:579;left:607"><nobr><span class="ft4">. Now let us examine some particular</span></nobr></DIV>
<DIV style="position:absolute;top:595;left:475"><nobr><span class="ft9">attribute, t. We know that a fraction h of users have that<br>attribute and 1 - h do not. Let us define a set of policies<br>L = {p|t  T , k  Kq</span></nobr></DIV>
<DIV style="position:absolute;top:631;left:623"><nobr><span class="ft11">s</span></nobr></DIV>
<DIV style="position:absolute;top:633;left:629"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:625;left:639"><nobr><span class="ft4"> Q such that p = q</span></nobr></DIV>
<DIV style="position:absolute;top:631;left:766"><nobr><span class="ft11">s</span></nobr></DIV>
<DIV style="position:absolute;top:633;left:772"><nobr><span class="ft14">t</span></nobr></DIV>
<DIV style="position:absolute;top:626;left:777"><nobr><span class="ft4">(k)}. We</span></nobr></DIV>
<DIV style="position:absolute;top:642;left:475"><nobr><span class="ft9">also need to know the fraction of users who have each policy<br>in L. As the number of users grows towards infinity, the<br>number of possible policies stays finite, so multiple users<br>with the attribute will wind up sharing the same policy.<br>For every member l  L, we define f</span></nobr></DIV>
<DIV style="position:absolute;top:709;left:701"><nobr><span class="ft11">l</span></nobr></DIV>
<DIV style="position:absolute;top:704;left:710"><nobr><span class="ft4">to be the fraction of</span></nobr></DIV>
<DIV style="position:absolute;top:720;left:475"><nobr><span class="ft4">users with attribute t who have policy l. P</span></nobr></DIV>
<DIV style="position:absolute;top:727;left:744"><nobr><span class="ft11">lL</span></nobr></DIV>
<DIV style="position:absolute;top:720;left:766"><nobr><span class="ft4">f</span></nobr></DIV>
<DIV style="position:absolute;top:725;left:772"><nobr><span class="ft11">l</span></nobr></DIV>
<DIV style="position:absolute;top:720;left:781"><nobr><span class="ft4">= 1. We</span></nobr></DIV>
<DIV style="position:absolute;top:736;left:475"><nobr><span class="ft4">assume that as n approaches infinity, f</span></nobr></DIV>
<DIV style="position:absolute;top:741;left:721"><nobr><span class="ft11">l</span></nobr></DIV>
<DIV style="position:absolute;top:736;left:731"><nobr><span class="ft4">approaches some</span></nobr></DIV>
<DIV style="position:absolute;top:752;left:475"><nobr><span class="ft4">fixed quantity ^</span></nobr></DIV>
<DIV style="position:absolute;top:752;left:565"><nobr><span class="ft4">f</span></nobr></DIV>
<DIV style="position:absolute;top:756;left:572"><nobr><span class="ft11">l</span></nobr></DIV>
<DIV style="position:absolute;top:752;left:582"><nobr><span class="ft4">for every l  L. Essentially, what we are</span></nobr></DIV>
<DIV style="position:absolute;top:767;left:475"><nobr><span class="ft9">assuming is that there is a fixed fraction of users with the<br>attribute who will chose any given policy. The particular<br>number will vary at any given time, but over time, we will<br>approach this fraction. We should then know that for some<br>particular policy l, the odds of a user without the attribute<br>drawing policy l are also f</span></nobr></DIV>
<DIV style="position:absolute;top:850;left:634"><nobr><span class="ft11">l</span></nobr></DIV>
<DIV style="position:absolute;top:846;left:643"><nobr><span class="ft4">because policies are handed out</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:475"><nobr><span class="ft4">with the same distribution that they are submitted.</span></nobr></DIV>
<DIV style="position:absolute;top:877;left:489"><nobr><span class="ft4">The distribution which describes how many users we are</span></nobr></DIV>
<DIV style="position:absolute;top:893;left:475"><nobr><span class="ft9">actually going to have with this policy is a binomial dis-<br>tribution. The variance of a binomial distribution is </span></nobr></DIV>
<DIV style="position:absolute;top:906;left:812"><nobr><span class="ft11">2</span></nobr></DIV>
<DIV style="position:absolute;top:908;left:823"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:924;left:475"><nobr><span class="ft4">n(1-h)f</span></nobr></DIV>
<DIV style="position:absolute;top:929;left:529"><nobr><span class="ft11">l</span></nobr></DIV>
<DIV style="position:absolute;top:924;left:533"><nobr><span class="ft4">(1-f</span></nobr></DIV>
<DIV style="position:absolute;top:929;left:565"><nobr><span class="ft11">l</span></nobr></DIV>
<DIV style="position:absolute;top:924;left:570"><nobr><span class="ft4">). The difference between the actual and the</span></nobr></DIV>
<DIV style="position:absolute;top:940;left:475"><nobr><span class="ft9">ideal is the square root of the variance divided by the ex-<br>pected number of users who have a given policy, which is nf</span></nobr></DIV>
<DIV style="position:absolute;top:960;left:826"><nobr><span class="ft11">l</span></nobr></DIV>
<DIV style="position:absolute;top:956;left:830"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:971;left:475"><nobr><span class="ft4">Hence, the expected difference between our practical sys-</span></nobr></DIV>
<DIV style="position:absolute;top:994;left:475"><nobr><span class="ft4">tem and the ideal system is</span></nobr></DIV>
<DIV style="position:absolute;top:976;left:641"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:989;left:652"><nobr><span class="ft11">n(1-h)f</span></nobr></DIV>
<DIV style="position:absolute;top:992;left:694"><nobr><span class="ft14">l</span></nobr></DIV>
<DIV style="position:absolute;top:989;left:698"><nobr><span class="ft11">(1-f</span></nobr></DIV>
<DIV style="position:absolute;top:992;left:722"><nobr><span class="ft14">l</span></nobr></DIV>
<DIV style="position:absolute;top:989;left:726"><nobr><span class="ft11">)</span></nobr></DIV>
<DIV style="position:absolute;top:1001;left:677"><nobr><span class="ft11">nf</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:690"><nobr><span class="ft14">l</span></nobr></DIV>
<DIV style="position:absolute;top:994;left:736"><nobr><span class="ft4">= q</span></nobr></DIV>
<DIV style="position:absolute;top:990;left:767"><nobr><span class="ft11">(1-h)(1-f</span></nobr></DIV>
<DIV style="position:absolute;top:993;left:820"><nobr><span class="ft14">l</span></nobr></DIV>
<DIV style="position:absolute;top:990;left:824"><nobr><span class="ft11">)</span></nobr></DIV>
<DIV style="position:absolute;top:1001;left:789"><nobr><span class="ft11">nf</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:801"><nobr><span class="ft14">l</span></nobr></DIV>
<DIV style="position:absolute;top:994;left:830"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:1016;left:475"><nobr><span class="ft4">1 - h is a constant term, and f</span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:668"><nobr><span class="ft11">l</span></nobr></DIV>
<DIV style="position:absolute;top:1016;left:677"><nobr><span class="ft4">will approach ^</span></nobr></DIV>
<DIV style="position:absolute;top:1016;left:764"><nobr><span class="ft4">f</span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:771"><nobr><span class="ft11">l</span></nobr></DIV>
<DIV style="position:absolute;top:1016;left:775"><nobr><span class="ft4">, which is</span></nobr></DIV>
<DIV style="position:absolute;top:1033;left:475"><nobr><span class="ft4">a fixed quantity. So lim</span></nobr></DIV>
<DIV style="position:absolute;top:1038;left:622"><nobr><span class="ft11">ninf</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:658"><nobr><span class="ft11">(1-h)(1-f</span></nobr></DIV>
<DIV style="position:absolute;top:1033;left:711"><nobr><span class="ft14">l</span></nobr></DIV>
<DIV style="position:absolute;top:1030;left:715"><nobr><span class="ft11">)</span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:680"><nobr><span class="ft11">nf</span></nobr></DIV>
<DIV style="position:absolute;top:1044;left:693"><nobr><span class="ft14">l</span></nobr></DIV>
<DIV style="position:absolute;top:1033;left:726"><nobr><span class="ft4">= 0, and we have</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:475"><nobr><span class="ft9">proven that our system approaches the ideal as the number<br>of users goes to infinity.</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:452"><nobr><span class="ft8">45</span></nobr></DIV>
</DIV>
</BODY>
</HTML>
