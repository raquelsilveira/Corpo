<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
<HEAD>
<TITLE>f35-ntoulas.dvi</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<META name="generator" content="pdftohtml 0.35beta">
<META name="date" content="2005-05-31T19:27:59+00:00">
</HEAD>
<BODY bgcolor="#A0A0A0" vlink="blue" link="blue">
<!-- Page 1 -->
<a name="1"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft0{font-size:24px;font-family:Helvetica;color:#000000;}
	.ft1{font-size:15px;font-family:Helvetica;color:#000000;}
	.ft2{font-size:12px;font-family:Helvetica;color:#000000;}
	.ft3{font-size:15px;font-family:Times;color:#000000;}
	.ft4{font-size:11px;font-family:Times;color:#000000;}
	.ft5{font-size:11px;font-family:Times;color:#000000;}
	.ft6{font-size:11px;font-family:Times;color:#000000;}
	.ft7{font-size:11px;font-family:Times;color:#000000;}
	.ft8{font-size:9px;font-family:Times;color:#000000;}
	.ft9{font-size:9px;font-family:Times;color:#000000;}
	.ft10{font-size:6px;font-family:Times;color:#000000;}
	.ft11{font-size:16px;font-family:Courier;color:#000000;}
	.ft12{font-size:11px;line-height:15px;font-family:Times;color:#000000;}
	.ft13{font-size:11px;line-height:15px;font-family:Times;color:#000000;}
	.ft14{font-size:9px;line-height:13px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="74001.png" alt="background image">
<DIV style="position:absolute;top:108;left:130"><nobr><span class="ft0"><b>Downloading Textual Hidden Web Content Through</b></span></nobr></DIV>
<DIV style="position:absolute;top:138;left:348"><nobr><span class="ft0"><b>Keyword Queries</b></span></nobr></DIV>
<DIV style="position:absolute;top:205;left:160"><nobr><span class="ft1">Alexandros Ntoulas</span></nobr></DIV>
<DIV style="position:absolute;top:223;left:154"><nobr><span class="ft2">UCLA Computer Science</span></nobr></DIV>
<DIV style="position:absolute;top:245;left:155"><nobr><span class="ft1">ntoulas@cs.ucla.edu</span></nobr></DIV>
<DIV style="position:absolute;top:205;left:404"><nobr><span class="ft1">Petros Zerfos</span></nobr></DIV>
<DIV style="position:absolute;top:223;left:374"><nobr><span class="ft2">UCLA Computer Science</span></nobr></DIV>
<DIV style="position:absolute;top:245;left:374"><nobr><span class="ft1">pzerfos@cs.ucla.edu</span></nobr></DIV>
<DIV style="position:absolute;top:205;left:624"><nobr><span class="ft1">Junghoo Cho</span></nobr></DIV>
<DIV style="position:absolute;top:223;left:593"><nobr><span class="ft2">UCLA Computer Science</span></nobr></DIV>
<DIV style="position:absolute;top:245;left:608"><nobr><span class="ft1">cho@cs.ucla.edu</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:81"><nobr><span class="ft3"><b>ABSTRACT</b></span></nobr></DIV>
<DIV style="position:absolute;top:337;left:81"><nobr><span class="ft12">An ever-increasing amount of information on the Web today is<br>available only through search interfaces: the users have to type in a<br>set of keywords in a search form in order to access the pages from<br>certain Web sites. These pages are often referred to as the <i>Hidden<br>Web </i>or the <i>Deep Web</i>. Since there are no static links to the Hidden<br>Web pages, search engines cannot discover and index such pages<br>and thus do not return them in the results. However, according to<br>recent studies, the content provided by many Hidden Web sites is<br>often of very high quality and can be extremely valuable to many<br>users.</span></nobr></DIV>
<DIV style="position:absolute;top:494;left:94"><nobr><span class="ft4">In this paper, we study how we can build an effective <i>Hidden Web</i></span></nobr></DIV>
<DIV style="position:absolute;top:509;left:81"><nobr><span class="ft12"><i>crawler </i>that can autonomously discover and download pages from<br>the Hidden Web. Since the only "entry point" to a Hidden Web site<br>is a query interface, the main challenge that a Hidden Web crawler<br>has to face is how to automatically generate meaningful queries to<br>issue to the site. Here, we provide a theoretical framework to in-<br>vestigate the query generation problem for the Hidden Web and we<br>propose effective policies for generating queries automatically. Our<br>policies proceed iteratively, issuing a different query in every itera-<br>tion. We experimentally evaluate the effectiveness of these policies<br>on</span></nobr></DIV>
<DIV style="position:absolute;top:647;left:98"><nobr><span class="ft6">4 real Hidden Web sites and our results are very promising. For</span></nobr></DIV>
<DIV style="position:absolute;top:666;left:81"><nobr><span class="ft12">instance, in one experiment, one of our policies downloaded more<br>than</span></nobr></DIV>
<DIV style="position:absolute;top:678;left:109"><nobr><span class="ft6">90% of a Hidden Web site (that contains 14 million docu-</span></nobr></DIV>
<DIV style="position:absolute;top:698;left:81"><nobr><span class="ft4">ments) after issuing fewer than 100 queries.</span></nobr></DIV>
<DIV style="position:absolute;top:718;left:81"><nobr><span class="ft3"><b>Categories and Subject Descriptors</span></nobr></DIV>
<DIV style="position:absolute;top:718;left:81"><nobr><span class="ft12">H.3.7 [Information Systems]:<br>Digital Libraries; H.3.1 [Information Systems]: Content Analysis<br>and Indexing; H.3.3 [Information Systems]: Information Search<br>and Retrieval.</span></nobr></DIV>
<DIV style="position:absolute;top:785;left:81"><nobr><span class="ft3"><b>General Terms</span></nobr></DIV>
<DIV style="position:absolute;top:785;left:81"><nobr><span class="ft4">Algorithms, Performance, Design.</span></nobr></DIV>
<DIV style="position:absolute;top:805;left:81"><nobr><span class="ft12"><b>Keywords: </b>Hidden Web crawling, Deep Web crawler, keyword<br>queries, adaptive algorithm, query selection.</span></nobr></DIV>
<DIV style="position:absolute;top:841;left:81"><nobr><span class="ft3"><b>1.</b></span></nobr></DIV>
<DIV style="position:absolute;top:841;left:112"><nobr><span class="ft3"><b>INTRODUCTION</b></span></nobr></DIV>
<DIV style="position:absolute;top:863;left:94"><nobr><span class="ft4">Recent studies show that a significant fraction of Web content</span></nobr></DIV>
<DIV style="position:absolute;top:879;left:81"><nobr><span class="ft12">cannot be reached by following links [7, 12]. In particular, a large<br>part of the Web is "hidden" behind search forms and is reachable<br>only when users type in a set of keywords, or <i>queries</i>, to the forms.<br>These pages are often referred to as the <i>Hidden Web </i>[17] or the</span></nobr></DIV>
<DIV style="position:absolute;top:977;left:81"><nobr><span class="ft14">Permission to make digital or hard copies of all or part of this work for<br>personal or classroom use is granted without fee provided that copies are<br>not made or distributed for profit or commercial advantage and that copies<br>bear this notice and the full citation on the first page. To copy otherwise, to<br>republish, to post on servers or to redistribute to lists, requires prior specific<br>permission and/or a fee.<br><i>JCDL'05, </i>June 7­11, 2005, Denver, Colorado, USA.<br>Copyright 2005 ACM 1-58113-876-8/05/0006 ...</span></nobr></DIV>
<DIV style="position:absolute;top:1070;left:315"><nobr><span class="ft4">$</span></nobr></DIV>
<DIV style="position:absolute;top:1071;left:322"><nobr><span class="ft8">5.00.</span></nobr></DIV>
<DIV style="position:absolute;top:315;left:475"><nobr><span class="ft12"><i>Deep Web </i>[7], because search engines typically cannot index the<br>pages and do not return them in their results (thus, the pages are<br>essentially "hidden" from a typical Web user).</span></nobr></DIV>
<DIV style="position:absolute;top:362;left:489"><nobr><span class="ft4">According to many studies, the size of the Hidden Web increases</span></nobr></DIV>
<DIV style="position:absolute;top:378;left:475"><nobr><span class="ft12">rapidly as more organizations put their valuable content online<br>through an easy-to-use Web interface [7]. In [12], Chang et al.<br>estimate that well over 100,000 Hidden-Web sites currently exist<br>on the Web. Moreover, the content provided by many Hidden-Web<br>sites is often of very high quality and can be extremely valuable<br>to many users [7]. For example, PubMed hosts many high-quality<br>papers on medical research that were selected from careful peer-<br>review processes, while the site of the US Patent and Trademarks<br>Office</span></nobr></DIV>
<DIV style="position:absolute;top:501;left:508"><nobr><span class="ft10">1</span></nobr></DIV>
<DIV style="position:absolute;top:503;left:517"><nobr><span class="ft4">makes existing patent documents available, helping poten-</span></nobr></DIV>
<DIV style="position:absolute;top:519;left:475"><nobr><span class="ft4">tial inventors examine "prior art."</span></nobr></DIV>
<DIV style="position:absolute;top:535;left:489"><nobr><span class="ft4">In this paper, we study how we can build a <i>Hidden-Web crawler</i></span></nobr></DIV>
<DIV style="position:absolute;top:532;left:829"><nobr><span class="ft10">2</span></nobr></DIV>
<DIV style="position:absolute;top:550;left:475"><nobr><span class="ft12">that can automatically download pages from the Hidden Web, so<br>that search engines can index them. Conventional crawlers rely<br>on the hyperlinks on the Web to discover pages, so current search<br>engines cannot index the Hidden-Web pages (due to the lack of<br>links). We believe that an effective Hidden-Web crawler can have<br>a tremendous impact on how users search information on the Web:</span></nobr></DIV>
<DIV style="position:absolute;top:645;left:477"><nobr><span class="ft6">· <i>Tapping into unexplored information</i>:</span></nobr></DIV>
<DIV style="position:absolute;top:648;left:734"><nobr><span class="ft4">The Hidden-Web</span></nobr></DIV>
<DIV style="position:absolute;top:664;left:490"><nobr><span class="ft12">crawler will allow an average Web user to easily explore the<br>vast amount of information that is mostly "hidden" at present.<br>Since a majority of Web users rely on search engines to discover<br>pages, when pages are not indexed by search engines, they are<br>unlikely to be viewed by many Web users. Unless users go di-<br>rectly to Hidden-Web sites and issue queries there, they cannot<br>access the pages at the sites.</span></nobr></DIV>
<DIV style="position:absolute;top:776;left:477"><nobr><span class="ft6">· <i>Improving user experience</i>: Even if a user is aware of a num-</span></nobr></DIV>
<DIV style="position:absolute;top:795;left:490"><nobr><span class="ft12">ber of Hidden-Web sites, the user still has to waste a significant<br>amount of time and effort, visiting all of the potentially relevant<br>sites, querying each of them and exploring the result. By making<br>the Hidden-Web pages searchable at a central location, we can<br>significantly reduce the user's wasted time and effort in search-<br>ing the Hidden Web.</span></nobr></DIV>
<DIV style="position:absolute;top:892;left:477"><nobr><span class="ft6">· <i>Reducing potential bias</i>: Due to the heavy reliance of many Web</span></nobr></DIV>
<DIV style="position:absolute;top:912;left:490"><nobr><span class="ft12">users on search engines for locating information, search engines<br>influence how the users perceive the Web [28]. Users do <i>not<br></i>necessarily perceive what actually <i>exists </i>on the Web, but what<br>is <i>indexed </i>by search engines [28]. According to a recent arti-<br>cle [5], several organizations have recognized the importance of<br>bringing information of their Hidden Web sites onto the surface,<br>and committed considerable resources towards this effort. Our</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:477"><nobr><span class="ft10">1</span></nobr></DIV>
<DIV style="position:absolute;top:1037;left:482"><nobr><span class="ft4">US Patent Office: http://www.uspto.gov</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:477"><nobr><span class="ft10">2</span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:482"><nobr><span class="ft4">Crawlers are the programs that traverse the Web automatically and</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:475"><nobr><span class="ft4">download pages for search engines.</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft4">100</span></nobr></DIV>
</DIV>
<!-- Page 2 -->
<a name="2"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft15{font-size:11px;line-height:16px;font-family:Times;color:#000000;}
	.ft16{font-size:11px;line-height:13px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="74002.png" alt="background image">
<DIV style="position:absolute;top:118;left:134"><nobr><span class="ft7"><b>Figure 1: A single-attribute search interface</b></span></nobr></DIV>
<DIV style="position:absolute;top:153;left:96"><nobr><span class="ft12">Hidden-Web crawler attempts to automate this process for Hid-<br>den Web sites with textual content, thus minimizing the associ-<br>ated costs and effort required.</span></nobr></DIV>
<DIV style="position:absolute;top:202;left:94"><nobr><span class="ft4">Given that the only "entry" to Hidden Web pages is through</span></nobr></DIV>
<DIV style="position:absolute;top:218;left:81"><nobr><span class="ft12">querying a search form, there are two core challenges to imple-<br>menting an effective Hidden Web crawler: (a) The crawler has to<br>be able to understand and model a query interface, and (b) The<br>crawler has to come up with meaningful queries to issue to the<br>query interface. The first challenge was addressed by Raghavan<br>and Garcia-Molina in [29], where a method for learning search in-<br>terfaces was presented. Here, we present a solution to the second<br>challenge, i.e. how a crawler can automatically generate queries so<br>that it can discover and download the Hidden Web pages.</span></nobr></DIV>
<DIV style="position:absolute;top:359;left:94"><nobr><span class="ft4">Clearly, when the search forms list all possible values for a query</span></nobr></DIV>
<DIV style="position:absolute;top:375;left:81"><nobr><span class="ft12">(e.g., through a drop-down list), the solution is straightforward. We<br>exhaustively issue all possible queries, one query at a time. When<br>the query forms have a "free text" input, however, an <i>infinite </i>num-<br>ber of queries are possible, so we cannot exhaustively issue all pos-<br>sible queries. In this case, what queries should we pick? Can the<br>crawler automatically come up with meaningful queries without<br>understanding the semantics of the search form?</span></nobr></DIV>
<DIV style="position:absolute;top:484;left:94"><nobr><span class="ft4">In this paper, we provide a theoretical framework to investigate</span></nobr></DIV>
<DIV style="position:absolute;top:500;left:81"><nobr><span class="ft12">the Hidden-Web crawling problem and propose effective ways of<br>generating queries automatically. We also evaluate our proposed<br>solutions through experiments conducted on <i>real </i>Hidden-Web sites.<br>In summary, this paper makes the following contributions:</span></nobr></DIV>
<DIV style="position:absolute;top:562;left:82"><nobr><span class="ft6">· We present a formal framework to study the problem of Hidden-</span></nobr></DIV>
<DIV style="position:absolute;top:581;left:96"><nobr><span class="ft4">Web crawling. (Section 2).</span></nobr></DIV>
<DIV style="position:absolute;top:597;left:82"><nobr><span class="ft6">· We investigate a number of crawling policies for the Hidden</span></nobr></DIV>
<DIV style="position:absolute;top:616;left:96"><nobr><span class="ft12">Web, including the optimal policy that can potentially download<br>the maximum number of pages through the minimum number of<br>interactions. Unfortunately, we show that the optimal policy is<br>NP-hard and cannot be implemented in practice (Section 2.2).</span></nobr></DIV>
<DIV style="position:absolute;top:680;left:82"><nobr><span class="ft6">· We propose a new adaptive policy that approximates the optimal</span></nobr></DIV>
<DIV style="position:absolute;top:699;left:96"><nobr><span class="ft12">policy. Our adaptive policy examines the pages returned from<br>previous queries and adapts its query-selection policy automati-<br>cally based on them (Section 3).</span></nobr></DIV>
<DIV style="position:absolute;top:747;left:82"><nobr><span class="ft6">· We evaluate various crawling policies through experiments on</span></nobr></DIV>
<DIV style="position:absolute;top:766;left:96"><nobr><span class="ft12">real Web sites. Our experiments will show the relative advan-<br>tages of various crawling policies and demonstrate their poten-<br>tial. The results from our experiments are very promising. In<br>one experiment, for example, our adaptive policy downloaded<br>more than 90% of the pages within PubMed (that contains 14<br>million documents) after it issued fewer than 100 queries.</span></nobr></DIV>
<DIV style="position:absolute;top:870;left:81"><nobr><span class="ft3"><b>2.</b></span></nobr></DIV>
<DIV style="position:absolute;top:870;left:112"><nobr><span class="ft3"><b>FRAMEWORK</b></span></nobr></DIV>
<DIV style="position:absolute;top:892;left:94"><nobr><span class="ft4">In this section, we present a formal framework for the study of</span></nobr></DIV>
<DIV style="position:absolute;top:908;left:81"><nobr><span class="ft12">the Hidden-Web crawling problem. In Section 2.1, we describe our<br>assumptions on Hidden-Web sites and explain how users interact<br>with the sites. Based on this interaction model, we present a high-<br>level algorithm for a Hidden-Web crawler in Section 2.2. Finally in<br>Section 2.3, we formalize the Hidden-Web crawling problem.</span></nobr></DIV>
<DIV style="position:absolute;top:997;left:81"><nobr><span class="ft3"><b>2.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:997;left:121"><nobr><span class="ft3"><b>Hidden-Web database model</b></span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:94"><nobr><span class="ft4">There exists a variety of Hidden Web sources that provide infor-</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:81"><nobr><span class="ft13">mation on a multitude of topics. Depending on the type of infor-<br>mation, we may categorize a Hidden-Web site either as a <i>textual<br>database </i>or a <i>structured database</i>. A textual database is a site that</span></nobr></DIV>
<DIV style="position:absolute;top:170;left:530"><nobr><span class="ft7"><b>Figure 2: A multi-attribute search interface</b></span></nobr></DIV>
<DIV style="position:absolute;top:204;left:475"><nobr><span class="ft15">mainly contains plain-text documents, such as <i>PubMed </i>and <i>Lexis-<br>Nexis </i>(an online database of legal documents [1]). Since plain-<br>text documents do not usually have well-defined structure, most<br>textual databases provide a simple search interface where users<br>type a list of keywords in a <i>single </i>search box (Figure 1). In con-<br>trast, a structured database often contains multi-attribute relational<br>data (e.g., a book on the Amazon Web site may have the fields<br>title=`Harry Potter'</span></nobr></DIV>
<DIV style="position:absolute;top:313;left:637"><nobr><span class="ft4">, author=`J.K. Rowling' and</span></nobr></DIV>
<DIV style="position:absolute;top:330;left:475"><nobr><span class="ft6">isbn=`0590353403'</span></nobr></DIV>
<DIV style="position:absolute;top:329;left:612"><nobr><span class="ft4">) and supports <i>multi-attribute </i>search in-</span></nobr></DIV>
<DIV style="position:absolute;top:345;left:475"><nobr><span class="ft12">terfaces (Figure 2). In this paper, we will mainly focus on <i>tex-<br>tual databases </i>that support <i>single-attribute </i>keyword queries. We<br>discuss how we can extend our ideas for the textual databases to<br>multi-attribute structured databases in Section 6.1.</span></nobr></DIV>
<DIV style="position:absolute;top:408;left:489"><nobr><span class="ft4">Typically, the users need to take the following steps in order to</span></nobr></DIV>
<DIV style="position:absolute;top:423;left:475"><nobr><span class="ft4">access pages in a Hidden-Web database:</span></nobr></DIV>
<DIV style="position:absolute;top:441;left:473"><nobr><span class="ft4">1. <b>Step 1. </b>First, the user issues a query, say "liver," through the</span></nobr></DIV>
<DIV style="position:absolute;top:457;left:490"><nobr><span class="ft12">search interface provided by the Web site (such as the one shown<br>in Figure 1).</span></nobr></DIV>
<DIV style="position:absolute;top:492;left:473"><nobr><span class="ft4">2. <b>Step 2. </b>Shortly after the user issues the query, she is presented</span></nobr></DIV>
<DIV style="position:absolute;top:507;left:490"><nobr><span class="ft12">with a <i>result index page</i>. That is, the Web site returns a list of<br>links to potentially relevant Web pages, as shown in Figure 3(a).</span></nobr></DIV>
<DIV style="position:absolute;top:542;left:473"><nobr><span class="ft4">3. <b>Step 3. </b>From the list in the result index page, the user identifies</span></nobr></DIV>
<DIV style="position:absolute;top:558;left:490"><nobr><span class="ft12">the pages that look "interesting" and follows the links. Clicking<br>on a link leads the user to the actual Web page, such as the one<br>shown in Figure 3(b), that the user wants to look at.</span></nobr></DIV>
<DIV style="position:absolute;top:615;left:475"><nobr><span class="ft3"><b>2.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:615;left:516"><nobr><span class="ft3"><b>A generic Hidden Web crawling algorithm</b></span></nobr></DIV>
<DIV style="position:absolute;top:637;left:489"><nobr><span class="ft4">Given that the only "entry" to the pages in a Hidden-Web site</span></nobr></DIV>
<DIV style="position:absolute;top:653;left:475"><nobr><span class="ft12">is its search from, a Hidden-Web crawler should follow the three<br>steps described in the previous section. That is, the crawler has<br>to generate a query, issue it to the Web site, download the result<br>index page, and follow the links to download the actual pages. In<br>most cases, a crawler has limited time and network resources, so<br>the crawler repeats these steps until it uses up its resources.</span></nobr></DIV>
<DIV style="position:absolute;top:747;left:489"><nobr><span class="ft4">In Figure 4 we show the generic algorithm for a Hidden-Web</span></nobr></DIV>
<DIV style="position:absolute;top:763;left:475"><nobr><span class="ft12">crawler. For simplicity, we assume that the Hidden-Web crawler<br>issues single-term queries only.</span></nobr></DIV>
<DIV style="position:absolute;top:776;left:648"><nobr><span class="ft10">3</span></nobr></DIV>
<DIV style="position:absolute;top:778;left:660"><nobr><span class="ft4">The crawler first decides which</span></nobr></DIV>
<DIV style="position:absolute;top:794;left:475"><nobr><span class="ft12">query term it is going to use (Step (2)), issues the query, and re-<br>trieves the result index page (Step (3)). Finally, based on the links<br>found on the result index page, it downloads the Hidden Web pages<br>from the site (Step (4)). This same process is repeated until all the<br>available resources are used up (Step (1)).</span></nobr></DIV>
<DIV style="position:absolute;top:873;left:489"><nobr><span class="ft4">Given this algorithm, we can see that the most critical decision</span></nobr></DIV>
<DIV style="position:absolute;top:888;left:475"><nobr><span class="ft12">that a crawler has to make is what query to issue next. If the<br>crawler can issue successful queries that will return many matching<br>pages, the crawler can finish its crawling early on using minimum<br>resources. In contrast, if the crawler issues completely irrelevant<br>queries that do not return any matching pages, it may waste all<br>of its resources simply issuing queries without ever retrieving ac-<br>tual pages. Therefore, how the crawler selects the next query can<br>greatly affect its effectiveness. In the next section, we formalize<br>this query selection problem.</span></nobr></DIV>
<DIV style="position:absolute;top:1037;left:477"><nobr><span class="ft10">3</span></nobr></DIV>
<DIV style="position:absolute;top:1040;left:482"><nobr><span class="ft4">For most Web sites that assume "AND" for multi-keyword</span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:475"><nobr><span class="ft16">queries, single-term queries return the maximum number of results.<br>Extending our work to multi-keyword queries is straightforward.</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft4">101</span></nobr></DIV>
</DIV>
<!-- Page 3 -->
<a name="3"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft17{font-size:8px;font-family:Times;color:#000000;}
	.ft18{font-size:6px;font-family:Times;color:#000000;}
	.ft19{font-size:12px;font-family:Times;color:#000000;}
	.ft20{font-size:14px;font-family:Times;color:#000000;}
	.ft21{font-size:11px;line-height:15px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="74003.png" alt="background image">
<DIV style="position:absolute;top:244;left:132"><nobr><span class="ft4">(a) List of matching pages for query "liver".</span></nobr></DIV>
<DIV style="position:absolute;top:244;left:553"><nobr><span class="ft4">(b) The first matching page for "liver".</span></nobr></DIV>
<DIV style="position:absolute;top:274;left:332"><nobr><span class="ft7"><b>Figure 3: Pages from the PubMed Web site.</b></span></nobr></DIV>
<DIV style="position:absolute;top:335;left:114"><nobr><span class="ft4">A</span></nobr></DIV>
<DIV style="position:absolute;top:337;left:124"><nobr><span class="ft17">LGORITHM</span></nobr></DIV>
<DIV style="position:absolute;top:335;left:194"><nobr><span class="ft4">2.1.</span></nobr></DIV>
<DIV style="position:absolute;top:335;left:226"><nobr><span class="ft7"><b>Crawling a Hidden Web site</b></span></nobr></DIV>
<DIV style="position:absolute;top:354;left:113"><nobr><span class="ft21"><b>Procedure<br></b><i>(1)</i></span></nobr></DIV>
<DIV style="position:absolute;top:370;left:141"><nobr><span class="ft5"><i>while ( there are available resources ) do</i></span></nobr></DIV>
<DIV style="position:absolute;top:389;left:155"><nobr><span class="ft5"><i>// select a term to send to the site</i></span></nobr></DIV>
<DIV style="position:absolute;top:405;left:113"><nobr><span class="ft5"><i>(2)</i></span></nobr></DIV>
<DIV style="position:absolute;top:405;left:170"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:409;left:176"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:405;left:184"><nobr><span class="ft5"><i>= SelectTerm()</i></span></nobr></DIV>
<DIV style="position:absolute;top:424;left:155"><nobr><span class="ft5"><i>// send query and acquire result index page</i></span></nobr></DIV>
<DIV style="position:absolute;top:440;left:113"><nobr><span class="ft5"><i>(3)</i></span></nobr></DIV>
<DIV style="position:absolute;top:440;left:170"><nobr><span class="ft6">R(q</span></nobr></DIV>
<DIV style="position:absolute;top:444;left:192"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:436;left:196"><nobr><span class="ft6">) <i>= QueryWebSite( </i>q</span></nobr></DIV>
<DIV style="position:absolute;top:444;left:308"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:440;left:316"><nobr><span class="ft5"><i>)</i></span></nobr></DIV>
<DIV style="position:absolute;top:459;left:155"><nobr><span class="ft5"><i>// download the pages of interest</i></span></nobr></DIV>
<DIV style="position:absolute;top:475;left:113"><nobr><span class="ft5"><i>(4)</i></span></nobr></DIV>
<DIV style="position:absolute;top:475;left:170"><nobr><span class="ft5"><i>Download(</i></span></nobr></DIV>
<DIV style="position:absolute;top:475;left:234"><nobr><span class="ft6">R(q</span></nobr></DIV>
<DIV style="position:absolute;top:479;left:256"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:471;left:260"><nobr><span class="ft6">) <i>)</i></span></nobr></DIV>
<DIV style="position:absolute;top:494;left:113"><nobr><span class="ft5"><i>(5)</i></span></nobr></DIV>
<DIV style="position:absolute;top:494;left:141"><nobr><span class="ft5"><i>done</i></span></nobr></DIV>
<DIV style="position:absolute;top:540;left:109"><nobr><span class="ft7"><b>Figure 4: Algorithm for crawling a Hidden Web site.</b></span></nobr></DIV>
<DIV style="position:absolute;top:554;left:213"><nobr><span class="ft19"><i>S</i></span></nobr></DIV>
<DIV style="position:absolute;top:563;left:263"><nobr><span class="ft19"><i>q</i></span></nobr></DIV>
<DIV style="position:absolute;top:569;left:269"><nobr><span class="ft9"><i>1</i></span></nobr></DIV>
<DIV style="position:absolute;top:588;left:290"><nobr><span class="ft19"><i>q</i></span></nobr></DIV>
<DIV style="position:absolute;top:611;left:321"><nobr><span class="ft19"><i>q</i></span></nobr></DIV>
<DIV style="position:absolute;top:614;left:213"><nobr><span class="ft19"><i>q</i></span></nobr></DIV>
<DIV style="position:absolute;top:593;left:296"><nobr><span class="ft9"><i>2</i></span></nobr></DIV>
<DIV style="position:absolute;top:617;left:327"><nobr><span class="ft9"><i>3</i></span></nobr></DIV>
<DIV style="position:absolute;top:619;left:220"><nobr><span class="ft9"><i>4</i></span></nobr></DIV>
<DIV style="position:absolute;top:693;left:81"><nobr><span class="ft21"><b>Figure 5: A set-formalization of the optimal query selection<br>problem.</b></span></nobr></DIV>
<DIV style="position:absolute;top:740;left:81"><nobr><span class="ft3"><b>2.3</b></span></nobr></DIV>
<DIV style="position:absolute;top:740;left:121"><nobr><span class="ft3"><b>Problem formalization</b></span></nobr></DIV>
<DIV style="position:absolute;top:762;left:94"><nobr><span class="ft4">Theoretically, the problem of query selection can be formalized</span></nobr></DIV>
<DIV style="position:absolute;top:778;left:81"><nobr><span class="ft12">as follows: We assume that the crawler downloads pages from a<br>Web site that has a set of pages</span></nobr></DIV>
<DIV style="position:absolute;top:793;left:256"><nobr><span class="ft6">S (the rectangle in Figure 5). We</span></nobr></DIV>
<DIV style="position:absolute;top:809;left:81"><nobr><span class="ft4">represent each Web page in</span></nobr></DIV>
<DIV style="position:absolute;top:809;left:234"><nobr><span class="ft6">S as a point (dots in Figure 5). Every</span></nobr></DIV>
<DIV style="position:absolute;top:825;left:81"><nobr><span class="ft4">potential query</span></nobr></DIV>
<DIV style="position:absolute;top:825;left:164"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:829;left:170"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:825;left:178"><nobr><span class="ft4">that we may issue can be viewed as a subset of</span></nobr></DIV>
<DIV style="position:absolute;top:825;left:427"><nobr><span class="ft6">S,</span></nobr></DIV>
<DIV style="position:absolute;top:841;left:81"><nobr><span class="ft4">containing all the points (pages) that are returned when we issue</span></nobr></DIV>
<DIV style="position:absolute;top:841;left:428"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:845;left:435"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:856;left:81"><nobr><span class="ft12">to the site. Each subset is associated with a weight that represents<br>the cost of issuing the query. Under this formalization, our goal is to<br>find which subsets (queries) cover the maximum number of points<br>(Web pages) with the minimum total weight (cost). This problem<br>is equivalent to the <i>set-covering </i>problem in graph theory [16].</span></nobr></DIV>
<DIV style="position:absolute;top:935;left:94"><nobr><span class="ft4">There are two main difficulties that we need to address in this</span></nobr></DIV>
<DIV style="position:absolute;top:950;left:81"><nobr><span class="ft12">formalization. First, in a practical situation, the crawler does not<br>know which Web pages will be returned by which queries, so the<br>subsets of</span></nobr></DIV>
<DIV style="position:absolute;top:982;left:141"><nobr><span class="ft6">S are not known in advance. Without knowing these</span></nobr></DIV>
<DIV style="position:absolute;top:998;left:81"><nobr><span class="ft12">subsets the crawler cannot decide which queries to pick to maxi-<br>mize the coverage. Second, the set-covering problem is known to<br>be NP-Hard [16], so an efficient algorithm to solve this problem<br>optimally in polynomial time has yet to be found.</span></nobr></DIV>
<DIV style="position:absolute;top:319;left:489"><nobr><span class="ft4">In this paper, we will present an <i>approximation algorithm </i>that</span></nobr></DIV>
<DIV style="position:absolute;top:335;left:475"><nobr><span class="ft12">can find a near-optimal solution at a reasonable computational cost.<br>Our algorithm leverages the observation that although we do not<br>know which pages will be returned by each query</span></nobr></DIV>
<DIV style="position:absolute;top:366;left:747"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:370;left:753"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:366;left:761"><nobr><span class="ft4">that we issue,</span></nobr></DIV>
<DIV style="position:absolute;top:382;left:475"><nobr><span class="ft12">we can <i>predict how many </i>pages will be returned. Based on this in-<br>formation our query selection algorithm can then select the "best"<br>queries that cover the content of the Web site. We present our pre-<br>diction method and our query selection algorithm in Section 3.</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:479"><nobr><span class="ft20"><i>2.3.1</i></span></nobr></DIV>
<DIV style="position:absolute;top:447;left:529"><nobr><span class="ft20"><i>Performance Metric</i></span></nobr></DIV>
<DIV style="position:absolute;top:468;left:489"><nobr><span class="ft4">Before we present our ideas for the query selection problem, we</span></nobr></DIV>
<DIV style="position:absolute;top:484;left:475"><nobr><span class="ft12">briefly discuss some of our notation and the cost/performance met-<br>rics.</span></nobr></DIV>
<DIV style="position:absolute;top:515;left:489"><nobr><span class="ft4">Given a query</span></nobr></DIV>
<DIV style="position:absolute;top:515;left:570"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:520;left:576"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:515;left:581"><nobr><span class="ft4">, we use</span></nobr></DIV>
<DIV style="position:absolute;top:515;left:630"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:520;left:653"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:512;left:657"><nobr><span class="ft6">) to denote the fraction of pages</span></nobr></DIV>
<DIV style="position:absolute;top:531;left:475"><nobr><span class="ft4">that we will get back if we issue query</span></nobr></DIV>
<DIV style="position:absolute;top:531;left:681"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:535;left:687"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:531;left:694"><nobr><span class="ft4">to the site. For example, if</span></nobr></DIV>
<DIV style="position:absolute;top:547;left:475"><nobr><span class="ft12">a Web site has 10,000 pages in total, and if 3,000 pages are returned<br>for the query</span></nobr></DIV>
<DIV style="position:absolute;top:562;left:548"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:567;left:554"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:559;left:563"><nobr><span class="ft6">= <i>"medicine"</i>, then P (q</span></nobr></DIV>
<DIV style="position:absolute;top:567;left:696"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:559;left:701"><nobr><span class="ft6">) = 0.3. We use P (q</span></nobr></DIV>
<DIV style="position:absolute;top:565;left:815"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:559;left:825"><nobr><span class="ft6"></span></nobr></DIV>
<DIV style="position:absolute;top:578;left:475"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:481"><nobr><span class="ft18">2</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:488"><nobr><span class="ft6">) to represent the fraction of pages that are returned from both</span></nobr></DIV>
<DIV style="position:absolute;top:594;left:475"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:481"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:594;left:491"><nobr><span class="ft4">and</span></nobr></DIV>
<DIV style="position:absolute;top:594;left:514"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:520"><nobr><span class="ft18">2</span></nobr></DIV>
<DIV style="position:absolute;top:594;left:529"><nobr><span class="ft4">(i.e., the intersection of</span></nobr></DIV>
<DIV style="position:absolute;top:594;left:657"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:679"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:590;left:685"><nobr><span class="ft6">) and P (q</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:739"><nobr><span class="ft18">2</span></nobr></DIV>
<DIV style="position:absolute;top:590;left:745"><nobr><span class="ft6">)). Similarly, we</span></nobr></DIV>
<DIV style="position:absolute;top:609;left:475"><nobr><span class="ft4">use</span></nobr></DIV>
<DIV style="position:absolute;top:609;left:497"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:612;left:519"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:606;left:529"><nobr><span class="ft6"> q</span></nobr></DIV>
<DIV style="position:absolute;top:612;left:547"><nobr><span class="ft18">2</span></nobr></DIV>
<DIV style="position:absolute;top:606;left:554"><nobr><span class="ft6">) to represent the fraction of pages that are returned</span></nobr></DIV>
<DIV style="position:absolute;top:625;left:475"><nobr><span class="ft4">from either</span></nobr></DIV>
<DIV style="position:absolute;top:625;left:539"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:627;left:545"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:625;left:554"><nobr><span class="ft4">or</span></nobr></DIV>
<DIV style="position:absolute;top:625;left:569"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:627;left:575"><nobr><span class="ft18">2</span></nobr></DIV>
<DIV style="position:absolute;top:625;left:585"><nobr><span class="ft4">(i.e., the union of</span></nobr></DIV>
<DIV style="position:absolute;top:625;left:681"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:627;left:703"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:622;left:709"><nobr><span class="ft6">) and P (q</span></nobr></DIV>
<DIV style="position:absolute;top:627;left:763"><nobr><span class="ft18">2</span></nobr></DIV>
<DIV style="position:absolute;top:622;left:769"><nobr><span class="ft6">)).</span></nobr></DIV>
<DIV style="position:absolute;top:641;left:489"><nobr><span class="ft4">We also use <i>Cost</i></span></nobr></DIV>
<DIV style="position:absolute;top:637;left:583"><nobr><span class="ft6">(q</span></nobr></DIV>
<DIV style="position:absolute;top:645;left:595"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:637;left:600"><nobr><span class="ft6">) to represent the cost of issuing the query</span></nobr></DIV>
<DIV style="position:absolute;top:656;left:475"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:661;left:481"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:656;left:486"><nobr><span class="ft4">. Depending on the scenario, the cost can be measured either in</span></nobr></DIV>
<DIV style="position:absolute;top:672;left:475"><nobr><span class="ft12">time, network bandwidth, the number of interactions with the site,<br>or it can be a function of all of these. As we will see later, our<br>proposed algorithms are independent of the exact cost function.</span></nobr></DIV>
<DIV style="position:absolute;top:719;left:489"><nobr><span class="ft4">In the most common case, the query cost consists of a number</span></nobr></DIV>
<DIV style="position:absolute;top:735;left:475"><nobr><span class="ft12">of factors, including the cost for submitting the query to the site,<br>retrieving the result index page (Figure 3(a)) and downloading the<br>actual pages (Figure 3(b)). We assume that submitting a query in-<br>curs a fixed cost of</span></nobr></DIV>
<DIV style="position:absolute;top:782;left:584"><nobr><span class="ft6">c</span></nobr></DIV>
<DIV style="position:absolute;top:786;left:589"><nobr><span class="ft18">q</span></nobr></DIV>
<DIV style="position:absolute;top:782;left:596"><nobr><span class="ft4">. The cost for downloading the result index</span></nobr></DIV>
<DIV style="position:absolute;top:798;left:475"><nobr><span class="ft12">page is proportional to the number of matching documents to the<br>query, while the cost</span></nobr></DIV>
<DIV style="position:absolute;top:813;left:593"><nobr><span class="ft6">c</span></nobr></DIV>
<DIV style="position:absolute;top:818;left:599"><nobr><span class="ft18">d</span></nobr></DIV>
<DIV style="position:absolute;top:813;left:610"><nobr><span class="ft4">for downloading a matching document is</span></nobr></DIV>
<DIV style="position:absolute;top:829;left:475"><nobr><span class="ft4">also fixed. Then the overall cost of query</span></nobr></DIV>
<DIV style="position:absolute;top:829;left:699"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:834;left:705"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:829;left:713"><nobr><span class="ft4">is</span></nobr></DIV>
<DIV style="position:absolute;top:850;left:552"><nobr><span class="ft5"><i>Cost</i></span></nobr></DIV>
<DIV style="position:absolute;top:847;left:577"><nobr><span class="ft6">(q</span></nobr></DIV>
<DIV style="position:absolute;top:855;left:589"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:847;left:593"><nobr><span class="ft6">) = c</span></nobr></DIV>
<DIV style="position:absolute;top:855;left:623"><nobr><span class="ft18">q</span></nobr></DIV>
<DIV style="position:absolute;top:847;left:633"><nobr><span class="ft6">+ c</span></nobr></DIV>
<DIV style="position:absolute;top:855;left:652"><nobr><span class="ft18">r</span></nobr></DIV>
<DIV style="position:absolute;top:850;left:659"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:855;left:681"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:847;left:686"><nobr><span class="ft6">) + c</span></nobr></DIV>
<DIV style="position:absolute;top:855;left:714"><nobr><span class="ft18">d</span></nobr></DIV>
<DIV style="position:absolute;top:850;left:720"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:855;left:743"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:847;left:747"><nobr><span class="ft6">).</span></nobr></DIV>
<DIV style="position:absolute;top:850;left:818"><nobr><span class="ft4">(1)</span></nobr></DIV>
<DIV style="position:absolute;top:871;left:475"><nobr><span class="ft4">In certain cases, some of the documents from</span></nobr></DIV>
<DIV style="position:absolute;top:871;left:724"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:876;left:731"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:871;left:739"><nobr><span class="ft4">may have already</span></nobr></DIV>
<DIV style="position:absolute;top:887;left:475"><nobr><span class="ft12">been downloaded from previous queries. In this case, the crawler<br>may skip downloading these documents and the cost of</span></nobr></DIV>
<DIV style="position:absolute;top:903;left:776"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:907;left:782"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:903;left:790"><nobr><span class="ft4">can be</span></nobr></DIV>
<DIV style="position:absolute;top:924;left:542"><nobr><span class="ft5"><i>Cost</i></span></nobr></DIV>
<DIV style="position:absolute;top:921;left:566"><nobr><span class="ft6">(q</span></nobr></DIV>
<DIV style="position:absolute;top:929;left:578"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:921;left:583"><nobr><span class="ft6">) = c</span></nobr></DIV>
<DIV style="position:absolute;top:929;left:615"><nobr><span class="ft18">q</span></nobr></DIV>
<DIV style="position:absolute;top:921;left:624"><nobr><span class="ft6">+ c</span></nobr></DIV>
<DIV style="position:absolute;top:929;left:644"><nobr><span class="ft18">r</span></nobr></DIV>
<DIV style="position:absolute;top:924;left:650"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:929;left:672"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:921;left:677"><nobr><span class="ft6">) + c</span></nobr></DIV>
<DIV style="position:absolute;top:929;left:705"><nobr><span class="ft18">d</span></nobr></DIV>
<DIV style="position:absolute;top:924;left:712"><nobr><span class="ft6">P</span></nobr></DIV>
<DIV style="position:absolute;top:929;left:721"><nobr><span class="ft18">new</span></nobr></DIV>
<DIV style="position:absolute;top:921;left:742"><nobr><span class="ft6">(q</span></nobr></DIV>
<DIV style="position:absolute;top:929;left:753"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:921;left:758"><nobr><span class="ft6">).</span></nobr></DIV>
<DIV style="position:absolute;top:924;left:818"><nobr><span class="ft4">(2)</span></nobr></DIV>
<DIV style="position:absolute;top:949;left:475"><nobr><span class="ft4">Here, we use</span></nobr></DIV>
<DIV style="position:absolute;top:949;left:551"><nobr><span class="ft6">P</span></nobr></DIV>
<DIV style="position:absolute;top:954;left:560"><nobr><span class="ft18">new</span></nobr></DIV>
<DIV style="position:absolute;top:946;left:581"><nobr><span class="ft6">(q</span></nobr></DIV>
<DIV style="position:absolute;top:954;left:593"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:946;left:597"><nobr><span class="ft6">) to represent the fraction of the <i>new </i>docu-</span></nobr></DIV>
<DIV style="position:absolute;top:965;left:475"><nobr><span class="ft4">ments from</span></nobr></DIV>
<DIV style="position:absolute;top:965;left:542"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:970;left:548"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:965;left:556"><nobr><span class="ft4">that have <i>not </i>been retrieved from previous queries.</span></nobr></DIV>
<DIV style="position:absolute;top:981;left:475"><nobr><span class="ft4">Later in Section 3.1 we will study how we can estimate</span></nobr></DIV>
<DIV style="position:absolute;top:981;left:779"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:985;left:801"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:977;left:805"><nobr><span class="ft6">) and</span></nobr></DIV>
<DIV style="position:absolute;top:996;left:475"><nobr><span class="ft6">P</span></nobr></DIV>
<DIV style="position:absolute;top:1001;left:484"><nobr><span class="ft18">new</span></nobr></DIV>
<DIV style="position:absolute;top:993;left:505"><nobr><span class="ft6">(q</span></nobr></DIV>
<DIV style="position:absolute;top:1001;left:517"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:993;left:522"><nobr><span class="ft6">) to estimate the cost of q</span></nobr></DIV>
<DIV style="position:absolute;top:1001;left:658"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:997;left:663"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:1012;left:489"><nobr><span class="ft4">Since our algorithms are independent of the exact cost function,</span></nobr></DIV>
<DIV style="position:absolute;top:1028;left:475"><nobr><span class="ft4">we will assume a generic cost function <i>Cost</i></span></nobr></DIV>
<DIV style="position:absolute;top:1025;left:706"><nobr><span class="ft6">(q</span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:718"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:1025;left:722"><nobr><span class="ft6">) in this paper. When</span></nobr></DIV>
<DIV style="position:absolute;top:1044;left:475"><nobr><span class="ft4">we need a concrete cost function, however, we will use Equation 2.</span></nobr></DIV>
<DIV style="position:absolute;top:1059;left:489"><nobr><span class="ft4">Given the notation, we can formalize the goal of a Hidden-Web</span></nobr></DIV>
<DIV style="position:absolute;top:1075;left:475"><nobr><span class="ft4">crawler as follows:</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft4">102</span></nobr></DIV>
</DIV>
<!-- Page 4 -->
<a name="4"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="74004.png" alt="background image">
<DIV style="position:absolute;top:86;left:96"><nobr><span class="ft4">P</span></nobr></DIV>
<DIV style="position:absolute;top:88;left:104"><nobr><span class="ft17">ROBLEM</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:160"><nobr><span class="ft4">1. <i>Find the set of queries</i></span></nobr></DIV>
<DIV style="position:absolute;top:86;left:299"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:89;left:305"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:311"><nobr><span class="ft6">, . . . , q</span></nobr></DIV>
<DIV style="position:absolute;top:91;left:348"><nobr><span class="ft18">n</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:359"><nobr><span class="ft5"><i>that maximizes</i></span></nobr></DIV>
<DIV style="position:absolute;top:111;left:213"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:113;left:235"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:108;left:244"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:116;left:294"><nobr><span class="ft18">n</span></nobr></DIV>
<DIV style="position:absolute;top:108;left:302"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:136;left:81"><nobr><span class="ft5"><i>under the constraint</i></span></nobr></DIV>
<DIV style="position:absolute;top:151;left:219"><nobr><span class="ft18">n</span></nobr></DIV>
<DIV style="position:absolute;top:183;left:213"><nobr><span class="ft18">i=1</span></nobr></DIV>
<DIV style="position:absolute;top:164;left:234"><nobr><span class="ft5"><i>Cost</i></span></nobr></DIV>
<DIV style="position:absolute;top:161;left:259"><nobr><span class="ft6">(q</span></nobr></DIV>
<DIV style="position:absolute;top:169;left:271"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:161;left:275"><nobr><span class="ft6">)  t.</span></nobr></DIV>
<DIV style="position:absolute;top:197;left:81"><nobr><span class="ft5"><i>Here,</i></span></nobr></DIV>
<DIV style="position:absolute;top:197;left:114"><nobr><span class="ft6">t <i>is the maximum download resource that the crawler has.</i></span></nobr></DIV>
<DIV style="position:absolute;top:228;left:81"><nobr><span class="ft3"><b>3.</b></span></nobr></DIV>
<DIV style="position:absolute;top:228;left:112"><nobr><span class="ft3"><b>KEYWORD SELECTION</b></span></nobr></DIV>
<DIV style="position:absolute;top:250;left:94"><nobr><span class="ft4">How should a crawler select the queries to issue? Given that the</span></nobr></DIV>
<DIV style="position:absolute;top:266;left:81"><nobr><span class="ft12">goal is to download the maximum number of unique documents<br>from a textual database, we may consider one of the following op-<br>tions:</span></nobr></DIV>
<DIV style="position:absolute;top:314;left:82"><nobr><span class="ft6">· <i>Random</i>: We select random keywords from, say, an English dic-</span></nobr></DIV>
<DIV style="position:absolute;top:333;left:96"><nobr><span class="ft12">tionary and issue them to the database. The hope is that a random<br>query will return a reasonable number of matching documents.</span></nobr></DIV>
<DIV style="position:absolute;top:363;left:82"><nobr><span class="ft6">· <i>Generic-frequency</i>: We analyze a generic document corpus col-</span></nobr></DIV>
<DIV style="position:absolute;top:382;left:96"><nobr><span class="ft12">lected elsewhere (say, from the Web) and obtain the generic fre-<br>quency distribution of each keyword. Based on this generic dis-<br>tribution, we start with the most frequent keyword, issue it to the<br>Hidden-Web database and retrieve the result. We then continue<br>to the second-most frequent keyword and repeat this process un-<br>til we exhaust all download resources. The hope is that the fre-<br>quent keywords in a generic corpus will also be frequent in the<br>Hidden-Web database, returning many matching documents.</span></nobr></DIV>
<DIV style="position:absolute;top:507;left:82"><nobr><span class="ft6">· <i>Adaptive</i>: We analyze the documents returned from the previous</span></nobr></DIV>
<DIV style="position:absolute;top:526;left:96"><nobr><span class="ft12">queries issued to the Hidden-Web database and estimate which<br>keyword is most likely to return the most documents. Based on<br>this analysis, we issue the most "promising" query, and repeat<br>the process.</span></nobr></DIV>
<DIV style="position:absolute;top:587;left:94"><nobr><span class="ft4">Among these three general policies, we may consider the ran-</span></nobr></DIV>
<DIV style="position:absolute;top:603;left:81"><nobr><span class="ft12">dom policy as the <i>base comparison point </i>since it is expected to<br>perform the worst. Between the generic-frequency and the adap-<br>tive policies, both policies may show similar performance if the<br>crawled database has a <i>generic </i>document collection without a spe-<br>cialized topic. The adaptive policy, however, may perform signifi-<br>cantly better than the generic-frequency policy if the database has a<br>very specialized collection that is different from the generic corpus.<br>We will experimentally compare these three policies in Section 4.</span></nobr></DIV>
<DIV style="position:absolute;top:729;left:94"><nobr><span class="ft4">While the first two policies (random and generic-frequency poli-</span></nobr></DIV>
<DIV style="position:absolute;top:744;left:81"><nobr><span class="ft12">cies) are easy to implement, we need to understand how we can an-<br>alyze the downloaded pages to identify the most "promising" query<br>in order to implement the adaptive policy. We address this issue in<br>the rest of this section.</span></nobr></DIV>
<DIV style="position:absolute;top:816;left:81"><nobr><span class="ft3"><b>3.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:816;left:121"><nobr><span class="ft3"><b>Estimating the number of matching pages</b></span></nobr></DIV>
<DIV style="position:absolute;top:838;left:94"><nobr><span class="ft4">In order to identify the most promising query, we need to esti-</span></nobr></DIV>
<DIV style="position:absolute;top:854;left:81"><nobr><span class="ft12">mate how many new documents we will download if we issue the<br>query</span></nobr></DIV>
<DIV style="position:absolute;top:870;left:115"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:874;left:122"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:870;left:130"><nobr><span class="ft4">as the next query. That is, assuming that we have issued</span></nobr></DIV>
<DIV style="position:absolute;top:885;left:81"><nobr><span class="ft4">queries</span></nobr></DIV>
<DIV style="position:absolute;top:885;left:122"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:888;left:128"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:885;left:135"><nobr><span class="ft6">, . . . , q</span></nobr></DIV>
<DIV style="position:absolute;top:890;left:172"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:885;left:193"><nobr><span class="ft4">we need to estimate</span></nobr></DIV>
<DIV style="position:absolute;top:885;left:300"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:888;left:323"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:882;left:329"><nobr><span class="ft6">· · ·q</span></nobr></DIV>
<DIV style="position:absolute;top:890;left:372"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:882;left:391"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:890;left:407"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:882;left:412"><nobr><span class="ft6">), for</span></nobr></DIV>
<DIV style="position:absolute;top:901;left:81"><nobr><span class="ft4">every potential next query</span></nobr></DIV>
<DIV style="position:absolute;top:901;left:224"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:906;left:230"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:901;left:238"><nobr><span class="ft4">and compare this value. In estimating</span></nobr></DIV>
<DIV style="position:absolute;top:917;left:81"><nobr><span class="ft4">this number, we note that we can rewrite</span></nobr></DIV>
<DIV style="position:absolute;top:917;left:305"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:919;left:328"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:913;left:337"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:921;left:388"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:913;left:410"><nobr><span class="ft6"> q</span></nobr></DIV>
<DIV style="position:absolute;top:921;left:429"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:913;left:434"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:933;left:81"><nobr><span class="ft4">as:</span></nobr></DIV>
<DIV style="position:absolute;top:950;left:93"><nobr><span class="ft6">P ((q</span></nobr></DIV>
<DIV style="position:absolute;top:952;left:121"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:947;left:130"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:955;left:180"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:947;left:199"><nobr><span class="ft6">)  q</span></nobr></DIV>
<DIV style="position:absolute;top:955;left:226"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:947;left:231"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:967;left:97"><nobr><span class="ft6">= P (q</span></nobr></DIV>
<DIV style="position:absolute;top:973;left:134"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:967;left:143"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:975;left:193"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:967;left:212"><nobr><span class="ft6">) + P (q</span></nobr></DIV>
<DIV style="position:absolute;top:975;left:257"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:967;left:262"><nobr><span class="ft6">) - P ((q</span></nobr></DIV>
<DIV style="position:absolute;top:973;left:311"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:967;left:321"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:975;left:371"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:967;left:390"><nobr><span class="ft6">)  q</span></nobr></DIV>
<DIV style="position:absolute;top:975;left:417"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:967;left:421"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:987;left:97"><nobr><span class="ft6">= P (q</span></nobr></DIV>
<DIV style="position:absolute;top:993;left:134"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:987;left:143"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:995;left:193"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:987;left:212"><nobr><span class="ft6">) + P (q</span></nobr></DIV>
<DIV style="position:absolute;top:995;left:257"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:987;left:262"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:1007;left:113"><nobr><span class="ft6">- P (q</span></nobr></DIV>
<DIV style="position:absolute;top:1013;left:149"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:1007;left:159"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:209"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:1007;left:228"><nobr><span class="ft6">)P (q</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:255"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:1007;left:260"><nobr><span class="ft6">|q</span></nobr></DIV>
<DIV style="position:absolute;top:1013;left:270"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:1007;left:279"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:329"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:1007;left:348"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:1011;left:424"><nobr><span class="ft4">(3)</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:94"><nobr><span class="ft4">In the above formula, note that we can precisely measure</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:400"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:1038;left:422"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:1032;left:430"><nobr><span class="ft6"></span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:81"><nobr><span class="ft6">· · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:1056;left:119"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:138"><nobr><span class="ft6">) and P (q</span></nobr></DIV>
<DIV style="position:absolute;top:1056;left:193"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:202"><nobr><span class="ft6">| q</span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:217"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:226"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:1056;left:277"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:296"><nobr><span class="ft6">) by analyzing previously-</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:81"><nobr><span class="ft4">downloaded pages: We know</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:251"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:1069;left:273"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:1063;left:284"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:1071;left:338"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:1063;left:356"><nobr><span class="ft6">), the union of</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft4">all pages downloaded from</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:624"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:89;left:630"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:637"><nobr><span class="ft6">, . . . , q</span></nobr></DIV>
<DIV style="position:absolute;top:91;left:674"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:692"><nobr><span class="ft4">, since we have already is-</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:475"><nobr><span class="ft4">sued</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:504"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:104;left:511"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:517"><nobr><span class="ft6">, . . . , q</span></nobr></DIV>
<DIV style="position:absolute;top:107;left:554"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:577"><nobr><span class="ft4">and downloaded the matching pages.</span></nobr></DIV>
<DIV style="position:absolute;top:99;left:780"><nobr><span class="ft10">4</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:793"><nobr><span class="ft4">We can</span></nobr></DIV>
<DIV style="position:absolute;top:118;left:475"><nobr><span class="ft4">also measure</span></nobr></DIV>
<DIV style="position:absolute;top:118;left:550"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:573"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:114;left:583"><nobr><span class="ft6">| q</span></nobr></DIV>
<DIV style="position:absolute;top:120;left:599"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:114;left:609"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:661"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:114;left:680"><nobr><span class="ft6">), the probability that q</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:808"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:118;left:817"><nobr><span class="ft4">ap-</span></nobr></DIV>
<DIV style="position:absolute;top:133;left:475"><nobr><span class="ft4">pears in the pages from</span></nobr></DIV>
<DIV style="position:absolute;top:133;left:604"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:136;left:610"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:133;left:616"><nobr><span class="ft6">, . . . , q</span></nobr></DIV>
<DIV style="position:absolute;top:138;left:653"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:133;left:672"><nobr><span class="ft4">, by counting how many times</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:475"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:154;left:481"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:489"><nobr><span class="ft4">appears in the pages from</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:628"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:151;left:634"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:641"><nobr><span class="ft6">, . . . , q</span></nobr></DIV>
<DIV style="position:absolute;top:154;left:678"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:696"><nobr><span class="ft4">. Therefore, we only need</span></nobr></DIV>
<DIV style="position:absolute;top:165;left:475"><nobr><span class="ft4">to estimate</span></nobr></DIV>
<DIV style="position:absolute;top:165;left:537"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:169;left:559"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:161;left:564"><nobr><span class="ft6">) to evaluate P (q</span></nobr></DIV>
<DIV style="position:absolute;top:167;left:656"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:161;left:665"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:169;left:714"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:161;left:719"><nobr><span class="ft6">). We may consider a</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:475"><nobr><span class="ft4">number of different ways to estimate</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:680"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:185;left:702"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:177;left:707"><nobr><span class="ft6">), including the follow-</span></nobr></DIV>
<DIV style="position:absolute;top:196;left:475"><nobr><span class="ft4">ing:</span></nobr></DIV>
<DIV style="position:absolute;top:214;left:473"><nobr><span class="ft4">1. <i>Independence estimator</i>: We assume that the appearance of the</span></nobr></DIV>
<DIV style="position:absolute;top:230;left:490"><nobr><span class="ft4">term</span></nobr></DIV>
<DIV style="position:absolute;top:230;left:520"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:234;left:526"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:230;left:535"><nobr><span class="ft4">is independent of the terms</span></nobr></DIV>
<DIV style="position:absolute;top:230;left:691"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:232;left:698"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:230;left:704"><nobr><span class="ft6">, . . . , q</span></nobr></DIV>
<DIV style="position:absolute;top:234;left:741"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:230;left:760"><nobr><span class="ft4">. That is, we</span></nobr></DIV>
<DIV style="position:absolute;top:246;left:490"><nobr><span class="ft4">assume that</span></nobr></DIV>
<DIV style="position:absolute;top:245;left:557"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:250;left:579"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:242;left:584"><nobr><span class="ft6">) = P (q</span></nobr></DIV>
<DIV style="position:absolute;top:250;left:630"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:242;left:635"><nobr><span class="ft6">|q</span></nobr></DIV>
<DIV style="position:absolute;top:248;left:645"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:242;left:654"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:250;left:704"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:242;left:723"><nobr><span class="ft6">).</span></nobr></DIV>
<DIV style="position:absolute;top:265;left:473"><nobr><span class="ft4">2. <i>Zipf estimator</i>: In [19], Ipeirotis et al. proposed a method to</span></nobr></DIV>
<DIV style="position:absolute;top:281;left:490"><nobr><span class="ft12">estimate how many times a particular term occurs in the <i>entire<br></i>corpus based on a subset of documents from the corpus. Their<br>method exploits the fact that the frequency of terms inside text<br>collections follows a power law distribution [30, 25]. That is,<br>if we rank all terms based on their occurrence frequency (with<br>the most frequent term having a rank of 1, second most frequent<br>a rank of 2 etc.), then the frequency</span></nobr></DIV>
<DIV style="position:absolute;top:375;left:691"><nobr><span class="ft6">f of a term inside the text</span></nobr></DIV>
<DIV style="position:absolute;top:391;left:490"><nobr><span class="ft4">collection is given by:</span></nobr></DIV>
<DIV style="position:absolute;top:417;left:615"><nobr><span class="ft6">f = (r + )</span></nobr></DIV>
<DIV style="position:absolute;top:411;left:693"><nobr><span class="ft18">-</span></nobr></DIV>
<DIV style="position:absolute;top:417;left:818"><nobr><span class="ft4">(4)</span></nobr></DIV>
<DIV style="position:absolute;top:435;left:490"><nobr><span class="ft4">where</span></nobr></DIV>
<DIV style="position:absolute;top:435;left:526"><nobr><span class="ft6">r is the rank of the term and , , and  are constants that</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:490"><nobr><span class="ft4">depend on the text collection.</span></nobr></DIV>
<DIV style="position:absolute;top:473;left:490"><nobr><span class="ft4">Their main idea is (1) to estimate the three parameters,</span></nobr></DIV>
<DIV style="position:absolute;top:473;left:788"><nobr><span class="ft6">,  and</span></nobr></DIV>
<DIV style="position:absolute;top:489;left:490"><nobr><span class="ft12">, based on the subset of documents that we have downloaded<br>from previous queries, and (2) use the estimated parameters to<br>predict</span></nobr></DIV>
<DIV style="position:absolute;top:520;left:532"><nobr><span class="ft6">f given the ranking r of a term within the subset. For</span></nobr></DIV>
<DIV style="position:absolute;top:536;left:490"><nobr><span class="ft12">a more detailed description on how we can use this method to<br>estimate</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:540"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:556;left:562"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:548;left:567"><nobr><span class="ft6">), we refer the reader to the extended version of</span></nobr></DIV>
<DIV style="position:absolute;top:567;left:490"><nobr><span class="ft4">this paper [27].</span></nobr></DIV>
<DIV style="position:absolute;top:585;left:489"><nobr><span class="ft4">After we estimate</span></nobr></DIV>
<DIV style="position:absolute;top:585;left:590"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:590;left:612"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:582;left:617"><nobr><span class="ft6">) and P (q</span></nobr></DIV>
<DIV style="position:absolute;top:590;left:672"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:582;left:677"><nobr><span class="ft6">|q</span></nobr></DIV>
<DIV style="position:absolute;top:587;left:687"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:582;left:697"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:590;left:748"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:582;left:767"><nobr><span class="ft6">) values, we</span></nobr></DIV>
<DIV style="position:absolute;top:601;left:475"><nobr><span class="ft4">can calculate</span></nobr></DIV>
<DIV style="position:absolute;top:601;left:551"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:603;left:574"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:597;left:584"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:605;left:637"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:597;left:642"><nobr><span class="ft6">). In Section 3.3, we explain how</span></nobr></DIV>
<DIV style="position:absolute;top:616;left:475"><nobr><span class="ft4">we can efficiently compute</span></nobr></DIV>
<DIV style="position:absolute;top:616;left:623"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:621;left:645"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:613;left:650"><nobr><span class="ft6">|q</span></nobr></DIV>
<DIV style="position:absolute;top:619;left:660"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:613;left:668"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:621;left:716"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:613;left:735"><nobr><span class="ft6">) by maintaining a</span></nobr></DIV>
<DIV style="position:absolute;top:632;left:475"><nobr><span class="ft12">succinct summary table. In the next section, we first examine how<br>we can use this value to decide which query we should issue next<br>to the Hidden Web site.</span></nobr></DIV>
<DIV style="position:absolute;top:690;left:475"><nobr><span class="ft3"><b>3.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:690;left:516"><nobr><span class="ft3"><b>Query selection algorithm</b></span></nobr></DIV>
<DIV style="position:absolute;top:712;left:489"><nobr><span class="ft4">The goal of the Hidden-Web crawler is to download the maxi-</span></nobr></DIV>
<DIV style="position:absolute;top:728;left:475"><nobr><span class="ft12">mum number of unique documents from a database using its lim-<br>ited download resources. Given this goal, the Hidden-Web crawler<br>has to take two factors into account. (1) the number of new doc-<br>uments that can be obtained from the query</span></nobr></DIV>
<DIV style="position:absolute;top:775;left:718"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:779;left:724"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:775;left:733"><nobr><span class="ft4">and (2) the cost of</span></nobr></DIV>
<DIV style="position:absolute;top:791;left:475"><nobr><span class="ft4">issuing the query</span></nobr></DIV>
<DIV style="position:absolute;top:791;left:572"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:795;left:578"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:791;left:583"><nobr><span class="ft4">. For example, if two queries,</span></nobr></DIV>
<DIV style="position:absolute;top:791;left:749"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:795;left:755"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:791;left:764"><nobr><span class="ft4">and</span></nobr></DIV>
<DIV style="position:absolute;top:791;left:787"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:795;left:793"><nobr><span class="ft18">j</span></nobr></DIV>
<DIV style="position:absolute;top:791;left:799"><nobr><span class="ft4">, incur</span></nobr></DIV>
<DIV style="position:absolute;top:806;left:475"><nobr><span class="ft4">the same cost, but</span></nobr></DIV>
<DIV style="position:absolute;top:806;left:579"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:811;left:585"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:806;left:595"><nobr><span class="ft4">returns more new pages than</span></nobr></DIV>
<DIV style="position:absolute;top:806;left:757"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:811;left:764"><nobr><span class="ft18">j</span></nobr></DIV>
<DIV style="position:absolute;top:806;left:769"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:806;left:778"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:811;left:784"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:806;left:793"><nobr><span class="ft4">is more</span></nobr></DIV>
<DIV style="position:absolute;top:822;left:475"><nobr><span class="ft4">desirable than</span></nobr></DIV>
<DIV style="position:absolute;top:822;left:556"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:827;left:562"><nobr><span class="ft18">j</span></nobr></DIV>
<DIV style="position:absolute;top:822;left:568"><nobr><span class="ft4">. Similarly, if</span></nobr></DIV>
<DIV style="position:absolute;top:822;left:648"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:827;left:654"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:822;left:663"><nobr><span class="ft4">and</span></nobr></DIV>
<DIV style="position:absolute;top:822;left:687"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:827;left:693"><nobr><span class="ft18">j</span></nobr></DIV>
<DIV style="position:absolute;top:822;left:703"><nobr><span class="ft4">return the same number</span></nobr></DIV>
<DIV style="position:absolute;top:838;left:475"><nobr><span class="ft4">of new documents, but</span></nobr></DIV>
<DIV style="position:absolute;top:838;left:605"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:842;left:611"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:838;left:620"><nobr><span class="ft4">incurs less cost then</span></nobr></DIV>
<DIV style="position:absolute;top:838;left:736"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:842;left:742"><nobr><span class="ft18">j</span></nobr></DIV>
<DIV style="position:absolute;top:838;left:748"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:838;left:756"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:842;left:762"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:838;left:771"><nobr><span class="ft4">is more de-</span></nobr></DIV>
<DIV style="position:absolute;top:853;left:475"><nobr><span class="ft12">sirable. Based on this observation, the Hidden-Web crawler may<br>use the following <i>efficiency </i>metric to quantify the desirability of<br>the query</span></nobr></DIV>
<DIV style="position:absolute;top:885;left:529"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:889;left:535"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:885;left:540"><nobr><span class="ft4">:</span></nobr></DIV>
<DIV style="position:absolute;top:917;left:580"><nobr><span class="ft5"><i>Efficiency</i></span></nobr></DIV>
<DIV style="position:absolute;top:914;left:633"><nobr><span class="ft6">(q</span></nobr></DIV>
<DIV style="position:absolute;top:921;left:645"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:914;left:650"><nobr><span class="ft6">) = P</span></nobr></DIV>
<DIV style="position:absolute;top:913;left:684"><nobr><span class="ft18">new</span></nobr></DIV>
<DIV style="position:absolute;top:905;left:705"><nobr><span class="ft6">(q</span></nobr></DIV>
<DIV style="position:absolute;top:913;left:717"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:905;left:721"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:926;left:678"><nobr><span class="ft5"><i>Cost</i></span></nobr></DIV>
<DIV style="position:absolute;top:923;left:702"><nobr><span class="ft6">(q</span></nobr></DIV>
<DIV style="position:absolute;top:931;left:714"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:923;left:719"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:950;left:475"><nobr><span class="ft4">Here,</span></nobr></DIV>
<DIV style="position:absolute;top:950;left:509"><nobr><span class="ft6">P</span></nobr></DIV>
<DIV style="position:absolute;top:955;left:517"><nobr><span class="ft18">new</span></nobr></DIV>
<DIV style="position:absolute;top:947;left:539"><nobr><span class="ft6">(q</span></nobr></DIV>
<DIV style="position:absolute;top:955;left:550"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:947;left:555"><nobr><span class="ft6">) represents the amount of <i>new </i>documents returned</span></nobr></DIV>
<DIV style="position:absolute;top:966;left:475"><nobr><span class="ft4">for</span></nobr></DIV>
<DIV style="position:absolute;top:966;left:495"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:970;left:501"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:966;left:509"><nobr><span class="ft4">(the pages that have not been returned for previous queries).</span></nobr></DIV>
<DIV style="position:absolute;top:981;left:475"><nobr><span class="ft5"><i>Cost</i></span></nobr></DIV>
<DIV style="position:absolute;top:978;left:500"><nobr><span class="ft6">(q</span></nobr></DIV>
<DIV style="position:absolute;top:986;left:511"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:978;left:516"><nobr><span class="ft6">) represents the cost of issuing the query q</span></nobr></DIV>
<DIV style="position:absolute;top:986;left:744"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:981;left:748"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:997;left:489"><nobr><span class="ft4">Intuitively, the efficiency of</span></nobr></DIV>
<DIV style="position:absolute;top:997;left:645"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:1002;left:651"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:997;left:661"><nobr><span class="ft4">measures how many new docu-</span></nobr></DIV>
<DIV style="position:absolute;top:1013;left:475"><nobr><span class="ft4">ments are retrieved per unit cost, and can be used as an indicator of</span></nobr></DIV>
<DIV style="position:absolute;top:1037;left:477"><nobr><span class="ft10">4</span></nobr></DIV>
<DIV style="position:absolute;top:1040;left:482"><nobr><span class="ft4">For exact estimation, we need to know the total number of pages in</span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:475"><nobr><span class="ft16">the site. However, in order to compare only relative values among<br>queries, this information is not actually needed.</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft4">103</span></nobr></DIV>
</DIV>
<!-- Page 5 -->
<a name="5"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft22{font-size:5px;font-family:Times;color:#000000;}
	.ft23{font-size:12px;font-family:Times;color:#000000;}
	.ft24{font-size:10px;font-family:Times;color:#000000;}
	.ft25{font-size:7px;font-family:Times;color:#000000;}
	.ft26{font-size:15px;line-height:17px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="74005.png" alt="background image">
<DIV style="position:absolute;top:101;left:151"><nobr><span class="ft4">A</span></nobr></DIV>
<DIV style="position:absolute;top:103;left:161"><nobr><span class="ft17">LGORITHM</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:231"><nobr><span class="ft4">3.1.</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:264"><nobr><span class="ft7"><b>Greedy SelectTerm()</b></span></nobr></DIV>
<DIV style="position:absolute;top:116;left:136"><nobr><span class="ft7"><b>Parameters:</b></span></nobr></DIV>
<DIV style="position:absolute;top:132;left:150"><nobr><span class="ft6">T <i>: The list of potential query keywords</i></span></nobr></DIV>
<DIV style="position:absolute;top:148;left:136"><nobr><span class="ft7"><b>Procedure</b></span></nobr></DIV>
<DIV style="position:absolute;top:164;left:150"><nobr><span class="ft5"><i>(1)</i></span></nobr></DIV>
<DIV style="position:absolute;top:164;left:178"><nobr><span class="ft5"><i>Foreach</i></span></nobr></DIV>
<DIV style="position:absolute;top:163;left:225"><nobr><span class="ft6">t</span></nobr></DIV>
<DIV style="position:absolute;top:168;left:230"><nobr><span class="ft18">k</span></nobr></DIV>
<DIV style="position:absolute;top:164;left:240"><nobr><span class="ft5"><i>in</i></span></nobr></DIV>
<DIV style="position:absolute;top:163;left:254"><nobr><span class="ft6">T <i>do</i></span></nobr></DIV>
<DIV style="position:absolute;top:181;left:150"><nobr><span class="ft5"><i>(2)</i></span></nobr></DIV>
<DIV style="position:absolute;top:181;left:193"><nobr><span class="ft5"><i>Estimate Efficiency</i></span></nobr></DIV>
<DIV style="position:absolute;top:178;left:296"><nobr><span class="ft6">(t</span></nobr></DIV>
<DIV style="position:absolute;top:186;left:306"><nobr><span class="ft18">k</span></nobr></DIV>
<DIV style="position:absolute;top:178;left:313"><nobr><span class="ft6">) =</span></nobr></DIV>
<DIV style="position:absolute;top:178;left:339"><nobr><span class="ft18">P</span></nobr></DIV>
<DIV style="position:absolute;top:179;left:346"><nobr><span class="ft22">new</span></nobr></DIV>
<DIV style="position:absolute;top:176;left:366"><nobr><span class="ft18">(t</span></nobr></DIV>
<DIV style="position:absolute;top:179;left:374"><nobr><span class="ft22">k</span></nobr></DIV>
<DIV style="position:absolute;top:176;left:381"><nobr><span class="ft18">)</span></nobr></DIV>
<DIV style="position:absolute;top:189;left:340"><nobr><span class="ft18">Cost(t</span></nobr></DIV>
<DIV style="position:absolute;top:190;left:373"><nobr><span class="ft22">k</span></nobr></DIV>
<DIV style="position:absolute;top:187;left:379"><nobr><span class="ft18">)</span></nobr></DIV>
<DIV style="position:absolute;top:199;left:150"><nobr><span class="ft5"><i>(3)</i></span></nobr></DIV>
<DIV style="position:absolute;top:199;left:178"><nobr><span class="ft5"><i>done</i></span></nobr></DIV>
<DIV style="position:absolute;top:215;left:150"><nobr><span class="ft5"><i>(4)</i></span></nobr></DIV>
<DIV style="position:absolute;top:215;left:178"><nobr><span class="ft5"><i>return</i></span></nobr></DIV>
<DIV style="position:absolute;top:215;left:215"><nobr><span class="ft6">t</span></nobr></DIV>
<DIV style="position:absolute;top:220;left:220"><nobr><span class="ft18">k</span></nobr></DIV>
<DIV style="position:absolute;top:215;left:230"><nobr><span class="ft5"><i>with maximum Efficiency</i></span></nobr></DIV>
<DIV style="position:absolute;top:212;left:365"><nobr><span class="ft6">(t</span></nobr></DIV>
<DIV style="position:absolute;top:220;left:375"><nobr><span class="ft18">k</span></nobr></DIV>
<DIV style="position:absolute;top:212;left:382"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:264;left:105"><nobr><span class="ft7"><b>Figure 6: Algorithm for selecting the next query term.</b></span></nobr></DIV>
<DIV style="position:absolute;top:298;left:81"><nobr><span class="ft4">how well our resources are spent when issuing</span></nobr></DIV>
<DIV style="position:absolute;top:298;left:339"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:302;left:346"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:298;left:350"><nobr><span class="ft4">. Thus, the Hid-</span></nobr></DIV>
<DIV style="position:absolute;top:313;left:81"><nobr><span class="ft4">den Web crawler can estimate the efficiency of every candidate</span></nobr></DIV>
<DIV style="position:absolute;top:313;left:425"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:318;left:431"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:313;left:436"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:329;left:81"><nobr><span class="ft12">and select the one with the highest value. By using its resources<br>more efficiently, the crawler may eventually download the maxi-<br>mum number of unique documents. In Figure 6, we show the query<br>selection function that uses the concept of efficiency. In principle,<br>this algorithm takes a <i>greedy approach </i>and tries to maximize the<br>"potential gain" in every step.</span></nobr></DIV>
<DIV style="position:absolute;top:423;left:94"><nobr><span class="ft4">We can estimate the efficiency of every query using the estima-</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:81"><nobr><span class="ft12">tion method described in Section 3.1. That is, the size of the new<br>documents from the query</span></nobr></DIV>
<DIV style="position:absolute;top:455;left:226"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:459;left:232"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:455;left:237"><nobr><span class="ft4">,</span></nobr></DIV>
<DIV style="position:absolute;top:455;left:243"><nobr><span class="ft6">P</span></nobr></DIV>
<DIV style="position:absolute;top:459;left:252"><nobr><span class="ft18">new</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:273"><nobr><span class="ft6">(q</span></nobr></DIV>
<DIV style="position:absolute;top:459;left:285"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:290"><nobr><span class="ft6">), is</span></nobr></DIV>
<DIV style="position:absolute;top:480;left:113"><nobr><span class="ft6">P</span></nobr></DIV>
<DIV style="position:absolute;top:485;left:122"><nobr><span class="ft18">new</span></nobr></DIV>
<DIV style="position:absolute;top:477;left:143"><nobr><span class="ft6">(q</span></nobr></DIV>
<DIV style="position:absolute;top:485;left:155"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:477;left:159"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:497;left:117"><nobr><span class="ft6">= P (q</span></nobr></DIV>
<DIV style="position:absolute;top:503;left:154"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:497;left:163"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:213"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:497;left:235"><nobr><span class="ft6"> q</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:253"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:497;left:258"><nobr><span class="ft6">) - P (q</span></nobr></DIV>
<DIV style="position:absolute;top:503;left:303"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:497;left:312"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:362"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:497;left:381"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:117"><nobr><span class="ft6">= P (q</span></nobr></DIV>
<DIV style="position:absolute;top:525;left:154"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:158"><nobr><span class="ft6">) - P (q</span></nobr></DIV>
<DIV style="position:absolute;top:523;left:203"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:212"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:525;left:262"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:281"><nobr><span class="ft6">)P (q</span></nobr></DIV>
<DIV style="position:absolute;top:525;left:309"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:314"><nobr><span class="ft6">|q</span></nobr></DIV>
<DIV style="position:absolute;top:523;left:324"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:333"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:525;left:383"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:402"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:546;left:81"><nobr><span class="ft4">from Equation 3, where</span></nobr></DIV>
<DIV style="position:absolute;top:546;left:217"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:550;left:239"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:542;left:244"><nobr><span class="ft6">) can be estimated using one of the</span></nobr></DIV>
<DIV style="position:absolute;top:561;left:81"><nobr><span class="ft4">methods described in section 3. We can also estimate <i>Cost</i></span></nobr></DIV>
<DIV style="position:absolute;top:558;left:391"><nobr><span class="ft6">(q</span></nobr></DIV>
<DIV style="position:absolute;top:566;left:402"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:558;left:407"><nobr><span class="ft6">) sim-</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:81"><nobr><span class="ft4">ilarly. For example, if <i>Cost</i></span></nobr></DIV>
<DIV style="position:absolute;top:574;left:226"><nobr><span class="ft6">(q</span></nobr></DIV>
<DIV style="position:absolute;top:582;left:237"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:574;left:242"><nobr><span class="ft6">) is</span></nobr></DIV>
<DIV style="position:absolute;top:602;left:147"><nobr><span class="ft5"><i>Cost</i></span></nobr></DIV>
<DIV style="position:absolute;top:599;left:172"><nobr><span class="ft6">(q</span></nobr></DIV>
<DIV style="position:absolute;top:607;left:183"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:599;left:188"><nobr><span class="ft6">) = c</span></nobr></DIV>
<DIV style="position:absolute;top:607;left:224"><nobr><span class="ft18">q</span></nobr></DIV>
<DIV style="position:absolute;top:599;left:233"><nobr><span class="ft6">+ c</span></nobr></DIV>
<DIV style="position:absolute;top:607;left:253"><nobr><span class="ft18">r</span></nobr></DIV>
<DIV style="position:absolute;top:602;left:259"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:607;left:282"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:599;left:286"><nobr><span class="ft6">) + c</span></nobr></DIV>
<DIV style="position:absolute;top:607;left:315"><nobr><span class="ft18">d</span></nobr></DIV>
<DIV style="position:absolute;top:602;left:321"><nobr><span class="ft6">P</span></nobr></DIV>
<DIV style="position:absolute;top:607;left:330"><nobr><span class="ft18">new</span></nobr></DIV>
<DIV style="position:absolute;top:599;left:351"><nobr><span class="ft6">(q</span></nobr></DIV>
<DIV style="position:absolute;top:607;left:363"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:599;left:367"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:628;left:81"><nobr><span class="ft4">(Equation 2), we can estimate <i>Cost</i></span></nobr></DIV>
<DIV style="position:absolute;top:624;left:277"><nobr><span class="ft6">(q</span></nobr></DIV>
<DIV style="position:absolute;top:632;left:288"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:624;left:293"><nobr><span class="ft6">) by estimating P (q</span></nobr></DIV>
<DIV style="position:absolute;top:632;left:405"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:624;left:410"><nobr><span class="ft6">) and</span></nobr></DIV>
<DIV style="position:absolute;top:643;left:81"><nobr><span class="ft6">P</span></nobr></DIV>
<DIV style="position:absolute;top:648;left:90"><nobr><span class="ft18">new</span></nobr></DIV>
<DIV style="position:absolute;top:640;left:111"><nobr><span class="ft6">(q</span></nobr></DIV>
<DIV style="position:absolute;top:648;left:122"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:640;left:127"><nobr><span class="ft6">).</span></nobr></DIV>
<DIV style="position:absolute;top:668;left:81"><nobr><span class="ft3"><b>3.3</b></span></nobr></DIV>
<DIV style="position:absolute;top:668;left:121"><nobr><span class="ft3"><b>Efficient calculation of query statistics</b></span></nobr></DIV>
<DIV style="position:absolute;top:691;left:94"><nobr><span class="ft4">In estimating the efficiency of queries, we found that we need to</span></nobr></DIV>
<DIV style="position:absolute;top:707;left:81"><nobr><span class="ft4">measure</span></nobr></DIV>
<DIV style="position:absolute;top:707;left:128"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:711;left:150"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:703;left:155"><nobr><span class="ft6">|q</span></nobr></DIV>
<DIV style="position:absolute;top:709;left:165"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:703;left:172"><nobr><span class="ft6">· · ·q</span></nobr></DIV>
<DIV style="position:absolute;top:711;left:214"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:703;left:233"><nobr><span class="ft6">) for every potential query q</span></nobr></DIV>
<DIV style="position:absolute;top:711;left:381"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:707;left:385"><nobr><span class="ft4">. This cal-</span></nobr></DIV>
<DIV style="position:absolute;top:722;left:81"><nobr><span class="ft12">culation can be very time-consuming if we repeat it from scratch for<br>every query</span></nobr></DIV>
<DIV style="position:absolute;top:738;left:149"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:743;left:155"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:738;left:164"><nobr><span class="ft4">in every iteration of our algorithm. In this section,</span></nobr></DIV>
<DIV style="position:absolute;top:754;left:81"><nobr><span class="ft4">we explain how we can compute</span></nobr></DIV>
<DIV style="position:absolute;top:754;left:261"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:758;left:283"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:750;left:288"><nobr><span class="ft6">|q</span></nobr></DIV>
<DIV style="position:absolute;top:756;left:298"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:750;left:307"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:758;left:357"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:750;left:376"><nobr><span class="ft6">) efficiently</span></nobr></DIV>
<DIV style="position:absolute;top:770;left:81"><nobr><span class="ft4">by maintaining a small table that we call a <i>query statistics table</i>.</span></nobr></DIV>
<DIV style="position:absolute;top:785;left:94"><nobr><span class="ft4">The main idea for the query statistics table is that</span></nobr></DIV>
<DIV style="position:absolute;top:785;left:358"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:790;left:380"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:782;left:385"><nobr><span class="ft6">|q</span></nobr></DIV>
<DIV style="position:absolute;top:788;left:395"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:782;left:402"><nobr><span class="ft6">· · ·</span></nobr></DIV>
<DIV style="position:absolute;top:801;left:81"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:805;left:87"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:798;left:106"><nobr><span class="ft6">) can be measured by counting how many times the keyword</span></nobr></DIV>
<DIV style="position:absolute;top:816;left:81"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:821;left:87"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:817;left:97"><nobr><span class="ft4">appears within the documents downloaded from</span></nobr></DIV>
<DIV style="position:absolute;top:816;left:368"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:819;left:374"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:816;left:380"><nobr><span class="ft6">, . . . , q</span></nobr></DIV>
<DIV style="position:absolute;top:821;left:417"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:817;left:436"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:832;left:81"><nobr><span class="ft12">We record these counts in a table, as shown in Figure 7(a). The<br>left column of the table contains all potential query terms and the<br>right column contains the number of previously-downloaded docu-<br>ments containing the respective term. For example, the table in Fig-<br>ure 7(a) shows that we have downloaded 50 documents so far, and<br>the term <i>model </i>appears in 10 of these documents. Given this num-<br>ber, we can compute that</span></nobr></DIV>
<DIV style="position:absolute;top:926;left:218"><nobr><span class="ft6">P (<i>model</i>|q</span></nobr></DIV>
<DIV style="position:absolute;top:929;left:277"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:923;left:287"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:931;left:337"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:923;left:355"><nobr><span class="ft6">) =</span></nobr></DIV>
<DIV style="position:absolute;top:922;left:381"><nobr><span class="ft18">10</span></nobr></DIV>
<DIV style="position:absolute;top:932;left:381"><nobr><span class="ft18">50</span></nobr></DIV>
<DIV style="position:absolute;top:923;left:398"><nobr><span class="ft6">= 0.2.</span></nobr></DIV>
<DIV style="position:absolute;top:942;left:94"><nobr><span class="ft4">We note that the query statistics table needs to be updated when-</span></nobr></DIV>
<DIV style="position:absolute;top:958;left:81"><nobr><span class="ft4">ever we issue a new query</span></nobr></DIV>
<DIV style="position:absolute;top:958;left:225"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:962;left:231"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:958;left:239"><nobr><span class="ft4">and download more documents. This</span></nobr></DIV>
<DIV style="position:absolute;top:973;left:81"><nobr><span class="ft12">update can be done efficiently as we illustrate in the following ex-<br>ample.</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:96"><nobr><span class="ft4">E</span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:105"><nobr><span class="ft17">XAMPLE</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:160"><nobr><span class="ft4">1. <i>After examining the </i>query statistics table <i>of Fig-</i></span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:81"><nobr><span class="ft13"><i>ure 7(a), we have decided to use the term "computer" as our next<br>query</i></span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:116"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:1056;left:122"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:127"><nobr><span class="ft5"><i>. From the new query</i></span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:253"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:1056;left:259"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:270"><nobr><span class="ft6">= "computer," <i>we downloaded</i></span></nobr></DIV>
<DIV style="position:absolute;top:1063;left:81"><nobr><span class="ft6">20 <i>more new pages. Out of these, </i>12 <i>contain the keyword "model"</i></span></nobr></DIV>
<DIV style="position:absolute;top:86;left:515"><nobr><span class="ft4">Term</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:547"><nobr><span class="ft6">t</span></nobr></DIV>
<DIV style="position:absolute;top:91;left:552"><nobr><span class="ft18">k</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:579"><nobr><span class="ft6">N (t</span></nobr></DIV>
<DIV style="position:absolute;top:91;left:602"><nobr><span class="ft18">k</span></nobr></DIV>
<DIV style="position:absolute;top:83;left:609"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:106;left:520"><nobr><span class="ft4">model</span></nobr></DIV>
<DIV style="position:absolute;top:106;left:590"><nobr><span class="ft4">10</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:512"><nobr><span class="ft4">computer</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:590"><nobr><span class="ft4">38</span></nobr></DIV>
<DIV style="position:absolute;top:138;left:520"><nobr><span class="ft4">digital</span></nobr></DIV>
<DIV style="position:absolute;top:138;left:590"><nobr><span class="ft4">50</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:676"><nobr><span class="ft4">Term</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:707"><nobr><span class="ft6">t</span></nobr></DIV>
<DIV style="position:absolute;top:91;left:712"><nobr><span class="ft18">k</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:739"><nobr><span class="ft6">N (t</span></nobr></DIV>
<DIV style="position:absolute;top:91;left:762"><nobr><span class="ft18">k</span></nobr></DIV>
<DIV style="position:absolute;top:83;left:769"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:106;left:680"><nobr><span class="ft4">model</span></nobr></DIV>
<DIV style="position:absolute;top:106;left:750"><nobr><span class="ft4">12</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:672"><nobr><span class="ft4">computer</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:750"><nobr><span class="ft4">20</span></nobr></DIV>
<DIV style="position:absolute;top:138;left:686"><nobr><span class="ft4">disk</span></nobr></DIV>
<DIV style="position:absolute;top:138;left:750"><nobr><span class="ft4">18</span></nobr></DIV>
<DIV style="position:absolute;top:158;left:521"><nobr><span class="ft4">Total pages:</span></nobr></DIV>
<DIV style="position:absolute;top:155;left:591"><nobr><span class="ft6">50</span></nobr></DIV>
<DIV style="position:absolute;top:158;left:683"><nobr><span class="ft4">New pages:</span></nobr></DIV>
<DIV style="position:absolute;top:155;left:750"><nobr><span class="ft6">20</span></nobr></DIV>
<DIV style="position:absolute;top:174;left:502"><nobr><span class="ft7"><b>(a) After</b></span></nobr></DIV>
<DIV style="position:absolute;top:174;left:555"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:176;left:561"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:174;left:568"><nobr><span class="ft6">, . . . , q</span></nobr></DIV>
<DIV style="position:absolute;top:178;left:605"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:174;left:640"><nobr><span class="ft7"><b>(b) New from</b></span></nobr></DIV>
<DIV style="position:absolute;top:174;left:720"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:178;left:726"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:170;left:734"><nobr><span class="ft6">= computer</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:593"><nobr><span class="ft4">Term</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:625"><nobr><span class="ft6">t</span></nobr></DIV>
<DIV style="position:absolute;top:248;left:630"><nobr><span class="ft18">k</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:671"><nobr><span class="ft6">N (t</span></nobr></DIV>
<DIV style="position:absolute;top:248;left:694"><nobr><span class="ft18">k</span></nobr></DIV>
<DIV style="position:absolute;top:240;left:700"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:263;left:598"><nobr><span class="ft4">model</span></nobr></DIV>
<DIV style="position:absolute;top:263;left:657"><nobr><span class="ft4">10+12 = 22</span></nobr></DIV>
<DIV style="position:absolute;top:279;left:590"><nobr><span class="ft4">computer</span></nobr></DIV>
<DIV style="position:absolute;top:279;left:657"><nobr><span class="ft4">38+20 = 58</span></nobr></DIV>
<DIV style="position:absolute;top:296;left:604"><nobr><span class="ft4">disk</span></nobr></DIV>
<DIV style="position:absolute;top:296;left:661"><nobr><span class="ft4">0+18 = 18</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:598"><nobr><span class="ft4">digital</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:661"><nobr><span class="ft4">50+0 = 50</span></nobr></DIV>
<DIV style="position:absolute;top:331;left:582"><nobr><span class="ft4">Total pages:</span></nobr></DIV>
<DIV style="position:absolute;top:328;left:651"><nobr><span class="ft6">50 + 20 = 70</span></nobr></DIV>
<DIV style="position:absolute;top:347;left:601"><nobr><span class="ft7"><b>(c) After</b></span></nobr></DIV>
<DIV style="position:absolute;top:347;left:654"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:349;left:660"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:347;left:666"><nobr><span class="ft6">, . . . , q</span></nobr></DIV>
<DIV style="position:absolute;top:351;left:703"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:378;left:526"><nobr><span class="ft7"><b>Figure 7: Updating the query statistics table.</b></span></nobr></DIV>
<DIV style="position:absolute;top:411;left:696"><nobr><span class="ft23">q</span></nobr></DIV>
<DIV style="position:absolute;top:420;left:704"><nobr><span class="ft24">i</span></nobr></DIV>
<DIV style="position:absolute;top:420;left:601"><nobr><span class="ft24">1</span></nobr></DIV>
<DIV style="position:absolute;top:420;left:645"><nobr><span class="ft24">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:411;left:637"><nobr><span class="ft23">q</span></nobr></DIV>
<DIV style="position:absolute;top:414;left:608"><nobr><span class="ft25">\/ ... \/</span></nobr></DIV>
<DIV style="position:absolute;top:411;left:593"><nobr><span class="ft23">q</span></nobr></DIV>
<DIV style="position:absolute;top:440;left:700"><nobr><span class="ft23">q</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:708"><nobr><span class="ft24">i</span></nobr></DIV>
<DIV style="position:absolute;top:437;left:700"><nobr><span class="ft25">   /</span></nobr></DIV>
<DIV style="position:absolute;top:393;left:608"><nobr><span class="ft19"><i>S</i></span></nobr></DIV>
<DIV style="position:absolute;top:532;left:495"><nobr><span class="ft7"><b>Figure 8: A Web site that does not return all the results.</b></span></nobr></DIV>
<DIV style="position:absolute;top:566;left:475"><nobr><span class="ft5"><i>and</i></span></nobr></DIV>
<DIV style="position:absolute;top:563;left:501"><nobr><span class="ft6">18 <i>the keyword "disk." The table in Figure 7(b) shows the</i></span></nobr></DIV>
<DIV style="position:absolute;top:582;left:475"><nobr><span class="ft5"><i>frequency of each term in the newly-downloaded pages.</i></span></nobr></DIV>
<DIV style="position:absolute;top:597;left:489"><nobr><span class="ft5"><i>We can update the old table (Figure 7(a)) to include this new</i></span></nobr></DIV>
<DIV style="position:absolute;top:613;left:475"><nobr><span class="ft13"><i>information by simply adding corresponding entries in Figures 7(a)<br>and (b). The result is shown on Figure 7(c). For example, keyword<br>"model" exists in</i></span></nobr></DIV>
<DIV style="position:absolute;top:641;left:575"><nobr><span class="ft6">10 + 12 = 22 <i>pages within the pages retrieved</i></span></nobr></DIV>
<DIV style="position:absolute;top:660;left:475"><nobr><span class="ft5"><i>from</i></span></nobr></DIV>
<DIV style="position:absolute;top:660;left:503"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:663;left:509"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:660;left:515"><nobr><span class="ft6">, . . . , q</span></nobr></DIV>
<DIV style="position:absolute;top:665;left:552"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:660;left:557"><nobr><span class="ft5"><i>. According to this new table,</i></span></nobr></DIV>
<DIV style="position:absolute;top:660;left:714"><nobr><span class="ft6">P (model|q</span></nobr></DIV>
<DIV style="position:absolute;top:663;left:777"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:783"><nobr><span class="ft6">· · ·q</span></nobr></DIV>
<DIV style="position:absolute;top:665;left:824"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:828"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:676;left:475"><nobr><span class="ft5"><i>is now</i></span></nobr></DIV>
<DIV style="position:absolute;top:671;left:515"><nobr><span class="ft18">22</span></nobr></DIV>
<DIV style="position:absolute;top:681;left:515"><nobr><span class="ft18">70</span></nobr></DIV>
<DIV style="position:absolute;top:673;left:532"><nobr><span class="ft6">= 0.3<i>.</i></span></nobr></DIV>
<DIV style="position:absolute;top:713;left:475"><nobr><span class="ft3"><b>3.4</b></span></nobr></DIV>
<DIV style="position:absolute;top:713;left:516"><nobr><span class="ft26"><b>Crawling sites that limit the number of<br>results</b></span></nobr></DIV>
<DIV style="position:absolute;top:753;left:489"><nobr><span class="ft4">In certain cases, when a query matches a large number of pages,</span></nobr></DIV>
<DIV style="position:absolute;top:769;left:475"><nobr><span class="ft12">the Hidden Web site returns only a portion of those pages. For ex-<br>ample, the Open Directory Project [2] allows the users to see only<br>up to</span></nobr></DIV>
<DIV style="position:absolute;top:797;left:507"><nobr><span class="ft6">10, 000 results after they issue a query. Obviously, this kind</span></nobr></DIV>
<DIV style="position:absolute;top:816;left:475"><nobr><span class="ft12">of limitation has an immediate effect on our Hidden Web crawler.<br>First, since we can only retrieve up to a specific number of pages<br>per query, our crawler will need to issue more queries (and po-<br>tentially will use up more resources) in order to download all the<br>pages. Second, the query selection method that we presented in<br>Section 3.2 assumes that for every potential query</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:752"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:899;left:758"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:763"><nobr><span class="ft4">, we can find</span></nobr></DIV>
<DIV style="position:absolute;top:910;left:475"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:914;left:498"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:906;left:502"><nobr><span class="ft6">|q</span></nobr></DIV>
<DIV style="position:absolute;top:912;left:512"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:906;left:522"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:914;left:573"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:906;left:591"><nobr><span class="ft6">). That is, for every query q</span></nobr></DIV>
<DIV style="position:absolute;top:914;left:743"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:910;left:751"><nobr><span class="ft4">we can find the</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:475"><nobr><span class="ft4">fraction of documents in the <i>whole </i>text database that contains</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:823"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:930;left:829"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:475"><nobr><span class="ft4">with at least one of</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:582"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:944;left:588"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:595"><nobr><span class="ft6">, . . . , q</span></nobr></DIV>
<DIV style="position:absolute;top:946;left:631"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:650"><nobr><span class="ft4">. However, if the text database re-</span></nobr></DIV>
<DIV style="position:absolute;top:957;left:475"><nobr><span class="ft4">turned only a portion of the results for any of the</span></nobr></DIV>
<DIV style="position:absolute;top:957;left:739"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:959;left:745"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:957;left:752"><nobr><span class="ft6">, . . . , q</span></nobr></DIV>
<DIV style="position:absolute;top:961;left:789"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:957;left:811"><nobr><span class="ft4">then</span></nobr></DIV>
<DIV style="position:absolute;top:973;left:475"><nobr><span class="ft4">the value</span></nobr></DIV>
<DIV style="position:absolute;top:972;left:527"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:977;left:550"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:969;left:554"><nobr><span class="ft6">|q</span></nobr></DIV>
<DIV style="position:absolute;top:975;left:564"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:969;left:574"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:977;left:624"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:969;left:643"><nobr><span class="ft6">) is not accurate and may affect our</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:475"><nobr><span class="ft4">decision for the next query</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:626"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:993;left:632"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:637"><nobr><span class="ft4">, and potentially the performance of</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:475"><nobr><span class="ft12">our crawler. Since we cannot retrieve more results per query than<br>the maximum number the Web site allows, our crawler has no other<br>choice besides submitting more queries. However, there is a way<br>to <i>estimate </i>the correct value for</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:651"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:1056;left:673"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:678"><nobr><span class="ft6">|q</span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:688"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:698"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:1056;left:748"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:767"><nobr><span class="ft6">) in the case</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:475"><nobr><span class="ft4">where the Web site returns only a portion of the results.</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft4">104</span></nobr></DIV>
</DIV>
<!-- Page 6 -->
<a name="6"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="74006.png" alt="background image">
<DIV style="position:absolute;top:86;left:94"><nobr><span class="ft4">Again, assume that the Hidden Web site we are currently crawl-</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:81"><nobr><span class="ft12">ing is represented as the rectangle on Figure 8 and its pages as<br>points in the figure. Assume that we have already issued queries<br>q</span></nobr></DIV>
<DIV style="position:absolute;top:136;left:87"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:133;left:93"><nobr><span class="ft6">, . . . , q</span></nobr></DIV>
<DIV style="position:absolute;top:138;left:130"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:133;left:152"><nobr><span class="ft4">which returned a number of results less than the max-</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:81"><nobr><span class="ft12">imum number than the site allows, and therefore we have down-<br>loaded all the pages for these queries (big circle in Figure 8). That<br>is, at this point, our estimation for</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:263"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:185;left:286"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:177;left:290"><nobr><span class="ft6">|q</span></nobr></DIV>
<DIV style="position:absolute;top:183;left:300"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:177;left:308"><nobr><span class="ft6">· · ·q</span></nobr></DIV>
<DIV style="position:absolute;top:185;left:352"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:177;left:371"><nobr><span class="ft6">) is accurate.</span></nobr></DIV>
<DIV style="position:absolute;top:196;left:81"><nobr><span class="ft4">Now assume that we submit query</span></nobr></DIV>
<DIV style="position:absolute;top:196;left:272"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:201;left:278"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:196;left:287"><nobr><span class="ft4">to the Web site, but due to a</span></nobr></DIV>
<DIV style="position:absolute;top:212;left:81"><nobr><span class="ft12">limitation in the number of results that we get back, we retrieve the<br>set</span></nobr></DIV>
<DIV style="position:absolute;top:227;left:99"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:233;left:106"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:228;left:114"><nobr><span class="ft4">(small circle in Figure 8) instead of the set</span></nobr></DIV>
<DIV style="position:absolute;top:227;left:349"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:232;left:355"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:228;left:364"><nobr><span class="ft4">(dashed circle</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:81"><nobr><span class="ft12">in Figure 8). Now we need to update our <i>query statistics table </i>so<br>that it has accurate information for the next step. That is, although<br>we got the set</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:162"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:280;left:168"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:177"><nobr><span class="ft4">back, for every potential query</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:350"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:279;left:356"><nobr><span class="ft18">i+1</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:379"><nobr><span class="ft4">we need to</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:81"><nobr><span class="ft4">find</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:105"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:295;left:127"><nobr><span class="ft18">i+1</span></nobr></DIV>
<DIV style="position:absolute;top:287;left:146"><nobr><span class="ft6">|q</span></nobr></DIV>
<DIV style="position:absolute;top:293;left:156"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:287;left:165"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:295;left:215"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:287;left:220"><nobr><span class="ft6">):</span></nobr></DIV>
<DIV style="position:absolute;top:315;left:113"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:320;left:135"><nobr><span class="ft18">i+1</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:153"><nobr><span class="ft6">|q</span></nobr></DIV>
<DIV style="position:absolute;top:317;left:163"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:173"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:320;left:223"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:227"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:340;left:116"><nobr><span class="ft6">=</span></nobr></DIV>
<DIV style="position:absolute;top:331;left:175"><nobr><span class="ft6">1</span></nobr></DIV>
<DIV style="position:absolute;top:352;left:133"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:355;left:155"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:349;left:164"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:357;left:214"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:349;left:219"><nobr><span class="ft6">) · [P (q</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:262"><nobr><span class="ft18">i+1</span></nobr></DIV>
<DIV style="position:absolute;top:340;left:284"><nobr><span class="ft6"> (q</span></nobr></DIV>
<DIV style="position:absolute;top:345;left:308"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:340;left:317"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:367"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:340;left:386"><nobr><span class="ft6">))+</span></nobr></DIV>
<DIV style="position:absolute;top:386;left:122"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:391;left:144"><nobr><span class="ft18">i+1</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:166"><nobr><span class="ft6"> q</span></nobr></DIV>
<DIV style="position:absolute;top:391;left:184"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:189"><nobr><span class="ft6">) - P (q</span></nobr></DIV>
<DIV style="position:absolute;top:391;left:234"><nobr><span class="ft18">i+1</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:255"><nobr><span class="ft6"> q</span></nobr></DIV>
<DIV style="position:absolute;top:391;left:274"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:282"><nobr><span class="ft6"> (q</span></nobr></DIV>
<DIV style="position:absolute;top:388;left:305"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:315"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:391;left:365"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:383;left:384"><nobr><span class="ft6">))]</span></nobr></DIV>
<DIV style="position:absolute;top:386;left:424"><nobr><span class="ft4">(5)</span></nobr></DIV>
<DIV style="position:absolute;top:411;left:94"><nobr><span class="ft4">In the previous equation, we can find</span></nobr></DIV>
<DIV style="position:absolute;top:411;left:293"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:413;left:315"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:407;left:323"><nobr><span class="ft6">· · ·q</span></nobr></DIV>
<DIV style="position:absolute;top:415;left:367"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:407;left:371"><nobr><span class="ft6">) by estimat-</span></nobr></DIV>
<DIV style="position:absolute;top:426;left:81"><nobr><span class="ft4">ing</span></nobr></DIV>
<DIV style="position:absolute;top:426;left:102"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:431;left:125"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:423;left:129"><nobr><span class="ft6">) with the method shown in Section 3. Additionally, we</span></nobr></DIV>
<DIV style="position:absolute;top:442;left:81"><nobr><span class="ft4">can calculate</span></nobr></DIV>
<DIV style="position:absolute;top:442;left:153"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:176"><nobr><span class="ft18">i+1</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:197"><nobr><span class="ft6"> (q</span></nobr></DIV>
<DIV style="position:absolute;top:444;left:220"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:228"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:276"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:294"><nobr><span class="ft6">)) and P (q</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:353"><nobr><span class="ft18">i+1</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:374"><nobr><span class="ft6"> q</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:392"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:399"><nobr><span class="ft6"> (q</span></nobr></DIV>
<DIV style="position:absolute;top:444;left:422"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:430"><nobr><span class="ft6"></span></nobr></DIV>
<DIV style="position:absolute;top:454;left:81"><nobr><span class="ft6">· · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:462;left:121"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:454;left:140"><nobr><span class="ft6">)) by directly examining the documents that we have</span></nobr></DIV>
<DIV style="position:absolute;top:473;left:81"><nobr><span class="ft4">downloaded from queries</span></nobr></DIV>
<DIV style="position:absolute;top:473;left:227"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:476;left:233"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:473;left:239"><nobr><span class="ft6">, . . . , q</span></nobr></DIV>
<DIV style="position:absolute;top:478;left:276"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:473;left:295"><nobr><span class="ft4">. The term</span></nobr></DIV>
<DIV style="position:absolute;top:473;left:364"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:478;left:386"><nobr><span class="ft18">i+1</span></nobr></DIV>
<DIV style="position:absolute;top:470;left:409"><nobr><span class="ft6"> q</span></nobr></DIV>
<DIV style="position:absolute;top:478;left:429"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:470;left:434"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:489;left:81"><nobr><span class="ft4">however is unknown and we need to estimate it. Assuming that</span></nobr></DIV>
<DIV style="position:absolute;top:489;left:429"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:495;left:435"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:81"><nobr><span class="ft4">is a random sample of</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:203"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:509;left:209"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:214"><nobr><span class="ft4">, then:</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:197"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:546;left:219"><nobr><span class="ft18">i+1</span></nobr></DIV>
<DIV style="position:absolute;top:538;left:241"><nobr><span class="ft6"> q</span></nobr></DIV>
<DIV style="position:absolute;top:546;left:259"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:538;left:264"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:559;left:197"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:563;left:219"><nobr><span class="ft18">i+1</span></nobr></DIV>
<DIV style="position:absolute;top:556;left:241"><nobr><span class="ft6"> q</span></nobr></DIV>
<DIV style="position:absolute;top:566;left:259"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:556;left:264"><nobr><span class="ft6">) =</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:291"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:546;left:313"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:538;left:318"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:559;left:291"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:566;left:313"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:556;left:318"><nobr><span class="ft6">)</span></nobr></DIV>
<DIV style="position:absolute;top:550;left:424"><nobr><span class="ft4">(6)</span></nobr></DIV>
<DIV style="position:absolute;top:583;left:94"><nobr><span class="ft4">From Equation 6 we can calculate</span></nobr></DIV>
<DIV style="position:absolute;top:583;left:290"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:588;left:312"><nobr><span class="ft18">i+1</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:335"><nobr><span class="ft6"> q</span></nobr></DIV>
<DIV style="position:absolute;top:588;left:355"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:360"><nobr><span class="ft6">) and after we</span></nobr></DIV>
<DIV style="position:absolute;top:599;left:81"><nobr><span class="ft4">replace this value to Equation 5 we can find</span></nobr></DIV>
<DIV style="position:absolute;top:599;left:318"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:603;left:340"><nobr><span class="ft18">i+1</span></nobr></DIV>
<DIV style="position:absolute;top:595;left:359"><nobr><span class="ft6">|q</span></nobr></DIV>
<DIV style="position:absolute;top:601;left:369"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:595;left:378"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:603;left:426"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:595;left:431"><nobr><span class="ft6">).</span></nobr></DIV>
<DIV style="position:absolute;top:619;left:81"><nobr><span class="ft3"><b>4.</b></span></nobr></DIV>
<DIV style="position:absolute;top:619;left:112"><nobr><span class="ft3"><b>EXPERIMENTAL EVALUATION</b></span></nobr></DIV>
<DIV style="position:absolute;top:641;left:94"><nobr><span class="ft4">In this section we experimentally evaluate the performance of</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:81"><nobr><span class="ft12">the various algorithms for Hidden Web crawling presented in this<br>paper. Our goal is to validate our theoretical analysis through real-<br>world experiments, by crawling popular Hidden Web sites of tex-<br>tual databases. Since the number of documents that are discovered<br>and downloaded from a textual database depends on the selection<br>of the words that will be issued as queries</span></nobr></DIV>
<DIV style="position:absolute;top:733;left:310"><nobr><span class="ft10">5</span></nobr></DIV>
<DIV style="position:absolute;top:735;left:319"><nobr><span class="ft4">to the search interface</span></nobr></DIV>
<DIV style="position:absolute;top:751;left:81"><nobr><span class="ft12">of each site, we compare the various selection policies that were<br>described in section 3, namely the <i>random</i>, <i>generic-frequency</i>, and<br><i>adaptive </i>algorithms.</span></nobr></DIV>
<DIV style="position:absolute;top:798;left:94"><nobr><span class="ft4">The <i>adaptive </i>algorithm learns new keywords and terms from the</span></nobr></DIV>
<DIV style="position:absolute;top:814;left:81"><nobr><span class="ft13">documents that it downloads, and its selection process is driven by<br>a cost model as described in Section 3.2. To keep our experiment<br>and its analysis simple at this point, we will assume that the cost for<br>every query is constant. That is, our goal is to maximize the number<br>of downloaded pages by issuing the least number of queries. Later,<br>in Section 4.4 we will present a comparison of our policies based<br>on a more elaborate cost model. In addition, we use the <i>indepen-<br>dence estimator </i>(Section 3.1) to estimate</span></nobr></DIV>
<DIV style="position:absolute;top:924;left:308"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:928;left:330"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:920;left:335"><nobr><span class="ft6">) from downloaded</span></nobr></DIV>
<DIV style="position:absolute;top:939;left:81"><nobr><span class="ft12">pages. Although the <i>independence estimator </i>is a simple estimator,<br>our experiments will show that it can work very well in practice.</span></nobr></DIV>
<DIV style="position:absolute;top:953;left:427"><nobr><span class="ft10">6</span></nobr></DIV>
<DIV style="position:absolute;top:971;left:94"><nobr><span class="ft4">For the <i>generic-frequency </i>policy, we compute the frequency dis-</span></nobr></DIV>
<DIV style="position:absolute;top:986;left:81"><nobr><span class="ft4">tribution of words that appear in a 5.5-million-Web-page corpus</span></nobr></DIV>
<DIV style="position:absolute;top:1008;left:82"><nobr><span class="ft10">5</span></nobr></DIV>
<DIV style="position:absolute;top:1010;left:87"><nobr><span class="ft4">Throughout our experiments, once an algorithm has submitted a</span></nobr></DIV>
<DIV style="position:absolute;top:1024;left:81"><nobr><span class="ft16">query to a database, we exclude the query from subsequent submis-<br>sions to the same database from the same algorithm.</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:82"><nobr><span class="ft10">6</span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:87"><nobr><span class="ft4">We defer the reporting of results based on the <i>Zipf estimation </i>to a</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:81"><nobr><span class="ft4">future work.</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft12">downloaded from 154 Web sites of various topics [26]. Keywords<br>are selected based on their decreasing frequency with which they<br>appear in this document set, with the most frequent one being se-<br>lected first, followed by the second-most frequent keyword, etc.</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:818"><nobr><span class="ft10">7</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:489"><nobr><span class="ft4">Regarding the <i>random </i>policy, we use the same set of words col-</span></nobr></DIV>
<DIV style="position:absolute;top:165;left:475"><nobr><span class="ft12">lected from the Web corpus, but in this case, instead of selecting<br>keywords based on their relative frequency, we choose them ran-<br>domly (uniform distribution). In order to further investigate how<br>the quality of the potential query-term list affects the random-based<br>algorithm, we construct two sets: one with the</span></nobr></DIV>
<DIV style="position:absolute;top:224;left:738"><nobr><span class="ft6">16, 000 most fre-</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:475"><nobr><span class="ft12">quent words of the term collection used in the generic-frequency<br>policy (hereafter, the random policy with the set of 16,000 words<br>will be referred to as <i>random-16K</i>), and another set with the</span></nobr></DIV>
<DIV style="position:absolute;top:271;left:801"><nobr><span class="ft6">1 mil-</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:475"><nobr><span class="ft12">lion most frequent words of the same collection as above (hereafter,<br>referred to as <i>random-1M</i>). The former set has frequent words that<br>appear in a large number of documents (at least</span></nobr></DIV>
<DIV style="position:absolute;top:318;left:734"><nobr><span class="ft6">10, 000 in our col-</span></nobr></DIV>
<DIV style="position:absolute;top:337;left:475"><nobr><span class="ft12">lection), and therefore can be considered of "high-quality" terms.<br>The latter set though contains a much larger collection of words,<br>among which some might be bogus, and meaningless.</span></nobr></DIV>
<DIV style="position:absolute;top:384;left:489"><nobr><span class="ft4">The experiments were conducted by employing each one of the</span></nobr></DIV>
<DIV style="position:absolute;top:400;left:475"><nobr><span class="ft12">aforementioned algorithms (adaptive, generic-frequency, random-<br>16K, and random-1M) to crawl and download contents from three<br>Hidden Web sites: The PubMed Medical Library,</span></nobr></DIV>
<DIV style="position:absolute;top:429;left:746"><nobr><span class="ft10">8</span></nobr></DIV>
<DIV style="position:absolute;top:432;left:756"><nobr><span class="ft4">Amazon,</span></nobr></DIV>
<DIV style="position:absolute;top:429;left:805"><nobr><span class="ft10">9</span></nobr></DIV>
<DIV style="position:absolute;top:432;left:814"><nobr><span class="ft4">and</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:475"><nobr><span class="ft12">the Open Directory Project[2]. According to the information on<br><i>PubMed</i>'s Web site, its collection contains approximately</span></nobr></DIV>
<DIV style="position:absolute;top:460;left:794"><nobr><span class="ft6">14 mil-</span></nobr></DIV>
<DIV style="position:absolute;top:479;left:475"><nobr><span class="ft12">lion abstracts of biomedical articles. We consider these abstracts<br>as the "documents" in the site, and in each iteration of the adaptive<br>policy, we use these abstracts as input to the algorithm. Thus our<br>goal is to "discover" as many unique abstracts as possible by repeat-<br>edly querying the Web query interface provided by PubMed. The<br>Hidden Web crawling on the PubMed Web site can be considered<br>as topic-specific, due to the fact that all abstracts within PubMed<br>are related to the fields of medicine and biology.</span></nobr></DIV>
<DIV style="position:absolute;top:604;left:489"><nobr><span class="ft4">In the case of the <i>Amazon </i>Web site, we are interested in down-</span></nobr></DIV>
<DIV style="position:absolute;top:620;left:475"><nobr><span class="ft12">loading all the hidden pages that contain information on books.<br>The querying to Amazon is performed through the Software De-<br>veloper's Kit that Amazon provides for interfacing to its Web site,<br>and which returns results in XML form. The generic "keyword"<br>field is used for searching, and as input to the adaptive policy we<br>extract the product description and the text of customer reviews<br>when present in the XML reply. Since Amazon does not provide<br>any information on how many books it has in its catalogue, we use<br>random sampling on the 10-digit ISBN number of the books to es-<br>timate the size of the collection. Out of the</span></nobr></DIV>
<DIV style="position:absolute;top:758;left:714"><nobr><span class="ft6">10, 000 random ISBN</span></nobr></DIV>
<DIV style="position:absolute;top:777;left:475"><nobr><span class="ft4">numbers queried,</span></nobr></DIV>
<DIV style="position:absolute;top:773;left:572"><nobr><span class="ft6">46 are found in the Amazon catalogue, therefore</span></nobr></DIV>
<DIV style="position:absolute;top:792;left:475"><nobr><span class="ft4">the size of its book collection is estimated to be</span></nobr></DIV>
<DIV style="position:absolute;top:788;left:742"><nobr><span class="ft18">46</span></nobr></DIV>
<DIV style="position:absolute;top:798;left:734"><nobr><span class="ft18">10000</span></nobr></DIV>
<DIV style="position:absolute;top:789;left:766"><nobr><span class="ft6">· 10</span></nobr></DIV>
<DIV style="position:absolute;top:788;left:786"><nobr><span class="ft18">10</span></nobr></DIV>
<DIV style="position:absolute;top:789;left:802"><nobr><span class="ft6">= 4.6</span></nobr></DIV>
<DIV style="position:absolute;top:808;left:475"><nobr><span class="ft12">million books. It's also worth noting here that Amazon poses an<br>upper limit on the number of results (books in our case) returned<br>by each query, which is set to</span></nobr></DIV>
<DIV style="position:absolute;top:836;left:637"><nobr><span class="ft6">32, 000.</span></nobr></DIV>
<DIV style="position:absolute;top:855;left:489"><nobr><span class="ft4">As for the third Hidden Web site, the <i>Open Directory Project</i></span></nobr></DIV>
<DIV style="position:absolute;top:871;left:475"><nobr><span class="ft12">(hereafter also referred to as <i>dmoz</i>), the site maintains the links to<br>3.8 million sites together with a brief summary of each listed site.<br>The links are searchable through a keyword-search interface. We<br>consider each indexed link together with its brief summary as the<br>document of the <i>dmoz </i>site, and we provide the short summaries<br>to the adaptive algorithm to drive the selection of new keywords<br>for querying. On the dmoz Web site, we perform two Hidden Web<br>crawls: the first is on its generic collection of</span></nobr></DIV>
<DIV style="position:absolute;top:977;left:727"><nobr><span class="ft6">3.8-million indexed</span></nobr></DIV>
<DIV style="position:absolute;top:1005;left:477"><nobr><span class="ft10">7</span></nobr></DIV>
<DIV style="position:absolute;top:1008;left:482"><nobr><span class="ft4">We did not manually exclude <i>stop words </i>(e.g., the, is, of, etc.)</span></nobr></DIV>
<DIV style="position:absolute;top:1021;left:475"><nobr><span class="ft16">from the keyword list. As it turns out, all Web sites except PubMed<br>return matching documents for the stop words, such as "the."</span></nobr></DIV>
<DIV style="position:absolute;top:1048;left:477"><nobr><span class="ft10">8</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:482"><nobr><span class="ft4">PubMed Medical Library: http://www.pubmed.org</span></nobr></DIV>
<DIV style="position:absolute;top:1064;left:477"><nobr><span class="ft10">9</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:482"><nobr><span class="ft4">Amazon Inc.: http://www.amazon.com</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft4">105</span></nobr></DIV>
</DIV>
<!-- Page 7 -->
<a name="7"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft27{font-size:5px;font-family:Helvetica;color:#000000;}
	.ft28{font-size:11px;line-height:16px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="74007.png" alt="background image">
<DIV style="position:absolute;top:298;left:118"><nobr><span class="ft27"> 0</span></nobr></DIV>
<DIV style="position:absolute;top:278;left:112"><nobr><span class="ft27"> 0.1</span></nobr></DIV>
<DIV style="position:absolute;top:258;left:112"><nobr><span class="ft27"> 0.2</span></nobr></DIV>
<DIV style="position:absolute;top:239;left:112"><nobr><span class="ft27"> 0.3</span></nobr></DIV>
<DIV style="position:absolute;top:219;left:112"><nobr><span class="ft27"> 0.4</span></nobr></DIV>
<DIV style="position:absolute;top:199;left:112"><nobr><span class="ft27"> 0.5</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:112"><nobr><span class="ft27"> 0.6</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:112"><nobr><span class="ft27"> 0.7</span></nobr></DIV>
<DIV style="position:absolute;top:140;left:112"><nobr><span class="ft27"> 0.8</span></nobr></DIV>
<DIV style="position:absolute;top:121;left:112"><nobr><span class="ft27"> 0.9</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:118"><nobr><span class="ft27"> 1</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:126"><nobr><span class="ft27"> 0</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:192"><nobr><span class="ft27"> 50</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:259"><nobr><span class="ft27"> 100</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:327"><nobr><span class="ft27"> 150</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:396"><nobr><span class="ft27"> 200</span></nobr></DIV>
<DIV style="position:absolute;top:234;left:101"><nobr><span class="ft27">fraction of documents</span></nobr></DIV>
<DIV style="position:absolute;top:317;left:250"><nobr><span class="ft27">query number</span></nobr></DIV>
<DIV style="position:absolute;top:89;left:173"><nobr><span class="ft27">Cumulative fraction of unique documents - PubMed website</span></nobr></DIV>
<DIV style="position:absolute;top:108;left:182"><nobr><span class="ft27">adaptive</span></nobr></DIV>
<DIV style="position:absolute;top:116;left:150"><nobr><span class="ft27">generic-frequency</span></nobr></DIV>
<DIV style="position:absolute;top:123;left:169"><nobr><span class="ft27">random-16K</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:172"><nobr><span class="ft27">random-1M</span></nobr></DIV>
<DIV style="position:absolute;top:340;left:139"><nobr><span class="ft7"><b>Figure 9: Coverage of policies for Pubmed</b></span></nobr></DIV>
<DIV style="position:absolute;top:569;left:118"><nobr><span class="ft27"> 0</span></nobr></DIV>
<DIV style="position:absolute;top:549;left:112"><nobr><span class="ft27"> 0.1</span></nobr></DIV>
<DIV style="position:absolute;top:530;left:112"><nobr><span class="ft27"> 0.2</span></nobr></DIV>
<DIV style="position:absolute;top:510;left:112"><nobr><span class="ft27"> 0.3</span></nobr></DIV>
<DIV style="position:absolute;top:490;left:112"><nobr><span class="ft27"> 0.4</span></nobr></DIV>
<DIV style="position:absolute;top:471;left:112"><nobr><span class="ft27"> 0.5</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:112"><nobr><span class="ft27"> 0.6</span></nobr></DIV>
<DIV style="position:absolute;top:431;left:112"><nobr><span class="ft27"> 0.7</span></nobr></DIV>
<DIV style="position:absolute;top:412;left:112"><nobr><span class="ft27"> 0.8</span></nobr></DIV>
<DIV style="position:absolute;top:392;left:112"><nobr><span class="ft27"> 0.9</span></nobr></DIV>
<DIV style="position:absolute;top:372;left:118"><nobr><span class="ft27"> 1</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:126"><nobr><span class="ft27"> 0</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:159"><nobr><span class="ft27"> 100</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:195"><nobr><span class="ft27"> 200</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:232"><nobr><span class="ft27"> 300</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:269"><nobr><span class="ft27"> 400</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:306"><nobr><span class="ft27"> 500</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:343"><nobr><span class="ft27"> 600</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:380"><nobr><span class="ft27"> 700</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:101"><nobr><span class="ft27">fraction of documents</span></nobr></DIV>
<DIV style="position:absolute;top:588;left:250"><nobr><span class="ft27">query number</span></nobr></DIV>
<DIV style="position:absolute;top:361;left:174"><nobr><span class="ft27">Cumulative fraction of unique documents - Amazon website</span></nobr></DIV>
<DIV style="position:absolute;top:379;left:182"><nobr><span class="ft27">adaptive</span></nobr></DIV>
<DIV style="position:absolute;top:387;left:150"><nobr><span class="ft27">generic-frequency</span></nobr></DIV>
<DIV style="position:absolute;top:395;left:169"><nobr><span class="ft27">random-16K</span></nobr></DIV>
<DIV style="position:absolute;top:402;left:172"><nobr><span class="ft27">random-1M</span></nobr></DIV>
<DIV style="position:absolute;top:612;left:135"><nobr><span class="ft7"><b>Figure 10: Coverage of policies for Amazon</b></span></nobr></DIV>
<DIV style="position:absolute;top:646;left:81"><nobr><span class="ft28">sites, regardless of the category that they fall into. The other crawl<br>is performed specifically on the Arts section of <i>dmoz </i>(http://<br>dmoz.org/Arts</span></nobr></DIV>
<DIV style="position:absolute;top:677;left:186"><nobr><span class="ft4">), which comprises of approximately</span></nobr></DIV>
<DIV style="position:absolute;top:674;left:392"><nobr><span class="ft6">429, 000</span></nobr></DIV>
<DIV style="position:absolute;top:693;left:81"><nobr><span class="ft12">indexed sites that are relevant to Arts, making this crawl topic-<br>specific, as in PubMed. Like Amazon, <i>dmoz </i>also enforces an upper<br>limit on the number of returned results, which is</span></nobr></DIV>
<DIV style="position:absolute;top:721;left:342"><nobr><span class="ft6">10, 000 links with</span></nobr></DIV>
<DIV style="position:absolute;top:740;left:81"><nobr><span class="ft4">their summaries.</span></nobr></DIV>
<DIV style="position:absolute;top:762;left:81"><nobr><span class="ft3"><b>4.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:762;left:121"><nobr><span class="ft3"><b>Comparison of policies</b></span></nobr></DIV>
<DIV style="position:absolute;top:784;left:94"><nobr><span class="ft4">The first question that we seek to answer is the evolution of the</span></nobr></DIV>
<DIV style="position:absolute;top:800;left:81"><nobr><span class="ft12"><i>coverage </i>metric as we submit queries to the sites. That is, what<br>fraction of the collection of documents stored in the Hidden Web<br>site can we download as we continuously query for new words se-<br>lected using the policies described above? More formally, we are<br>interested in the value of</span></nobr></DIV>
<DIV style="position:absolute;top:863;left:217"><nobr><span class="ft6">P (q</span></nobr></DIV>
<DIV style="position:absolute;top:865;left:239"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:859;left:248"><nobr><span class="ft6"> · · ·  q</span></nobr></DIV>
<DIV style="position:absolute;top:867;left:298"><nobr><span class="ft18">i-1</span></nobr></DIV>
<DIV style="position:absolute;top:859;left:320"><nobr><span class="ft6"> q</span></nobr></DIV>
<DIV style="position:absolute;top:867;left:339"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:859;left:344"><nobr><span class="ft6">), after we submit</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:81"><nobr><span class="ft6">q</span></nobr></DIV>
<DIV style="position:absolute;top:881;left:87"><nobr><span class="ft18">1</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:93"><nobr><span class="ft6">, . . . , q</span></nobr></DIV>
<DIV style="position:absolute;top:883;left:130"><nobr><span class="ft18">i</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:138"><nobr><span class="ft4">queries, and as</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:221"><nobr><span class="ft6">i increases.</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:94"><nobr><span class="ft4">In Figures 9, 10, 11, and 12 we present the coverage metric for</span></nobr></DIV>
<DIV style="position:absolute;top:910;left:81"><nobr><span class="ft12">each policy, as a function of the query number, for the Web sites<br>of PubMed, Amazon, general <i>dmoz </i>and the art-specific <i>dmoz</i>, re-<br>spectively. On the y-axis the fraction of the total documents down-<br>loaded from the website is plotted, while the x-axis represents the<br>query number. A first observation from these graphs is that in gen-<br>eral, the generic-frequency and the adaptive policies perform much<br>better than the random-based algorithms. In all of the figures, the<br>graphs for the random-1M and the random-16K are significantly<br>below those of other policies.</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:94"><nobr><span class="ft4">Between the generic-frequency and the adaptive policies, we can</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:81"><nobr><span class="ft4">see that the latter outperforms the former when the site is topic spe-</span></nobr></DIV>
<DIV style="position:absolute;top:298;left:513"><nobr><span class="ft27"> 0</span></nobr></DIV>
<DIV style="position:absolute;top:278;left:506"><nobr><span class="ft27"> 0.1</span></nobr></DIV>
<DIV style="position:absolute;top:258;left:506"><nobr><span class="ft27"> 0.2</span></nobr></DIV>
<DIV style="position:absolute;top:239;left:506"><nobr><span class="ft27"> 0.3</span></nobr></DIV>
<DIV style="position:absolute;top:219;left:506"><nobr><span class="ft27"> 0.4</span></nobr></DIV>
<DIV style="position:absolute;top:199;left:506"><nobr><span class="ft27"> 0.5</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:506"><nobr><span class="ft27"> 0.6</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:506"><nobr><span class="ft27"> 0.7</span></nobr></DIV>
<DIV style="position:absolute;top:140;left:506"><nobr><span class="ft27"> 0.8</span></nobr></DIV>
<DIV style="position:absolute;top:121;left:506"><nobr><span class="ft27"> 0.9</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:513"><nobr><span class="ft27"> 1</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:520"><nobr><span class="ft27"> 0</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:554"><nobr><span class="ft27"> 100</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:591"><nobr><span class="ft27"> 200</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:628"><nobr><span class="ft27"> 300</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:666"><nobr><span class="ft27"> 400</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:703"><nobr><span class="ft27"> 500</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:740"><nobr><span class="ft27"> 600</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:778"><nobr><span class="ft27"> 700</span></nobr></DIV>
<DIV style="position:absolute;top:234;left:495"><nobr><span class="ft27">fraction of documents</span></nobr></DIV>
<DIV style="position:absolute;top:317;left:644"><nobr><span class="ft27">query number</span></nobr></DIV>
<DIV style="position:absolute;top:89;left:573"><nobr><span class="ft27">Cumulative fraction of unique documents - dmoz website</span></nobr></DIV>
<DIV style="position:absolute;top:108;left:576"><nobr><span class="ft27">adaptive</span></nobr></DIV>
<DIV style="position:absolute;top:116;left:545"><nobr><span class="ft27">generic-frequency</span></nobr></DIV>
<DIV style="position:absolute;top:123;left:563"><nobr><span class="ft27">random-16K</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:566"><nobr><span class="ft27">random-1M</span></nobr></DIV>
<DIV style="position:absolute;top:340;left:515"><nobr><span class="ft7"><b>Figure 11: Coverage of policies for general dmoz</b></span></nobr></DIV>
<DIV style="position:absolute;top:569;left:513"><nobr><span class="ft27"> 0</span></nobr></DIV>
<DIV style="position:absolute;top:549;left:506"><nobr><span class="ft27"> 0.1</span></nobr></DIV>
<DIV style="position:absolute;top:530;left:506"><nobr><span class="ft27"> 0.2</span></nobr></DIV>
<DIV style="position:absolute;top:510;left:506"><nobr><span class="ft27"> 0.3</span></nobr></DIV>
<DIV style="position:absolute;top:490;left:506"><nobr><span class="ft27"> 0.4</span></nobr></DIV>
<DIV style="position:absolute;top:471;left:506"><nobr><span class="ft27"> 0.5</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:506"><nobr><span class="ft27"> 0.6</span></nobr></DIV>
<DIV style="position:absolute;top:431;left:506"><nobr><span class="ft27"> 0.7</span></nobr></DIV>
<DIV style="position:absolute;top:412;left:506"><nobr><span class="ft27"> 0.8</span></nobr></DIV>
<DIV style="position:absolute;top:392;left:506"><nobr><span class="ft27"> 0.9</span></nobr></DIV>
<DIV style="position:absolute;top:372;left:513"><nobr><span class="ft27"> 1</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:520"><nobr><span class="ft27"> 0</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:549"><nobr><span class="ft27"> 50</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:577"><nobr><span class="ft27"> 100</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:608"><nobr><span class="ft27"> 150</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:638"><nobr><span class="ft27"> 200</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:669"><nobr><span class="ft27"> 250</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:699"><nobr><span class="ft27"> 300</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:730"><nobr><span class="ft27"> 350</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:760"><nobr><span class="ft27"> 400</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:791"><nobr><span class="ft27"> 450</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:495"><nobr><span class="ft27">fraction of documents</span></nobr></DIV>
<DIV style="position:absolute;top:588;left:644"><nobr><span class="ft27">query number</span></nobr></DIV>
<DIV style="position:absolute;top:361;left:565"><nobr><span class="ft27">Cumulative fraction of unique documents - dmoz/Arts website</span></nobr></DIV>
<DIV style="position:absolute;top:379;left:576"><nobr><span class="ft27">adaptive</span></nobr></DIV>
<DIV style="position:absolute;top:387;left:545"><nobr><span class="ft27">generic-frequency</span></nobr></DIV>
<DIV style="position:absolute;top:395;left:563"><nobr><span class="ft27">random-16K</span></nobr></DIV>
<DIV style="position:absolute;top:402;left:566"><nobr><span class="ft27">random-1M</span></nobr></DIV>
<DIV style="position:absolute;top:612;left:484"><nobr><span class="ft7"><b>Figure 12: Coverage of policies for the Arts section of dmoz</b></span></nobr></DIV>
<DIV style="position:absolute;top:646;left:475"><nobr><span class="ft12">cific. For example, for the PubMed site (Figure 9), the adaptive<br>algorithm issues only 83 queries to download almost 80% of the<br>documents stored in PubMed, but the generic-frequency algorithm<br>requires 106 queries for the same coverage,. For the dmoz/Arts<br>crawl (Figure 12), the difference is even more substantial: the adap-<br>tive policy is able to download 99.98% of the total sites indexed in<br>the Directory by issuing 471 queries, while the frequency-based al-<br>gorithm is much less effective using the same number of queries,<br>and discovers only 72% of the total number of indexed sites. The<br>adaptive algorithm, by examining the contents of the pages that it<br>downloads at each iteration, is able to identify the topic of the site as<br>expressed by the words that appear most frequently in the result-set.<br>Consequently, it is able to select words for subsequent queries that<br>are more relevant to the site, than those preferred by the generic-<br>frequency policy, which are drawn from a large, generic collection.<br>Table 1 shows a sample of 10 keywords out of 211 chosen and sub-<br>mitted to the PubMed Web site by the adaptive algorithm, but not<br>by the other policies. For each keyword, we present the number of<br>the iteration, along with the number of results that it returned. As<br>one can see from the table, these keywords are highly relevant to<br>the topics of medicine and biology of the Public Medical Library,<br>and match against numerous articles stored in its Web site.</span></nobr></DIV>
<DIV style="position:absolute;top:991;left:489"><nobr><span class="ft4">In both cases examined in Figures 9, and 12, the random-based</span></nobr></DIV>
<DIV style="position:absolute;top:1007;left:475"><nobr><span class="ft12">policies perform much worse than the adaptive algorithm, and the<br>generic-frequency. It is worthy noting however, that the random-<br>based policy with the small, carefully selected set of</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:757"><nobr><span class="ft6">16, 000 "qual-</span></nobr></DIV>
<DIV style="position:absolute;top:1054;left:475"><nobr><span class="ft4">ity" words manages to download a considerable fraction of 42.5%</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft4">106</span></nobr></DIV>
</DIV>
<!-- Page 8 -->
<a name="8"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="918" height="1188" src="74008.png" alt="background image">
<DIV style="position:absolute;top:83;left:138"><nobr><span class="ft5"><i>Iteration</i></span></nobr></DIV>
<DIV style="position:absolute;top:83;left:208"><nobr><span class="ft5"><i>Keyword</i></span></nobr></DIV>
<DIV style="position:absolute;top:83;left:279"><nobr><span class="ft5"><i>Number of Results</i></span></nobr></DIV>
<DIV style="position:absolute;top:96;left:155"><nobr><span class="ft6">23</span></nobr></DIV>
<DIV style="position:absolute;top:99;left:202"><nobr><span class="ft4">department</span></nobr></DIV>
<DIV style="position:absolute;top:96;left:300"><nobr><span class="ft6">2, 719, 031</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:155"><nobr><span class="ft6">34</span></nobr></DIV>
<DIV style="position:absolute;top:116;left:211"><nobr><span class="ft4">patients</span></nobr></DIV>
<DIV style="position:absolute;top:112;left:300"><nobr><span class="ft6">1, 934, 428</span></nobr></DIV>
<DIV style="position:absolute;top:128;left:155"><nobr><span class="ft6">53</span></nobr></DIV>
<DIV style="position:absolute;top:132;left:212"><nobr><span class="ft4">clinical</span></nobr></DIV>
<DIV style="position:absolute;top:128;left:300"><nobr><span class="ft6">1, 198, 322</span></nobr></DIV>
<DIV style="position:absolute;top:145;left:155"><nobr><span class="ft6">67</span></nobr></DIV>
<DIV style="position:absolute;top:148;left:207"><nobr><span class="ft4">treatment</span></nobr></DIV>
<DIV style="position:absolute;top:145;left:300"><nobr><span class="ft6">4, 034, 565</span></nobr></DIV>
<DIV style="position:absolute;top:161;left:155"><nobr><span class="ft6">69</span></nobr></DIV>
<DIV style="position:absolute;top:164;left:211"><nobr><span class="ft4">medical</span></nobr></DIV>
<DIV style="position:absolute;top:161;left:300"><nobr><span class="ft6">1, 368, 200</span></nobr></DIV>
<DIV style="position:absolute;top:177;left:155"><nobr><span class="ft6">70</span></nobr></DIV>
<DIV style="position:absolute;top:181;left:211"><nobr><span class="ft4">hospital</span></nobr></DIV>
<DIV style="position:absolute;top:177;left:307"><nobr><span class="ft6">503, 307</span></nobr></DIV>
<DIV style="position:absolute;top:194;left:151"><nobr><span class="ft6">146</span></nobr></DIV>
<DIV style="position:absolute;top:197;left:213"><nobr><span class="ft4">disease</span></nobr></DIV>
<DIV style="position:absolute;top:194;left:300"><nobr><span class="ft6">1, 520, 908</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:151"><nobr><span class="ft6">172</span></nobr></DIV>
<DIV style="position:absolute;top:213;left:213"><nobr><span class="ft4">protein</span></nobr></DIV>
<DIV style="position:absolute;top:210;left:300"><nobr><span class="ft6">2, 620, 938</span></nobr></DIV>
<DIV style="position:absolute;top:244;left:81"><nobr><span class="ft21"><b>Table 1: Sample of keywords queried to PubMed exclusively by<br>the adaptive policy</b></span></nobr></DIV>
<DIV style="position:absolute;top:308;left:81"><nobr><span class="ft12">from the PubMed Web site after 200 queries, while the coverage<br>for the Arts section of dmoz reaches 22.7%, after 471 queried key-<br>words. On the other hand, the random-based approach that makes<br>use of the vast collection of</span></nobr></DIV>
<DIV style="position:absolute;top:352;left:234"><nobr><span class="ft6">1 million words, among which a large</span></nobr></DIV>
<DIV style="position:absolute;top:371;left:81"><nobr><span class="ft12">number is bogus keywords, fails to download even a mere 1% of the<br>total collection, after submitting the same number of query words.</span></nobr></DIV>
<DIV style="position:absolute;top:402;left:94"><nobr><span class="ft4">For the generic collections of Amazon and the <i>dmoz </i>sites, shown</span></nobr></DIV>
<DIV style="position:absolute;top:418;left:81"><nobr><span class="ft12">in Figures 10 and 11 respectively, we get mixed results: The generic-<br>frequency policy shows slightly better performance than the adap-<br>tive policy for the Amazon site (Figure 10), and the adaptive method<br>clearly outperforms the generic-frequency for the general <i>dmoz </i>site<br>(Figure 11). A closer look at the log files of the two Hidden Web<br>crawlers reveals the main reason: Amazon was functioning in a<br>very flaky way when the adaptive crawler visited it, resulting in<br>a large number of lost results. Thus, we suspect that the slightly<br>poor performance of the adaptive policy is due to this experimen-<br>tal variance. We are currently running another experiment to ver-<br>ify whether this is indeed the case. Aside from this experimental<br>variance, the Amazon result indicates that if the collection and the<br>words that a Hidden Web site contains are generic enough, then the<br>generic-frequency approach may be a good candidate algorithm for<br>effective crawling.</span></nobr></DIV>
<DIV style="position:absolute;top:653;left:94"><nobr><span class="ft4">As in the case of topic-specific Hidden Web sites, the random-</span></nobr></DIV>
<DIV style="position:absolute;top:669;left:81"><nobr><span class="ft12">based policies also exhibit poor performance compared to the other<br>two algorithms when crawling generic sites: for the Amazon Web<br>site, random-16K succeeds in downloading almost 36.7% after is-<br>suing 775 queries, alas for the generic collection of dmoz, the frac-<br>tion of the collection of links downloaded is 13.5% after the 770th<br>query. Finally, as expected, random-1M is even worse than random-<br>16K, downloading only 14.5% of Amazon and 0.3% of the generic<br>dmoz.</span></nobr></DIV>
<DIV style="position:absolute;top:794;left:94"><nobr><span class="ft4">In summary, the adaptive algorithm performs remarkably well in</span></nobr></DIV>
<DIV style="position:absolute;top:810;left:81"><nobr><span class="ft12">all cases: it is able to discover and download most of the documents<br>stored in Hidden Web sites by issuing the least number of queries.<br>When the collection refers to a specific topic, it is able to identify<br>the keywords most relevant to the topic of the site and consequently<br>ask for terms that is most likely that will return a large number of<br>results . On the other hand, the generic-frequency policy proves to<br>be quite effective too, though less than the adaptive: it is able to re-<br>trieve relatively fast a large portion of the collection, and when the<br>site is not topic-specific, its effectiveness can reach that of adap-<br>tive (e.g. Amazon). Finally, the random policy performs poorly in<br>general, and should not be preferred.</span></nobr></DIV>
<DIV style="position:absolute;top:997;left:81"><nobr><span class="ft3"><b>4.2</b></span></nobr></DIV>
<DIV style="position:absolute;top:997;left:121"><nobr><span class="ft3"><b>Impact of the initial query</b></span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:94"><nobr><span class="ft4">An interesting issue that deserves further examination is whether</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:81"><nobr><span class="ft12">the initial choice of the keyword used as the first query issued by<br>the adaptive algorithm affects its effectiveness in subsequent itera-<br>tions. The choice of this keyword is not done by the selection of the</span></nobr></DIV>
<DIV style="position:absolute;top:298;left:513"><nobr><span class="ft27"> 0</span></nobr></DIV>
<DIV style="position:absolute;top:278;left:506"><nobr><span class="ft27"> 0.1</span></nobr></DIV>
<DIV style="position:absolute;top:258;left:506"><nobr><span class="ft27"> 0.2</span></nobr></DIV>
<DIV style="position:absolute;top:239;left:506"><nobr><span class="ft27"> 0.3</span></nobr></DIV>
<DIV style="position:absolute;top:219;left:506"><nobr><span class="ft27"> 0.4</span></nobr></DIV>
<DIV style="position:absolute;top:199;left:506"><nobr><span class="ft27"> 0.5</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:506"><nobr><span class="ft27"> 0.6</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:506"><nobr><span class="ft27"> 0.7</span></nobr></DIV>
<DIV style="position:absolute;top:140;left:506"><nobr><span class="ft27"> 0.8</span></nobr></DIV>
<DIV style="position:absolute;top:121;left:506"><nobr><span class="ft27"> 0.9</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:513"><nobr><span class="ft27"> 1</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:520"><nobr><span class="ft27"> 0</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:565"><nobr><span class="ft27"> 10</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:613"><nobr><span class="ft27"> 20</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:660"><nobr><span class="ft27"> 30</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:707"><nobr><span class="ft27"> 40</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:754"><nobr><span class="ft27"> 50</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:801"><nobr><span class="ft27"> 60</span></nobr></DIV>
<DIV style="position:absolute;top:234;left:495"><nobr><span class="ft27">fraction of documents</span></nobr></DIV>
<DIV style="position:absolute;top:317;left:644"><nobr><span class="ft27">query number</span></nobr></DIV>
<DIV style="position:absolute;top:89;left:546"><nobr><span class="ft27">Convergence of adaptive under different initial queries - PubMed website</span></nobr></DIV>
<DIV style="position:absolute;top:108;left:550"><nobr><span class="ft27">pubmed</span></nobr></DIV>
<DIV style="position:absolute;top:116;left:563"><nobr><span class="ft27">data</span></nobr></DIV>
<DIV style="position:absolute;top:123;left:540"><nobr><span class="ft27">information</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:558"><nobr><span class="ft27">return</span></nobr></DIV>
<DIV style="position:absolute;top:340;left:475"><nobr><span class="ft21"><b>Figure 13: Convergence of the adaptive algorithm using differ-<br>ent initial queries for crawling the PubMed Web site</b></span></nobr></DIV>
<DIV style="position:absolute;top:390;left:475"><nobr><span class="ft12">adaptive algorithm itself and has to be manually set, since its query<br>statistics tables have not been populated yet. Thus, the selection is<br>generally arbitrary, so for purposes of fully automating the whole<br>process, some additional investigation seems necessary.</span></nobr></DIV>
<DIV style="position:absolute;top:453;left:489"><nobr><span class="ft4">For this reason, we initiated three adaptive Hidden Web crawlers</span></nobr></DIV>
<DIV style="position:absolute;top:468;left:475"><nobr><span class="ft12">targeting the PubMed Web site with different seed-words: the word<br>"data", which returns 1,344,999 results, the word "information"<br>that reports</span></nobr></DIV>
<DIV style="position:absolute;top:496;left:544"><nobr><span class="ft6">308, 474 documents, and the word "return" that re-</span></nobr></DIV>
<DIV style="position:absolute;top:515;left:475"><nobr><span class="ft4">trieves</span></nobr></DIV>
<DIV style="position:absolute;top:512;left:515"><nobr><span class="ft6">29, 707 pages, out of 14 million. These keywords repre-</span></nobr></DIV>
<DIV style="position:absolute;top:531;left:475"><nobr><span class="ft12">sent varying degrees of term popularity in PubMed, with the first<br>one being of high popularity, the second of medium, and the third<br>of low. We also show results for the keyword "pubmed", used in<br>the experiments for coverage of Section 4.1, and which returns 695<br>articles. As we can see from Figure 13, after a small number of<br>queries, all four crawlers roughly download the same fraction of<br>the collection, regardless of their starting point: Their coverages<br>are roughly equivalent from the 25th query. Eventually, all four<br>crawlers use the same set of terms for their queries, regardless of<br>the initial query. In the specific experiment, from the 36th query on-<br>ward, all four crawlers use the same terms for their queries in each<br>iteration, or the same terms are used off by one or two query num-<br>bers. Our result confirms the observation of [11] that the choice of<br>the initial query has minimal effect on the final performance. We<br>can explain this intuitively as follows: Our algorithm approximates<br>the optimal set of queries to use for a particular Web site. Once<br>the algorithm has issued a significant number of queries, it has an<br>accurate estimation of the content of the Web site, regardless of<br>the initial query. Since this estimation is similar for all runs of the<br>algorithm, the crawlers will use roughly the same queries.</span></nobr></DIV>
<DIV style="position:absolute;top:856;left:475"><nobr><span class="ft3"><b>4.3</b></span></nobr></DIV>
<DIV style="position:absolute;top:856;left:516"><nobr><span class="ft3"><b>Impact of the limit in the number of results</b></span></nobr></DIV>
<DIV style="position:absolute;top:878;left:489"><nobr><span class="ft4">While the Amazon and dmoz sites have the respective limit of</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:475"><nobr><span class="ft12">32,000 and 10,000 in their result sizes, these limits may be larger<br>than those imposed by other Hidden Web sites. In order to inves-<br>tigate how a "tighter" limit in the result size affects the perfor-<br>mance of our algorithms, we performed two additional crawls to<br>the generic-dmoz site: we ran the generic-frequency and adaptive<br>policies but we retrieved only up to the top 1,000 results for ev-<br>ery query. In Figure 14 we plot the coverage for the two policies<br>as a function of the number of queries. As one might expect, by<br>comparing the new result in Figure 14 to that of Figure 11 where<br>the result limit was 10,000, we conclude that the tighter limit re-<br>quires a higher number of queries to achieve the same coverage.<br>For example, when the result limit was 10,000, the adaptive pol-</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft4">107</span></nobr></DIV>
</DIV>
<!-- Page 9 -->
<a name="9"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft29{font-size:4px;font-family:Helvetica;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="74009.png" alt="background image">
<DIV style="position:absolute;top:298;left:118"><nobr><span class="ft27"> 0</span></nobr></DIV>
<DIV style="position:absolute;top:278;left:112"><nobr><span class="ft27"> 0.1</span></nobr></DIV>
<DIV style="position:absolute;top:258;left:112"><nobr><span class="ft27"> 0.2</span></nobr></DIV>
<DIV style="position:absolute;top:239;left:112"><nobr><span class="ft27"> 0.3</span></nobr></DIV>
<DIV style="position:absolute;top:219;left:112"><nobr><span class="ft27"> 0.4</span></nobr></DIV>
<DIV style="position:absolute;top:199;left:112"><nobr><span class="ft27"> 0.5</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:112"><nobr><span class="ft27"> 0.6</span></nobr></DIV>
<DIV style="position:absolute;top:160;left:112"><nobr><span class="ft27"> 0.7</span></nobr></DIV>
<DIV style="position:absolute;top:140;left:112"><nobr><span class="ft27"> 0.8</span></nobr></DIV>
<DIV style="position:absolute;top:121;left:112"><nobr><span class="ft27"> 0.9</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:118"><nobr><span class="ft27"> 1</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:126"><nobr><span class="ft27"> 0</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:163"><nobr><span class="ft27"> 500</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:202"><nobr><span class="ft27"> 1000</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:243"><nobr><span class="ft27"> 1500</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:284"><nobr><span class="ft27"> 2000</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:325"><nobr><span class="ft27"> 2500</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:366"><nobr><span class="ft27"> 3000</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:407"><nobr><span class="ft27"> 3500</span></nobr></DIV>
<DIV style="position:absolute;top:240;left:101"><nobr><span class="ft27">Fraction of Unique Pages</span></nobr></DIV>
<DIV style="position:absolute;top:317;left:248"><nobr><span class="ft27">Query Number</span></nobr></DIV>
<DIV style="position:absolute;top:89;left:119"><nobr><span class="ft27">Cumulative fraction of unique pages downloaded per query - Dmoz Web site (cap limit 1000)</span></nobr></DIV>
<DIV style="position:absolute;top:108;left:182"><nobr><span class="ft27">adaptive</span></nobr></DIV>
<DIV style="position:absolute;top:116;left:150"><nobr><span class="ft27">generic-frequency</span></nobr></DIV>
<DIV style="position:absolute;top:340;left:81"><nobr><span class="ft21"><b>Figure 14: Coverage of general dmoz after limiting the number<br>of results to 1,000</b></span></nobr></DIV>
<DIV style="position:absolute;top:390;left:81"><nobr><span class="ft12">icy could download 70% of the site after issuing 630 queries, while<br>it had to issue 2,600 queries to download 70% of the site when<br>the limit was 1,000. On the other hand, our new result shows that<br>even with a tight result limit, it is still possible to download most<br>of a Hidden Web site after issuing a reasonable number of queries.<br>The adaptive policy could download more than 85% of the site af-<br>ter issuing 3,500 queries when the limit was 1,000. Finally, our<br>result shows that our adaptive policy consistently outperforms the<br>generic-frequency policy regardless of the result limit. In both Fig-<br>ure 14 and Figure 11, our adaptive policy shows significantly larger<br>coverage than the generic-frequency policy for the same number of<br>queries.</span></nobr></DIV>
<DIV style="position:absolute;top:589;left:81"><nobr><span class="ft3"><b>4.4</b></span></nobr></DIV>
<DIV style="position:absolute;top:589;left:121"><nobr><span class="ft3"><b>Incorporating the document download</b></span></nobr></DIV>
<DIV style="position:absolute;top:605;left:121"><nobr><span class="ft3"><b>cost</b></span></nobr></DIV>
<DIV style="position:absolute;top:627;left:94"><nobr><span class="ft4">For brevity of presentation, the performance evaluation results</span></nobr></DIV>
<DIV style="position:absolute;top:643;left:81"><nobr><span class="ft12">provided so far assumed a simplified cost-model where every query<br>involved a constant cost. In this section we present results regarding<br>the performance of the adaptive and generic-frequency algorithms<br>using Equation 2 to drive our query selection process. As we dis-<br>cussed in Section 2.3.1, this query cost model includes the cost for<br>submitting the query to the site, retrieving the result index page,<br>and also downloading the actual pages. For these costs, we exam-<br>ined the size of every result in the index page and the sizes of the<br>documents, and we chose</span></nobr></DIV>
<DIV style="position:absolute;top:768;left:224"><nobr><span class="ft6">c</span></nobr></DIV>
<DIV style="position:absolute;top:773;left:230"><nobr><span class="ft18">q</span></nobr></DIV>
<DIV style="position:absolute;top:765;left:241"><nobr><span class="ft6">= 100, c</span></nobr></DIV>
<DIV style="position:absolute;top:773;left:290"><nobr><span class="ft18">r</span></nobr></DIV>
<DIV style="position:absolute;top:765;left:302"><nobr><span class="ft6">= 100, and c</span></nobr></DIV>
<DIV style="position:absolute;top:773;left:374"><nobr><span class="ft18">d</span></nobr></DIV>
<DIV style="position:absolute;top:765;left:386"><nobr><span class="ft6">= 10000,</span></nobr></DIV>
<DIV style="position:absolute;top:784;left:81"><nobr><span class="ft12">as values for the parameters of Equation 2, and for the particular<br>experiment that we ran on the PubMed website. The values that<br>we selected imply that the cost for issuing one query and retrieving<br>one result from the result index page are roughly the same, while<br>the cost for downloading an actual page is 100 times larger. We<br>believe that these values are reasonable for the PubMed Web site.</span></nobr></DIV>
<DIV style="position:absolute;top:878;left:94"><nobr><span class="ft4">Figure 15 shows the coverage of the adaptive and generic-</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:81"><nobr><span class="ft12">frequency algorithms as a function of the resource units used dur-<br>ing the download process. The horizontal axis is the amount of<br>resources used, and the vertical axis is the coverage. As it is evi-<br>dent from the graph, the adaptive policy makes more efficient use of<br>the available resources, as it is able to download more articles than<br>the generic-frequency, using the same amount of resource units.<br>However, the difference in coverage is less dramatic in this case,<br>compared to the graph of Figure 9. The smaller difference is due<br>to the fact that under the current cost metric, the download cost of<br>documents constitutes a significant portion of the cost. Therefore,<br>when both policies downloaded the same number of documents,<br>the saving of the adaptive policy is not as dramatic as before. That</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:513"><nobr><span class="ft27"> 0</span></nobr></DIV>
<DIV style="position:absolute;top:271;left:506"><nobr><span class="ft27"> 0.1</span></nobr></DIV>
<DIV style="position:absolute;top:252;left:506"><nobr><span class="ft27"> 0.2</span></nobr></DIV>
<DIV style="position:absolute;top:233;left:506"><nobr><span class="ft27"> 0.3</span></nobr></DIV>
<DIV style="position:absolute;top:214;left:506"><nobr><span class="ft27"> 0.4</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:506"><nobr><span class="ft27"> 0.5</span></nobr></DIV>
<DIV style="position:absolute;top:177;left:506"><nobr><span class="ft27"> 0.6</span></nobr></DIV>
<DIV style="position:absolute;top:158;left:506"><nobr><span class="ft27"> 0.7</span></nobr></DIV>
<DIV style="position:absolute;top:139;left:506"><nobr><span class="ft27"> 0.8</span></nobr></DIV>
<DIV style="position:absolute;top:120;left:506"><nobr><span class="ft27"> 0.9</span></nobr></DIV>
<DIV style="position:absolute;top:101;left:513"><nobr><span class="ft27"> 1</span></nobr></DIV>
<DIV style="position:absolute;top:298;left:520"><nobr><span class="ft27"> 0</span></nobr></DIV>
<DIV style="position:absolute;top:298;left:560"><nobr><span class="ft27"> 5000</span></nobr></DIV>
<DIV style="position:absolute;top:298;left:605"><nobr><span class="ft27"> 10000</span></nobr></DIV>
<DIV style="position:absolute;top:298;left:651"><nobr><span class="ft27"> 15000</span></nobr></DIV>
<DIV style="position:absolute;top:298;left:698"><nobr><span class="ft27"> 20000</span></nobr></DIV>
<DIV style="position:absolute;top:298;left:744"><nobr><span class="ft27"> 25000</span></nobr></DIV>
<DIV style="position:absolute;top:298;left:790"><nobr><span class="ft27"> 30000</span></nobr></DIV>
<DIV style="position:absolute;top:237;left:495"><nobr><span class="ft27">Fraction of Unique Pages</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:603"><nobr><span class="ft27">Total Cost (c</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:645"><nobr><span class="ft29">q</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:649"><nobr><span class="ft27">=100, c</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:674"><nobr><span class="ft29">r</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:676"><nobr><span class="ft27">=100, c</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:701"><nobr><span class="ft29">d</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:704"><nobr><span class="ft27">=10000)</span></nobr></DIV>
<DIV style="position:absolute;top:89;left:530"><nobr><span class="ft27">Cumulative fraction of unique pages downloaded per cost unit  - PubMed Web site</span></nobr></DIV>
<DIV style="position:absolute;top:108;left:540"><nobr><span class="ft27">adaptive</span></nobr></DIV>
<DIV style="position:absolute;top:116;left:536"><nobr><span class="ft27">frequency</span></nobr></DIV>
<DIV style="position:absolute;top:340;left:475"><nobr><span class="ft21"><b>Figure 15: Coverage of PubMed after incorporating the docu-<br>ment download cost</b></span></nobr></DIV>
<DIV style="position:absolute;top:387;left:475"><nobr><span class="ft12">is, the savings in the query cost and the result index download cost<br>is only a relatively small portion of the overall cost. Still, we ob-<br>serve noticeable savings from the adaptive policy. At the total cost<br>of 8000, for example, the coverage of the adaptive policy is roughly<br>0.5 while the coverage of the frequency policy is only 0.3.</span></nobr></DIV>
<DIV style="position:absolute;top:479;left:475"><nobr><span class="ft3"><b>5.</b></span></nobr></DIV>
<DIV style="position:absolute;top:479;left:507"><nobr><span class="ft3"><b>RELATED WORK</b></span></nobr></DIV>
<DIV style="position:absolute;top:502;left:489"><nobr><span class="ft4">In a recent study, Raghavan and Garcia-Molina [29] present an</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:475"><nobr><span class="ft12">architectural model for a Hidden Web crawler. The main focus of<br>this work is to <i>learn </i>Hidden-Web query interfaces, not to gener-<br>ate queries automatically. The potential queries are either provided<br>manually by users or collected from the query interfaces. In con-<br>trast, our main focus is to generate queries automatically without<br>any human intervention.</span></nobr></DIV>
<DIV style="position:absolute;top:612;left:489"><nobr><span class="ft4">The idea of automatically issuing queries to a database and ex-</span></nobr></DIV>
<DIV style="position:absolute;top:627;left:475"><nobr><span class="ft12">amining the results has been previously used in different contexts.<br>For example, in [10, 11], Callan and Connel try to acquire an <i>accu-<br>rate language model </i>by collecting a uniform random sample from<br>the database. In [22] Lawrence and Giles issue random queries to<br>a number of Web Search Engines in order to estimate the <i>fraction<br></i>of the Web that has been indexed by each of them. In a similar<br>fashion, Bharat and Broder [8] issue random queries to a set of<br>Search Engines in order to estimate the <i>relative size and overlap </i>of<br>their indexes. In [6], Barbosa and Freire experimentally evaluate<br>methods for building multi-keyword queries that can return a large<br>fraction of a document collection. Our work differs from the previ-<br>ous studies in two ways. First, it provides a theoretical framework<br>for analyzing the process of generating queries for a database and<br>examining the results, which can help us better understand the ef-<br>fectiveness of the methods presented in the previous work. Second,<br>we apply our framework to the problem of Hidden Web crawling<br>and demonstrate the efficiency of our algorithms.</span></nobr></DIV>
<DIV style="position:absolute;top:894;left:489"><nobr><span class="ft4">Cope et al. [15] propose a method to automatically detect whether</span></nobr></DIV>
<DIV style="position:absolute;top:910;left:475"><nobr><span class="ft12">a particular Web page contains a search form. This work is com-<br>plementary to ours; once we detect search interfaces on the Web<br>using the method in [15], we may use our proposed algorithms to<br>download pages automatically from those Web sites.</span></nobr></DIV>
<DIV style="position:absolute;top:973;left:489"><nobr><span class="ft4">Reference [4] reports methods to estimate what fraction of a</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:475"><nobr><span class="ft12">text database can be eventually acquired by issuing queries to the<br>database. In [3] the authors study query-based techniques that can<br>extract <i>relational data </i>from large text databases. Again, these works<br>study orthogonal issues and are complementary to our work.</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:489"><nobr><span class="ft4">In order to make documents in multiple textual databases search-</span></nobr></DIV>
<DIV style="position:absolute;top:1067;left:475"><nobr><span class="ft4">able at a central place, a number of "harvesting" approaches have</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft4">108</span></nobr></DIV>
</DIV>
<!-- Page 10 -->
<a name="10"></a>
<DIV style="position:relative;width:918;height:1188;">
<STYLE type="text/css">
<!--
	.ft30{font-size:8px;font-family:Times;color:#000000;}
	.ft31{font-size:8px;font-family:Times;color:#000000;}
	.ft32{font-size:8px;line-height:13px;font-family:Times;color:#000000;}
	.ft33{font-size:8px;line-height:12px;font-family:Times;color:#000000;}
	.ft34{font-size:8px;line-height:11px;font-family:Times;color:#000000;}
	.ft35{font-size:8px;line-height:11px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="918" height="1188" src="74010.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft12">been proposed (e.g., OAI [21], DP9 [24]). These approaches essen-<br>tially assume cooperative document databases that willingly share<br>some of their metadata and/or documents to help a third-party search<br>engine to index the documents. Our approach assumes uncoop-<br>erative databases that do not share their data publicly and whose<br>documents are accessible only through search interfaces.</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:94"><nobr><span class="ft4">There exists a large body of work studying how to identify the</span></nobr></DIV>
<DIV style="position:absolute;top:196;left:81"><nobr><span class="ft12">most relevant database given a user query [20, 19, 14, 23, 18]. This<br>body of work is often referred to as <i>meta-searching </i>or <i>database<br>selection </i>problem over the Hidden Web. For example, [19] sug-<br>gests the use of <i>focused probing </i>to classify databases into a topical<br>category, so that given a query, a relevant database can be selected<br>based on its topical category. Our vision is different from this body<br>of work in that we intend to <i>download </i>and <i>index </i>the Hidden pages<br>at a central location in advance, so that users can access all the<br>information at their convenience from one single location.</span></nobr></DIV>
<DIV style="position:absolute;top:339;left:81"><nobr><span class="ft3"><b>6.</b></span></nobr></DIV>
<DIV style="position:absolute;top:339;left:112"><nobr><span class="ft3"><b>CONCLUSION AND FUTURE WORK</b></span></nobr></DIV>
<DIV style="position:absolute;top:362;left:94"><nobr><span class="ft4">Traditional crawlers normally follow links on the Web to dis-</span></nobr></DIV>
<DIV style="position:absolute;top:377;left:81"><nobr><span class="ft12">cover and download pages. Therefore they cannot get to the Hidden<br>Web pages which are only accessible through query interfaces. In<br>this paper, we studied how we can build a Hidden Web crawler that<br>can automatically query a Hidden Web site and download pages<br>from it. We proposed three different query generation policies for<br>the Hidden Web: a policy that picks queries at <i>random </i>from a list<br>of keywords, a policy that picks queries based on their <i>frequency<br></i>in a generic text collection, and a policy which <i>adaptively </i>picks a<br>good query based on the content of the pages downloaded from the<br>Hidden Web site. Experimental evaluation on 4 real Hidden Web<br>sites shows that our policies have a great potential. In particular, in<br>certain cases the <i>adaptive </i>policy can download more than</span></nobr></DIV>
<DIV style="position:absolute;top:547;left:399"><nobr><span class="ft6">90% of</span></nobr></DIV>
<DIV style="position:absolute;top:566;left:81"><nobr><span class="ft4">a Hidden Web site after issuing approximately</span></nobr></DIV>
<DIV style="position:absolute;top:562;left:335"><nobr><span class="ft6">100 queries. Given</span></nobr></DIV>
<DIV style="position:absolute;top:581;left:81"><nobr><span class="ft12">these results, we believe that our work provides a potential mech-<br>anism to improve the search-engine coverage of the Web and the<br>user experience of Web search.</span></nobr></DIV>
<DIV style="position:absolute;top:636;left:81"><nobr><span class="ft3"><b>6.1</b></span></nobr></DIV>
<DIV style="position:absolute;top:636;left:121"><nobr><span class="ft3"><b>Future Work</b></span></nobr></DIV>
<DIV style="position:absolute;top:659;left:81"><nobr><span class="ft12">We briefly discuss some future-research avenues.<br><b>Multi-attribute Databases</b></span></nobr></DIV>
<DIV style="position:absolute;top:674;left:248"><nobr><span class="ft4">We are currently investigating how</span></nobr></DIV>
<DIV style="position:absolute;top:690;left:81"><nobr><span class="ft28">to extend our ideas to <i>structured multi-attribute </i>databases. While<br>generating queries for multi-attribute databases is clearly a more<br>difficult problem, we may exploit the following observation to ad-<br>dress this problem: When a site supports multi-attribute queries,<br>the site often returns pages that contain values for each of the query<br>attributes. For example, when an online bookstore supports queries<br>on title, author and isbn, the pages returned from a query<br>typically contain the title, author and ISBN of corresponding books.<br>Thus, if we can analyze the returned pages and extract the values<br>for each field (e.g, title = `Harry Potter', author =<br>`J.K. Rowling'</span></nobr></DIV>
<DIV style="position:absolute;top:847;left:194"><nobr><span class="ft4">, etc), we can apply the same idea that we</span></nobr></DIV>
<DIV style="position:absolute;top:863;left:81"><nobr><span class="ft12">used for the textual database: estimate the frequency of each at-<br>tribute value and pick the most promising one. The main challenge<br>is to automatically segment the returned pages so that we can iden-<br>tify the sections of the pages that present the values corresponding<br>to each attribute. Since many Web sites follow limited formatting<br>styles in presenting multiple attributes -- for example, most book<br>titles are preceded by the label "Title:" -- we believe we may learn<br>page-segmentation rules automatically from a small set of training<br>examples.<br><b>Other Practical Issues</b></span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:226"><nobr><span class="ft4">In addition to the automatic query gen-</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:81"><nobr><span class="ft12">eration problem, there are many practical issues to be addressed<br>to build a fully automatic Hidden-Web crawler. For example, in<br>this paper we assumed that the crawler already knows all query in-<br>terfaces for Hidden-Web sites. But how can the crawler discover</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft12">the query interfaces? The method proposed in [15] may be a good<br>starting point. In addition, some Hidden-Web sites return their re-<br>sults in batches of, say, 20 pages, so the user has to click on a<br>"next" button in order to see more results. In this case, a fully au-<br>tomatic Hidden-Web crawler should know that the first result index<br>page contains only a partial result and "press" the next button auto-<br>matically. Finally, some Hidden Web sites may contain an infinite<br>number of Hidden Web pages which do not contribute much sig-<br>nificant content (e.g. a calendar with links for every day). In this<br>case the Hidden-Web crawler should be able to detect that the site<br>does not have much more new content and stop downloading pages<br>from the site. Page similarity detection algorithms may be useful<br>for this purpose [9, 13].</span></nobr></DIV>
<DIV style="position:absolute;top:299;left:475"><nobr><span class="ft3"><b>7.</b></span></nobr></DIV>
<DIV style="position:absolute;top:299;left:507"><nobr><span class="ft3"><b>REFERENCES</b></span></nobr></DIV>
<DIV style="position:absolute;top:316;left:480"><nobr><span class="ft32">[1] Lexisnexis http://www.lexisnexis.com.<br>[2] The Open Directory Project, http://www.dmoz.org.<br>[3] E. Agichtein and L. Gravano. Querying text databases for efficient information</span></nobr></DIV>
<DIV style="position:absolute;top:355;left:499"><nobr><span class="ft17">extraction. In <i>ICDE</i>, 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:369;left:480"><nobr><span class="ft17">[4] E. Agichtein, P. Ipeirotis, and L. Gravano. Modeling query-based access to text</span></nobr></DIV>
<DIV style="position:absolute;top:381;left:499"><nobr><span class="ft17">databases. In <i>WebDB</i>, 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:394;left:480"><nobr><span class="ft17">[5] Article on New York Times. Old Search Engine, the Library, Tries to Fit Into a</span></nobr></DIV>
<DIV style="position:absolute;top:406;left:499"><nobr><span class="ft33">Google World. Available at: http:<br>//www.nytimes.com/2004/06/21/technology/21LIBR.html</span></nobr></DIV>
<DIV style="position:absolute;top:418;left:820"><nobr><span class="ft17">,</span></nobr></DIV>
<DIV style="position:absolute;top:430;left:499"><nobr><span class="ft17">June 2004.</span></nobr></DIV>
<DIV style="position:absolute;top:443;left:480"><nobr><span class="ft17">[6] L. Barbosa and J. Freire. Siphoning hidden-web data through keyword-based</span></nobr></DIV>
<DIV style="position:absolute;top:455;left:499"><nobr><span class="ft17">interfaces. In <i>SBBD</i>, 2004.</span></nobr></DIV>
<DIV style="position:absolute;top:469;left:480"><nobr><span class="ft17">[7] M. K. Bergman. The deep web: Surfacing hidden value,http:</span></nobr></DIV>
<DIV style="position:absolute;top:481;left:499"><nobr><span class="ft30">//www.press.umich.edu/jep/07-01/bergman.html</span></nobr></DIV>
<DIV style="position:absolute;top:481;left:776"><nobr><span class="ft17">.</span></nobr></DIV>
<DIV style="position:absolute;top:494;left:480"><nobr><span class="ft17">[8] K. Bharat and A. Broder. A technique for measuring the relative size and</span></nobr></DIV>
<DIV style="position:absolute;top:506;left:499"><nobr><span class="ft17">overlap of public web search engines. In <i>WWW</i>, 1998.</span></nobr></DIV>
<DIV style="position:absolute;top:520;left:480"><nobr><span class="ft17">[9] A. Z. Broder, S. C. Glassman, M. S. Manasse, and G. Zweig. Syntactic</span></nobr></DIV>
<DIV style="position:absolute;top:532;left:499"><nobr><span class="ft17">clustering of the web. In <i>WWW</i>, 1997.</span></nobr></DIV>
<DIV style="position:absolute;top:545;left:475"><nobr><span class="ft17">[10] J. Callan, M. Connell, and A. Du. Automatic discovery of language models for</span></nobr></DIV>
<DIV style="position:absolute;top:557;left:499"><nobr><span class="ft17">text databases. In <i>SIGMOD</i>, 1999.</span></nobr></DIV>
<DIV style="position:absolute;top:570;left:475"><nobr><span class="ft17">[11] J. P. Callan and M. E. Connell. Query-based sampling of text databases.</span></nobr></DIV>
<DIV style="position:absolute;top:582;left:499"><nobr><span class="ft31"><i>Information Systems</i>, 19(2):97­130, 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:475"><nobr><span class="ft17">[12] K. C.-C. Chang, B. He, C. Li, and Z. Zhang. Structured databases on the web:</span></nobr></DIV>
<DIV style="position:absolute;top:608;left:499"><nobr><span class="ft17">Observations and implications. Technical report, UIUC.</span></nobr></DIV>
<DIV style="position:absolute;top:621;left:475"><nobr><span class="ft17">[13] J. Cho, N. Shivakumar, and H. Garcia-Molina. Finding replicated web</span></nobr></DIV>
<DIV style="position:absolute;top:633;left:499"><nobr><span class="ft17">collections. In <i>SIGMOD</i>, 2000.</span></nobr></DIV>
<DIV style="position:absolute;top:647;left:475"><nobr><span class="ft17">[14] W. Cohen and Y. Singer. Learning to query the web. In <i>AAAI Workshop on</i></span></nobr></DIV>
<DIV style="position:absolute;top:659;left:499"><nobr><span class="ft31"><i>Internet-Based Information Systems</i>, 1996.</span></nobr></DIV>
<DIV style="position:absolute;top:672;left:475"><nobr><span class="ft17">[15] J. Cope, N. Craswell, and D. Hawking. Automated discovery of search</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:499"><nobr><span class="ft34">interfaces on the web. In <i>14th Australasian conference on Database<br>technologies</i>, 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:709;left:475"><nobr><span class="ft17">[16] T. H. Cormen, C. E. Leiserson, and R. L. Rivest. <i>Introduction to Algorithms,</i></span></nobr></DIV>
<DIV style="position:absolute;top:721;left:499"><nobr><span class="ft31"><i>2nd Edition</i>. MIT Press/McGraw Hill, 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:735;left:475"><nobr><span class="ft17">[17] D. Florescu, A. Y. Levy, and A. O. Mendelzon. Database techniques for the</span></nobr></DIV>
<DIV style="position:absolute;top:747;left:499"><nobr><span class="ft17">world-wide web: A survey. <i>SIGMOD Record</i>, 27(3):59­74, 1998.</span></nobr></DIV>
<DIV style="position:absolute;top:760;left:475"><nobr><span class="ft17">[18] B. He and K. C.-C. Chang. Statistical schema matching across web query</span></nobr></DIV>
<DIV style="position:absolute;top:772;left:499"><nobr><span class="ft17">interfaces. In <i>SIGMOD Conference</i>, 2003.</span></nobr></DIV>
<DIV style="position:absolute;top:786;left:475"><nobr><span class="ft17">[19] P. Ipeirotis and L. Gravano. Distributed search over the hidden web:</span></nobr></DIV>
<DIV style="position:absolute;top:798;left:499"><nobr><span class="ft17">Hierarchical database sampling and selection. In <i>VLDB</i>, 2002.</span></nobr></DIV>
<DIV style="position:absolute;top:811;left:475"><nobr><span class="ft17">[20] P. G. Ipeirotis, L. Gravano, and M. Sahami. Probe, count, and classify:</span></nobr></DIV>
<DIV style="position:absolute;top:823;left:499"><nobr><span class="ft17">Categorizing hidden web databases. In <i>SIGMOD</i>, 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:836;left:475"><nobr><span class="ft17">[21] C. Lagoze and H. V. Sompel. The Open Archives Initiative: Building a</span></nobr></DIV>
<DIV style="position:absolute;top:848;left:499"><nobr><span class="ft17">low-barrier interoperability framework In <i>JCDL</i>, 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:862;left:475"><nobr><span class="ft17">[22] S. Lawrence and C. L. Giles. Searching the World Wide Web. <i>Science</i>,</span></nobr></DIV>
<DIV style="position:absolute;top:874;left:499"><nobr><span class="ft17">280(5360):98--100, 1998.</span></nobr></DIV>
<DIV style="position:absolute;top:887;left:475"><nobr><span class="ft17">[23] V. Z. Liu, J. C. Richard C. Luo and, and W. W. Chu. Dpro: A probabilistic</span></nobr></DIV>
<DIV style="position:absolute;top:899;left:499"><nobr><span class="ft35">approach for hidden web database selection using dynamic probing. In <i>ICDE</i>,<br>2004.</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:475"><nobr><span class="ft17">[24] X. Liu, K. Maly, M. Zubair and M. L. Nelson. <i>DP9-An OAI Gateway Service</i></span></nobr></DIV>
<DIV style="position:absolute;top:937;left:499"><nobr><span class="ft31"><i>for Web Crawlers. </i>In <i>JCDL</i>, 2002.</span></nobr></DIV>
<DIV style="position:absolute;top:950;left:475"><nobr><span class="ft32">[25] B. B. Mandelbrot. <i>Fractal Geometry of Nature</i>. W. H. Freeman &amp; Co.<br>[26] A. Ntoulas, J. Cho, and C. Olston. What's new on the web? the evolution of the</span></nobr></DIV>
<DIV style="position:absolute;top:975;left:499"><nobr><span class="ft17">web from a search engine perspective. In <i>WWW</i>, 2004.</span></nobr></DIV>
<DIV style="position:absolute;top:989;left:475"><nobr><span class="ft17">[27] A. Ntoulas, P. Zerfos, and J. Cho. Downloading hidden web content. Technical</span></nobr></DIV>
<DIV style="position:absolute;top:1001;left:499"><nobr><span class="ft17">report, UCLA, 2004.</span></nobr></DIV>
<DIV style="position:absolute;top:1014;left:475"><nobr><span class="ft17">[28] S. Olsen. Does search engine's power threaten web's independence?</span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:499"><nobr><span class="ft30">http://news.com.com/2009-1023-963618.html</span></nobr></DIV>
<DIV style="position:absolute;top:1026;left:758"><nobr><span class="ft17">.</span></nobr></DIV>
<DIV style="position:absolute;top:1040;left:475"><nobr><span class="ft32">[29] S. Raghavan and H. Garcia-Molina. Crawling the hidden web. In <i>VLDB</i>, 2001.<br>[30] G. K. Zipf. <i>Human Behavior and the Principle of Least-Effort</i>.</span></nobr></DIV>
<DIV style="position:absolute;top:1065;left:499"><nobr><span class="ft17">Addison-Wesley, Cambridge, MA, 1949.</span></nobr></DIV>
<DIV style="position:absolute;top:1128;left:449"><nobr><span class="ft4">109</span></nobr></DIV>
</DIV>
</BODY>
</HTML>
