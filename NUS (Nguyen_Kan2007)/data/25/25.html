<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
<HEAD>
<TITLE></TITLE>
<META http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<META name="generator" content="pdftohtml 0.35beta">
<META name="author" content="">
<META name="keywords" content="">
<META name="date" content="2002-04-23T08:52:40+00:00">
<META name="subject" content="">
</HEAD>
<BODY bgcolor="#A0A0A0" vlink="blue" link="blue">
<!-- Page 1 -->
<a name="1"></a>
<DIV style="position:relative;width:917;height:1187;">
<STYLE type="text/css">
<!--
	.ft0{font-size:24px;font-family:Helvetica;color:#000000;}
	.ft1{font-size:15px;font-family:Times;color:#000000;}
	.ft2{font-size:15px;font-family:Helvetica;color:#000000;}
	.ft3{font-size:8px;font-family:Times;color:#000000;}
	.ft4{font-size:11px;font-family:Times;color:#000000;}
	.ft5{font-size:5px;font-family:Times;color:#000000;}
	.ft6{font-size:7px;font-family:Helvetica;color:#ffffff;}
	.ft7{font-size:7px;font-family:Helvetica;color:#000000;}
	.ft8{font-size:7px;font-family:Helvetica;color:#000000;}
	.ft9{font-size:6px;font-family:Times;color:#000000;}
	.ft10{font-size:16px;font-family:Helvetica;color:#000000;}
	.ft11{font-size:11px;font-family:Helvetica;color:#000000;}
	.ft12{font-size:11px;line-height:15px;font-family:Times;color:#000000;}
	.ft13{font-size:8px;line-height:11px;font-family:Times;color:#000000;}
	.ft14{font-size:8px;line-height:12px;font-family:Times;color:#000000;}
	.ft15{font-size:7px;line-height:11px;font-family:Helvetica;color:#000000;}
	.ft16{font-size:7px;line-height:11px;font-family:Helvetica;color:#000000;}
-->
</STYLE>
<IMG width="917" height="1187" src="25001.png" alt="background image">
<DIV style="position:absolute;top:81;left:207"><nobr><span class="ft0"><b>Accelerated Focused Crawling through</b></span></nobr></DIV>
<DIV style="position:absolute;top:108;left:275"><nobr><span class="ft0"><b>Online Relevance Feedback</b></span></nobr></DIV>
<DIV style="position:absolute;top:104;left:630"><nobr><span class="ft1"><A href=""></a></span></nobr></DIV>
<DIV style="position:absolute;top:152;left:124"><nobr><span class="ft2">Soumen Chakrabarti</span></nobr></DIV>
<DIV style="position:absolute;top:151;left:289"><nobr><span class="ft3"><A href=""></a></span></nobr></DIV>
<DIV style="position:absolute;top:152;left:385"><nobr><span class="ft2">Kunal Punera</span></nobr></DIV>
<DIV style="position:absolute;top:152;left:598"><nobr><span class="ft2">Mallela Subramanyam</span></nobr></DIV>
<DIV style="position:absolute;top:170;left:164"><nobr><span class="ft2">IIT Bombay</span></nobr></DIV>
<DIV style="position:absolute;top:170;left:393"><nobr><span class="ft2">IIT Bombay</span></nobr></DIV>
<DIV style="position:absolute;top:170;left:582"><nobr><span class="ft2">University of Texas, Austin</span></nobr></DIV>
<DIV style="position:absolute;top:214;left:81"><nobr><span class="ft1">Abstract</span></nobr></DIV>
<DIV style="position:absolute;top:246;left:81"><nobr><span class="ft12">The organization of HTML into a tag tree structure, which<br>is rendered by browsers as roughly rectangular regions with<br>embedded text and HREF links, greatly helps surfers locate<br>and click on links that best satisfy their information need.<br>Can an automatic program emulate this human behavior<br>and thereby learn to predict the relevance of an unseen<br>HREF target page w.r.t. an information need, based on<br>information limited to the HREF source page?</span></nobr></DIV>
<DIV style="position:absolute;top:355;left:396"><nobr><span class="ft4">Such a</span></nobr></DIV>
<DIV style="position:absolute;top:371;left:81"><nobr><span class="ft12">capability would be of great interest in focused crawling and<br>resource discovery, because it can fine-tune the priority of<br>unvisited URLs in the crawl frontier, and reduce the number<br>of irrelevant pages which are fetched and discarded.</span></nobr></DIV>
<DIV style="position:absolute;top:434;left:103"><nobr><span class="ft4">We show that there is indeed a great deal of usable</span></nobr></DIV>
<DIV style="position:absolute;top:450;left:81"><nobr><span class="ft12">information on a HREF source page about the relevance<br>of the target page. This information, encoded suitably, can<br>be exploited by a supervised apprentice which takes online<br>lessons from a traditional focused crawler by observing<br>a carefully designed set of features and events associated<br>with the crawler.</span></nobr></DIV>
<DIV style="position:absolute;top:528;left:204"><nobr><span class="ft4">Once the apprentice gets a sufficient</span></nobr></DIV>
<DIV style="position:absolute;top:544;left:81"><nobr><span class="ft12">number of examples, the crawler starts consulting it to<br>better prioritize URLs in the crawl frontier. Experiments on<br>a dozen topics using a 482-topic taxonomy from the Open<br>Directory (Dmoz) show that online relevance feedback can<br>reduce false positives by 30% to 90%.</span></nobr></DIV>
<DIV style="position:absolute;top:634;left:81"><nobr><span class="ft12">Categories and subject descriptors:<br>H.5.4 [Information interfaces and presentation]:<br>Hypertext/hypermedia; I.5.4 [Pattern recognition]:<br>Applications, Text processing; I.2.6 [Artificial<br>intelligence]: Learning; I.2.8 [Artificial intelligence]:<br>Problem Solving, Control Methods, and Search.</span></nobr></DIV>
<DIV style="position:absolute;top:736;left:81"><nobr><span class="ft4">General terms:</span></nobr></DIV>
<DIV style="position:absolute;top:736;left:199"><nobr><span class="ft4">Algorithms, performance,</span></nobr></DIV>
<DIV style="position:absolute;top:751;left:81"><nobr><span class="ft4">measurements, experimentation.</span></nobr></DIV>
<DIV style="position:absolute;top:775;left:81"><nobr><span class="ft4">Keywords:</span></nobr></DIV>
<DIV style="position:absolute;top:775;left:168"><nobr><span class="ft4">Focused crawling, Document object model,</span></nobr></DIV>
<DIV style="position:absolute;top:790;left:81"><nobr><span class="ft4">Reinforcement learning.</span></nobr></DIV>
<DIV style="position:absolute;top:833;left:81"><nobr><span class="ft1">1</span></nobr></DIV>
<DIV style="position:absolute;top:833;left:111"><nobr><span class="ft1">Introduction</span></nobr></DIV>
<DIV style="position:absolute;top:865;left:81"><nobr><span class="ft12">Keyword search and clicking on links are the dominant<br>modes of accessing hypertext on the Web.</span></nobr></DIV>
<DIV style="position:absolute;top:881;left:367"><nobr><span class="ft4">Support for</span></nobr></DIV>
<DIV style="position:absolute;top:896;left:81"><nobr><span class="ft12">keyword search through crawlers and search engines is very<br>mature, but the surfing paradigm is not modeled or assisted</span></nobr></DIV>
<DIV style="position:absolute;top:935;left:96"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:938;left:102"><nobr><span class="ft3">(Note: The HTML version of this paper is best viewed using</span></nobr></DIV>
<DIV style="position:absolute;top:950;left:81"><nobr><span class="ft13">Microsoft Internet Explorer. To view the HTML version using<br>Netscape, add the following line to your ~/.Xdefaults or<br>~/.Xresources file:<br>Netscape*documentFonts.charset*adobe-fontspecific: iso-8859-1<br>For printing use the PDF version, as browsers may not print the<br>mathematics properly.)</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:96"><nobr><span class="ft5"></span></nobr></DIV>
<DIV style="position:absolute;top:1023;left:102"><nobr><span class="ft3">Contact author, email soumen@cse.iitb.ac.in</span></nobr></DIV>
<DIV style="position:absolute;top:1040;left:81"><nobr><span class="ft13">Copyright is held by the author/owner(s).<br>WWW2002, May 7­11, 2002, Honolulu, Hawaii, USA.<br>ACM 1-58113-449-5/02/0005</span></nobr></DIV>
<DIV style="position:absolute;top:329;left:525"><nobr><span class="ft6"><b>Baseline learner</b></span></nobr></DIV>
<DIV style="position:absolute;top:290;left:513"><nobr><span class="ft7">Dmoz</span></nobr></DIV>
<DIV style="position:absolute;top:301;left:515"><nobr><span class="ft7">topic</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:505"><nobr><span class="ft7">taxonomy</span></nobr></DIV>
<DIV style="position:absolute;top:285;left:576"><nobr><span class="ft7">Class models</span></nobr></DIV>
<DIV style="position:absolute;top:296;left:578"><nobr><span class="ft7">consisting of</span></nobr></DIV>
<DIV style="position:absolute;top:307;left:583"><nobr><span class="ft7">term stats</span></nobr></DIV>
<DIV style="position:absolute;top:242;left:664"><nobr><span class="ft7">Frontier URLS</span></nobr></DIV>
<DIV style="position:absolute;top:254;left:666"><nobr><span class="ft7">priority queue</span></nobr></DIV>
<DIV style="position:absolute;top:307;left:682"><nobr><span class="ft6"><b>Crawler</b></span></nobr></DIV>
<DIV style="position:absolute;top:274;left:706"><nobr><span class="ft15">Pick<br>best</span></nobr></DIV>
<DIV style="position:absolute;top:344;left:670"><nobr><span class="ft7">Newly fetched</span></nobr></DIV>
<DIV style="position:absolute;top:356;left:685"><nobr><span class="ft7">page <i>u</i></span></nobr></DIV>
<DIV style="position:absolute;top:358;left:507"><nobr><span class="ft7">Submit page for classification</span></nobr></DIV>
<DIV style="position:absolute;top:218;left:494"><nobr><span class="ft16">If Pr(<i>c</i>*|<i>u</i>) is large enough<br>then enqueue all outlinks <i>v </i>of <i>u<br></i>with priority Pr(<i>c</i>*|<i>u</i>)</span></nobr></DIV>
<DIV style="position:absolute;top:341;left:788"><nobr><span class="ft7">Crawl</span></nobr></DIV>
<DIV style="position:absolute;top:352;left:781"><nobr><span class="ft7">database</span></nobr></DIV>
<DIV style="position:absolute;top:239;left:776"><nobr><span class="ft15">Seed<br>URLs</span></nobr></DIV>
<DIV style="position:absolute;top:388;left:475"><nobr><span class="ft12">Figure 1: A basic focused crawler controlled by one topic<br>classifier/learner.</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:475"><nobr><span class="ft12">as well. Support for surfing is limited to the basic interface<br>provided by Web browsers, except for a few notable research<br>prototypes.</span></nobr></DIV>
<DIV style="position:absolute;top:494;left:498"><nobr><span class="ft4">While surfing, the user typically has a topic-specific</span></nobr></DIV>
<DIV style="position:absolute;top:509;left:475"><nobr><span class="ft12">information need, and explores out from a few known<br>relevant starting points in the Web graph (which may be<br>query responses) to seek new pages relevant to the chosen<br>topic/s. While deciding for or against clicking on a specific<br>link (u, v), humans use a variety of clues on the source<br>page u to estimate the worth of the (unseen) target page<br>v, including the tag tree structure of u, text embedded in<br>various regions of that tag tree, and whether the link is<br>relative or remote. "Every click on a link is a leap of faith"<br><A href="25.html#12">[19], </a>but humans are very good at discriminating between<br>links based on these clues.</span></nobr></DIV>
<DIV style="position:absolute;top:682;left:498"><nobr><span class="ft4">Making an educated guess about the worth of clicking</span></nobr></DIV>
<DIV style="position:absolute;top:698;left:475"><nobr><span class="ft12">on a link (u, v) without knowledge of the target v is<br>central to the surfing activity. Automatic programs which<br>can learn this capability would be valuable for a number<br>of applications which can be broadly characterized as<br>personalized, topic-specific information foragers.</span></nobr></DIV>
<DIV style="position:absolute;top:776;left:498"><nobr><span class="ft4">Large-scale, topic-specific information gatherers are</span></nobr></DIV>
<DIV style="position:absolute;top:792;left:475"><nobr><span class="ft12">called focused crawlers <A href="25.html#12">[1, 9, 14, 28, 30]. </a>In contrast to giant,<br>all-purpose crawlers which must process large portions of<br>the Web in a centralized manner, a distributed federation of<br>focused crawlers can cover specialized topics in more depth<br>and keep the crawl more fresh, because there is less to cover<br>for each crawler.</span></nobr></DIV>
<DIV style="position:absolute;top:886;left:498"><nobr><span class="ft4">In its simplest form, a focused crawler consists of a</span></nobr></DIV>
<DIV style="position:absolute;top:901;left:475"><nobr><span class="ft12">supervised topic classifier (also called a `learner') controlling<br>the priority of the unvisited frontier of a crawler (see<br>Figure <A href="25.html#1">1). </a>The classifier is trained a priori on document<br>samples embedded in a topic taxonomy such as Yahoo!<br>or Dmoz.</span></nobr></DIV>
<DIV style="position:absolute;top:964;left:549"><nobr><span class="ft4">It thereby learns to label new documents as</span></nobr></DIV>
<DIV style="position:absolute;top:980;left:475"><nobr><span class="ft12">belonging to topics in the given taxonomy <A href="25.html#12">[2, 5, 21]. </a>The<br>goal of the focused crawler is to start from nodes relevant<br>to a focus topic c</span></nobr></DIV>
<DIV style="position:absolute;top:1008;left:583"><nobr><span class="ft9"></span></nobr></DIV>
<DIV style="position:absolute;top:1011;left:596"><nobr><span class="ft4">in the Web graph and explore links to</span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:475"><nobr><span class="ft4">selectively collect pages about c</span></nobr></DIV>
<DIV style="position:absolute;top:1024;left:674"><nobr><span class="ft9"></span></nobr></DIV>
<DIV style="position:absolute;top:1027;left:681"><nobr><span class="ft4">, while avoiding fetching</span></nobr></DIV>
<DIV style="position:absolute;top:1043;left:475"><nobr><span class="ft4">pages not about c</span></nobr></DIV>
<DIV style="position:absolute;top:1040;left:583"><nobr><span class="ft9"></span></nobr></DIV>
<DIV style="position:absolute;top:1043;left:590"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:1058;left:498"><nobr><span class="ft4">Suppose the crawler has collected a page u and</span></nobr></DIV>
<DIV style="position:absolute;top:1121;left:447"><nobr><span class="ft11">148</span></nobr></DIV>
</DIV>
<!-- Page 2 -->
<a name="2"></a>
<DIV style="position:relative;width:917;height:1187;">
<STYLE type="text/css">
<!--
	.ft17{font-size:12px;font-family:Times;color:#000000;}
	.ft18{font-size:5px;font-family:Helvetica;color:#ffffff;}
	.ft19{font-size:5px;font-family:Helvetica;color:#000000;}
	.ft20{font-size:5px;font-family:Helvetica;color:#000000;}
	.ft21{font-size:5px;font-family:Helvetica;color:#000000;}
	.ft22{font-size:13px;font-family:Helvetica;color:#000000;}
	.ft23{font-size:5px;line-height:9px;font-family:Helvetica;color:#000000;}
-->
</STYLE>
<IMG width="917" height="1187" src="25002.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft12">encountered in u an unvisited link to v. A simple crawler<br>(which we call the baseline) will use the relevance of u<br>to topic c</span></nobr></DIV>
<DIV style="position:absolute;top:115;left:142"><nobr><span class="ft9"></span></nobr></DIV>
<DIV style="position:absolute;top:118;left:155"><nobr><span class="ft4">(which, in a Bayesian setting, we can denote</span></nobr></DIV>
<DIV style="position:absolute;top:133;left:81"><nobr><span class="ft4">Pr(c</span></nobr></DIV>
<DIV style="position:absolute;top:130;left:107"><nobr><span class="ft9"></span></nobr></DIV>
<DIV style="position:absolute;top:133;left:113"><nobr><span class="ft4">|u)) as the estimated relevance of the unvisited page</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:81"><nobr><span class="ft4">v.</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:105"><nobr><span class="ft4">This reflects our belief that pages across a hyperlink</span></nobr></DIV>
<DIV style="position:absolute;top:165;left:81"><nobr><span class="ft12">are more similar than two randomly chosen pages on the<br>Web, or, in other words, topics appear clustered in the<br>Web graph <A href="25.html#12">[11, 23]. </a>Node v will be added to the crawler's<br>priority queue with priority Pr(c</span></nobr></DIV>
<DIV style="position:absolute;top:209;left:282"><nobr><span class="ft9"></span></nobr></DIV>
<DIV style="position:absolute;top:211;left:288"><nobr><span class="ft4">|u). This is essentially a</span></nobr></DIV>
<DIV style="position:absolute;top:228;left:81"><nobr><span class="ft12">"best-first" crawling strategy. When v comes to the head<br>of the queue and is actually fetched, we can verify if the<br>gamble paid off, by evaluating Pr(c</span></nobr></DIV>
<DIV style="position:absolute;top:256;left:305"><nobr><span class="ft9"></span></nobr></DIV>
<DIV style="position:absolute;top:258;left:312"><nobr><span class="ft4">|v). The fraction of</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:81"><nobr><span class="ft4">relevant pages collected is called the harvest rate.</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:412"><nobr><span class="ft4">If V</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:81"><nobr><span class="ft12">is the set of nodes collected, the harvest rate is defined<br>as (1/</span></nobr></DIV>
<DIV style="position:absolute;top:305;left:119"><nobr><span class="ft4">|V |)</span></nobr></DIV>
<DIV style="position:absolute;top:314;left:161"><nobr><span class="ft9">v</span></nobr></DIV>
<DIV style="position:absolute;top:313;left:167"><nobr><span class="ft9">V</span></nobr></DIV>
<DIV style="position:absolute;top:306;left:186"><nobr><span class="ft4">Pr(c</span></nobr></DIV>
<DIV style="position:absolute;top:303;left:213"><nobr><span class="ft9"></span></nobr></DIV>
<DIV style="position:absolute;top:305;left:219"><nobr><span class="ft4">|v). Alternatively, we can measure</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:81"><nobr><span class="ft12">the loss rate, which is one minus the harvest rate, i.e., the<br>(expected) fraction of fetched pages that must be thrown<br>away.</span></nobr></DIV>
<DIV style="position:absolute;top:353;left:130"><nobr><span class="ft4">Since the effort on relevant pages is well-spent,</span></nobr></DIV>
<DIV style="position:absolute;top:369;left:81"><nobr><span class="ft12">reduction in loss rate is the primary goal and the most<br>appropriate figure of merit.</span></nobr></DIV>
<DIV style="position:absolute;top:400;left:103"><nobr><span class="ft4">For focused crawling applications to succeed, the "leap</span></nobr></DIV>
<DIV style="position:absolute;top:416;left:81"><nobr><span class="ft12">of faith" from u to v must pay off frequently. In other words,<br>if Pr(c</span></nobr></DIV>
<DIV style="position:absolute;top:428;left:120"><nobr><span class="ft9"></span></nobr></DIV>
<DIV style="position:absolute;top:431;left:126"><nobr><span class="ft4">|v) is often much less than the preliminary estimate</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:81"><nobr><span class="ft4">Pr(c</span></nobr></DIV>
<DIV style="position:absolute;top:444;left:107"><nobr><span class="ft9"></span></nobr></DIV>
<DIV style="position:absolute;top:446;left:113"><nobr><span class="ft4">|u), a great deal of network traffic and CPU cycles</span></nobr></DIV>
<DIV style="position:absolute;top:463;left:81"><nobr><span class="ft12">are being wasted eliminating bad pages. Experience with<br>random walks on the Web show that as one walks away<br>from a fixed page u</span></nobr></DIV>
<DIV style="position:absolute;top:499;left:202"><nobr><span class="ft9">0</span></nobr></DIV>
<DIV style="position:absolute;top:494;left:214"><nobr><span class="ft4">relevant to topic c</span></nobr></DIV>
<DIV style="position:absolute;top:499;left:327"><nobr><span class="ft9">0</span></nobr></DIV>
<DIV style="position:absolute;top:494;left:333"><nobr><span class="ft4">, the relevance of</span></nobr></DIV>
<DIV style="position:absolute;top:510;left:81"><nobr><span class="ft4">successive nodes u</span></nobr></DIV>
<DIV style="position:absolute;top:515;left:193"><nobr><span class="ft9">1</span></nobr></DIV>
<DIV style="position:absolute;top:510;left:199"><nobr><span class="ft4">, u</span></nobr></DIV>
<DIV style="position:absolute;top:515;left:213"><nobr><span class="ft9">2</span></nobr></DIV>
<DIV style="position:absolute;top:510;left:219"><nobr><span class="ft4">, . . . to c</span></nobr></DIV>
<DIV style="position:absolute;top:515;left:270"><nobr><span class="ft9">0</span></nobr></DIV>
<DIV style="position:absolute;top:510;left:282"><nobr><span class="ft4">drops dramatically within</span></nobr></DIV>
<DIV style="position:absolute;top:526;left:81"><nobr><span class="ft12">a few hops <A href="25.html#12">[9, 23]. </a>This means that only a fraction of out-<br>links from a page is typically worth following. The average<br>out-degree of the Web graph is about 7 <A href="25.html#12">[29]. </a>Therefore, a<br>large number of page fetches may result in disappointment,<br>especially if we wish to push the utility of focused crawling<br>to topic communities which are not very densely linked.</span></nobr></DIV>
<DIV style="position:absolute;top:620;left:103"><nobr><span class="ft4">Even w.r.t. topics that are not very narrow, the</span></nobr></DIV>
<DIV style="position:absolute;top:635;left:81"><nobr><span class="ft12">number of distracting outlinks emerging from even fairly<br>relevant pages has grown substantially since the early<br>days of Web authoring <A href="25.html#12">[4].</a></span></nobr></DIV>
<DIV style="position:absolute;top:667;left:274"><nobr><span class="ft4">Template-based authoring,</span></nobr></DIV>
<DIV style="position:absolute;top:683;left:81"><nobr><span class="ft12">dynamic page generation from semi-structured databases,<br>ad links, navigation panels, and Web rings contribute many<br>irrelevant links which reduce the harvest rate of focused<br>crawlers. Topic-based link discrimination will also reduce<br>these problems.</span></nobr></DIV>
<DIV style="position:absolute;top:781;left:81"><nobr><span class="ft17">1.1</span></nobr></DIV>
<DIV style="position:absolute;top:781;left:120"><nobr><span class="ft17">Our contribution: Leaping with more faith</span></nobr></DIV>
<DIV style="position:absolute;top:806;left:81"><nobr><span class="ft4">In this paper we address the following questions:</span></nobr></DIV>
<DIV style="position:absolute;top:832;left:90"><nobr><span class="ft12">How much information about the topic of the HREF<br>target is available and/or latent in the HREF source page,<br>its tag-tree structure, and its text? Can these sources be<br>exploited for accelerating a focused crawler?</span></nobr></DIV>
<DIV style="position:absolute;top:906;left:81"><nobr><span class="ft12">Our basic idea is to use two classifiers. Earlier, the regular<br>baseline classifier was used to assign priorities to unvisited<br>frontier nodes. This no longer remains its function. The role<br>of assigning priorities to unvisited URLs in the crawl frontier<br>is now assigned to a new learner called the apprentice, and<br>the priority of v is specific to the features associated with<br>the (u, v) link which leads to it</span></nobr></DIV>
<DIV style="position:absolute;top:997;left:271"><nobr><span class="ft9"><A href="25.html#2">1</a></span></nobr></DIV>
<DIV style="position:absolute;top:1000;left:277"><nobr><span class="ft4"><A href="25.html#2">. </a>The features used by the</span></nobr></DIV>
<DIV style="position:absolute;top:1015;left:81"><nobr><span class="ft4">apprentice are derived from the Document Object Model or</span></nobr></DIV>
<DIV style="position:absolute;top:1038;left:96"><nobr><span class="ft5">1</span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:102"><nobr><span class="ft3">If many u's link to a single v, it is easiest to freeze the priority of</span></nobr></DIV>
<DIV style="position:absolute;top:1053;left:81"><nobr><span class="ft13">v when the first-visited u linking to v is assessed, but combinations<br>of scores are also possible.</span></nobr></DIV>
<DIV style="position:absolute;top:258;left:505"><nobr><span class="ft18"><b>Baseline learner (Critic)</b></span></nobr></DIV>
<DIV style="position:absolute;top:225;left:508"><nobr><span class="ft19">Dmoz</span></nobr></DIV>
<DIV style="position:absolute;top:235;left:510"><nobr><span class="ft19">topic</span></nobr></DIV>
<DIV style="position:absolute;top:244;left:501"><nobr><span class="ft19">taxonomy</span></nobr></DIV>
<DIV style="position:absolute;top:221;left:561"><nobr><span class="ft19">Class models</span></nobr></DIV>
<DIV style="position:absolute;top:230;left:563"><nobr><span class="ft19">consisting of</span></nobr></DIV>
<DIV style="position:absolute;top:240;left:568"><nobr><span class="ft19">term stats</span></nobr></DIV>
<DIV style="position:absolute;top:185;left:636"><nobr><span class="ft19">Frontier URLS</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:638"><nobr><span class="ft19">priority queue</span></nobr></DIV>
<DIV style="position:absolute;top:240;left:651"><nobr><span class="ft18"><b>Crawler</b></span></nobr></DIV>
<DIV style="position:absolute;top:212;left:671"><nobr><span class="ft23">Pick<br>best</span></nobr></DIV>
<DIV style="position:absolute;top:271;left:641"><nobr><span class="ft19">Newly fetched</span></nobr></DIV>
<DIV style="position:absolute;top:281;left:654"><nobr><span class="ft19">page <i>u</i></span></nobr></DIV>
<DIV style="position:absolute;top:283;left:503"><nobr><span class="ft19">Submit page for classification</span></nobr></DIV>
<DIV style="position:absolute;top:182;left:489"><nobr><span class="ft23">If Pr(<i>c</i>*|<i>u</i>) is<br>large enough...</span></nobr></DIV>
<DIV style="position:absolute;top:183;left:745"><nobr><span class="ft19">An instance (<i>u</i>,<i>v</i>)</span></nobr></DIV>
<DIV style="position:absolute;top:193;left:744"><nobr><span class="ft19">for the apprentice</span></nobr></DIV>
<DIV style="position:absolute;top:116;left:757"><nobr><span class="ft20"><i>u</i></span></nobr></DIV>
<DIV style="position:absolute;top:157;left:797"><nobr><span class="ft20"><i>v</i></span></nobr></DIV>
<DIV style="position:absolute;top:163;left:755"><nobr><span class="ft19">Pr(<i>c</i>*|<i>v</i>)</span></nobr></DIV>
<DIV style="position:absolute;top:97;left:774"><nobr><span class="ft23">Pr(<i>c</i>|<i>u</i>) for<br>all classes <i>c</i></span></nobr></DIV>
<DIV style="position:absolute;top:245;left:765"><nobr><span class="ft19">Crawl</span></nobr></DIV>
<DIV style="position:absolute;top:254;left:759"><nobr><span class="ft19">database</span></nobr></DIV>
<DIV style="position:absolute;top:139;left:571"><nobr><span class="ft21"><b>Apprentice learner</b></span></nobr></DIV>
<DIV style="position:absolute;top:107;left:627"><nobr><span class="ft19">Class</span></nobr></DIV>
<DIV style="position:absolute;top:116;left:625"><nobr><span class="ft19">models</span></nobr></DIV>
<DIV style="position:absolute;top:117;left:554"><nobr><span class="ft22">+</span></nobr></DIV>
<DIV style="position:absolute;top:117;left:583"><nobr><span class="ft22">-</span></nobr></DIV>
<DIV style="position:absolute;top:97;left:678"><nobr><span class="ft23">Online<br>training</span></nobr></DIV>
<DIV style="position:absolute;top:97;left:479"><nobr><span class="ft23">... submit (<i>u</i>,<i>v</i>)<br>to the apprentice</span></nobr></DIV>
<DIV style="position:absolute;top:155;left:555"><nobr><span class="ft23">Apprentice<br>assigns more<br>accurate priority<br>to node <i>v</i></span></nobr></DIV>
<DIV style="position:absolute;top:308;left:475"><nobr><span class="ft4">Figure 2:</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:546"><nobr><span class="ft4">The apprentice is continually presented with</span></nobr></DIV>
<DIV style="position:absolute;top:324;left:475"><nobr><span class="ft12">training cases (u, v) with suitable features. The apprentice<br>is interposed where new outlinks (u, v) are registered with<br>the priority queue, and helps assign the unvisited node v a<br>better estimate of its relevance.</span></nobr></DIV>
<DIV style="position:absolute;top:410;left:475"><nobr><span class="ft12">DOM (<A href="http://www.w3.org/DOM/">http://www.w3.org/DOM/) </a>of u. Meanwhile, the role<br>of the baseline classifier becomes one of generating training<br>instances for the apprentice, as shown in Figure <A href="25.html#2">2. </a>We may<br>therefore regard the baseline learner as a critic or a trainer,<br>which provides feedback to the apprentice so that it can<br>improve "on the job."</span></nobr></DIV>
<DIV style="position:absolute;top:504;left:498"><nobr><span class="ft4">The critic-apprentice paradigm is related to reinforce-</span></nobr></DIV>
<DIV style="position:absolute;top:520;left:475"><nobr><span class="ft12">ment learning and AI programs that learn to play games<br><A href="25.html#12">[26,</a></span></nobr></DIV>
<DIV style="position:absolute;top:535;left:503"><nobr><span class="ft4">§1.2]. We argue that this division of labor is natural</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:475"><nobr><span class="ft4">and effective.</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:574"><nobr><span class="ft4">The baseline learner can be regarded as</span></nobr></DIV>
<DIV style="position:absolute;top:567;left:475"><nobr><span class="ft12">a user specification for what kind of content is desired.<br>Although we limit ourselves to a generative statistical model<br>for this specification, this can be an arbitrary black-box<br>predicate.</span></nobr></DIV>
<DIV style="position:absolute;top:614;left:550"><nobr><span class="ft4">For rich and meaningful distinction between</span></nobr></DIV>
<DIV style="position:absolute;top:630;left:475"><nobr><span class="ft12">Web communities and topics, the baseline learner needs<br>to be fairly sophisticated, perhaps leveraging off human<br>annotations on the Web (such as topic directories).</span></nobr></DIV>
<DIV style="position:absolute;top:661;left:821"><nobr><span class="ft4">In</span></nobr></DIV>
<DIV style="position:absolute;top:677;left:475"><nobr><span class="ft12">contrast, the apprentice specializes in how to locate pages<br>to satisfy the baseline learner.</span></nobr></DIV>
<DIV style="position:absolute;top:692;left:678"><nobr><span class="ft4">Its feature space is more</span></nobr></DIV>
<DIV style="position:absolute;top:708;left:475"><nobr><span class="ft12">limited, so that it can train fast and adapt nimbly to<br>changing fortunes at following links during a crawl.</span></nobr></DIV>
<DIV style="position:absolute;top:724;left:821"><nobr><span class="ft4">In</span></nobr></DIV>
<DIV style="position:absolute;top:739;left:475"><nobr><span class="ft12">Mitchell's words <A href="25.html#12">[27], </a>the baseline learner recognizes "global<br>regularity" while the apprentice helps the crawler adapt<br>to "local regularity."</span></nobr></DIV>
<DIV style="position:absolute;top:771;left:623"><nobr><span class="ft4">This marked asymmetry between</span></nobr></DIV>
<DIV style="position:absolute;top:786;left:475"><nobr><span class="ft12">the classifiers distinguishes our approach from Blum and<br>Mitchell's co-training technique <A href="25.html#12">[3], </a>in which two learners<br>train each other by selecting unlabeled instances.</span></nobr></DIV>
<DIV style="position:absolute;top:834;left:498"><nobr><span class="ft4">Using a dozen topics from a topic taxonomy derived</span></nobr></DIV>
<DIV style="position:absolute;top:849;left:475"><nobr><span class="ft12">from the Open Directory, we compare our enhanced crawler<br>with the baseline crawler. The number of pages that are<br>thrown away (because they are irrelevant), called the loss<br>rate, is cut down by 30­90%. We also demonstrate that<br>the fine-grained tag-tree model, together with our synthesis<br>and encoding of features for the apprentice, are superior to<br>simpler alternatives.</span></nobr></DIV>
<DIV style="position:absolute;top:978;left:475"><nobr><span class="ft17">1.2</span></nobr></DIV>
<DIV style="position:absolute;top:978;left:514"><nobr><span class="ft17">Related work</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:475"><nobr><span class="ft12">Optimizing the priority of unvisited URLs on the crawl<br>frontier for specific crawling goals is not new. FishSearch<br>by De Bra et al. <A href="25.html#12">[12, 13] </a>and SharkSearch by Hersovici<br>et al. <A href="25.html#12">[16] </a>were some of the earliest systems for localized<br>searches in the Web graph for pages with specified keywords.</span></nobr></DIV>
<DIV style="position:absolute;top:1121;left:447"><nobr><span class="ft11">149</span></nobr></DIV>
</DIV>
<!-- Page 3 -->
<a name="3"></a>
<DIV style="position:relative;width:917;height:1187;">
<STYLE type="text/css">
<!--
	.ft24{font-size:11px;line-height:20px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="917" height="1187" src="25003.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft12">In another early paper, Cho et al. <A href="25.html#12">[10] </a>experimented with a<br>variety of strategies for prioritizing how to fetch unvisited<br>URLs.</span></nobr></DIV>
<DIV style="position:absolute;top:118;left:132"><nobr><span class="ft4">They used the anchor text as a bag of words to</span></nobr></DIV>
<DIV style="position:absolute;top:133;left:81"><nobr><span class="ft12">guide link expansion to crawl for pages matching a specified<br>keyword query, which led to some extent of differentiation<br>among out-links, but no trainer-apprentice combination was<br>involved. No notion of supervised topics had emerged at<br>that point, and simple properties like the in-degree or the<br>presence of specified keywords in pages were used to guide<br>the crawler.</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:103"><nobr><span class="ft4">Topical locality on the Web has been studied for a few</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:81"><nobr><span class="ft4">years.</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:131"><nobr><span class="ft4">Davison made early measurements on a 100000-</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:81"><nobr><span class="ft12">node Web subgraph <A href="25.html#12">[11] </a>collected by the DiscoWeb system.<br>Using the standard notion of vector space TFIDF similarity<br><A href="25.html#12">[31], </a>he found that the endpoints of a hyperlink are much<br>more similar to each other than two random pages, and that<br>HREFs close together on a page link to documents which are<br>more similar than targets which are far apart. Menczer has<br>made similar observations <A href="25.html#12">[23]. </a>The HyperClass hypertext<br>classifier also uses such locality patterns for better semi-<br>supervised learning of topics <A href="25.html#12">[7], </a>as does IBM's Automatic<br>Resource Compilation (ARC) and Clever topic distillation<br>systems <A href="25.html#12">[6, 8].</a></span></nobr></DIV>
<DIV style="position:absolute;top:447;left:103"><nobr><span class="ft4">Two important advances have been made beyond the</span></nobr></DIV>
<DIV style="position:absolute;top:463;left:81"><nobr><span class="ft12">baseline best-first focused crawler: the use of context graphs<br>by Diligenti et al. <A href="25.html#12">[14] </a>and the use of reinforcement learning<br>by Rennie and McCallum <A href="25.html#12">[30].</a></span></nobr></DIV>
<DIV style="position:absolute;top:494;left:289"><nobr><span class="ft4">Both techniques trained</span></nobr></DIV>
<DIV style="position:absolute;top:510;left:81"><nobr><span class="ft12">a learner with features collected from paths leading up to<br>relevant nodes rather than relevant nodes alone. Such paths<br>may be collected by following backlinks.</span></nobr></DIV>
<DIV style="position:absolute;top:557;left:103"><nobr><span class="ft4">Diligenti et al. used a classifier (learner) that regressed</span></nobr></DIV>
<DIV style="position:absolute;top:573;left:81"><nobr><span class="ft12">from the text of u to the estimated link distance from u to<br>some relevant page w, rather than the relevance of u or an<br>outlink (u, v), as was the case with the baseline crawler.<br>This lets their system continue expanding u even if the<br>reward for following a link is not immediate, but several<br>links away.</span></nobr></DIV>
<DIV style="position:absolute;top:651;left:163"><nobr><span class="ft4">However, they do favor links whose payoffs</span></nobr></DIV>
<DIV style="position:absolute;top:667;left:81"><nobr><span class="ft12">are closest. Our work is specifically useful in conjunction<br>with the use of context graphs: when the context graph<br>learner predicts that a goal is several links away, it is crucial<br>to offer additional guidance to the crawler based on local<br>structure in pages, because the fan-out at that radius could<br>be enormous.</span></nobr></DIV>
<DIV style="position:absolute;top:761;left:103"><nobr><span class="ft4">Rennie and McCallum <A href="25.html#12">[30] </a>also collected paths leading</span></nobr></DIV>
<DIV style="position:absolute;top:777;left:81"><nobr><span class="ft12">to relevant nodes, but they trained a slightly different<br>classifier, for which:</span></nobr></DIV>
<DIV style="position:absolute;top:814;left:104"><nobr><span class="ft24">· An instance was a single HREF link like (u, v).<br>· The features were terms from the title and headers</span></nobr></DIV>
<DIV style="position:absolute;top:851;left:118"><nobr><span class="ft4">(&lt;h1&gt;...&lt;/h1&gt; etc.)</span></nobr></DIV>
<DIV style="position:absolute;top:851;left:258"><nobr><span class="ft4">of u, together with the text</span></nobr></DIV>
<DIV style="position:absolute;top:867;left:118"><nobr><span class="ft4">in and `near' the anchor (u, v).</span></nobr></DIV>
<DIV style="position:absolute;top:867;left:343"><nobr><span class="ft4">Directories and</span></nobr></DIV>
<DIV style="position:absolute;top:882;left:118"><nobr><span class="ft4">pathnames were also used.</span></nobr></DIV>
<DIV style="position:absolute;top:882;left:300"><nobr><span class="ft4">(We do not know the</span></nobr></DIV>
<DIV style="position:absolute;top:898;left:118"><nobr><span class="ft12">precise definition of `near', or how these features were<br>encoded and combined.)</span></nobr></DIV>
<DIV style="position:absolute;top:933;left:104"><nobr><span class="ft4">· The prediction was a discretized estimate of the</span></nobr></DIV>
<DIV style="position:absolute;top:950;left:118"><nobr><span class="ft12">number of relevant nodes reachable by following (u, v),<br>where the reward from goals distant from v was<br>geometrically discounted by some factor  &lt; 1/2 per<br>hop.</span></nobr></DIV>
<DIV style="position:absolute;top:1020;left:81"><nobr><span class="ft12">Rennie and McCallum obtained impressive harvests of<br>research papers from four Computer Science department<br>sites, and of pages about officers and directors from 26<br>company Websites.</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:498"><nobr><span class="ft4">Lexical proximity and contextual features have been</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:475"><nobr><span class="ft12">used extensively in natural language processing for disam-<br>biguating word sense <A href="25.html#12">[15]. </a>Compared to plain text, DOM<br>trees and hyperlinks give us a richer set of potential features.</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:498"><nobr><span class="ft4">Aggarwal et al. have proposed an "intelligent crawling"</span></nobr></DIV>
<DIV style="position:absolute;top:165;left:475"><nobr><span class="ft12">framework <A href="25.html#12">[1] </a>in which only one classifier is used, but similar<br>to our system, that classifier trains as the crawl progresses.<br>They do not use our apprentice-critic approach, and do not<br>exploit features derived from tag-trees to guide the crawler.</span></nobr></DIV>
<DIV style="position:absolute;top:228;left:498"><nobr><span class="ft4">The "intelligent agents" literature has brought forth</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:475"><nobr><span class="ft12">several systems for resource discovery and assistance to<br>browsing <A href="25.html#12">[19].</a></span></nobr></DIV>
<DIV style="position:absolute;top:259;left:574"><nobr><span class="ft4">They range between client- and site-level</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:475"><nobr><span class="ft12">tools. Letizia <A href="25.html#12">[18], </a>Powerscout, and WebWatcher <A href="25.html#12">[17] </a>are<br>such systems.</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:574"><nobr><span class="ft4">Menczer and Belew proposed InfoSpiders</span></nobr></DIV>
<DIV style="position:absolute;top:306;left:475"><nobr><span class="ft12"><A href="25.html#12">[24], </a>a collection of autonomous goal-driven crawlers without<br>global control or state, in the style of genetic algorithms. A<br>recent extensive study <A href="25.html#12">[25] </a>comparing several topic-driven<br>crawlers including the best-first crawler and InfoSpiders<br>found the best-first approach to show the highest harvest<br>rate (which our new system outperforms).</span></nobr></DIV>
<DIV style="position:absolute;top:400;left:498"><nobr><span class="ft4">In all the systems mentioned above, improving the</span></nobr></DIV>
<DIV style="position:absolute;top:416;left:475"><nobr><span class="ft12">chances of a successful "leap of faith" will clearly reduce<br>the overheads of fetching, filtering, and analyzing pages.<br>Furthermore, whereas we use an automatic first-generation<br>focused crawler to generate the input to train the apprentice,<br>one can envisage specially instrumented browsers being used<br>to monitor users as they seek out information.</span></nobr></DIV>
<DIV style="position:absolute;top:510;left:498"><nobr><span class="ft4">We distinguish our work from prior art in the following</span></nobr></DIV>
<DIV style="position:absolute;top:526;left:475"><nobr><span class="ft4">important ways:</span></nobr></DIV>
<DIV style="position:absolute;top:549;left:475"><nobr><span class="ft4">Two classifiers:</span></nobr></DIV>
<DIV style="position:absolute;top:549;left:595"><nobr><span class="ft4">We use two classifiers. The first one is</span></nobr></DIV>
<DIV style="position:absolute;top:565;left:475"><nobr><span class="ft12">used to obtain `enriched' training data for the second one.<br>(A breadth-first or random crawl would have a negligible<br>fraction of positive instances.) The apprentice is a simplified<br>reinforcement learner. It improves the harvest rate, thereby<br>`enriching' the data collected and labeled by the first learner<br>in turn.</span></nobr></DIV>
<DIV style="position:absolute;top:666;left:475"><nobr><span class="ft4">No manual path collection:</span></nobr></DIV>
<DIV style="position:absolute;top:666;left:682"><nobr><span class="ft4">Our two-classifier frame-</span></nobr></DIV>
<DIV style="position:absolute;top:682;left:475"><nobr><span class="ft12">work essentially eliminates the manual effort needed to<br>create reinforcement paths or context graphs. The input<br>needed to start off a focused crawl is just a pre-trained topic<br>taxonomy (easily available from the Web) and a few focus<br>topics.</span></nobr></DIV>
<DIV style="position:absolute;top:768;left:475"><nobr><span class="ft4">Online training:</span></nobr></DIV>
<DIV style="position:absolute;top:768;left:601"><nobr><span class="ft4">Our apprentice trains continually, ac-</span></nobr></DIV>
<DIV style="position:absolute;top:783;left:475"><nobr><span class="ft12">quiring ever-larger vocabularies and improving its accuracy<br>as the crawl progresses. This property holds also for the<br>"intelligent crawler" proposed by Aggarwal et al., but they<br>have a single learner, whose drift is controlled by precise<br>relevance predicates provided by the user.</span></nobr></DIV>
<DIV style="position:absolute;top:869;left:475"><nobr><span class="ft4">No manual feature tuning:</span></nobr></DIV>
<DIV style="position:absolute;top:869;left:679"><nobr><span class="ft4">Rather than tune ad-hoc</span></nobr></DIV>
<DIV style="position:absolute;top:885;left:475"><nobr><span class="ft12">notions of proximity between text and hyperlinks, we encode<br>the features of link (u, v) using the DOM-tree of u, and<br>automatically learn a robust definition of `nearness' of a<br>textual feature to (u, v).</span></nobr></DIV>
<DIV style="position:absolute;top:932;left:653"><nobr><span class="ft4">In contrast, Aggarwal et al</span></nobr></DIV>
<DIV style="position:absolute;top:948;left:475"><nobr><span class="ft12">use many tuned constants combining the strength of text-<br>and link-based predictors, and Rennie et al. use domain<br>knowledge to select the paths to goal nodes and the word<br>bags that are submitted to their learner.</span></nobr></DIV>
<DIV style="position:absolute;top:1121;left:447"><nobr><span class="ft11">150</span></nobr></DIV>
</DIV>
<!-- Page 4 -->
<a name="4"></a>
<DIV style="position:relative;width:917;height:1187;">
<STYLE type="text/css">
<!--
	.ft25{font-size:6px;font-family:Helvetica;color:#000000;}
	.ft26{font-size:12px;line-height:17px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="917" height="1187" src="25004.png" alt="background image">
<DIV style="position:absolute;top:83;left:81"><nobr><span class="ft1">2</span></nobr></DIV>
<DIV style="position:absolute;top:83;left:111"><nobr><span class="ft1">Methodology and algorithms</span></nobr></DIV>
<DIV style="position:absolute;top:115;left:81"><nobr><span class="ft12">We first review the baseline focused crawler and then<br>describe how the enhanced crawler is set up using the<br>apprentice-critic mechanism.</span></nobr></DIV>
<DIV style="position:absolute;top:182;left:81"><nobr><span class="ft17">2.1</span></nobr></DIV>
<DIV style="position:absolute;top:182;left:120"><nobr><span class="ft17">The baseline focused crawler</span></nobr></DIV>
<DIV style="position:absolute;top:208;left:81"><nobr><span class="ft12">The baseline focused crawler has been described in detail<br>elsewhere <A href="25.html#12">[9, 14], </a>and has been sketched in Figure <A href="25.html#1">1. </a>Here<br>we review its design and operation briefly.</span></nobr></DIV>
<DIV style="position:absolute;top:255;left:103"><nobr><span class="ft4">There are two inputs to the baseline crawler.</span></nobr></DIV>
<DIV style="position:absolute;top:280;left:104"><nobr><span class="ft4">· A topic taxonomy or hierarchy with example URLs</span></nobr></DIV>
<DIV style="position:absolute;top:297;left:118"><nobr><span class="ft4">for each topic.</span></nobr></DIV>
<DIV style="position:absolute;top:317;left:104"><nobr><span class="ft4">· One or a few topics in the taxonomy marked as the</span></nobr></DIV>
<DIV style="position:absolute;top:334;left:118"><nobr><span class="ft4">topic(s) of focus.</span></nobr></DIV>
<DIV style="position:absolute;top:360;left:81"><nobr><span class="ft12">Although we will generally use the terms `taxonomy' and<br>`hierarchy', a topic tree is not essential; all we really need is<br>a two-way classifier where the classes have the connotations<br>of being `relevant' or `irrelevant' to the topic(s) of focus.<br>A topic hierarchy is proposed purely to reduce the tedium<br>of defining new focused crawls. With a two-class classifier,<br>the crawl administrator has to seed positive and negative<br>examples for each crawl. Using a taxonomy, she composes<br>the `irrelevant' class as the union of all classes that are not<br>relevant. Thanks to extensive hierarchies like Dmoz in the<br>public domain, it should be quite easy to seed topic-based<br>crawls in this way.</span></nobr></DIV>
<DIV style="position:absolute;top:548;left:103"><nobr><span class="ft4">The baseline crawler maintains a priority queue on the</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:81"><nobr><span class="ft12">estimated relevance of nodes v which have not been visited,<br>and keeps removing the highest priority node and visiting it,<br>expanding its outlinks and checking them into the priority<br>queue with the relevance score of v in turn.</span></nobr></DIV>
<DIV style="position:absolute;top:611;left:373"><nobr><span class="ft4">Despite its</span></nobr></DIV>
<DIV style="position:absolute;top:627;left:81"><nobr><span class="ft12">extreme simplicity, the best-first crawler has been found to<br>have very high harvest rates in extensive evaluations <A href="25.html#12">[25].</a></span></nobr></DIV>
<DIV style="position:absolute;top:658;left:103"><nobr><span class="ft4">Why do we need negative examples and negative classes</span></nobr></DIV>
<DIV style="position:absolute;top:674;left:81"><nobr><span class="ft12">at all? Instead of using class probabilities, we could maintain<br>a priority queue on, say, the TFIDF cosine similarity<br>between u and the centroid of the seed pages (acting as an<br>estimate for the corresponding similarity between v and the<br>centroid, until v has been fetched). Experience has shown<br><A href="25.html#12">[32] </a>that characterizing a negative class is quite important to<br>prevent the centroid of the crawled documents from drifting<br>away indefinitely from the desired topic profile.</span></nobr></DIV>
<DIV style="position:absolute;top:800;left:103"><nobr><span class="ft4">In this paper, the baseline crawler also has the implicit</span></nobr></DIV>
<DIV style="position:absolute;top:815;left:81"><nobr><span class="ft12">job of gathering instances of successful and unsuccessful<br>"leaps of faith" to submit to the apprentice, discussed next.</span></nobr></DIV>
<DIV style="position:absolute;top:866;left:81"><nobr><span class="ft17">2.2</span></nobr></DIV>
<DIV style="position:absolute;top:866;left:120"><nobr><span class="ft26">The basic structure of the apprentice<br>learner</span></nobr></DIV>
<DIV style="position:absolute;top:910;left:81"><nobr><span class="ft12">In estimating the worth of traversing the HREF (u, v), we<br>will limit our attention to u alone. The page u is modeled<br>as a tag tree (also called the Document Object Model or<br>DOM). In principle, any feature from u, even font color and<br>site membership may be perfect predictors of the relevance<br>of v. The total number of potentially predictive features will<br>be quite staggering, so we need to simplify the feature space<br>and massage it into a form suited to conventional learning<br>algorithms. Also note that we specifically study properties<br>of u and not larger contexts such as paths leading to u,<br>meaning that our method may become even more robust and</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft12">useful in conjunction with context graphs or reinforcement<br>along paths.</span></nobr></DIV>
<DIV style="position:absolute;top:118;left:498"><nobr><span class="ft4">Initially, the apprentice has no training data, and passes</span></nobr></DIV>
<DIV style="position:absolute;top:133;left:475"><nobr><span class="ft12">judgment on (u, v) links according to some fixed prior<br>obtained from a baseline crawl run ahead of time (e.g., see<br>the statistics in</span></nobr></DIV>
<DIV style="position:absolute;top:164;left:577"><nobr><span class="ft4"><A href="25.html#7">§3.3). </a>Ideally, we would like to train the</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:475"><nobr><span class="ft12">apprentice continuously, but to reduce overheads, we declare<br>a batch size between a few hundred and a few thousand<br>pages. After every batch of pages is collected, we check if any<br>page u fetched before the current batch links to some page<br>v in the batch. If such a (u, v) is found, we extract suitable<br>features for (u, v) as described later in this section, and add</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:481"><nobr><span class="ft4">(u, v), Pr(c</span></nobr></DIV>
<DIV style="position:absolute;top:271;left:545"><nobr><span class="ft9"></span></nobr></DIV>
<DIV style="position:absolute;top:274;left:551"><nobr><span class="ft4">|v) as another instance of the training data for</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:475"><nobr><span class="ft12">the apprentice. Many apprentices, certainly the simple naive<br>Bayes and linear perceptrons that we have studied, need not<br>start learning from scratch; they can accept the additional<br>training data with a small additional computational cost.</span></nobr></DIV>
<DIV style="position:absolute;top:371;left:475"><nobr><span class="ft4">2.2.1</span></nobr></DIV>
<DIV style="position:absolute;top:371;left:524"><nobr><span class="ft4">Preprocessing the DOM tree</span></nobr></DIV>
<DIV style="position:absolute;top:396;left:475"><nobr><span class="ft4">First, we parse u and form the DOM tree for u.</span></nobr></DIV>
<DIV style="position:absolute;top:396;left:798"><nobr><span class="ft4">Sadly,</span></nobr></DIV>
<DIV style="position:absolute;top:412;left:475"><nobr><span class="ft12">much of the HTML available on the Web violates any<br>HTML standards that permit context-free parsing, but<br>a variety of repair heuristics (see, e.g., HTML Tidy,<br>available at <A href="http://www.w3.org/People/Raggett/tidy/">http://www.w3.org/People/Raggett/tidy/</a>)<br>let us generate reasonable DOM trees from bad HTML.</span></nobr></DIV>
<DIV style="position:absolute;top:583;left:632"><nobr><span class="ft25">a</span></nobr></DIV>
<DIV style="position:absolute;top:604;left:667"><nobr><span class="ft25">HREF</span></nobr></DIV>
<DIV style="position:absolute;top:620;left:600"><nobr><span class="ft25">TEXT</span></nobr></DIV>
<DIV style="position:absolute;top:620;left:640"><nobr><span class="ft25">font</span></nobr></DIV>
<DIV style="position:absolute;top:646;left:636"><nobr><span class="ft25">TEXT</span></nobr></DIV>
<DIV style="position:absolute;top:552;left:632"><nobr><span class="ft25">li</span></nobr></DIV>
<DIV style="position:absolute;top:552;left:564"><nobr><span class="ft25">li</span></nobr></DIV>
<DIV style="position:absolute;top:552;left:703"><nobr><span class="ft25">li</span></nobr></DIV>
<DIV style="position:absolute;top:510;left:631"><nobr><span class="ft25">ul</span></nobr></DIV>
<DIV style="position:absolute;top:552;left:753"><nobr><span class="ft25">li</span></nobr></DIV>
<DIV style="position:absolute;top:620;left:694"><nobr><span class="ft25">TEXT</span></nobr></DIV>
<DIV style="position:absolute;top:604;left:736"><nobr><span class="ft25">TEXT</span></nobr></DIV>
<DIV style="position:absolute;top:604;left:777"><nobr><span class="ft25">em</span></nobr></DIV>
<DIV style="position:absolute;top:630;left:772"><nobr><span class="ft25">TEXT</span></nobr></DIV>
<DIV style="position:absolute;top:583;left:540"><nobr><span class="ft25">tt</span></nobr></DIV>
<DIV style="position:absolute;top:609;left:532"><nobr><span class="ft25">TEXT</span></nobr></DIV>
<DIV style="position:absolute;top:583;left:574"><nobr><span class="ft25">TEXT</span></nobr></DIV>
<DIV style="position:absolute;top:672;left:599"><nobr><span class="ft25">@0</span></nobr></DIV>
<DIV style="position:absolute;top:672;left:656"><nobr><span class="ft25">@0</span></nobr></DIV>
<DIV style="position:absolute;top:672;left:698"><nobr><span class="ft25">@1</span></nobr></DIV>
<DIV style="position:absolute;top:672;left:735"><nobr><span class="ft25">@2</span></nobr></DIV>
<DIV style="position:absolute;top:672;left:776"><nobr><span class="ft25">@3</span></nobr></DIV>
<DIV style="position:absolute;top:672;left:557"><nobr><span class="ft25">@-1</span></nobr></DIV>
<DIV style="position:absolute;top:672;left:520"><nobr><span class="ft25">@-2</span></nobr></DIV>
<DIV style="position:absolute;top:696;left:475"><nobr><span class="ft12">Figure 3: Numbering of DOM leaves used to derive offset<br>attributes for textual tokens. `@' means "is at offset".</span></nobr></DIV>
<DIV style="position:absolute;top:757;left:498"><nobr><span class="ft4">Second, we number all leaf nodes consecutively from left</span></nobr></DIV>
<DIV style="position:absolute;top:773;left:475"><nobr><span class="ft12">to right. For uniformity, we assign numbers even to those<br>DOM leaves which have no text associated with them. The<br>specific &lt;a href...&gt; which links to v is actually an internal<br>node a</span></nobr></DIV>
<DIV style="position:absolute;top:824;left:518"><nobr><span class="ft9">v</span></nobr></DIV>
<DIV style="position:absolute;top:820;left:525"><nobr><span class="ft4">, which is the root of the subtree containing the</span></nobr></DIV>
<DIV style="position:absolute;top:836;left:475"><nobr><span class="ft12">anchor text of the link (u, v). There may be other element<br>tags such as &lt;em&gt; or &lt;b&gt; in the subtree rooted at a</span></nobr></DIV>
<DIV style="position:absolute;top:856;left:794"><nobr><span class="ft9">v</span></nobr></DIV>
<DIV style="position:absolute;top:851;left:801"><nobr><span class="ft4">. Let</span></nobr></DIV>
<DIV style="position:absolute;top:867;left:475"><nobr><span class="ft4">the leaf or leaves in this subtree be numbered (a</span></nobr></DIV>
<DIV style="position:absolute;top:872;left:770"><nobr><span class="ft9">v</span></nobr></DIV>
<DIV style="position:absolute;top:867;left:777"><nobr><span class="ft4">) through</span></nobr></DIV>
<DIV style="position:absolute;top:883;left:475"><nobr><span class="ft4">r(a</span></nobr></DIV>
<DIV style="position:absolute;top:887;left:495"><nobr><span class="ft9">v</span></nobr></DIV>
<DIV style="position:absolute;top:883;left:501"><nobr><span class="ft4">)</span></nobr></DIV>
<DIV style="position:absolute;top:882;left:511"><nobr><span class="ft4"> (a</span></nobr></DIV>
<DIV style="position:absolute;top:887;left:544"><nobr><span class="ft9">v</span></nobr></DIV>
<DIV style="position:absolute;top:883;left:551"><nobr><span class="ft4">). We regard the textual tokens available from</span></nobr></DIV>
<DIV style="position:absolute;top:898;left:475"><nobr><span class="ft12">any of these leaves as being at DOM offset zero w.r.t. the<br>(u, v) link. Text tokens from a leaf numbered µ, to the left of</span></nobr></DIV>
<DIV style="position:absolute;top:930;left:481"><nobr><span class="ft4">(a</span></nobr></DIV>
<DIV style="position:absolute;top:934;left:494"><nobr><span class="ft9">v</span></nobr></DIV>
<DIV style="position:absolute;top:930;left:500"><nobr><span class="ft4">), are at negative DOM offset µ</span></nobr></DIV>
<DIV style="position:absolute;top:929;left:695"><nobr><span class="ft4">- (a</span></nobr></DIV>
<DIV style="position:absolute;top:934;left:728"><nobr><span class="ft9">v</span></nobr></DIV>
<DIV style="position:absolute;top:930;left:734"><nobr><span class="ft4">). Likewise, text</span></nobr></DIV>
<DIV style="position:absolute;top:945;left:475"><nobr><span class="ft4">from a leaf numbered µ to the right of r(a</span></nobr></DIV>
<DIV style="position:absolute;top:950;left:732"><nobr><span class="ft9">v</span></nobr></DIV>
<DIV style="position:absolute;top:945;left:739"><nobr><span class="ft4">) are at positive</span></nobr></DIV>
<DIV style="position:absolute;top:961;left:475"><nobr><span class="ft4">DOM offset µ</span></nobr></DIV>
<DIV style="position:absolute;top:960;left:562"><nobr><span class="ft4">- r(a</span></nobr></DIV>
<DIV style="position:absolute;top:966;left:595"><nobr><span class="ft9">v</span></nobr></DIV>
<DIV style="position:absolute;top:961;left:602"><nobr><span class="ft4">). See Figure <A href="25.html#4">3 </a>for an example.</span></nobr></DIV>
<DIV style="position:absolute;top:995;left:475"><nobr><span class="ft4">2.2.2</span></nobr></DIV>
<DIV style="position:absolute;top:995;left:524"><nobr><span class="ft12">Features derived from the DOM and text<br>tokens</span></nobr></DIV>
<DIV style="position:absolute;top:1035;left:475"><nobr><span class="ft4">Many related projects mentioned in</span></nobr></DIV>
<DIV style="position:absolute;top:1034;left:695"><nobr><span class="ft4">§<A href="25.html#2">1.2 </a>use a linear notion</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:475"><nobr><span class="ft12">of proximity between a HREF and textual tokens. In the<br>ARC system, there is a crude cut-off distance measured</span></nobr></DIV>
<DIV style="position:absolute;top:1121;left:447"><nobr><span class="ft11">151</span></nobr></DIV>
</DIV>
<!-- Page 5 -->
<a name="5"></a>
<DIV style="position:relative;width:917;height:1187;">
<STYLE type="text/css">
<!--
	.ft27{font-size:11px;line-height:14px;font-family:Times;color:#000000;}
	.ft28{font-size:11px;line-height:16px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="917" height="1187" src="25005.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft4">in bytes to the left and right of the anchor.</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:399"><nobr><span class="ft4">In the</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:81"><nobr><span class="ft12">Clever system, distance is measured in tokens, and the<br>importance attached to a token decays with the distance.<br>In reinforcement learning and intelligent predicate-based<br>crawling, the exact specification of neighborhood text is not<br>known to us. In all cases, some ad-hoc tuning appears to be<br>involved.</span></nobr></DIV>
<DIV style="position:absolute;top:196;left:103"><nobr><span class="ft4">We claim (and show in</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:250"><nobr><span class="ft4">§<A href="25.html#7">3.4) </a>that the relation between</span></nobr></DIV>
<DIV style="position:absolute;top:212;left:81"><nobr><span class="ft12">the relevance of the target v of a HREF (u, v) and the<br>proximity of terms to (u, v) can be learnt automatically. The<br>results are better than ad-hoc tuning of cut-off distances,<br>provided the DOM offset information is encoded as features<br>suitable for the apprentice.</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:103"><nobr><span class="ft4">One obvious idea is to extend the Clever model: a page</span></nobr></DIV>
<DIV style="position:absolute;top:306;left:81"><nobr><span class="ft12">is a linear sequence of tokens. If a token t is distant x from<br>the HREF (u, v) in question, we encode it as a feature t, x .<br>Such features will not be useful because there are too many<br>possible values of x, making the t, x space too sparse to<br>learn well. (How many HREFS will be exactly five tokens<br>from the term `basketball' ?)</span></nobr></DIV>
<DIV style="position:absolute;top:400;left:103"><nobr><span class="ft4">Clearly, we need to bucket x into a small number of</span></nobr></DIV>
<DIV style="position:absolute;top:416;left:81"><nobr><span class="ft12">ranges. Rather than tune arbitrary bucket boundaries by<br>hand, we argue that DOM offsets are a natural bucketing<br>scheme provided by the page author.</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:340"><nobr><span class="ft4">Using the node</span></nobr></DIV>
<DIV style="position:absolute;top:463;left:81"><nobr><span class="ft12">numbering scheme described above, each token t on page u<br>can be annotated w.r.t. the link (u, v) (for simplicity assume<br>there is only one such link) as t, d , where d is the DOM<br>offset calculated above.</span></nobr></DIV>
<DIV style="position:absolute;top:510;left:238"><nobr><span class="ft4">This is the main set of features</span></nobr></DIV>
<DIV style="position:absolute;top:526;left:81"><nobr><span class="ft12">used by the apprentice. We shall see that the apprentice<br>can learn to limit</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:194"><nobr><span class="ft4">|d| to less than d</span></nobr></DIV>
<DIV style="position:absolute;top:546;left:299"><nobr><span class="ft9">max</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:325"><nobr><span class="ft4">= 5 in most cases,</span></nobr></DIV>
<DIV style="position:absolute;top:557;left:81"><nobr><span class="ft4">which reduces its vocabulary and saves time.</span></nobr></DIV>
<DIV style="position:absolute;top:573;left:103"><nobr><span class="ft4">A variety of other feature encodings suggest themselves.</span></nobr></DIV>
<DIV style="position:absolute;top:588;left:81"><nobr><span class="ft4">We are experimenting with some in ongoing work (</span></nobr></DIV>
<DIV style="position:absolute;top:588;left:417"><nobr><span class="ft4"><A href="25.html#11">§4),</a></span></nobr></DIV>
<DIV style="position:absolute;top:604;left:81"><nobr><span class="ft12">but decided against some others. For example, we do not<br>expect gains from encoding specific HTML tag names owing<br>to the diversity of authoring styles.</span></nobr></DIV>
<DIV style="position:absolute;top:635;left:318"><nobr><span class="ft4">Authors use &lt;div&gt;,</span></nobr></DIV>
<DIV style="position:absolute;top:652;left:81"><nobr><span class="ft12">&lt;span&gt;, &lt;layer&gt; and nested tables for layout control in<br>non-standard ways; these are best deflated to a nameless<br>DOM node representation.</span></nobr></DIV>
<DIV style="position:absolute;top:683;left:266"><nobr><span class="ft4">Similar comments apply to</span></nobr></DIV>
<DIV style="position:absolute;top:698;left:81"><nobr><span class="ft28">HREF collections embedded in &lt;ul&gt;, &lt;ol&gt;, &lt;td&gt; and<br>&lt;dd&gt;.</span></nobr></DIV>
<DIV style="position:absolute;top:714;left:129"><nobr><span class="ft4">Font and lower/upper case information is useful</span></nobr></DIV>
<DIV style="position:absolute;top:730;left:81"><nobr><span class="ft12">for search engines, but would make features even sparser<br>for the apprentice.</span></nobr></DIV>
<DIV style="position:absolute;top:745;left:209"><nobr><span class="ft4">Our representation also flattens two-</span></nobr></DIV>
<DIV style="position:absolute;top:761;left:81"><nobr><span class="ft4">dimensional tables to their "row-major" representation.</span></nobr></DIV>
<DIV style="position:absolute;top:777;left:103"><nobr><span class="ft4">The features we ignore are definitely crucial for other</span></nobr></DIV>
<DIV style="position:absolute;top:792;left:81"><nobr><span class="ft12">applications, such as information extraction. We did not<br>see any cases where this sloppiness led to a large loss rate.<br>We would be surprised to see tables where relevant links<br>occurred in the third column and irrelevant links in the fifth,<br>or pages where they are rendered systematically in different<br>fonts and colors, but are not otherwise demarcated by the<br>DOM structure.</span></nobr></DIV>
<DIV style="position:absolute;top:921;left:81"><nobr><span class="ft4">2.2.3</span></nobr></DIV>
<DIV style="position:absolute;top:921;left:129"><nobr><span class="ft4">Non-textual features</span></nobr></DIV>
<DIV style="position:absolute;top:945;left:81"><nobr><span class="ft12">Limiting d may lead us to miss features of u that may be<br>useful at the whole-page level. One approach would be to use<br>"d =</span></nobr></DIV>
<DIV style="position:absolute;top:976;left:113"><nobr><span class="ft4">" for all d larger in magnitude than some threshold.</span></nobr></DIV>
<DIV style="position:absolute;top:993;left:81"><nobr><span class="ft12">But this would make our apprentice as bulky and slow to<br>train as the baseline learner.</span></nobr></DIV>
<DIV style="position:absolute;top:1024;left:103"><nobr><span class="ft4">Instead, we use the baseline learner to abstract u for</span></nobr></DIV>
<DIV style="position:absolute;top:1040;left:81"><nobr><span class="ft12">the apprentice. Specifically, we use a naive Bayes baseline<br>learner to classify u, and use the vector of class probabilities</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft12">returned as features for the apprentice. These features can<br>help the apprentice discover patterns such as</span></nobr></DIV>
<DIV style="position:absolute;top:128;left:493"><nobr><span class="ft12">"Pages about /Recreation/Boating/Sailing often<br>link to pages about /Sports/Canoe_and_Kayaking."</span></nobr></DIV>
<DIV style="position:absolute;top:170;left:475"><nobr><span class="ft12">This also covers for the baseline classifier confusing between<br>classes with related vocabulary, achieving an effect similar<br>to context graphs.</span></nobr></DIV>
<DIV style="position:absolute;top:217;left:498"><nobr><span class="ft4">Another kind of feature can be derived from co-citation.</span></nobr></DIV>
<DIV style="position:absolute;top:233;left:475"><nobr><span class="ft4">If v</span></nobr></DIV>
<DIV style="position:absolute;top:237;left:495"><nobr><span class="ft9">1</span></nobr></DIV>
<DIV style="position:absolute;top:233;left:506"><nobr><span class="ft4">has been fetched and found to be relevant and HREFS</span></nobr></DIV>
<DIV style="position:absolute;top:249;left:475"><nobr><span class="ft4">(u, v</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:501"><nobr><span class="ft9">1</span></nobr></DIV>
<DIV style="position:absolute;top:249;left:508"><nobr><span class="ft4">) and (u, v</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:575"><nobr><span class="ft9">2</span></nobr></DIV>
<DIV style="position:absolute;top:249;left:581"><nobr><span class="ft4">) are close to each other, v</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:754"><nobr><span class="ft9">2</span></nobr></DIV>
<DIV style="position:absolute;top:249;left:767"><nobr><span class="ft4">is likely to</span></nobr></DIV>
<DIV style="position:absolute;top:264;left:475"><nobr><span class="ft12">be relevant. Just like textual tokens were encoded as t, d<br>pairs, we can represent co-citation features as , d , where<br> is a suitable representation of relevance.</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:498"><nobr><span class="ft4">Many other features can be derived from the DOM tree</span></nobr></DIV>
<DIV style="position:absolute;top:327;left:475"><nobr><span class="ft12">and added to our feature pool. We discuss some options<br>in</span></nobr></DIV>
<DIV style="position:absolute;top:342;left:493"><nobr><span class="ft4"><A href="25.html#11">§4. </a>In our experience so far, we have found the t, d</span></nobr></DIV>
<DIV style="position:absolute;top:358;left:475"><nobr><span class="ft12">features to be most useful. For simplicity, we will limit our<br>subsequent discussion to t, d features only.</span></nobr></DIV>
<DIV style="position:absolute;top:410;left:475"><nobr><span class="ft17">2.3</span></nobr></DIV>
<DIV style="position:absolute;top:410;left:514"><nobr><span class="ft26">Choices of learning algorithms for the<br>apprentice</span></nobr></DIV>
<DIV style="position:absolute;top:453;left:475"><nobr><span class="ft12">Our feature set is thus an interesting mix of categorical,<br>ordered and continuous features:</span></nobr></DIV>
<DIV style="position:absolute;top:496;left:498"><nobr><span class="ft4">· Term tokens t, d have a categorical component t and</span></nobr></DIV>
<DIV style="position:absolute;top:512;left:513"><nobr><span class="ft12">a discrete ordered component d (which we may like to<br>smooth somewhat). Term counts are discrete but can<br>be normalized to constant document length, resulting<br>in continuous attribute values.</span></nobr></DIV>
<DIV style="position:absolute;top:580;left:498"><nobr><span class="ft4">· Class names are discrete and may be regarded as</span></nobr></DIV>
<DIV style="position:absolute;top:597;left:513"><nobr><span class="ft4">synthetic terms. The probabilities are continuous.</span></nobr></DIV>
<DIV style="position:absolute;top:624;left:475"><nobr><span class="ft4">The output we desire is an estimate of Pr(c</span></nobr></DIV>
<DIV style="position:absolute;top:621;left:731"><nobr><span class="ft9"></span></nobr></DIV>
<DIV style="position:absolute;top:623;left:737"><nobr><span class="ft4">|v), given all the</span></nobr></DIV>
<DIV style="position:absolute;top:640;left:475"><nobr><span class="ft12">observations about u and the neighborhood of (u, v) that<br>we have discussed. Neural networks are a natural choice<br>to accommodate these requirements. We first experimented<br>with a simple linear perceptron, training it with the delta<br>rule (gradient descent) <A href="25.html#12">[26]. </a>Even for a linear perceptron,<br>convergence was surprisingly slow, and after convergence,<br>the error rate was rather high.</span></nobr></DIV>
<DIV style="position:absolute;top:734;left:696"><nobr><span class="ft4">It is likely that local</span></nobr></DIV>
<DIV style="position:absolute;top:750;left:475"><nobr><span class="ft12">optima were responsible, because stability was generally<br>poor, and got worse if we tried to add hidden layers or<br>sigmoids.</span></nobr></DIV>
<DIV style="position:absolute;top:781;left:543"><nobr><span class="ft4">In any case, convergence was too slow for use</span></nobr></DIV>
<DIV style="position:absolute;top:797;left:475"><nobr><span class="ft12">as an online learner. All this was unfortunate, because the<br>direct regression output from a neural network would be<br>convenient, and we were hoping to implement a Kohonen<br>layer for smoothing d.</span></nobr></DIV>
<DIV style="position:absolute;top:860;left:498"><nobr><span class="ft4">In contrast, a naive Bayes (NB) classifier worked very</span></nobr></DIV>
<DIV style="position:absolute;top:875;left:475"><nobr><span class="ft12">well. A NB learner is given a set of training documents,<br>each labeled with one of a finite set of classes/topic.</span></nobr></DIV>
<DIV style="position:absolute;top:891;left:824"><nobr><span class="ft4">A</span></nobr></DIV>
<DIV style="position:absolute;top:907;left:475"><nobr><span class="ft12">document or Web page u is modeled as a multiset or bag<br>of words,</span></nobr></DIV>
<DIV style="position:absolute;top:922;left:538"><nobr><span class="ft4">{ , n(u,  ) } where  is a feature which occurs</span></nobr></DIV>
<DIV style="position:absolute;top:938;left:475"><nobr><span class="ft12">n(u,  ) times in u. In ordinary text classification (such as<br>our baseline learner) the features  are usually single words.<br>For our apprentice learner, a feature  is a t, d pair.</span></nobr></DIV>
<DIV style="position:absolute;top:985;left:498"><nobr><span class="ft4">NB classifiers can predict from a discrete set of classes,</span></nobr></DIV>
<DIV style="position:absolute;top:1001;left:475"><nobr><span class="ft12">but our prediction is a continuous (probability) score. To<br>bridge this gap, We used a simple two-bucket (low/high<br>relevance) special case of Torgo and Gama's technique of<br>using classifiers for discrete labels for continuous regression<br><A href="25.html#12">[33], </a>using "equally probable intervals" as far as possible.</span></nobr></DIV>
<DIV style="position:absolute;top:1121;left:447"><nobr><span class="ft11">152</span></nobr></DIV>
</DIV>
<!-- Page 6 -->
<a name="6"></a>
<DIV style="position:relative;width:917;height:1187;">
<STYLE type="text/css">
<!--
	.ft29{font-size:6px;line-height:8px;font-family:Times;color:#000000;}
-->
</STYLE>
<IMG width="917" height="1187" src="25006.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft12">Torgo and Gama recommend using a measure of centrality,<br>such as the median, of each interval as the predicted value of<br>that class. Rennie and McCallum <A href="25.html#12">[30] </a>corroborate that 2­3<br>bins are adequate. As will be clear from our experiments, the<br>medians of our `low' and `high' classes are very close to zero<br>and one respectively (see Figure <A href="25.html#7">5). </a>Therefore, we simply<br>take the probability of the `high' class as the prediction from<br>our naive Bayes apprentice.</span></nobr></DIV>
<DIV style="position:absolute;top:212;left:103"><nobr><span class="ft4">The prior probability of class c, denoted Pr(c) is the</span></nobr></DIV>
<DIV style="position:absolute;top:228;left:81"><nobr><span class="ft12">fraction of training documents labeled with class c. The NB<br>model is parameterized by a set of numbers </span></nobr></DIV>
<DIV style="position:absolute;top:248;left:368"><nobr><span class="ft9">c,</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:389"><nobr><span class="ft4">which is</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:81"><nobr><span class="ft12">roughly the rate of occurrence of feature  in class c, more<br>exactly,</span></nobr></DIV>
<DIV style="position:absolute;top:310;left:166"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:315;left:172"><nobr><span class="ft9">c,</span></nobr></DIV>
<DIV style="position:absolute;top:310;left:203"><nobr><span class="ft4">=</span></nobr></DIV>
<DIV style="position:absolute;top:299;left:235"><nobr><span class="ft4">1 +</span></nobr></DIV>
<DIV style="position:absolute;top:306;left:274"><nobr><span class="ft9">u</span></nobr></DIV>
<DIV style="position:absolute;top:306;left:281"><nobr><span class="ft9">V</span></nobr></DIV>
<DIV style="position:absolute;top:309;left:295"><nobr><span class="ft5">c</span></nobr></DIV>
<DIV style="position:absolute;top:299;left:303"><nobr><span class="ft4">n(u,  )</span></nobr></DIV>
<DIV style="position:absolute;top:319;left:230"><nobr><span class="ft4">|T | +</span></nobr></DIV>
<DIV style="position:absolute;top:328;left:280"><nobr><span class="ft9">u,</span></nobr></DIV>
<DIV style="position:absolute;top:320;left:304"><nobr><span class="ft4">n(u,  ) ,</span></nobr></DIV>
<DIV style="position:absolute;top:310;left:422"><nobr><span class="ft4">(1)</span></nobr></DIV>
<DIV style="position:absolute;top:346;left:81"><nobr><span class="ft4">where V</span></nobr></DIV>
<DIV style="position:absolute;top:351;left:128"><nobr><span class="ft9">c</span></nobr></DIV>
<DIV style="position:absolute;top:346;left:138"><nobr><span class="ft4">is the set of Web pages labeled with c and T is the</span></nobr></DIV>
<DIV style="position:absolute;top:362;left:81"><nobr><span class="ft12">entire vocabulary. The NB learner assumes independence<br>between features, and estimates</span></nobr></DIV>
<DIV style="position:absolute;top:406;left:108"><nobr><span class="ft4">Pr(c</span></nobr></DIV>
<DIV style="position:absolute;top:405;left:134"><nobr><span class="ft4">|u)</span></nobr></DIV>
<DIV style="position:absolute;top:405;left:166"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:406;left:192"><nobr><span class="ft4">Pr(c) Pr(u</span></nobr></DIV>
<DIV style="position:absolute;top:405;left:254"><nobr><span class="ft4">|c)</span></nobr></DIV>
<DIV style="position:absolute;top:405;left:287"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:406;left:315"><nobr><span class="ft4">Pr(c)</span></nobr></DIV>
<DIV style="position:absolute;top:427;left:349"><nobr><span class="ft9"></span></nobr></DIV>
<DIV style="position:absolute;top:426;left:355"><nobr><span class="ft9">u</span></nobr></DIV>
<DIV style="position:absolute;top:406;left:371"><nobr><span class="ft4"></span></nobr></DIV>
<DIV style="position:absolute;top:403;left:378"><nobr><span class="ft29">n(u, )<br>c,</span></nobr></DIV>
<DIV style="position:absolute;top:406;left:411"><nobr><span class="ft4">. (2)</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:81"><nobr><span class="ft4">Nigam et al. provide further details <A href="25.html#12">[22].</a></span></nobr></DIV>
<DIV style="position:absolute;top:485;left:81"><nobr><span class="ft1">3</span></nobr></DIV>
<DIV style="position:absolute;top:485;left:111"><nobr><span class="ft1">Experimental study</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:81"><nobr><span class="ft12">Our experiments were guided by the following requirements.<br>We wanted to cover a broad variety of topics, some `easy' and<br>some `difficult', in terms of the harvest rate of the baseline<br>crawler. Here is a quick preview of our results.</span></nobr></DIV>
<DIV style="position:absolute;top:594;left:104"><nobr><span class="ft4">· The apprentice classifier achieves high accuracy in</span></nobr></DIV>
<DIV style="position:absolute;top:610;left:118"><nobr><span class="ft12">predicting the relevance of unseen pages given t, d<br>features. It can determine the best value of d</span></nobr></DIV>
<DIV style="position:absolute;top:630;left:401"><nobr><span class="ft9">max</span></nobr></DIV>
<DIV style="position:absolute;top:626;left:427"><nobr><span class="ft4">to</span></nobr></DIV>
<DIV style="position:absolute;top:641;left:118"><nobr><span class="ft4">use, typically, 4­6.</span></nobr></DIV>
<DIV style="position:absolute;top:662;left:104"><nobr><span class="ft4">· Encoding DOM offsets in features improves the</span></nobr></DIV>
<DIV style="position:absolute;top:679;left:118"><nobr><span class="ft12">accuracy of the apprentice substantially, compared<br>to a bag of ordinary words collected from within the<br>same DOM offset window.</span></nobr></DIV>
<DIV style="position:absolute;top:731;left:104"><nobr><span class="ft4">· Compared to a baseline crawler, a crawler that is</span></nobr></DIV>
<DIV style="position:absolute;top:748;left:118"><nobr><span class="ft12">guided by an apprentice (trained offline) has a 30%<br>to 90% lower loss rate.</span></nobr></DIV>
<DIV style="position:absolute;top:763;left:276"><nobr><span class="ft4">It finds crawl paths never</span></nobr></DIV>
<DIV style="position:absolute;top:779;left:118"><nobr><span class="ft4">expanded by the baseline crawler.</span></nobr></DIV>
<DIV style="position:absolute;top:800;left:104"><nobr><span class="ft4">· Even if the apprentice-guided crawler is forced to</span></nobr></DIV>
<DIV style="position:absolute;top:816;left:118"><nobr><span class="ft12">stay within the (inferior) Web graph collected by the<br>baseline crawler, it collects the best pages early on.</span></nobr></DIV>
<DIV style="position:absolute;top:853;left:104"><nobr><span class="ft4">· The apprentice is easy to train online. As soon as it</span></nobr></DIV>
<DIV style="position:absolute;top:869;left:118"><nobr><span class="ft4">starts guiding the crawl, loss rates fall dramatically.</span></nobr></DIV>
<DIV style="position:absolute;top:890;left:104"><nobr><span class="ft4">· Compared to t, d features, topic- or cocitation-based</span></nobr></DIV>
<DIV style="position:absolute;top:907;left:118"><nobr><span class="ft4">features have negligible effect on the apprentice.</span></nobr></DIV>
<DIV style="position:absolute;top:937;left:103"><nobr><span class="ft4">To run so many experiments, we needed three highly</span></nobr></DIV>
<DIV style="position:absolute;top:953;left:81"><nobr><span class="ft12">optimized and robust modules: a crawler, a HTML-to-DOM<br>converter, and a classifier.</span></nobr></DIV>
<DIV style="position:absolute;top:984;left:103"><nobr><span class="ft4">We started with the w3c-libwww crawling library from</span></nobr></DIV>
<DIV style="position:absolute;top:1001;left:81"><nobr><span class="ft12"><A href="http://www.w3c.org/Library/">http://www.w3c.org/Library/</a>, but replaced it with our<br>own crawler because we could effectively overlap DNS<br>lookup, HTTP access, and disk access using a select over<br>all socket/file descriptors, and prevent memory leaks visible<br>in w3c-libwww. With three caching DNS servers, we could</span></nobr></DIV>
<DIV style="position:absolute;top:86;left:475"><nobr><span class="ft12">achieve over 90% utilization of a 2Mbps dedicated ISP<br>connection.</span></nobr></DIV>
<DIV style="position:absolute;top:118;left:498"><nobr><span class="ft4">We used the HTML parser libxml2 library to extract</span></nobr></DIV>
<DIV style="position:absolute;top:133;left:475"><nobr><span class="ft12">the DOM from HTML, but this library has memory leaks,<br>and does not always handle poorly written HTML well. We<br>had some stability problems with HTML Tidy <A href="http://www.w3.org/People/Raggett/tidy/">(http://www.<br>w3.org/People/Raggett/tidy/), </a>the well-known HTML<br>cleaner which is very robust to bad HTML. At present we<br>are using libxml2 and are rolling our own HTML parser and<br>cleaner for future work.</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:498"><nobr><span class="ft4">We intend to make our crawler and HTML parser code</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:475"><nobr><span class="ft4">available in the public domain for research use.</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:498"><nobr><span class="ft4">For both the baseline and apprentice classifier we used</span></nobr></DIV>
<DIV style="position:absolute;top:290;left:475"><nobr><span class="ft12">the public domain BOW toolkit and the Rainbow naive<br>Bayes classifier created by McCallum and others <A href="25.html#12">[20]. </a>Bow<br>and Rainbow are very fast C implementations which let us<br>classify pages in real time as they were being crawled.</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:475"><nobr><span class="ft17">3.1</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:514"><nobr><span class="ft17">Design of the topic taxonomy</span></nobr></DIV>
<DIV style="position:absolute;top:398;left:475"><nobr><span class="ft12">We downloaded from the Open Directory <A href="http://dmoz.org/">(http://dmoz.<br>org/</a>) an RDF file with over 271954 topics arranged in a<br>tree hierarchy with depth at least 6, containing a total of<br>about 1697266 sample URLs. The distribution of samples<br>over topics was quite non-uniform. Interpreting the tree as<br>an is-a hierarchy meant that internal nodes inherited all<br>examples from descendants, but they also had their own<br>examples. Since the set of topics was very large and many<br>topics had scarce training data, we pruned the Dmoz tree<br>to a manageable frontier by following these steps:</span></nobr></DIV>
<DIV style="position:absolute;top:567;left:494"><nobr><span class="ft4">1. Initially we placed example URLs in both internal and</span></nobr></DIV>
<DIV style="position:absolute;top:583;left:513"><nobr><span class="ft4">leaf nodes, as given by Dmoz.</span></nobr></DIV>
<DIV style="position:absolute;top:605;left:494"><nobr><span class="ft4">2. We fixed a minimum per-class training set size of k =</span></nobr></DIV>
<DIV style="position:absolute;top:620;left:513"><nobr><span class="ft4">300 documents.</span></nobr></DIV>
<DIV style="position:absolute;top:642;left:494"><nobr><span class="ft4">3. We iteratively performed the following step as long</span></nobr></DIV>
<DIV style="position:absolute;top:658;left:513"><nobr><span class="ft12">as possible: we found a leaf node with less than k<br>example URLs, moved all its examples to its parent,<br>and deleted the leaf.</span></nobr></DIV>
<DIV style="position:absolute;top:711;left:494"><nobr><span class="ft4">4. To</span></nobr></DIV>
<DIV style="position:absolute;top:711;left:540"><nobr><span class="ft4">each</span></nobr></DIV>
<DIV style="position:absolute;top:711;left:579"><nobr><span class="ft4">internal</span></nobr></DIV>
<DIV style="position:absolute;top:711;left:637"><nobr><span class="ft4">node</span></nobr></DIV>
<DIV style="position:absolute;top:711;left:678"><nobr><span class="ft4">c,</span></nobr></DIV>
<DIV style="position:absolute;top:711;left:702"><nobr><span class="ft4">we</span></nobr></DIV>
<DIV style="position:absolute;top:711;left:730"><nobr><span class="ft4">attached</span></nobr></DIV>
<DIV style="position:absolute;top:711;left:794"><nobr><span class="ft4">a</span></nobr></DIV>
<DIV style="position:absolute;top:711;left:813"><nobr><span class="ft4">leaf</span></nobr></DIV>
<DIV style="position:absolute;top:727;left:513"><nobr><span class="ft4">subdirectory called Other.</span></nobr></DIV>
<DIV style="position:absolute;top:727;left:704"><nobr><span class="ft4">Examples associated</span></nobr></DIV>
<DIV style="position:absolute;top:742;left:513"><nobr><span class="ft4">directly with c were moved to this Other subdirectory.</span></nobr></DIV>
<DIV style="position:absolute;top:764;left:494"><nobr><span class="ft4">5. Some topics were populated out of proportion, either</span></nobr></DIV>
<DIV style="position:absolute;top:780;left:513"><nobr><span class="ft12">at the beginning or through the above process. We<br>made the class priors more balanced by sampling<br>down the large classes so that each class had at most<br>300 examples.</span></nobr></DIV>
<DIV style="position:absolute;top:854;left:498"><nobr><span class="ft4">The resulting taxonomy had 482 leaf nodes and a total</span></nobr></DIV>
<DIV style="position:absolute;top:870;left:475"><nobr><span class="ft12">of 144859 sample URLs. Out of these we could successfully<br>fetch about 120000 URLs. At this point we discarded the<br>tree structure and considered only the leaf topics. Training<br>time for the baseline classifier was about about two hours<br>on a 729MHz Pentium III with 256kB cache and 512MB<br>RAM. This was very fast, given that 1.4GB of HTML text<br>had to be processed through Rainbow. The complete listing<br>of topics can be obtained from the authors.</span></nobr></DIV>
<DIV style="position:absolute;top:1016;left:475"><nobr><span class="ft17">3.2</span></nobr></DIV>
<DIV style="position:absolute;top:1016;left:514"><nobr><span class="ft17">Choice of topics</span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:475"><nobr><span class="ft12">Depending on the focus topic and prioritization strategy,<br>focused crawlers may achieve diverse harvest rates.</span></nobr></DIV>
<DIV style="position:absolute;top:1057;left:810"><nobr><span class="ft4">Our</span></nobr></DIV>
<DIV style="position:absolute;top:1121;left:447"><nobr><span class="ft11">153</span></nobr></DIV>
</DIV>
<!-- Page 7 -->
<a name="7"></a>
<DIV style="position:relative;width:917;height:1187;">
<STYLE type="text/css">
<!--
	.ft30{font-size:7px;line-height:-5px;font-family:Helvetica;color:#000000;}
	.ft31{font-size:7px;line-height:-2px;font-family:Helvetica;color:#000000;}
-->
</STYLE>
<IMG width="917" height="1187" src="25007.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft12">early prototype <A href="25.html#12">[9] </a>yielded harvest rates typically between<br>0.25 and 0.6.</span></nobr></DIV>
<DIV style="position:absolute;top:102;left:175"><nobr><span class="ft4">Rennie and McCallum <A href="25.html#12">[30] </a>reported recall</span></nobr></DIV>
<DIV style="position:absolute;top:118;left:81"><nobr><span class="ft12">and not harvest rates. Diligenti et al. <A href="25.html#12">[14] </a>focused on very<br>specific topics where the harvest rate was very low, 4­6%.<br>Obviously, the maximum gains shown by a new idea in<br>focused crawling can be sensitive to the baseline harvest<br>rate.</span></nobr></DIV>
<DIV style="position:absolute;top:196;left:103"><nobr><span class="ft4">To avoid showing our new system in an unduly positive</span></nobr></DIV>
<DIV style="position:absolute;top:212;left:81"><nobr><span class="ft12">or negative light, we picked a set of topics which were fairly<br>diverse, and appeared to be neither too broad to be useful<br>(e.g., /Arts, /Science) nor too narrow for the baseline<br>crawler to be a reasonable adversary.</span></nobr></DIV>
<DIV style="position:absolute;top:259;left:326"><nobr><span class="ft4">We list our topics</span></nobr></DIV>
<DIV style="position:absolute;top:275;left:81"><nobr><span class="ft12">in Figure <A href="25.html#7">4. </a>We chose the topics without prior estimates of<br>how well our new system would work, and froze the list<br>of topics.</span></nobr></DIV>
<DIV style="position:absolute;top:306;left:152"><nobr><span class="ft4">All topics that we experimented with showed</span></nobr></DIV>
<DIV style="position:absolute;top:322;left:81"><nobr><span class="ft12">visible improvements, and none of them showed deteriorated<br>performance.</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:81"><nobr><span class="ft17">3.3</span></nobr></DIV>
<DIV style="position:absolute;top:373;left:120"><nobr><span class="ft17">Baseline crawl results</span></nobr></DIV>
<DIV style="position:absolute;top:398;left:81"><nobr><span class="ft12">We will skip the results of breadth-first or random crawling<br>in our commentary, because it is known from earlier work<br>on focused crawling that our baseline crawls are already<br>far better than breadth-first or random crawls. Figure <A href="25.html#7">5<br></a>shows, for most of the topics listed above, the distribution<br>of page relevance after running the baseline crawler to<br>collect roughly 15000 to 25000 pages per topic.</span></nobr></DIV>
<DIV style="position:absolute;top:493;left:416"><nobr><span class="ft4">The</span></nobr></DIV>
<DIV style="position:absolute;top:508;left:81"><nobr><span class="ft12">baseline crawler used a standard naive Bayes classifier on<br>the ordinary term space of whole pages. We see that the<br>relevance distribution is bimodal, with most pages being<br>very relevant or not at all. This is partly, but only partly, a<br>result of using a multinomial naive Bayes model. The naive<br>Bayes classifier assumes term independence and multiplies<br>together many (small) term probabilities, with the result<br>that the winning class usually beats all others by a large<br>margin in probability. But it is also true that many outlinks<br>lead to pages with completely irrelevant topics. Figure <A href="25.html#7">5<br></a>gives a clear indication of how much improvement we can<br>expect for each topic from our new algorithm.</span></nobr></DIV>
<DIV style="position:absolute;top:717;left:81"><nobr><span class="ft17">3.4</span></nobr></DIV>
<DIV style="position:absolute;top:717;left:120"><nobr><span class="ft17">DOM window size and feature selection</span></nobr></DIV>
<DIV style="position:absolute;top:742;left:81"><nobr><span class="ft12">A key concern for us was how to limit the maximum window<br>width so that the total number of synthesized t, d features<br>remains much smaller than the training data for the baseline<br>classifier, enabling the apprentice to be trained or upgraded<br>in a very short time. At the same time, we did not want<br>to lose out on medium- to long-range dependencies between<br>significant tokens on a page and the topic of HREF targets<br>in the vicinity. We eventually settled for a maximum DOM<br>window size of 5. We made this choice through the following<br>experiments.</span></nobr></DIV>
<DIV style="position:absolute;top:899;left:103"><nobr><span class="ft4">The easiest initial approach was an end-to-end cross-</span></nobr></DIV>
<DIV style="position:absolute;top:915;left:81"><nobr><span class="ft12">validation of the apprentice for various topics while<br>increasing d</span></nobr></DIV>
<DIV style="position:absolute;top:935;left:155"><nobr><span class="ft9">max</span></nobr></DIV>
<DIV style="position:absolute;top:930;left:176"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:930;left:195"><nobr><span class="ft4">We observed an initial increase in the</span></nobr></DIV>
<DIV style="position:absolute;top:946;left:81"><nobr><span class="ft12">validation accuracy when the DOM window size was<br>increased beyond 0.</span></nobr></DIV>
<DIV style="position:absolute;top:962;left:218"><nobr><span class="ft4">However, the early increase leveled</span></nobr></DIV>
<DIV style="position:absolute;top:977;left:81"><nobr><span class="ft12">off or even reversed after the DOM window size was<br>increased beyond 5. The graphs in Figure <A href="25.html#8">6 </a>display these<br>results.</span></nobr></DIV>
<DIV style="position:absolute;top:1009;left:138"><nobr><span class="ft4">We see that in the Chess category, though the</span></nobr></DIV>
<DIV style="position:absolute;top:1025;left:81"><nobr><span class="ft12">validation accuracy increases monotonically, the gains are<br>less pronounced after d</span></nobr></DIV>
<DIV style="position:absolute;top:1045;left:222"><nobr><span class="ft9">max</span></nobr></DIV>
<DIV style="position:absolute;top:1040;left:248"><nobr><span class="ft4">exceeds 5. For the AI category,</span></nobr></DIV>
<DIV style="position:absolute;top:1056;left:81"><nobr><span class="ft4">accuracy fell beyond d</span></nobr></DIV>
<DIV style="position:absolute;top:1060;left:216"><nobr><span class="ft9">max</span></nobr></DIV>
<DIV style="position:absolute;top:1056;left:241"><nobr><span class="ft4">= 4.</span></nobr></DIV>
<DIV style="position:absolute;top:82;left:495"><nobr><span class="ft3">Topic</span></nobr></DIV>
<DIV style="position:absolute;top:82;left:740"><nobr><span class="ft3">#Good #Bad</span></nobr></DIV>
<DIV style="position:absolute;top:96;left:495"><nobr><span class="ft3">/Arts/Music/Styles/Classical/Composers</span></nobr></DIV>
<DIV style="position:absolute;top:95;left:748"><nobr><span class="ft3">24000 13000</span></nobr></DIV>
<DIV style="position:absolute;top:108;left:495"><nobr><span class="ft3">/Arts/Performing_Arts/Dance/Folk_Dancing</span></nobr></DIV>
<DIV style="position:absolute;top:107;left:754"><nobr><span class="ft3">7410</span></nobr></DIV>
<DIV style="position:absolute;top:107;left:791"><nobr><span class="ft3">8300</span></nobr></DIV>
<DIV style="position:absolute;top:120;left:495"><nobr><span class="ft3">/Business/Industries.../Livestock/Horses...</span></nobr></DIV>
<DIV style="position:absolute;top:119;left:748"><nobr><span class="ft3">17000</span></nobr></DIV>
<DIV style="position:absolute;top:119;left:791"><nobr><span class="ft3">7600</span></nobr></DIV>
<DIV style="position:absolute;top:132;left:495"><nobr><span class="ft3">/Computers/Artificial_Intelligence</span></nobr></DIV>
<DIV style="position:absolute;top:131;left:754"><nobr><span class="ft3">7701 14309</span></nobr></DIV>
<DIV style="position:absolute;top:144;left:495"><nobr><span class="ft3">/Computers/Software/Operating_Systems/Linux</span></nobr></DIV>
<DIV style="position:absolute;top:143;left:748"><nobr><span class="ft3">17500</span></nobr></DIV>
<DIV style="position:absolute;top:143;left:791"><nobr><span class="ft3">9300</span></nobr></DIV>
<DIV style="position:absolute;top:156;left:495"><nobr><span class="ft3">/Games/Board_Games/C/Chess</span></nobr></DIV>
<DIV style="position:absolute;top:155;left:748"><nobr><span class="ft3">17000</span></nobr></DIV>
<DIV style="position:absolute;top:155;left:791"><nobr><span class="ft3">4600</span></nobr></DIV>
<DIV style="position:absolute;top:168;left:495"><nobr><span class="ft3">/Health/Conditions_and_Diseases/Cancer</span></nobr></DIV>
<DIV style="position:absolute;top:167;left:748"><nobr><span class="ft3">14700</span></nobr></DIV>
<DIV style="position:absolute;top:167;left:791"><nobr><span class="ft3">5300</span></nobr></DIV>
<DIV style="position:absolute;top:180;left:495"><nobr><span class="ft3">/Home/Recipes/Soups_and_Stews</span></nobr></DIV>
<DIV style="position:absolute;top:179;left:748"><nobr><span class="ft3">20000</span></nobr></DIV>
<DIV style="position:absolute;top:179;left:791"><nobr><span class="ft3">3600</span></nobr></DIV>
<DIV style="position:absolute;top:191;left:495"><nobr><span class="ft3">/Recreation/Outdoors/Fishing/Fly_Fishing</span></nobr></DIV>
<DIV style="position:absolute;top:191;left:748"><nobr><span class="ft3">12000 13300</span></nobr></DIV>
<DIV style="position:absolute;top:203;left:495"><nobr><span class="ft3">/Recreation/Outdoors/Speleology</span></nobr></DIV>
<DIV style="position:absolute;top:203;left:754"><nobr><span class="ft3">6717 14890</span></nobr></DIV>
<DIV style="position:absolute;top:215;left:495"><nobr><span class="ft3">/Science/Astronomy</span></nobr></DIV>
<DIV style="position:absolute;top:215;left:748"><nobr><span class="ft3">14961</span></nobr></DIV>
<DIV style="position:absolute;top:215;left:791"><nobr><span class="ft3">5332</span></nobr></DIV>
<DIV style="position:absolute;top:227;left:495"><nobr><span class="ft3">/Science/Earth_Sciences/Meteorology</span></nobr></DIV>
<DIV style="position:absolute;top:226;left:748"><nobr><span class="ft3">19205</span></nobr></DIV>
<DIV style="position:absolute;top:226;left:791"><nobr><span class="ft3">8705</span></nobr></DIV>
<DIV style="position:absolute;top:239;left:495"><nobr><span class="ft3">/Sports/Basketball</span></nobr></DIV>
<DIV style="position:absolute;top:238;left:748"><nobr><span class="ft3">26700</span></nobr></DIV>
<DIV style="position:absolute;top:238;left:791"><nobr><span class="ft3">2588</span></nobr></DIV>
<DIV style="position:absolute;top:251;left:495"><nobr><span class="ft3">/Sports/Canoe_and_Kayaking</span></nobr></DIV>
<DIV style="position:absolute;top:250;left:748"><nobr><span class="ft3">12000 12700</span></nobr></DIV>
<DIV style="position:absolute;top:263;left:495"><nobr><span class="ft3">/Sports/Hockey/Ice_Hockey</span></nobr></DIV>
<DIV style="position:absolute;top:262;left:748"><nobr><span class="ft3">17500 17900</span></nobr></DIV>
<DIV style="position:absolute;top:277;left:475"><nobr><span class="ft12">Figure 4: We chose a variety of topics which were neither<br>too broad nor too narrow, so that the baseline crawler<br>was a reasonable adversary.</span></nobr></DIV>
<DIV style="position:absolute;top:309;left:669"><nobr><span class="ft4">#Good (#Bad) show the</span></nobr></DIV>
<DIV style="position:absolute;top:324;left:475"><nobr><span class="ft12">approximate number of pages collected by the baseline<br>crawler which have relevance above (below) 0.5, which<br>indicates the relative difficulty of the crawling task.</span></nobr></DIV>
<DIV style="position:absolute;top:677;left:535"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:697;left:562"><nobr><span class="ft31">0<br>.<br>2</span></nobr></DIV>
<DIV style="position:absolute;top:709;left:590"><nobr><span class="ft31">0<br>.<br>4</span></nobr></DIV>
<DIV style="position:absolute;top:722;left:618"><nobr><span class="ft31">0<br>.<br>6</span></nobr></DIV>
<DIV style="position:absolute;top:735;left:647"><nobr><span class="ft31">0<br>.<br>8</span></nobr></DIV>
<DIV style="position:absolute;top:741;left:677"><nobr><span class="ft7">1</span></nobr></DIV>
<DIV style="position:absolute;top:582;left:794"><nobr><span class="ft7">AI</span></nobr></DIV>
<DIV style="position:absolute;top:590;left:787"><nobr><span class="ft7">Astronomy</span></nobr></DIV>
<DIV style="position:absolute;top:599;left:781"><nobr><span class="ft7">Basketball</span></nobr></DIV>
<DIV style="position:absolute;top:608;left:774"><nobr><span class="ft7">Cancer</span></nobr></DIV>
<DIV style="position:absolute;top:618;left:767"><nobr><span class="ft7">Chess</span></nobr></DIV>
<DIV style="position:absolute;top:627;left:761"><nobr><span class="ft7">Composers</span></nobr></DIV>
<DIV style="position:absolute;top:637;left:753"><nobr><span class="ft7">FlyFishing</span></nobr></DIV>
<DIV style="position:absolute;top:647;left:746"><nobr><span class="ft7">FolkDance</span></nobr></DIV>
<DIV style="position:absolute;top:657;left:739"><nobr><span class="ft7">Horses</span></nobr></DIV>
<DIV style="position:absolute;top:667;left:731"><nobr><span class="ft7">IceHockey</span></nobr></DIV>
<DIV style="position:absolute;top:678;left:724"><nobr><span class="ft7">Kayaking</span></nobr></DIV>
<DIV style="position:absolute;top:688;left:716"><nobr><span class="ft7">Linux</span></nobr></DIV>
<DIV style="position:absolute;top:699;left:708"><nobr><span class="ft7">Meteorology</span></nobr></DIV>
<DIV style="position:absolute;top:711;left:699"><nobr><span class="ft7">Soups</span></nobr></DIV>
<DIV style="position:absolute;top:722;left:691"><nobr><span class="ft7">Tobacco</span></nobr></DIV>
<DIV style="position:absolute;top:664;left:515"><nobr><span class="ft7">10</span></nobr></DIV>
<DIV style="position:absolute;top:629;left:505"><nobr><span class="ft7">100</span></nobr></DIV>
<DIV style="position:absolute;top:592;left:495"><nobr><span class="ft7">1000</span></nobr></DIV>
<DIV style="position:absolute;top:552;left:485"><nobr><span class="ft7">10000</span></nobr></DIV>
<DIV style="position:absolute;top:509;left:475"><nobr><span class="ft7">100000</span></nobr></DIV>
<DIV style="position:absolute;top:494;left:437"><nobr><span class="ft7">Expected #pages</span></nobr></DIV>
<DIV style="position:absolute;top:725;left:516"><nobr><span class="ft7">Relevance probability</span></nobr></DIV>
<DIV style="position:absolute;top:757;left:475"><nobr><span class="ft12">Figure 5: All of the baseline classifiers have harvest rates<br>between 0.25 and 0.6, and all show strongly bimodal<br>relevance score distribution: most of the pages fetched are<br>very relevant or not at all.</span></nobr></DIV>
<DIV style="position:absolute;top:846;left:498"><nobr><span class="ft4">It is important to notice that the improvement in</span></nobr></DIV>
<DIV style="position:absolute;top:862;left:475"><nobr><span class="ft12">accuracy is almost entirely because with increasing number<br>of available features, the apprentice can reject negative<br>(low relevance) instances more accurately, although the<br>accuracy for positive instances decreases slightly. Rejecting<br>unpromising outlinks is critical to the success of the<br>enhanced crawler. Therefore we would rather lose a little<br>accuracy for positive instances rather than do poorly on the<br>negative instances. We therefore chose d</span></nobr></DIV>
<DIV style="position:absolute;top:976;left:724"><nobr><span class="ft9">max</span></nobr></DIV>
<DIV style="position:absolute;top:971;left:750"><nobr><span class="ft4">to be either 4</span></nobr></DIV>
<DIV style="position:absolute;top:987;left:475"><nobr><span class="ft4">or 5 for all the experiments.</span></nobr></DIV>
<DIV style="position:absolute;top:1003;left:498"><nobr><span class="ft4">We verified that adding offset information to text tokens</span></nobr></DIV>
<DIV style="position:absolute;top:1019;left:475"><nobr><span class="ft12">was better than simply using plain text near the link <A href="25.html#12">[8].<br></a>One sample result is shown in Figure <A href="25.html#8">7.</a></span></nobr></DIV>
<DIV style="position:absolute;top:1034;left:741"><nobr><span class="ft4">The apprentice</span></nobr></DIV>
<DIV style="position:absolute;top:1050;left:475"><nobr><span class="ft4">accuracy decreases with d</span></nobr></DIV>
<DIV style="position:absolute;top:1055;left:634"><nobr><span class="ft9">max</span></nobr></DIV>
<DIV style="position:absolute;top:1050;left:660"><nobr><span class="ft4">if only text is used, whereas</span></nobr></DIV>
<DIV style="position:absolute;top:1066;left:475"><nobr><span class="ft4">it increases if offset information is provided. This highlights</span></nobr></DIV>
<DIV style="position:absolute;top:1121;left:447"><nobr><span class="ft11">154</span></nobr></DIV>
</DIV>
<!-- Page 8 -->
<a name="8"></a>
<DIV style="position:relative;width:917;height:1187;">
<STYLE type="text/css">
<!--
	.ft32{font-size:7px;line-height:-8px;font-family:Helvetica;color:#000000;}
	.ft33{font-size:7px;line-height:-6px;font-family:Helvetica;color:#000000;}
	.ft34{font-size:7px;line-height:-4px;font-family:Helvetica;color:#000000;}
	.ft35{font-size:7px;line-height:-3px;font-family:Helvetica;color:#000000;}
	.ft36{font-size:6px;line-height:-7px;font-family:Helvetica;color:#000000;}
	.ft37{font-size:6px;line-height:-5px;font-family:Helvetica;color:#000000;}
	.ft38{font-size:6px;line-height:-4px;font-family:Helvetica;color:#000000;}
	.ft39{font-size:6px;line-height:-2px;font-family:Helvetica;color:#000000;}
	.ft40{font-size:6px;line-height:10px;font-family:Helvetica;color:#000000;}
	.ft41{font-size:5px;line-height:-2px;font-family:Helvetica;color:#000000;}
	.ft42{font-size:5px;line-height:-4px;font-family:Helvetica;color:#000000;}
	.ft43{font-size:5px;line-height:-6px;font-family:Helvetica;color:#000000;}
-->
</STYLE>
<IMG width="917" height="1187" src="25008.png" alt="background image">
<DIV style="position:absolute;top:83;left:261"><nobr><span class="ft7">Chess</span></nobr></DIV>
<DIV style="position:absolute;top:273;left:155"><nobr><span class="ft7">65</span></nobr></DIV>
<DIV style="position:absolute;top:247;left:155"><nobr><span class="ft7">70</span></nobr></DIV>
<DIV style="position:absolute;top:222;left:155"><nobr><span class="ft7">75</span></nobr></DIV>
<DIV style="position:absolute;top:196;left:155"><nobr><span class="ft7">80</span></nobr></DIV>
<DIV style="position:absolute;top:170;left:155"><nobr><span class="ft7">85</span></nobr></DIV>
<DIV style="position:absolute;top:145;left:155"><nobr><span class="ft7">90</span></nobr></DIV>
<DIV style="position:absolute;top:119;left:155"><nobr><span class="ft7">95</span></nobr></DIV>
<DIV style="position:absolute;top:93;left:150"><nobr><span class="ft7">100</span></nobr></DIV>
<DIV style="position:absolute;top:286;left:170"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:286;left:222"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:286;left:274"><nobr><span class="ft7">4</span></nobr></DIV>
<DIV style="position:absolute;top:286;left:327"><nobr><span class="ft7">6</span></nobr></DIV>
<DIV style="position:absolute;top:286;left:379"><nobr><span class="ft7">8</span></nobr></DIV>
<DIV style="position:absolute;top:295;left:263"><nobr><span class="ft7">d_max</span></nobr></DIV>
<DIV style="position:absolute;top:203;left:144"><nobr><span class="ft34">%<br>A<br>c<br>c<br>u<br>r<br>a<br>c<br>y</span></nobr></DIV>
<DIV style="position:absolute;top:206;left:333"><nobr><span class="ft7">Negative</span></nobr></DIV>
<DIV style="position:absolute;top:220;left:333"><nobr><span class="ft7">Positive</span></nobr></DIV>
<DIV style="position:absolute;top:233;left:333"><nobr><span class="ft7">Average</span></nobr></DIV>
<DIV style="position:absolute;top:314;left:273"><nobr><span class="ft7">AI</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:150"><nobr><span class="ft7">65</span></nobr></DIV>
<DIV style="position:absolute;top:468;left:150"><nobr><span class="ft7">70</span></nobr></DIV>
<DIV style="position:absolute;top:431;left:150"><nobr><span class="ft7">75</span></nobr></DIV>
<DIV style="position:absolute;top:394;left:150"><nobr><span class="ft7">80</span></nobr></DIV>
<DIV style="position:absolute;top:357;left:150"><nobr><span class="ft7">85</span></nobr></DIV>
<DIV style="position:absolute;top:320;left:150"><nobr><span class="ft7">90</span></nobr></DIV>
<DIV style="position:absolute;top:519;left:165"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:519;left:218"><nobr><span class="ft7">2</span></nobr></DIV>
<DIV style="position:absolute;top:519;left:271"><nobr><span class="ft7">4</span></nobr></DIV>
<DIV style="position:absolute;top:519;left:324"><nobr><span class="ft7">6</span></nobr></DIV>
<DIV style="position:absolute;top:519;left:377"><nobr><span class="ft7">8</span></nobr></DIV>
<DIV style="position:absolute;top:526;left:260"><nobr><span class="ft7">d_max</span></nobr></DIV>
<DIV style="position:absolute;top:433;left:144"><nobr><span class="ft34">%<br>A<br>c<br>c<br>u<br>r<br>a<br>c<br>y</span></nobr></DIV>
<DIV style="position:absolute;top:453;left:332"><nobr><span class="ft7">Negative</span></nobr></DIV>
<DIV style="position:absolute;top:467;left:332"><nobr><span class="ft7">Positive</span></nobr></DIV>
<DIV style="position:absolute;top:480;left:332"><nobr><span class="ft7">Average</span></nobr></DIV>
<DIV style="position:absolute;top:546;left:81"><nobr><span class="ft12">Figure 6: There is visible improvement in the accuracy<br>of the apprentice if d</span></nobr></DIV>
<DIV style="position:absolute;top:566;left:215"><nobr><span class="ft9">max</span></nobr></DIV>
<DIV style="position:absolute;top:562;left:243"><nobr><span class="ft4">is made larger, up to about 5­</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:81"><nobr><span class="ft12">7 depending on topic. The effect is more pronounced on<br>the the ability to correctly reject negative (low relevance)<br>outlink instances.</span></nobr></DIV>
<DIV style="position:absolute;top:609;left:202"><nobr><span class="ft4">`Average' is the microaverage over all</span></nobr></DIV>
<DIV style="position:absolute;top:624;left:81"><nobr><span class="ft12">test instances for the apprentice, not the arithmetic mean<br>of `Positive' and `Negative'.</span></nobr></DIV>
<DIV style="position:absolute;top:670;left:255"><nobr><span class="ft25">AI</span></nobr></DIV>
<DIV style="position:absolute;top:858;left:147"><nobr><span class="ft25">76</span></nobr></DIV>
<DIV style="position:absolute;top:822;left:147"><nobr><span class="ft25">78</span></nobr></DIV>
<DIV style="position:absolute;top:785;left:147"><nobr><span class="ft25">80</span></nobr></DIV>
<DIV style="position:absolute;top:749;left:147"><nobr><span class="ft25">82</span></nobr></DIV>
<DIV style="position:absolute;top:712;left:147"><nobr><span class="ft25">84</span></nobr></DIV>
<DIV style="position:absolute;top:676;left:147"><nobr><span class="ft25">86</span></nobr></DIV>
<DIV style="position:absolute;top:870;left:160"><nobr><span class="ft25">0</span></nobr></DIV>
<DIV style="position:absolute;top:870;left:187"><nobr><span class="ft25">1</span></nobr></DIV>
<DIV style="position:absolute;top:870;left:215"><nobr><span class="ft25">2</span></nobr></DIV>
<DIV style="position:absolute;top:870;left:242"><nobr><span class="ft25">3</span></nobr></DIV>
<DIV style="position:absolute;top:870;left:270"><nobr><span class="ft25">4</span></nobr></DIV>
<DIV style="position:absolute;top:870;left:297"><nobr><span class="ft25">5</span></nobr></DIV>
<DIV style="position:absolute;top:870;left:325"><nobr><span class="ft25">6</span></nobr></DIV>
<DIV style="position:absolute;top:870;left:352"><nobr><span class="ft25">7</span></nobr></DIV>
<DIV style="position:absolute;top:870;left:380"><nobr><span class="ft25">8</span></nobr></DIV>
<DIV style="position:absolute;top:880;left:260"><nobr><span class="ft25">d_max</span></nobr></DIV>
<DIV style="position:absolute;top:795;left:142"><nobr><span class="ft38">%<br>A<br>c<br>c<br>u<br>r<br>a<br>c<br>y</span></nobr></DIV>
<DIV style="position:absolute;top:688;left:206"><nobr><span class="ft40">Text<br>Offset</span></nobr></DIV>
<DIV style="position:absolute;top:897;left:81"><nobr><span class="ft12">Figure 7: Encoding DOM offset information with textual<br>features boosts the accuracy of the apprentice substantially.</span></nobr></DIV>
<DIV style="position:absolute;top:955;left:81"><nobr><span class="ft4">the importance of designing proper features.</span></nobr></DIV>
<DIV style="position:absolute;top:971;left:103"><nobr><span class="ft4">To corroborate the useful ranges of d</span></nobr></DIV>
<DIV style="position:absolute;top:975;left:347"><nobr><span class="ft9">max</span></nobr></DIV>
<DIV style="position:absolute;top:971;left:376"><nobr><span class="ft4">above, we</span></nobr></DIV>
<DIV style="position:absolute;top:986;left:81"><nobr><span class="ft12">compared the value of average mutual information gain for<br>terms found at various distances from the target HREF.<br>The experiments revealed that the information gain of terms<br>found further away from the target HREF was generally<br>lower than those that were found closer, but this reduction<br>was not monotonic. For instance, the average information</span></nobr></DIV>
<DIV style="position:absolute;top:82;left:659"><nobr><span class="ft19">Chess</span></nobr></DIV>
<DIV style="position:absolute;top:242;left:537"><nobr><span class="ft19">0.00002</span></nobr></DIV>
<DIV style="position:absolute;top:225;left:537"><nobr><span class="ft19">0.00004</span></nobr></DIV>
<DIV style="position:absolute;top:208;left:537"><nobr><span class="ft19">0.00006</span></nobr></DIV>
<DIV style="position:absolute;top:190;left:537"><nobr><span class="ft19">0.00008</span></nobr></DIV>
<DIV style="position:absolute;top:173;left:541"><nobr><span class="ft19">0.0001</span></nobr></DIV>
<DIV style="position:absolute;top:156;left:537"><nobr><span class="ft19">0.00012</span></nobr></DIV>
<DIV style="position:absolute;top:139;left:537"><nobr><span class="ft19">0.00014</span></nobr></DIV>
<DIV style="position:absolute;top:122;left:537"><nobr><span class="ft19">0.00016</span></nobr></DIV>
<DIV style="position:absolute;top:105;left:537"><nobr><span class="ft19">0.00018</span></nobr></DIV>
<DIV style="position:absolute;top:88;left:541"><nobr><span class="ft19">0.0002</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:567"><nobr><span class="ft19">-8</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:592"><nobr><span class="ft19">-6</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:618"><nobr><span class="ft19">-4</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:644"><nobr><span class="ft19">-2</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:671"><nobr><span class="ft19">0</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:697"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:723"><nobr><span class="ft19">4</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:749"><nobr><span class="ft19">6</span></nobr></DIV>
<DIV style="position:absolute;top:253;left:774"><nobr><span class="ft19">8</span></nobr></DIV>
<DIV style="position:absolute;top:261;left:671"><nobr><span class="ft19">d</span></nobr></DIV>
<DIV style="position:absolute;top:176;left:535"><nobr><span class="ft42">I<br>n<br>f<br>o<br>g<br>a<br>i<br>n</span></nobr></DIV>
<DIV style="position:absolute;top:106;left:731"><nobr><span class="ft19">d_max=8</span></nobr></DIV>
<DIV style="position:absolute;top:117;left:731"><nobr><span class="ft19">d_max=5</span></nobr></DIV>
<DIV style="position:absolute;top:129;left:731"><nobr><span class="ft19">d_max=4</span></nobr></DIV>
<DIV style="position:absolute;top:140;left:731"><nobr><span class="ft19">d_max=3</span></nobr></DIV>
<DIV style="position:absolute;top:276;left:676"><nobr><span class="ft19">AI</span></nobr></DIV>
<DIV style="position:absolute;top:435;left:540"><nobr><span class="ft19">4.00E-05</span></nobr></DIV>
<DIV style="position:absolute;top:410;left:540"><nobr><span class="ft19">5.00E-05</span></nobr></DIV>
<DIV style="position:absolute;top:384;left:540"><nobr><span class="ft19">6.00E-05</span></nobr></DIV>
<DIV style="position:absolute;top:359;left:540"><nobr><span class="ft19">7.00E-05</span></nobr></DIV>
<DIV style="position:absolute;top:333;left:540"><nobr><span class="ft19">8.00E-05</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:540"><nobr><span class="ft19">9.00E-05</span></nobr></DIV>
<DIV style="position:absolute;top:282;left:540"><nobr><span class="ft19">1.00E-04</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:574"><nobr><span class="ft19">-8</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:599"><nobr><span class="ft19">-6</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:623"><nobr><span class="ft19">-4</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:648"><nobr><span class="ft19">-2</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:674"><nobr><span class="ft19">0</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:699"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:724"><nobr><span class="ft19">4</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:748"><nobr><span class="ft19">6</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:773"><nobr><span class="ft19">8</span></nobr></DIV>
<DIV style="position:absolute;top:453;left:674"><nobr><span class="ft19">d</span></nobr></DIV>
<DIV style="position:absolute;top:371;left:537"><nobr><span class="ft42">I<br>n<br>f<br>o<br>G<br>a<br>i<br>n</span></nobr></DIV>
<DIV style="position:absolute;top:298;left:731"><nobr><span class="ft19">d_max=8</span></nobr></DIV>
<DIV style="position:absolute;top:310;left:731"><nobr><span class="ft19">d_max=5</span></nobr></DIV>
<DIV style="position:absolute;top:321;left:731"><nobr><span class="ft19">d_max=4</span></nobr></DIV>
<DIV style="position:absolute;top:333;left:731"><nobr><span class="ft19">d_max=3</span></nobr></DIV>
<DIV style="position:absolute;top:470;left:475"><nobr><span class="ft4">Figure 8:</span></nobr></DIV>
<DIV style="position:absolute;top:470;left:554"><nobr><span class="ft4">Information gain variation plotted against</span></nobr></DIV>
<DIV style="position:absolute;top:486;left:475"><nobr><span class="ft12">distance from the target HREF for various DOM window<br>sizes. We observe that the information gain is insensitive to<br>d</span></nobr></DIV>
<DIV style="position:absolute;top:522;left:482"><nobr><span class="ft9">max</span></nobr></DIV>
<DIV style="position:absolute;top:517;left:503"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:558;left:475"><nobr><span class="ft4">gain at d =</span></nobr></DIV>
<DIV style="position:absolute;top:558;left:545"><nobr><span class="ft4">-2 was higher than that at d = -1; see Figure <A href="25.html#8">8.</a></span></nobr></DIV>
<DIV style="position:absolute;top:574;left:475"><nobr><span class="ft12">For each DOM window size, we observe that the information<br>gain varies in a sawtooth fashion; this intriguing observation<br>is explained shortly. The average information gain settled<br>to an almost constant value after distance of 5 from the<br>target URL. We were initially concerned that to keep the<br>computation cost manageable, we would need some cap on<br>d</span></nobr></DIV>
<DIV style="position:absolute;top:673;left:482"><nobr><span class="ft9">max</span></nobr></DIV>
<DIV style="position:absolute;top:668;left:510"><nobr><span class="ft4">even while measuring information gain, but luckily,</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:475"><nobr><span class="ft4">the variation of information gain is insensitive to d</span></nobr></DIV>
<DIV style="position:absolute;top:689;left:791"><nobr><span class="ft9">max</span></nobr></DIV>
<DIV style="position:absolute;top:684;left:812"><nobr><span class="ft4">, as</span></nobr></DIV>
<DIV style="position:absolute;top:700;left:475"><nobr><span class="ft12">Figure <A href="25.html#8">8 </a>shows. These observations made our final choice of<br>d</span></nobr></DIV>
<DIV style="position:absolute;top:720;left:482"><nobr><span class="ft9">max</span></nobr></DIV>
<DIV style="position:absolute;top:715;left:508"><nobr><span class="ft4">easy.</span></nobr></DIV>
<DIV style="position:absolute;top:731;left:498"><nobr><span class="ft4">In a bid to explain the occurrence of the unexpected</span></nobr></DIV>
<DIV style="position:absolute;top:747;left:475"><nobr><span class="ft4">saw-tooth form in Figure <A href="25.html#8">8 </a>we measured the rate </span></nobr></DIV>
<DIV style="position:absolute;top:752;left:797"><nobr><span class="ft9">t,d</span></nobr></DIV>
<DIV style="position:absolute;top:747;left:822"><nobr><span class="ft4">at</span></nobr></DIV>
<DIV style="position:absolute;top:762;left:475"><nobr><span class="ft12">which term t occurred at offset d, relative to the total count<br>of all terms occurring at offset d. (They are roughly the<br>multinomial naive Bayes term probability parameters.) For<br>fixed values of d, we calculated the sum of  values of terms<br>found at those offsets from the target HREF. Figure <A href="25.html#9">9(a)<br></a>shows the plot of these sums to the distance(d) for various<br>categories. The  values showed a general decrease as the<br>distances from the target HREF increased, but this decrease,<br>like that of information gain, was not monotonic. The <br>values of the terms at odd numbered distances from the<br>target HREF were found to be lower than those of the<br>terms present at the even positions. For instance, the sum<br>of  values of terms occurring at distance</span></nobr></DIV>
<DIV style="position:absolute;top:950;left:740"><nobr><span class="ft4">-2 were higher</span></nobr></DIV>
<DIV style="position:absolute;top:966;left:475"><nobr><span class="ft4">than that of terms at position</span></nobr></DIV>
<DIV style="position:absolute;top:966;left:671"><nobr><span class="ft4">-1. This observation was</span></nobr></DIV>
<DIV style="position:absolute;top:982;left:475"><nobr><span class="ft28">explained by observing the HTML tags that are present<br>at various distances from the target HREF. We observed<br>that tags located at odd d are mostly non-text tags, thanks<br>to authoring idioms such as &lt;li&gt;&lt;a...&gt;&lt;li&gt;&lt;a...&gt; and<br>&lt;a...&gt;&lt;br&gt;&lt;a...&gt;&lt;br&gt; etc.</span></nobr></DIV>
<DIV style="position:absolute;top:1045;left:661"><nobr><span class="ft4">A plot of the frequency of</span></nobr></DIV>
<DIV style="position:absolute;top:1061;left:475"><nobr><span class="ft4">HTML tags against the distance from the HREF at which</span></nobr></DIV>
<DIV style="position:absolute;top:1121;left:447"><nobr><span class="ft11">155</span></nobr></DIV>
</DIV>
<!-- Page 9 -->
<a name="9"></a>
<DIV style="position:relative;width:917;height:1187;">
<STYLE type="text/css">
<!--
	.ft44{font-size:-1px;font-family:Times;color:#000000;}
	.ft45{font-size:5px;line-height:10px;font-family:Helvetica;color:#000000;}
	.ft46{font-size:5px;line-height:-5px;font-family:Helvetica;color:#000000;}
	.ft47{font-size:5px;line-height:-3px;font-family:Helvetica;color:#000000;}
	.ft48{font-size:5px;line-height:8px;font-family:Helvetica;color:#000000;}
-->
</STYLE>
<IMG width="917" height="1187" src="25009.png" alt="background image">
<DIV style="position:absolute;top:261;left:164"><nobr><span class="ft19">0.02</span></nobr></DIV>
<DIV style="position:absolute;top:241;left:164"><nobr><span class="ft19">0.04</span></nobr></DIV>
<DIV style="position:absolute;top:222;left:164"><nobr><span class="ft19">0.06</span></nobr></DIV>
<DIV style="position:absolute;top:202;left:164"><nobr><span class="ft19">0.08</span></nobr></DIV>
<DIV style="position:absolute;top:183;left:168"><nobr><span class="ft19">0.1</span></nobr></DIV>
<DIV style="position:absolute;top:163;left:164"><nobr><span class="ft19">0.12</span></nobr></DIV>
<DIV style="position:absolute;top:144;left:164"><nobr><span class="ft19">0.14</span></nobr></DIV>
<DIV style="position:absolute;top:124;left:164"><nobr><span class="ft19">0.16</span></nobr></DIV>
<DIV style="position:absolute;top:104;left:164"><nobr><span class="ft19">0.18</span></nobr></DIV>
<DIV style="position:absolute;top:85;left:168"><nobr><span class="ft19">0.2</span></nobr></DIV>
<DIV style="position:absolute;top:272;left:181"><nobr><span class="ft19">-5</span></nobr></DIV>
<DIV style="position:absolute;top:272;left:199"><nobr><span class="ft19">-4</span></nobr></DIV>
<DIV style="position:absolute;top:272;left:216"><nobr><span class="ft19">-3</span></nobr></DIV>
<DIV style="position:absolute;top:272;left:234"><nobr><span class="ft19">-2</span></nobr></DIV>
<DIV style="position:absolute;top:272;left:251"><nobr><span class="ft19">-1</span></nobr></DIV>
<DIV style="position:absolute;top:272;left:270"><nobr><span class="ft19">0</span></nobr></DIV>
<DIV style="position:absolute;top:272;left:288"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:272;left:306"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:272;left:323"><nobr><span class="ft19">3</span></nobr></DIV>
<DIV style="position:absolute;top:272;left:341"><nobr><span class="ft19">4</span></nobr></DIV>
<DIV style="position:absolute;top:272;left:359"><nobr><span class="ft19">5</span></nobr></DIV>
<DIV style="position:absolute;top:268;left:172"><nobr><span class="ft19">d</span></nobr></DIV>
<DIV style="position:absolute;top:189;left:159"><nobr><span class="ft42">T<br>h<br>e<br>t<br>a<br>_<br>{<br>t<br>,<br>d<br>}</span></nobr></DIV>
<DIV style="position:absolute;top:84;left:212"><nobr><span class="ft45">AI<br>Chess<br>Horses<br>Cancer<br>IceHockey<br>Linux<br>Bball+<br>Bball-</span></nobr></DIV>
<DIV style="position:absolute;top:286;left:208"><nobr><span class="ft19">Tags at various DOM offsets</span></nobr></DIV>
<DIV style="position:absolute;top:457;left:154"><nobr><span class="ft19">0</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:141"><nobr><span class="ft19">1000</span></nobr></DIV>
<DIV style="position:absolute;top:421;left:141"><nobr><span class="ft19">2000</span></nobr></DIV>
<DIV style="position:absolute;top:403;left:141"><nobr><span class="ft19">3000</span></nobr></DIV>
<DIV style="position:absolute;top:384;left:141"><nobr><span class="ft19">4000</span></nobr></DIV>
<DIV style="position:absolute;top:366;left:141"><nobr><span class="ft19">5000</span></nobr></DIV>
<DIV style="position:absolute;top:348;left:141"><nobr><span class="ft19">6000</span></nobr></DIV>
<DIV style="position:absolute;top:330;left:141"><nobr><span class="ft19">7000</span></nobr></DIV>
<DIV style="position:absolute;top:312;left:141"><nobr><span class="ft19">8000</span></nobr></DIV>
<DIV style="position:absolute;top:293;left:141"><nobr><span class="ft19">9000</span></nobr></DIV>
<DIV style="position:absolute;top:468;left:160"><nobr><span class="ft19">-5</span></nobr></DIV>
<DIV style="position:absolute;top:468;left:177"><nobr><span class="ft19">-4</span></nobr></DIV>
<DIV style="position:absolute;top:468;left:194"><nobr><span class="ft19">-3</span></nobr></DIV>
<DIV style="position:absolute;top:468;left:210"><nobr><span class="ft19">-2</span></nobr></DIV>
<DIV style="position:absolute;top:468;left:227"><nobr><span class="ft19">-1</span></nobr></DIV>
<DIV style="position:absolute;top:468;left:245"><nobr><span class="ft19">0</span></nobr></DIV>
<DIV style="position:absolute;top:468;left:262"><nobr><span class="ft19">1</span></nobr></DIV>
<DIV style="position:absolute;top:468;left:279"><nobr><span class="ft19">2</span></nobr></DIV>
<DIV style="position:absolute;top:468;left:295"><nobr><span class="ft19">3</span></nobr></DIV>
<DIV style="position:absolute;top:468;left:312"><nobr><span class="ft19">4</span></nobr></DIV>
<DIV style="position:absolute;top:468;left:329"><nobr><span class="ft19">5</span></nobr></DIV>
<DIV style="position:absolute;top:468;left:345"><nobr><span class="ft19">d</span></nobr></DIV>
<DIV style="position:absolute;top:413;left:139"><nobr><span class="ft42">N<br>u<br>m<br>b<br>e<br>r<br>o<br>f<br>o<br>c<br>c<br>u<br>r<br>r<br>e<br>n<br>c<br>e<br>s</span></nobr></DIV>
<DIV style="position:absolute;top:306;left:349"><nobr><span class="ft23">font<br>td<br>img<br>b<br>br<br>p<br>tr<br>li<br>comment<br>div<br>table<br>center<br>i<br>span<br>hr</span></nobr></DIV>
<DIV style="position:absolute;top:485;left:81"><nobr><span class="ft12">Figure 9: Variation of (a) relative term frequencies and<br>(b) frequencies of HTML tags plotted against d.</span></nobr></DIV>
<DIV style="position:absolute;top:544;left:81"><nobr><span class="ft12">they were found is shown in Figure <A href="25.html#9">9(b). </a>(The &lt;a...&gt; tag<br>obviously has the highest frequency and has been removed<br>for clarity.)</span></nobr></DIV>
<DIV style="position:absolute;top:591;left:103"><nobr><span class="ft4">These were important DOM idioms, spanning many</span></nobr></DIV>
<DIV style="position:absolute;top:607;left:81"><nobr><span class="ft12">diverse Web sites and authoring styles, that we did not<br>anticipate ahead of time.</span></nobr></DIV>
<DIV style="position:absolute;top:623;left:262"><nobr><span class="ft4">Learning to recognize these</span></nobr></DIV>
<DIV style="position:absolute;top:638;left:81"><nobr><span class="ft12">idioms was valuable for boosting the harvest of the enhanced<br>crawler. Yet, it would be unreasonable for the user-supplied<br>baseline black-box predicate or learner to capture crawling<br>strategies at such a low level.</span></nobr></DIV>
<DIV style="position:absolute;top:685;left:288"><nobr><span class="ft4">This is the ideal job of</span></nobr></DIV>
<DIV style="position:absolute;top:701;left:81"><nobr><span class="ft12">the apprentice. The apprentice took only 3­10 minutes<br>to train on its (u, v) instances from scratch, despite a<br>simple implementation that wrote a small file to disk for<br>each instance of the apprentice. Contrast this with several<br>hours taken by the baseline learner to learn general term<br>distribution for topics.</span></nobr></DIV>
<DIV style="position:absolute;top:815;left:81"><nobr><span class="ft17">3.5</span></nobr></DIV>
<DIV style="position:absolute;top:815;left:120"><nobr><span class="ft26">Crawling with the apprentice trained<br>off-line</span></nobr></DIV>
<DIV style="position:absolute;top:858;left:81"><nobr><span class="ft12">In this section we subject the apprentice to a "field test" as<br>part of the crawler, as shown in Figure <A href="25.html#2">2. </a>To do this we<br>follow these steps:</span></nobr></DIV>
<DIV style="position:absolute;top:918;left:100"><nobr><span class="ft4">1. Fix a topic and start the baseline crawler from all</span></nobr></DIV>
<DIV style="position:absolute;top:933;left:118"><nobr><span class="ft4">example URLs available from the given topic.</span></nobr></DIV>
<DIV style="position:absolute;top:955;left:100"><nobr><span class="ft4">2. Run the baseline crawler until roughly 20000­25000</span></nobr></DIV>
<DIV style="position:absolute;top:971;left:118"><nobr><span class="ft4">pages have been fetched.</span></nobr></DIV>
<DIV style="position:absolute;top:992;left:100"><nobr><span class="ft4">3. For all pages (u, v) such that both u and v have</span></nobr></DIV>
<DIV style="position:absolute;top:1008;left:118"><nobr><span class="ft12">been fetched by the baseline crawler, prepare an<br>instance from (u, v) and add to the training set of<br>the apprentice.</span></nobr></DIV>
<DIV style="position:absolute;top:1061;left:100"><nobr><span class="ft4">4. Train the apprentice. Set a suitable value for d</span></nobr></DIV>
<DIV style="position:absolute;top:1066;left:403"><nobr><span class="ft9">max</span></nobr></DIV>
<DIV style="position:absolute;top:1061;left:424"><nobr><span class="ft4">.</span></nobr></DIV>
<DIV style="position:absolute;top:298;left:548"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:234;left:531"><nobr><span class="ft7">2000</span></nobr></DIV>
<DIV style="position:absolute;top:170;left:531"><nobr><span class="ft7">4000</span></nobr></DIV>
<DIV style="position:absolute;top:107;left:531"><nobr><span class="ft7">6000</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:557"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:592"><nobr><span class="ft7">2000</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:636"><nobr><span class="ft7">4000</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:680"><nobr><span class="ft7">6000</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:724"><nobr><span class="ft7">8000</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:765"><nobr><span class="ft7">10000</span></nobr></DIV>
<DIV style="position:absolute;top:247;left:522"><nobr><span class="ft7">Expected #pages lost</span></nobr></DIV>
<DIV style="position:absolute;top:204;left:515"><nobr><span class="ft44"> </span></nobr></DIV>
<DIV style="position:absolute;top:323;left:635"><nobr><span class="ft7">#Pages fetched</span></nobr></DIV>
<DIV style="position:absolute;top:92;left:640"><nobr><span class="ft7">Folk Dancing</span></nobr></DIV>
<DIV style="position:absolute;top:115;left:587"><nobr><span class="ft7">Baseline</span></nobr></DIV>
<DIV style="position:absolute;top:125;left:578"><nobr><span class="ft7">Apprentice</span></nobr></DIV>
<DIV style="position:absolute;top:554;left:548"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:477;left:531"><nobr><span class="ft7">4000</span></nobr></DIV>
<DIV style="position:absolute;top:400;left:531"><nobr><span class="ft7">8000</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:557"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:587"><nobr><span class="ft7">4000</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:625"><nobr><span class="ft7">8000</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:660"><nobr><span class="ft7">12000</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:698"><nobr><span class="ft7">16000</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:736"><nobr><span class="ft7">20000</span></nobr></DIV>
<DIV style="position:absolute;top:502;left:522"><nobr><span class="ft7">Expected #pages lost</span></nobr></DIV>
<DIV style="position:absolute;top:460;left:515"><nobr><span class="ft44"> </span></nobr></DIV>
<DIV style="position:absolute;top:579;left:635"><nobr><span class="ft7">#Pages fetched</span></nobr></DIV>
<DIV style="position:absolute;top:347;left:645"><nobr><span class="ft7">Ice Hockey</span></nobr></DIV>
<DIV style="position:absolute;top:371;left:587"><nobr><span class="ft7">Baseline</span></nobr></DIV>
<DIV style="position:absolute;top:381;left:578"><nobr><span class="ft7">Apprentice</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:475"><nobr><span class="ft4">Figure 10:</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:557"><nobr><span class="ft4">Guidance from the apprentice significantly</span></nobr></DIV>
<DIV style="position:absolute;top:611;left:475"><nobr><span class="ft4">reduces the loss rate of the focused crawler.</span></nobr></DIV>
<DIV style="position:absolute;top:651;left:494"><nobr><span class="ft4">5. Start the enhanced crawler from the same set of pages</span></nobr></DIV>
<DIV style="position:absolute;top:667;left:513"><nobr><span class="ft4">that the baseline crawler had started from.</span></nobr></DIV>
<DIV style="position:absolute;top:688;left:494"><nobr><span class="ft4">6. Run the enhanced crawler to fetch about the same</span></nobr></DIV>
<DIV style="position:absolute;top:704;left:513"><nobr><span class="ft4">number of pages as the baseline crawler.</span></nobr></DIV>
<DIV style="position:absolute;top:725;left:494"><nobr><span class="ft4">7. Compare the loss rates of the two crawlers.</span></nobr></DIV>
<DIV style="position:absolute;top:753;left:498"><nobr><span class="ft4">Unlike with the reinforcement learner studied by Rennie</span></nobr></DIV>
<DIV style="position:absolute;top:768;left:475"><nobr><span class="ft12">and McCallum, we have no predetermined universe of URLs<br>which constitute the relevant set; our crawler must go<br>forth into the open Web and collect relevant pages from<br>an unspecified number of sites. Therefore, measuring recall<br>w.r.t. the baseline is not very meaningful (although we do<br>report such numbers, for completeness, in</span></nobr></DIV>
<DIV style="position:absolute;top:846;left:727"><nobr><span class="ft4"><A href="25.html#10">§3.6). </a>Instead, we</span></nobr></DIV>
<DIV style="position:absolute;top:863;left:475"><nobr><span class="ft12">measure the loss (the number of pages fetched which had to<br>be thrown away owing to poor relevance) at various epochs<br>in the crawl, where time is measured as the number of pages<br>fetched (to elide fluctuating network delay and bandwidth).<br>At epoch n, if the pages fetched are v</span></nobr></DIV>
<DIV style="position:absolute;top:930;left:694"><nobr><span class="ft9">1</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:700"><nobr><span class="ft4">, . . . , v</span></nobr></DIV>
<DIV style="position:absolute;top:930;left:737"><nobr><span class="ft9">n</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:745"><nobr><span class="ft4">, then the total</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:475"><nobr><span class="ft4">expected loss is (1/n)</span></nobr></DIV>
<DIV style="position:absolute;top:949;left:624"><nobr><span class="ft9">i</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:629"><nobr><span class="ft4">(1</span></nobr></DIV>
<DIV style="position:absolute;top:940;left:644"><nobr><span class="ft4">- Pr(c</span></nobr></DIV>
<DIV style="position:absolute;top:938;left:684"><nobr><span class="ft9"></span></nobr></DIV>
<DIV style="position:absolute;top:940;left:691"><nobr><span class="ft4">|v</span></nobr></DIV>
<DIV style="position:absolute;top:946;left:701"><nobr><span class="ft9">i</span></nobr></DIV>
<DIV style="position:absolute;top:941;left:706"><nobr><span class="ft4">)).</span></nobr></DIV>
<DIV style="position:absolute;top:957;left:498"><nobr><span class="ft4">Figure <A href="25.html#9">10 </a>shows the loss plotted against the number of</span></nobr></DIV>
<DIV style="position:absolute;top:972;left:475"><nobr><span class="ft12">pages crawled for two topics: Folk dancing and Ice hockey.<br>The behavior for Folk dancing is typical; Ice hockey is<br>one of the best examples. In both cases, the loss goes up<br>substantially faster with each crawled page for the baseline<br>crawler than for the enhanced crawler. The reduction of loss<br>for these topics are 40% and 90% respectively; typically, this<br>number is between 30% and 60%. In other words, for most</span></nobr></DIV>
<DIV style="position:absolute;top:1121;left:447"><nobr><span class="ft11">156</span></nobr></DIV>
</DIV>
<!-- Page 10 -->
<a name="10"></a>
<DIV style="position:relative;width:917;height:1187;">
<STYLE type="text/css">
<!--
	.ft49{font-size:6px;line-height:12px;font-family:Helvetica;color:#000000;}
-->
</STYLE>
<IMG width="917" height="1187" src="25010.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft12">topics, the apprentice reduces the number of useless pages<br>fetched by one-third to two-thirds.</span></nobr></DIV>
<DIV style="position:absolute;top:118;left:103"><nobr><span class="ft4">In a sense, comparing loss rates is the most meaningful</span></nobr></DIV>
<DIV style="position:absolute;top:133;left:81"><nobr><span class="ft12">evaluation in our setting, because the network cost of<br>fetching relevant pages has to be paid anyway, and can be<br>regarded as a fixed cost. Diligenti et al. show significant<br>improvements in harvest rate, but for their topics, the loss<br>rate for both the baseline crawler as well as the context-<br>focused crawler were much higher than ours.</span></nobr></DIV>
<DIV style="position:absolute;top:248;left:81"><nobr><span class="ft17">3.6</span></nobr></DIV>
<DIV style="position:absolute;top:248;left:120"><nobr><span class="ft17">URL overlap and recall</span></nobr></DIV>
<DIV style="position:absolute;top:273;left:81"><nobr><span class="ft12">The reader may feel that the apprentice crawler has an<br>unfair advantage because it is first trained on DOM-derived<br>features from the same set of pages that it has to crawl<br>again. We claim that the set of pages visited by the baseline<br>crawler and the (off-line trained) enhanced crawler have<br>small overlap, and the superior results for the crawler guided<br>by the apprentice are in large part because of generalizable<br>learning. This can be seen from the examples in Figure <A href="25.html#10">11.</a></span></nobr></DIV>
<DIV style="position:absolute;top:339;left:174"><nobr><span class="ft25">Baseline</span></nobr></DIV>
<DIV style="position:absolute;top:339;left:217"><nobr><span class="ft25">Apprentice Intersect</span></nobr></DIV>
<DIV style="position:absolute;top:349;left:131"><nobr><span class="ft25">Basketball</span></nobr></DIV>
<DIV style="position:absolute;top:349;left:190"><nobr><span class="ft25">27220</span></nobr></DIV>
<DIV style="position:absolute;top:349;left:233"><nobr><span class="ft25">26280</span></nobr></DIV>
<DIV style="position:absolute;top:349;left:281"><nobr><span class="ft25">2431</span></nobr></DIV>
<DIV style="position:absolute;top:360;left:131"><nobr><span class="ft25">FolkDance</span></nobr></DIV>
<DIV style="position:absolute;top:360;left:190"><nobr><span class="ft25">14011</span></nobr></DIV>
<DIV style="position:absolute;top:360;left:238"><nobr><span class="ft25">8168</span></nobr></DIV>
<DIV style="position:absolute;top:360;left:281"><nobr><span class="ft25">2199</span></nobr></DIV>
<DIV style="position:absolute;top:370;left:131"><nobr><span class="ft25">IceHockey</span></nobr></DIV>
<DIV style="position:absolute;top:370;left:190"><nobr><span class="ft25">34121</span></nobr></DIV>
<DIV style="position:absolute;top:370;left:233"><nobr><span class="ft25">22496</span></nobr></DIV>
<DIV style="position:absolute;top:370;left:281"><nobr><span class="ft25">1657</span></nobr></DIV>
<DIV style="position:absolute;top:381;left:131"><nobr><span class="ft25">FlyFishing</span></nobr></DIV>
<DIV style="position:absolute;top:381;left:190"><nobr><span class="ft25">19252</span></nobr></DIV>
<DIV style="position:absolute;top:381;left:233"><nobr><span class="ft25">14319</span></nobr></DIV>
<DIV style="position:absolute;top:381;left:281"><nobr><span class="ft25">6834</span></nobr></DIV>
<DIV style="position:absolute;top:417;left:212"><nobr><span class="ft25">Basketball</span></nobr></DIV>
<DIV style="position:absolute;top:469;left:234"><nobr><span class="ft25">49%</span></nobr></DIV>
<DIV style="position:absolute;top:480;left:136"><nobr><span class="ft25">47%</span></nobr></DIV>
<DIV style="position:absolute;top:425;left:179"><nobr><span class="ft25">4%</span></nobr></DIV>
<DIV style="position:absolute;top:489;left:149"><nobr><span class="ft25">Baseline</span></nobr></DIV>
<DIV style="position:absolute;top:501;left:149"><nobr><span class="ft49">Apprentice<br>Intersect</span></nobr></DIV>
<DIV style="position:absolute;top:416;left:341"><nobr><span class="ft25">FolkDance</span></nobr></DIV>
<DIV style="position:absolute;top:482;left:365"><nobr><span class="ft25">57%</span></nobr></DIV>
<DIV style="position:absolute;top:474;left:266"><nobr><span class="ft25">34%</span></nobr></DIV>
<DIV style="position:absolute;top:425;left:301"><nobr><span class="ft25">9%</span></nobr></DIV>
<DIV style="position:absolute;top:490;left:278"><nobr><span class="ft25">Baseline</span></nobr></DIV>
<DIV style="position:absolute;top:503;left:278"><nobr><span class="ft49">Apprentice<br>Intersect</span></nobr></DIV>
<DIV style="position:absolute;top:532;left:213"><nobr><span class="ft25">IceHockey</span></nobr></DIV>
<DIV style="position:absolute;top:597;left:235"><nobr><span class="ft25">58%</span></nobr></DIV>
<DIV style="position:absolute;top:577;left:137"><nobr><span class="ft25">39%</span></nobr></DIV>
<DIV style="position:absolute;top:538;left:183"><nobr><span class="ft25">3%</span></nobr></DIV>
<DIV style="position:absolute;top:605;left:148"><nobr><span class="ft25">Baseline</span></nobr></DIV>
<DIV style="position:absolute;top:618;left:148"><nobr><span class="ft49">Apprentice<br>Intersect</span></nobr></DIV>
<DIV style="position:absolute;top:532;left:343"><nobr><span class="ft25">FlyFishing</span></nobr></DIV>
<DIV style="position:absolute;top:584;left:358"><nobr><span class="ft25">48%</span></nobr></DIV>
<DIV style="position:absolute;top:615;left:266"><nobr><span class="ft25">35%</span></nobr></DIV>
<DIV style="position:absolute;top:546;left:278"><nobr><span class="ft25">17%</span></nobr></DIV>
<DIV style="position:absolute;top:606;left:336"><nobr><span class="ft25">Baseline</span></nobr></DIV>
<DIV style="position:absolute;top:618;left:336"><nobr><span class="ft49">Apprentice<br>Intersect</span></nobr></DIV>
<DIV style="position:absolute;top:651;left:81"><nobr><span class="ft4">Figure 11:</span></nobr></DIV>
<DIV style="position:absolute;top:651;left:159"><nobr><span class="ft4">The apprentice-guided crawler follows paths</span></nobr></DIV>
<DIV style="position:absolute;top:666;left:81"><nobr><span class="ft12">which are quite different from the baseline crawler because<br>of its superior priority estimation technique. As a result<br>there is little overlap between the URLs harvested by these<br>two crawlers.</span></nobr></DIV>
<DIV style="position:absolute;top:759;left:103"><nobr><span class="ft4">Given that the overlap between the baseline and the</span></nobr></DIV>
<DIV style="position:absolute;top:775;left:81"><nobr><span class="ft12">enhanced crawlers is small, which is `better' ? As per the<br>verdict of the baseline classifier, clearly the enhanced crawler<br>is better. Even so, we report the loss rate of a different<br>version of the enhanced crawler which is restricted to visiting<br>only those pages which were visited by the baseline learner.<br>We call this crawler the recall crawler. This means that in<br>the end, both crawlers have collected exactly the same set<br>of pages, and therefore have the same total loss. The test<br>then is how long can the enhanced learner prevent the loss<br>from approaching the baseline loss. These experiments are a<br>rough analog of the `recall' experiments done by Rennie and<br>McCallum. We note that for these recall experiments, the<br>apprentice does get the benefit of not having to generalize,<br>so the gap between baseline loss and recall loss could be<br>optimistic. Figure <A href="25.html#10">12 </a>compares the expected total loss of<br>the baseline crawler, the recall crawler, and the apprentice-<br>guided crawler (which is free to wander outside the baseline<br>collection) plotted against the number of pages fetched, for a<br>few topics. As expected, the recall crawler has loss generally</span></nobr></DIV>
<DIV style="position:absolute;top:298;left:548"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:172;left:531"><nobr><span class="ft7">1000</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:557"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:585"><nobr><span class="ft7">1000</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:622"><nobr><span class="ft7">2000</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:658"><nobr><span class="ft7">3000</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:695"><nobr><span class="ft7">4000</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:731"><nobr><span class="ft7">5000</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:768"><nobr><span class="ft7">6000</span></nobr></DIV>
<DIV style="position:absolute;top:247;left:522"><nobr><span class="ft7">Expected #pages lost</span></nobr></DIV>
<DIV style="position:absolute;top:204;left:515"><nobr><span class="ft44"> </span></nobr></DIV>
<DIV style="position:absolute;top:323;left:635"><nobr><span class="ft7">#Pages fetched</span></nobr></DIV>
<DIV style="position:absolute;top:92;left:645"><nobr><span class="ft7">Ice Hockey</span></nobr></DIV>
<DIV style="position:absolute;top:115;left:587"><nobr><span class="ft7">Baseline</span></nobr></DIV>
<DIV style="position:absolute;top:125;left:598"><nobr><span class="ft7">Recall</span></nobr></DIV>
<DIV style="position:absolute;top:135;left:578"><nobr><span class="ft7">Apprentice</span></nobr></DIV>
<DIV style="position:absolute;top:554;left:554"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:458;left:537"><nobr><span class="ft7">5000</span></nobr></DIV>
<DIV style="position:absolute;top:362;left:532"><nobr><span class="ft7">10000</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:563"><nobr><span class="ft7">0</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:608"><nobr><span class="ft7">5000</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:658"><nobr><span class="ft7">10000</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:712"><nobr><span class="ft7">15000</span></nobr></DIV>
<DIV style="position:absolute;top:564;left:765"><nobr><span class="ft7">20000</span></nobr></DIV>
<DIV style="position:absolute;top:502;left:522"><nobr><span class="ft7">Expected #pages lost</span></nobr></DIV>
<DIV style="position:absolute;top:460;left:515"><nobr><span class="ft44"> </span></nobr></DIV>
<DIV style="position:absolute;top:579;left:638"><nobr><span class="ft7">#Pages fetched</span></nobr></DIV>
<DIV style="position:absolute;top:347;left:652"><nobr><span class="ft7">Kayaking</span></nobr></DIV>
<DIV style="position:absolute;top:371;left:593"><nobr><span class="ft7">Baseline</span></nobr></DIV>
<DIV style="position:absolute;top:381;left:604"><nobr><span class="ft7">Recall</span></nobr></DIV>
<DIV style="position:absolute;top:390;left:584"><nobr><span class="ft7">Apprentice</span></nobr></DIV>
<DIV style="position:absolute;top:596;left:475"><nobr><span class="ft12">Figure 12: Recall for a crawler using the apprentice but<br>limited to the set of pages crawled earlier by the baseline<br>crawler.</span></nobr></DIV>
<DIV style="position:absolute;top:667;left:475"><nobr><span class="ft12">somewhere between the loss of the baseline and the enhanced<br>crawler.</span></nobr></DIV>
<DIV style="position:absolute;top:718;left:475"><nobr><span class="ft17">3.7</span></nobr></DIV>
<DIV style="position:absolute;top:718;left:514"><nobr><span class="ft17">Effect of training the apprentice online</span></nobr></DIV>
<DIV style="position:absolute;top:743;left:475"><nobr><span class="ft12">Next we observe the effect of a mid-flight correction when<br>the apprentice is trained some way into a baseline and<br>switched into the circuit. The precise steps were:</span></nobr></DIV>
<DIV style="position:absolute;top:802;left:494"><nobr><span class="ft4">1. Run the baseline crawler for the first n page fetches,</span></nobr></DIV>
<DIV style="position:absolute;top:818;left:513"><nobr><span class="ft4">then stop it.</span></nobr></DIV>
<DIV style="position:absolute;top:840;left:494"><nobr><span class="ft4">2. Prepare instances and train the apprentice.</span></nobr></DIV>
<DIV style="position:absolute;top:861;left:494"><nobr><span class="ft4">3. Re-evaluate the priorities of all unvisited pages v in</span></nobr></DIV>
<DIV style="position:absolute;top:877;left:513"><nobr><span class="ft4">the frontier table using the apprentice.</span></nobr></DIV>
<DIV style="position:absolute;top:899;left:494"><nobr><span class="ft4">4. Switch in the apprentice and resume an enhanced</span></nobr></DIV>
<DIV style="position:absolute;top:915;left:513"><nobr><span class="ft4">crawl.</span></nobr></DIV>
<DIV style="position:absolute;top:942;left:475"><nobr><span class="ft12">We report our experience with "Folk Dancing." The baseline<br>crawl was stopped after 5200 pages were fetched.</span></nobr></DIV>
<DIV style="position:absolute;top:958;left:813"><nobr><span class="ft4">Re-</span></nobr></DIV>
<DIV style="position:absolute;top:974;left:475"><nobr><span class="ft12">evaluating the priority of frontier nodes led to radical<br>changes in their individual ranks as well as the priority<br>distributions. As shown in Figure <A href="25.html#11">13(a), </a>the baseline learner<br>is overly optimistic about the yield it expects from the<br>frontier, whereas the apprentice already abandons a large<br>fraction of frontier outlinks, and is less optimistic about</span></nobr></DIV>
<DIV style="position:absolute;top:1121;left:447"><nobr><span class="ft11">157</span></nobr></DIV>
</DIV>
<!-- Page 11 -->
<a name="11"></a>
<DIV style="position:relative;width:917;height:1187;">
<STYLE type="text/css">
<!--
	.ft50{font-size:7px;line-height:-7px;font-family:Helvetica;color:#000000;}
-->
</STYLE>
<IMG width="917" height="1187" src="25011.png" alt="background image">
<DIV style="position:absolute;top:286;left:114"><nobr><span class="ft4">(a)</span></nobr></DIV>
<DIV style="position:absolute;top:83;left:258"><nobr><span class="ft25">Folk Dancing</span></nobr></DIV>
<DIV style="position:absolute;top:263;left:182"><nobr><span class="ft25">0</span></nobr></DIV>
<DIV style="position:absolute;top:235;left:167"><nobr><span class="ft25">2000</span></nobr></DIV>
<DIV style="position:absolute;top:206;left:167"><nobr><span class="ft25">4000</span></nobr></DIV>
<DIV style="position:absolute;top:178;left:167"><nobr><span class="ft25">6000</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:167"><nobr><span class="ft25">8000</span></nobr></DIV>
<DIV style="position:absolute;top:121;left:162"><nobr><span class="ft25">10000</span></nobr></DIV>
<DIV style="position:absolute;top:92;left:162"><nobr><span class="ft25">12000</span></nobr></DIV>
<DIV style="position:absolute;top:276;left:208"><nobr><span class="ft25">0</span></nobr></DIV>
<DIV style="position:absolute;top:276;left:237"><nobr><span class="ft25">0-.2</span></nobr></DIV>
<DIV style="position:absolute;top:276;left:270"><nobr><span class="ft25">.2-.4</span></nobr></DIV>
<DIV style="position:absolute;top:276;left:305"><nobr><span class="ft25">.4-.6</span></nobr></DIV>
<DIV style="position:absolute;top:276;left:339"><nobr><span class="ft25">.6-.8</span></nobr></DIV>
<DIV style="position:absolute;top:276;left:375"><nobr><span class="ft25">.8-1</span></nobr></DIV>
<DIV style="position:absolute;top:285;left:236"><nobr><span class="ft25">Estimated relevance of outlinks</span></nobr></DIV>
<DIV style="position:absolute;top:195;left:164"><nobr><span class="ft38">F<br>r<br>e<br>q<br>u<br>e<br>n<br>c<br>y</span></nobr></DIV>
<DIV style="position:absolute;top:119;left:255"><nobr><span class="ft25">Baseline</span></nobr></DIV>
<DIV style="position:absolute;top:132;left:255"><nobr><span class="ft25">Apprentice</span></nobr></DIV>
<DIV style="position:absolute;top:509;left:114"><nobr><span class="ft4">(b)</span></nobr></DIV>
<DIV style="position:absolute;top:300;left:255"><nobr><span class="ft7">Folk Dancing</span></nobr></DIV>
<DIV style="position:absolute;top:492;left:166"><nobr><span class="ft7">2100</span></nobr></DIV>
<DIV style="position:absolute;top:461;left:166"><nobr><span class="ft7">2200</span></nobr></DIV>
<DIV style="position:absolute;top:431;left:166"><nobr><span class="ft7">2300</span></nobr></DIV>
<DIV style="position:absolute;top:400;left:166"><nobr><span class="ft7">2400</span></nobr></DIV>
<DIV style="position:absolute;top:369;left:166"><nobr><span class="ft7">2500</span></nobr></DIV>
<DIV style="position:absolute;top:339;left:166"><nobr><span class="ft7">2600</span></nobr></DIV>
<DIV style="position:absolute;top:308;left:166"><nobr><span class="ft7">2700</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:183"><nobr><span class="ft7">4500</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:320"><nobr><span class="ft7">5500</span></nobr></DIV>
<DIV style="position:absolute;top:505;left:226"><nobr><span class="ft7">#Pages crawled</span></nobr></DIV>
<DIV style="position:absolute;top:446;left:159"><nobr><span class="ft34">E<br>x<br>p<br>e<br>c<br>t<br>e<br>d<br>l<br>o<br>s<br>s<br>(<br>#<br>p<br>a<br>g<br>e<br>s<br>)</span></nobr></DIV>
<DIV style="position:absolute;top:472;left:297"><nobr><span class="ft15">Train<br>apprentice</span></nobr></DIV>
<DIV style="position:absolute;top:382;left:202"><nobr><span class="ft15">Collect instances<br>for apprentice</span></nobr></DIV>
<DIV style="position:absolute;top:354;left:342"><nobr><span class="ft15">Apprentice<br>guides crawl</span></nobr></DIV>
<DIV style="position:absolute;top:527;left:81"><nobr><span class="ft12">Figure 13: The effect of online training of the apprentice.<br>(a)</span></nobr></DIV>
<DIV style="position:absolute;top:543;left:111"><nobr><span class="ft4">The</span></nobr></DIV>
<DIV style="position:absolute;top:543;left:147"><nobr><span class="ft4">apprentice</span></nobr></DIV>
<DIV style="position:absolute;top:543;left:222"><nobr><span class="ft4">makes</span></nobr></DIV>
<DIV style="position:absolute;top:543;left:271"><nobr><span class="ft4">sweeping</span></nobr></DIV>
<DIV style="position:absolute;top:543;left:337"><nobr><span class="ft4">changes</span></nobr></DIV>
<DIV style="position:absolute;top:543;left:396"><nobr><span class="ft4">in</span></nobr></DIV>
<DIV style="position:absolute;top:543;left:420"><nobr><span class="ft4">the</span></nobr></DIV>
<DIV style="position:absolute;top:558;left:81"><nobr><span class="ft12">estimated promise of unvisited nodes in the crawl frontier.<br>(b) Resuming the crawl under the guidance of the<br>apprentice immediately shows significant reduction in the<br>loss accumulation rate.</span></nobr></DIV>
<DIV style="position:absolute;top:645;left:81"><nobr><span class="ft12">the others, which appears more accurate from the Bayesian<br>perspective.</span></nobr></DIV>
<DIV style="position:absolute;top:676;left:103"><nobr><span class="ft4">Figure <A href="25.html#11">13(b) </a>shows the effect of resuming an enhanced</span></nobr></DIV>
<DIV style="position:absolute;top:692;left:81"><nobr><span class="ft4">crawl guided by the trained apprentice.</span></nobr></DIV>
<DIV style="position:absolute;top:692;left:345"><nobr><span class="ft4">The new (u, v)</span></nobr></DIV>
<DIV style="position:absolute;top:708;left:81"><nobr><span class="ft12">instances are all guaranteed to be unknown to the apprentice<br>now.</span></nobr></DIV>
<DIV style="position:absolute;top:723;left:133"><nobr><span class="ft4">It is clear that the apprentice's prioritization</span></nobr></DIV>
<DIV style="position:absolute;top:739;left:81"><nobr><span class="ft12">immediately starts reducing the loss rate. Figure <A href="25.html#11">14 </a>shows<br>an even more impressive example. There are additional mild<br>gains from retraining the apprentice at later points. It may<br>be possible to show a more gradual online learning effect<br>by retraining the classifier at a finer interval, e.g., every<br>100 page fetches, similar to Aggarwal et al. In our context,<br>however, losing a thousand pages at the outset because of<br>the baseline crawler's limitation is not a disaster, so we need<br>not bother.</span></nobr></DIV>
<DIV style="position:absolute;top:900;left:81"><nobr><span class="ft17">3.8</span></nobr></DIV>
<DIV style="position:absolute;top:900;left:120"><nobr><span class="ft17">Effect of other features</span></nobr></DIV>
<DIV style="position:absolute;top:925;left:81"><nobr><span class="ft12">We experimented with two other kinds of feature, which we<br>call topic and cocitation features.</span></nobr></DIV>
<DIV style="position:absolute;top:957;left:103"><nobr><span class="ft4">Our limiting d</span></nobr></DIV>
<DIV style="position:absolute;top:961;left:193"><nobr><span class="ft9">max</span></nobr></DIV>
<DIV style="position:absolute;top:957;left:221"><nobr><span class="ft4">to 5 may deprive the apprentice of</span></nobr></DIV>
<DIV style="position:absolute;top:972;left:81"><nobr><span class="ft12">important features in the source page u which are far from<br>the link (u, v).</span></nobr></DIV>
<DIV style="position:absolute;top:988;left:184"><nobr><span class="ft4">One indirect way to reveal such features</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:81"><nobr><span class="ft12">to the apprentice is to classify u, and to add the names<br>of some of the top-scoring classes for u to the instance<br>(u, v).</span></nobr></DIV>
<DIV style="position:absolute;top:1034;left:123"><nobr><span class="ft4">§<A href="25.html#5">2.2.3 </a>explains why this may help. This modification</span></nobr></DIV>
<DIV style="position:absolute;top:1051;left:81"><nobr><span class="ft12">resulted in a 1% increase in the accuracy of the apprentice.<br>A further increase of 1% was observed if we added all</span></nobr></DIV>
<DIV style="position:absolute;top:82;left:609"><nobr><span class="ft7">Classical Composers</span></nobr></DIV>
<DIV style="position:absolute;top:268;left:545"><nobr><span class="ft7">600</span></nobr></DIV>
<DIV style="position:absolute;top:238;left:545"><nobr><span class="ft7">800</span></nobr></DIV>
<DIV style="position:absolute;top:209;left:540"><nobr><span class="ft7">1000</span></nobr></DIV>
<DIV style="position:absolute;top:179;left:540"><nobr><span class="ft7">1200</span></nobr></DIV>
<DIV style="position:absolute;top:150;left:540"><nobr><span class="ft7">1400</span></nobr></DIV>
<DIV style="position:absolute;top:120;left:540"><nobr><span class="ft7">1600</span></nobr></DIV>
<DIV style="position:absolute;top:91;left:540"><nobr><span class="ft7">1800</span></nobr></DIV>
<DIV style="position:absolute;top:282;left:558"><nobr><span class="ft7">2000</span></nobr></DIV>
<DIV style="position:absolute;top:282;left:591"><nobr><span class="ft7">3000</span></nobr></DIV>
<DIV style="position:absolute;top:282;left:624"><nobr><span class="ft7">4000</span></nobr></DIV>
<DIV style="position:absolute;top:282;left:657"><nobr><span class="ft7">5000</span></nobr></DIV>
<DIV style="position:absolute;top:282;left:690"><nobr><span class="ft7">6000</span></nobr></DIV>
<DIV style="position:absolute;top:282;left:723"><nobr><span class="ft7">7000</span></nobr></DIV>
<DIV style="position:absolute;top:282;left:756"><nobr><span class="ft7">8000</span></nobr></DIV>
<DIV style="position:absolute;top:291;left:634"><nobr><span class="ft7">#Pages fetched</span></nobr></DIV>
<DIV style="position:absolute;top:251;left:537"><nobr><span class="ft30">C<br>u<br>m<br>u<br>l<br>a<br>t<br>i<br>v<br>e<br>e<br>x<br>p<br>e<br>c<br>t<br>e<br>d<br>l<br>o<br>s<br>s<br>(<br>#<br>p<br>a<br>g<br>e<br>s<br>)</span></nobr></DIV>
<DIV style="position:absolute;top:133;left:582"><nobr><span class="ft15">Collect<br>instances for<br>apprentice</span></nobr></DIV>
<DIV style="position:absolute;top:217;left:647"><nobr><span class="ft15">Train<br>apprentice</span></nobr></DIV>
<DIV style="position:absolute;top:156;left:701"><nobr><span class="ft15">Apprentice<br>guides crawl</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:475"><nobr><span class="ft4">Figure 14:</span></nobr></DIV>
<DIV style="position:absolute;top:311;left:553"><nobr><span class="ft4">Another example of training the apprentice</span></nobr></DIV>
<DIV style="position:absolute;top:326;left:475"><nobr><span class="ft12">online followed by starting to use it for crawl guidance.<br>Before guidance, loss accumulation rate is over 30%, after,<br>it drops to only 6%.</span></nobr></DIV>
<DIV style="position:absolute;top:400;left:475"><nobr><span class="ft4">prefixes of the class name.</span></nobr></DIV>
<DIV style="position:absolute;top:400;left:659"><nobr><span class="ft4">For example, the full name</span></nobr></DIV>
<DIV style="position:absolute;top:415;left:475"><nobr><span class="ft28">for the Linux category is /Computers/Software/Operating_<br>Systems/Linux.</span></nobr></DIV>
<DIV style="position:absolute;top:431;left:589"><nobr><span class="ft4">We added all of the following to the</span></nobr></DIV>
<DIV style="position:absolute;top:447;left:475"><nobr><span class="ft12">feature set of the source page: /, /Computers, /Computers/<br>Software, /Computers/Software/Operating_Systems and<br>/Computers/Software/Operating_Systems/Linux. We also<br>noted that various class names and some of their prefixes<br>appeared amongst the best discriminants of the positive and<br>negative classes.</span></nobr></DIV>
<DIV style="position:absolute;top:541;left:498"><nobr><span class="ft4">Cocitation features for the link (u, v) are constructed by</span></nobr></DIV>
<DIV style="position:absolute;top:557;left:475"><nobr><span class="ft4">looking for other links (u, w) within a DOM distance of d</span></nobr></DIV>
<DIV style="position:absolute;top:561;left:813"><nobr><span class="ft9">max</span></nobr></DIV>
<DIV style="position:absolute;top:572;left:475"><nobr><span class="ft4">such that w has already been fetched, so that Pr(c</span></nobr></DIV>
<DIV style="position:absolute;top:569;left:793"><nobr><span class="ft9"></span></nobr></DIV>
<DIV style="position:absolute;top:572;left:799"><nobr><span class="ft4">|w) is</span></nobr></DIV>
<DIV style="position:absolute;top:588;left:475"><nobr><span class="ft4">known. We discretize Pr(c</span></nobr></DIV>
<DIV style="position:absolute;top:585;left:634"><nobr><span class="ft9"></span></nobr></DIV>
<DIV style="position:absolute;top:587;left:641"><nobr><span class="ft4">|w) to two values high and low</span></nobr></DIV>
<DIV style="position:absolute;top:604;left:475"><nobr><span class="ft4">as in</span></nobr></DIV>
<DIV style="position:absolute;top:603;left:509"><nobr><span class="ft4"><A href="25.html#5">§2.3, </a>and encode the feature as low, d or high, d .</span></nobr></DIV>
<DIV style="position:absolute;top:619;left:475"><nobr><span class="ft12">The use of cocitation features did not improve the accuracy<br>of the apprentice to any appreciable extent.</span></nobr></DIV>
<DIV style="position:absolute;top:651;left:498"><nobr><span class="ft4">For both kinds of features, we estimated that random</span></nobr></DIV>
<DIV style="position:absolute;top:666;left:475"><nobr><span class="ft12">variations in crawling behavior (because of fluctuating<br>network load and tie-breaking frontier scores) may prevent<br>us from measuring an actual benefit to crawling under<br>realistic operating conditions. We note that these ideas may<br>be useful in other settings.</span></nobr></DIV>
<DIV style="position:absolute;top:767;left:475"><nobr><span class="ft1">4</span></nobr></DIV>
<DIV style="position:absolute;top:767;left:505"><nobr><span class="ft1">Conclusion</span></nobr></DIV>
<DIV style="position:absolute;top:799;left:475"><nobr><span class="ft12">We have presented a simple enhancement to a focused<br>crawler that helps assign better priorities to the unvisited<br>URLs in the crawl frontier. This leads to a higher rate of<br>fetching pages relevant to the focus topic and fewer false<br>positives which must be discarded after spending network,<br>CPU and storage resources processing them. There is no<br>need to manually train the system with paths leading to<br>relevant pages. The key idea is an apprentice learner which<br>can accurately predict the worth of fetching a page using<br>DOM features on pages that link to it. We show that the<br>DOM features we use are superior to simpler alternatives.<br>Using topics from Dmoz, we show that our new system can<br>cut down the fraction of false positives by 30­90%.</span></nobr></DIV>
<DIV style="position:absolute;top:1003;left:498"><nobr><span class="ft4">We are exploring several directions in ongoing work.</span></nobr></DIV>
<DIV style="position:absolute;top:1019;left:475"><nobr><span class="ft12">We wish to revisit continuous regression techniques for the<br>apprentice, as well as more extensive features derived from<br>the DOM. For example, we can associate with a token t the<br>length</span></nobr></DIV>
<DIV style="position:absolute;top:1066;left:526"><nobr><span class="ft4">of the DOM path from the text node containing t to</span></nobr></DIV>
<DIV style="position:absolute;top:1121;left:447"><nobr><span class="ft11">158</span></nobr></DIV>
</DIV>
<!-- Page 12 -->
<a name="12"></a>
<DIV style="position:relative;width:917;height:1187;">
<STYLE type="text/css">
<!--
-->
</STYLE>
<IMG width="917" height="1187" src="25012.png" alt="background image">
<DIV style="position:absolute;top:86;left:81"><nobr><span class="ft12">the HREF to v, or the depth of their least common ancestor<br>in the DOM tree. We cannot use these in lieu of DOM offset,<br>because regions which are far apart lexically may be close<br>to each other along a DOM path.</span></nobr></DIV>
<DIV style="position:absolute;top:133;left:304"><nobr><span class="ft4">t, , d features will be</span></nobr></DIV>
<DIV style="position:absolute;top:149;left:81"><nobr><span class="ft12">more numerous and sparser than t, d features, and could<br>be harder to learn. The introduction of large numbers of<br>strongly dependent features may even reduce the accuracy<br>of the apprentice. Finally, we wish to implement some form<br>of active learning where only those instances (u, v) with the<br>largest</span></nobr></DIV>
<DIV style="position:absolute;top:227;left:125"><nobr><span class="ft4">| Pr(c</span></nobr></DIV>
<DIV style="position:absolute;top:224;left:157"><nobr><span class="ft9"></span></nobr></DIV>
<DIV style="position:absolute;top:227;left:163"><nobr><span class="ft4">|u) - Pr(c</span></nobr></DIV>
<DIV style="position:absolute;top:224;left:221"><nobr><span class="ft9"></span></nobr></DIV>
<DIV style="position:absolute;top:227;left:227"><nobr><span class="ft4">|v)| are chosen as training instances</span></nobr></DIV>
<DIV style="position:absolute;top:243;left:81"><nobr><span class="ft4">for the apprentice.</span></nobr></DIV>
<DIV style="position:absolute;top:266;left:81"><nobr><span class="ft4">Acknowledgments:</span></nobr></DIV>
<DIV style="position:absolute;top:266;left:224"><nobr><span class="ft4">Thanks to the referees for suggest-</span></nobr></DIV>
<DIV style="position:absolute;top:282;left:81"><nobr><span class="ft4">ing that we present Figure <A href="25.html#8">7.</a></span></nobr></DIV>
<DIV style="position:absolute;top:316;left:81"><nobr><span class="ft1">References</span></nobr></DIV>
<DIV style="position:absolute;top:343;left:87"><nobr><span class="ft3">[1] C. C. Aggarwal, F. Al-Garawi, and P. S. Yu.</span></nobr></DIV>
<DIV style="position:absolute;top:343;left:386"><nobr><span class="ft3">Intelligent</span></nobr></DIV>
<DIV style="position:absolute;top:355;left:107"><nobr><span class="ft13">crawling on the World Wide Web with arbitrary predicates. In<br>WWW2001, Hong Kong, May 2001. ACM.</span></nobr></DIV>
<DIV style="position:absolute;top:367;left:354"><nobr><span class="ft3">Online at <A href="http://www10.org/cdrom/papers/110/">http:</a></span></nobr></DIV>
<DIV style="position:absolute;top:380;left:107"><nobr><span class="ft3"><A href="http://www10.org/cdrom/papers/110/">//www10.org/cdrom/papers/110/</a>.</span></nobr></DIV>
<DIV style="position:absolute;top:393;left:87"><nobr><span class="ft3">[2] C. Apte, F. Damerau, and S. M. Weiss.</span></nobr></DIV>
<DIV style="position:absolute;top:393;left:334"><nobr><span class="ft3">Automated learning</span></nobr></DIV>
<DIV style="position:absolute;top:405;left:107"><nobr><span class="ft13">of decision rules for text categorization. ACM Transactions on<br>Information Systems, 1994. IBM Research Report RC18879.</span></nobr></DIV>
<DIV style="position:absolute;top:431;left:87"><nobr><span class="ft3">[3] A. Blum and T. M. Mitchell. Combining labeled and unlabeled</span></nobr></DIV>
<DIV style="position:absolute;top:443;left:107"><nobr><span class="ft3">data with co-training.</span></nobr></DIV>
<DIV style="position:absolute;top:443;left:240"><nobr><span class="ft3">In Computational Learning Theory,</span></nobr></DIV>
<DIV style="position:absolute;top:455;left:107"><nobr><span class="ft3">pages 92­100, 1998.</span></nobr></DIV>
<DIV style="position:absolute;top:469;left:87"><nobr><span class="ft3">[4] S. Chakrabarti.</span></nobr></DIV>
<DIV style="position:absolute;top:469;left:199"><nobr><span class="ft3">Integrating the document object model with</span></nobr></DIV>
<DIV style="position:absolute;top:481;left:107"><nobr><span class="ft13">hyperlinks for enhanced topic distillation and information<br>extraction.</span></nobr></DIV>
<DIV style="position:absolute;top:493;left:174"><nobr><span class="ft3">In WWW 10, Hong Kong, May 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:493;left:388"><nobr><span class="ft3">Online at</span></nobr></DIV>
<DIV style="position:absolute;top:506;left:107"><nobr><span class="ft3"><A href="http://www10.org/cdrom/papers/489">http://www10.org/cdrom/papers/489</a>.</span></nobr></DIV>
<DIV style="position:absolute;top:520;left:87"><nobr><span class="ft3">[5] S. Chakrabarti,</span></nobr></DIV>
<DIV style="position:absolute;top:520;left:202"><nobr><span class="ft3">B. Dom,</span></nobr></DIV>
<DIV style="position:absolute;top:520;left:261"><nobr><span class="ft3">R. Agrawal,</span></nobr></DIV>
<DIV style="position:absolute;top:520;left:338"><nobr><span class="ft3">and P. Raghavan.</span></nobr></DIV>
<DIV style="position:absolute;top:531;left:107"><nobr><span class="ft13">Scalable feature selection, classification and signature generation<br>for organizing large text databases into hierarchical topic<br>taxonomies.</span></nobr></DIV>
<DIV style="position:absolute;top:555;left:184"><nobr><span class="ft3">VLDB Journal, Aug. 1998.</span></nobr></DIV>
<DIV style="position:absolute;top:555;left:352"><nobr><span class="ft3">Online at <A href="http://www.cs.berkeley.edu/~soumen/VLDB54_3.PDF">http:</a></span></nobr></DIV>
<DIV style="position:absolute;top:568;left:107"><nobr><span class="ft3"><A href="http://www.cs.berkeley.edu/~soumen/VLDB54_3.PDF">//www.cs.berkeley.edu/~soumen/VLDB54_3.PDF</a>.</span></nobr></DIV>
<DIV style="position:absolute;top:582;left:87"><nobr><span class="ft3">[6] S. Chakrabarti, B. Dom, D. Gibson, J. Kleinberg, P. Raghavan,</span></nobr></DIV>
<DIV style="position:absolute;top:594;left:107"><nobr><span class="ft3">and S. Rajagopalan.</span></nobr></DIV>
<DIV style="position:absolute;top:594;left:242"><nobr><span class="ft3">Automatic resource compilation by</span></nobr></DIV>
<DIV style="position:absolute;top:605;left:107"><nobr><span class="ft14">analyzing hyperlink structure and associated text. In 7th World-<br>wide web conference (WWW7), 1998. Online at <A href="http://www7.scu.edu.au/programme/fullpapers/1898/com1898.html">http://www7.<br>scu.edu.au/programme/fullpapers/1898/com1898.html</a>.</span></nobr></DIV>
<DIV style="position:absolute;top:644;left:87"><nobr><span class="ft3">[7] S. Chakrabarti, B. Dom, and P. Indyk.</span></nobr></DIV>
<DIV style="position:absolute;top:644;left:332"><nobr><span class="ft3">Enhanced hypertext</span></nobr></DIV>
<DIV style="position:absolute;top:656;left:107"><nobr><span class="ft14">categorization using hyperlinks. In SIGMOD Conference. ACM,<br>1998. Online at <A href="http://www.cs.berkeley.edu/~soumen/sigmod98.ps">http://www.cs.berkeley.edu/~soumen/sigmod98.<br>ps.</a></span></nobr></DIV>
<DIV style="position:absolute;top:694;left:87"><nobr><span class="ft3">[8] S.</span></nobr></DIV>
<DIV style="position:absolute;top:694;left:126"><nobr><span class="ft3">Chakrabarti,</span></nobr></DIV>
<DIV style="position:absolute;top:694;left:204"><nobr><span class="ft3">B.</span></nobr></DIV>
<DIV style="position:absolute;top:694;left:225"><nobr><span class="ft3">E.</span></nobr></DIV>
<DIV style="position:absolute;top:694;left:245"><nobr><span class="ft3">Dom,</span></nobr></DIV>
<DIV style="position:absolute;top:694;left:284"><nobr><span class="ft3">D.</span></nobr></DIV>
<DIV style="position:absolute;top:694;left:306"><nobr><span class="ft3">A.</span></nobr></DIV>
<DIV style="position:absolute;top:694;left:328"><nobr><span class="ft3">Gibson,</span></nobr></DIV>
<DIV style="position:absolute;top:694;left:378"><nobr><span class="ft3">R.</span></nobr></DIV>
<DIV style="position:absolute;top:694;left:400"><nobr><span class="ft3">Kumar,</span></nobr></DIV>
<DIV style="position:absolute;top:706;left:107"><nobr><span class="ft13">P. Raghavan, S. Rajagopalan, and A. Tomkins. Topic distillation<br>and spectral filtering.</span></nobr></DIV>
<DIV style="position:absolute;top:718;left:239"><nobr><span class="ft3">Artificial Intelligence Review, 13(5­</span></nobr></DIV>
<DIV style="position:absolute;top:730;left:107"><nobr><span class="ft3">6):409­435, 1999.</span></nobr></DIV>
<DIV style="position:absolute;top:744;left:87"><nobr><span class="ft3">[9] S. Chakrabarti, M. van den Berg, and B. Dom.</span></nobr></DIV>
<DIV style="position:absolute;top:744;left:398"><nobr><span class="ft3">Focused</span></nobr></DIV>
<DIV style="position:absolute;top:756;left:107"><nobr><span class="ft3">crawling:</span></nobr></DIV>
<DIV style="position:absolute;top:756;left:169"><nobr><span class="ft3">a new approach to topic-specific web resource</span></nobr></DIV>
<DIV style="position:absolute;top:768;left:107"><nobr><span class="ft3">discovery.</span></nobr></DIV>
<DIV style="position:absolute;top:768;left:172"><nobr><span class="ft3">Computer Networks, 31:1623­1640, 1999.</span></nobr></DIV>
<DIV style="position:absolute;top:768;left:414"><nobr><span class="ft3">First</span></nobr></DIV>
<DIV style="position:absolute;top:780;left:107"><nobr><span class="ft13">appeared in the 8th International World Wide Web Conference,<br>Toronto,</span></nobr></DIV>
<DIV style="position:absolute;top:792;left:162"><nobr><span class="ft3">May</span></nobr></DIV>
<DIV style="position:absolute;top:792;left:195"><nobr><span class="ft3">1999.</span></nobr></DIV>
<DIV style="position:absolute;top:792;left:231"><nobr><span class="ft3">Available</span></nobr></DIV>
<DIV style="position:absolute;top:792;left:289"><nobr><span class="ft3">online</span></nobr></DIV>
<DIV style="position:absolute;top:792;left:330"><nobr><span class="ft3">at</span></nobr></DIV>
<DIV style="position:absolute;top:792;left:350"><nobr><span class="ft3"><A href="http://www8.org/w8-papers/5a-search-query/crawling/index.html">http://www8.org/</a></span></nobr></DIV>
<DIV style="position:absolute;top:804;left:107"><nobr><span class="ft3"><A href="http://www8.org/w8-papers/5a-search-query/crawling/index.html">w8-papers/5a-search-query/crawling/index.html</a>.</span></nobr></DIV>
<DIV style="position:absolute;top:818;left:81"><nobr><span class="ft3">[10] J. Cho, H. Garcia-Molina, and L. Page.</span></nobr></DIV>
<DIV style="position:absolute;top:818;left:346"><nobr><span class="ft3">Efficient crawling</span></nobr></DIV>
<DIV style="position:absolute;top:830;left:107"><nobr><span class="ft14">through URL ordering. In 7th World Wide Web Conference,<br>Brisbane, Australia, Apr. 1998. Online at <A href="http://www7.scu.edu.au/programme/fullpapers/1919/com1919.htm">http://www7.scu.edu.<br>au/programme/fullpapers/1919/com1919.htm</a>.</span></nobr></DIV>
<DIV style="position:absolute;top:868;left:81"><nobr><span class="ft3">[11] B. D. Davison.</span></nobr></DIV>
<DIV style="position:absolute;top:868;left:198"><nobr><span class="ft3">Topical locality in the Web.</span></nobr></DIV>
<DIV style="position:absolute;top:868;left:361"><nobr><span class="ft3">In Proceedings</span></nobr></DIV>
<DIV style="position:absolute;top:880;left:107"><nobr><span class="ft14">of the 23rd Annual International Conference on Research and<br>Development in Information Retrieval (SIGIR 2000), pages<br>272­279, Athens, Greece, July 2000. ACM. Online at <A href="http://www.cs.rutgers.edu/~davison/pubs/2000/sigir/">http://<br>www.cs.rutgers.edu/~davison/pubs/2000/sigir/</a>.</span></nobr></DIV>
<DIV style="position:absolute;top:930;left:81"><nobr><span class="ft3">[12] P. M. E. De Bra and R. D. J. Post.</span></nobr></DIV>
<DIV style="position:absolute;top:930;left:328"><nobr><span class="ft3">Information retrieval</span></nobr></DIV>
<DIV style="position:absolute;top:942;left:107"><nobr><span class="ft14">in the world-wide web: Making client-based searching feasible.<br>In Proceedings of the First International World Wide Web<br>Conference, Geneva, Switzerland, 1994. Online at <A href="http://www1.cern.ch/PapersWWW94/reinpost.ps">http://www1.<br>cern.ch/PapersWWW94/reinpost.ps</a>.</span></nobr></DIV>
<DIV style="position:absolute;top:992;left:81"><nobr><span class="ft3">[13] P. M. E. De Bra and R. D. J. Post.</span></nobr></DIV>
<DIV style="position:absolute;top:992;left:317"><nobr><span class="ft3">Searching for arbitrary</span></nobr></DIV>
<DIV style="position:absolute;top:1004;left:107"><nobr><span class="ft13">information in the WWW: The fish search for Mosaic. In Second<br>World Wide Web Conference '94:</span></nobr></DIV>
<DIV style="position:absolute;top:1016;left:315"><nobr><span class="ft3">Mosaic and the Web,</span></nobr></DIV>
<DIV style="position:absolute;top:1028;left:107"><nobr><span class="ft3">Chicago, Oct. 1994.</span></nobr></DIV>
<DIV style="position:absolute;top:1028;left:222"><nobr><span class="ft3">Online at <A href="http://archive.ncsa.uiuc.edu/SDG/IT94/Proceedings/Searching/debra/article.html">http://archive.ncsa.uiuc.edu/</a></span></nobr></DIV>
<DIV style="position:absolute;top:1041;left:107"><nobr><span class="ft13"><A href="http://archive.ncsa.uiuc.edu/SDG/IT94/Proceedings/Searching/debra/article.html">SDG/IT94/Proceedings/Searching/debra/article.html </a>and <A href="http://citeseer.nj.nec.com/172936.html">http:<br>//citeseer.nj.nec.com/172936.html</a>.</span></nobr></DIV>
<DIV style="position:absolute;top:88;left:475"><nobr><span class="ft3">[14] M. Diligenti, F. Coetzee, S. Lawrence, C. L. Giles, and M. Gori.</span></nobr></DIV>
<DIV style="position:absolute;top:100;left:501"><nobr><span class="ft13">Focused crawling using context graphs. In A. E. Abbadi, M. L.<br>Brodie, S. Chakravarthy, U. Dayal, N. Kamel, G. Schlageter,<br>and</span></nobr></DIV>
<DIV style="position:absolute;top:124;left:530"><nobr><span class="ft3">K.-Y.</span></nobr></DIV>
<DIV style="position:absolute;top:124;left:568"><nobr><span class="ft3">Whang,</span></nobr></DIV>
<DIV style="position:absolute;top:124;left:619"><nobr><span class="ft3">editors,</span></nobr></DIV>
<DIV style="position:absolute;top:124;left:668"><nobr><span class="ft3">VLDB</span></nobr></DIV>
<DIV style="position:absolute;top:124;left:713"><nobr><span class="ft3">2000,</span></nobr></DIV>
<DIV style="position:absolute;top:124;left:752"><nobr><span class="ft3">Proceedings</span></nobr></DIV>
<DIV style="position:absolute;top:124;left:824"><nobr><span class="ft3">of</span></nobr></DIV>
<DIV style="position:absolute;top:136;left:501"><nobr><span class="ft14">26th International Conference on Very Large Data Bases,<br>September 10-14, 2000, Cairo, Egypt, pages 527­534. Morgan<br>Kaufmann, 2000. Online at <A href="http://www.neci.nec.com/~lawrence/papers/focus-vldb00/focus-vldb00.pdf">http://www.neci.nec.com/~lawrence/<br>papers/focus-vldb00/focus-vldb00.pdf.</a></span></nobr></DIV>
<DIV style="position:absolute;top:186;left:475"><nobr><span class="ft3">[15] W. A. Gale, K. W. Church, and D. Yarowsky. A method for</span></nobr></DIV>
<DIV style="position:absolute;top:198;left:501"><nobr><span class="ft13">disambiguating word senses in a large corpus. Computer and<br>the Humanities, 26:415­439, 1993.</span></nobr></DIV>
<DIV style="position:absolute;top:224;left:475"><nobr><span class="ft3">[16] M. Hersovici, M. Jacovi, Y. S. Maarek, D. Pelleg, M. Shtalhaim,</span></nobr></DIV>
<DIV style="position:absolute;top:236;left:501"><nobr><span class="ft14">and S. Ur. The shark-search algorithm--an application: Tailored<br>Web site mapping. In WWW7, 1998. Online at <A href="http://www7.scu.edu.au/programme/fullpapers/1849/com1849.htm">http://www7.scu.<br>edu.au/programme/fullpapers/1849/com1849.htm.</a></span></nobr></DIV>
<DIV style="position:absolute;top:274;left:475"><nobr><span class="ft3">[17] T. Joachims, D. Freitag, and T. Mitchell. WebWatcher: A tour</span></nobr></DIV>
<DIV style="position:absolute;top:286;left:501"><nobr><span class="ft14">guide for the web. In IJCAI, Aug. 1997. Online at <A href="http://www.cs.cmu.edu/~webwatcher/ijcai97.ps">http://www.<br>cs.cmu.edu/~webwatcher/ijcai97.ps.</a></span></nobr></DIV>
<DIV style="position:absolute;top:313;left:475"><nobr><span class="ft3">[18] H. Leiberman. Letizia: An agent that assists Web browsing. In</span></nobr></DIV>
<DIV style="position:absolute;top:325;left:501"><nobr><span class="ft14">International Joint Conference on Artificial Intelligence (IJ-<br>CAI), Montreal, Aug. 1995. See Website at <A href="http://lieber.www.media.mit.edu/people/lieber/Lieberary/Letizia/Letizia.html">http://lieber.www.<br>media.mit.edu/people/lieber/Lieberary/Letizia/Letizia.html.</a></span></nobr></DIV>
<DIV style="position:absolute;top:363;left:475"><nobr><span class="ft3">[19] H. Leiberman, C. Fry, and L. Weitzman.</span></nobr></DIV>
<DIV style="position:absolute;top:363;left:733"><nobr><span class="ft3">Exploring the Web</span></nobr></DIV>
<DIV style="position:absolute;top:375;left:501"><nobr><span class="ft3">with reconnaissance agents.</span></nobr></DIV>
<DIV style="position:absolute;top:375;left:660"><nobr><span class="ft3">CACM, 44(8):69­75, Aug. 2001.</span></nobr></DIV>
<DIV style="position:absolute;top:387;left:501"><nobr><span class="ft3"><A href="http://www.acm.org/cacm">http://www.acm.org/cacm</a>.</span></nobr></DIV>
<DIV style="position:absolute;top:401;left:475"><nobr><span class="ft3">[20] A. McCallum. Bow: A toolkit for statistical language modeling,</span></nobr></DIV>
<DIV style="position:absolute;top:413;left:501"><nobr><span class="ft13">text retrieval, classification and clustering. Software available<br>from <A href="http://www.cs.cmu.edu/~mccallum/bow/">http://www.cs.cmu.edu/~mccallum/bow/, </a>1998.</span></nobr></DIV>
<DIV style="position:absolute;top:439;left:475"><nobr><span class="ft3">[21] A. McCallum and K. Nigam. A comparison of event models for</span></nobr></DIV>
<DIV style="position:absolute;top:451;left:501"><nobr><span class="ft13">naive Bayes text classification. In AAAI/ICML-98 Workshop<br>on Learning for Text Categorization, pages 41­48. AAAI Press,<br>1998. Online at <A href="http://www.cs.cmu.edu/~knigam/">http://www.cs.cmu.edu/~knigam/.</a></span></nobr></DIV>
<DIV style="position:absolute;top:489;left:475"><nobr><span class="ft3">[22] A. McCallum and K. Nigam. A comparison of event models for</span></nobr></DIV>
<DIV style="position:absolute;top:501;left:501"><nobr><span class="ft13">naive Bayes text classification. In AAAI/ICML-98 Workshop<br>on Learning for Text Categorization, pages 41­48. AAAI Press,<br>1998.</span></nobr></DIV>
<DIV style="position:absolute;top:525;left:538"><nobr><span class="ft3">Also technical report WS-98-05, CMU; online at <A href="http://www.cs.cmu.edu/~knigam/papers/multinomial-aaaiws98.pdf">http:</a></span></nobr></DIV>
<DIV style="position:absolute;top:538;left:501"><nobr><span class="ft3"><A href="http://www.cs.cmu.edu/~knigam/papers/multinomial-aaaiws98.pdf">//www.cs.cmu.edu/~knigam/papers/multinomial-aaaiws98.pdf</a>.</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:475"><nobr><span class="ft3">[23] F.</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:522"><nobr><span class="ft3">Menczer.</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:591"><nobr><span class="ft3">Links</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:630"><nobr><span class="ft3">tell</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:656"><nobr><span class="ft3">us</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:677"><nobr><span class="ft3">about</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:717"><nobr><span class="ft3">lexical</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:760"><nobr><span class="ft3">and</span></nobr></DIV>
<DIV style="position:absolute;top:551;left:788"><nobr><span class="ft3">semantic</span></nobr></DIV>
<DIV style="position:absolute;top:563;left:501"><nobr><span class="ft3">Web content.</span></nobr></DIV>
<DIV style="position:absolute;top:563;left:586"><nobr><span class="ft3">Technical Report Computer Science Abstract</span></nobr></DIV>
<DIV style="position:absolute;top:575;left:501"><nobr><span class="ft14">CS.IR/0108004, arXiv.org, Aug. 2001. Online at <A href="http://arxiv.org/abs/cs.IR/0108004">http://arxiv.<br>org/abs/cs.IR/0108004</a>.</span></nobr></DIV>
<DIV style="position:absolute;top:601;left:475"><nobr><span class="ft3">[24] F. Menczer and R. K. Belew.</span></nobr></DIV>
<DIV style="position:absolute;top:601;left:691"><nobr><span class="ft3">Adaptive retrieval agents:</span></nobr></DIV>
<DIV style="position:absolute;top:613;left:501"><nobr><span class="ft13">Internalizing local context and scaling up to the Web. Machine<br>Learning, 39(2/3):203­242, 2000.</span></nobr></DIV>
<DIV style="position:absolute;top:625;left:689"><nobr><span class="ft3">Longer version available as</span></nobr></DIV>
<DIV style="position:absolute;top:637;left:501"><nobr><span class="ft14">Technical Report CS98-579, <A href="http://dollar.biz.uiowa.edu/~fil/Papers/MLJ.ps">http://dollar.biz.uiowa.edu/~fil/<br>Papers/MLJ.ps, </a>University of California, San Diego.</span></nobr></DIV>
<DIV style="position:absolute;top:663;left:475"><nobr><span class="ft3">[25] F. Menczer, G. Pant, M. Ruiz, and P. Srinivasan. Evaluating</span></nobr></DIV>
<DIV style="position:absolute;top:675;left:501"><nobr><span class="ft13">topic-driven Web crawlers. In SIGIR, New Orleans, Sept. 2001.<br>ACM.</span></nobr></DIV>
<DIV style="position:absolute;top:687;left:550"><nobr><span class="ft3">Online at <A href="http://dollar.biz.uiowa.edu/~fil/Papers/sigir-01.pdf">http://dollar.biz.uiowa.edu/~fil/Papers/</a></span></nobr></DIV>
<DIV style="position:absolute;top:700;left:501"><nobr><span class="ft3"><A href="http://dollar.biz.uiowa.edu/~fil/Papers/sigir-01.pdf">sigir-01.pdf.</a></span></nobr></DIV>
<DIV style="position:absolute;top:713;left:475"><nobr><span class="ft3">[26] T. Mitchell. Machine Learning. McGraw Hill, 1997.</span></nobr></DIV>
<DIV style="position:absolute;top:727;left:475"><nobr><span class="ft3">[27] T. Mitchell. Mining the Web. In SIGIR 2001, Sept. 2001. Invited</span></nobr></DIV>
<DIV style="position:absolute;top:739;left:501"><nobr><span class="ft3">talk.</span></nobr></DIV>
<DIV style="position:absolute;top:754;left:475"><nobr><span class="ft3">[28] S. Mukherjea.</span></nobr></DIV>
<DIV style="position:absolute;top:754;left:585"><nobr><span class="ft3">WTMS: a system for collecting and analyzing</span></nobr></DIV>
<DIV style="position:absolute;top:765;left:501"><nobr><span class="ft14">topic-specific Web information. WWW9/Computer Networks,<br>33(1­6):457­471, 2000. Online at <A href="http://www9.org/w9cdrom/293/293.html">http://www9.org/w9cdrom/293/<br>293.html.</a></span></nobr></DIV>
<DIV style="position:absolute;top:804;left:475"><nobr><span class="ft3">[29] S. RaviKumar, P. Raghavan, S. Rajagopalan, D. Sivakumar,</span></nobr></DIV>
<DIV style="position:absolute;top:816;left:501"><nobr><span class="ft14">A. Tomkins, and E. Upfal. Stochastic models for the Web graph.<br>In FOCS, volume 41, pages 57­65. IEEE, nov 2000. Online at<br><A href="http://www.cs.brown.edu/people/eli/papers/focs00.ps">http://www.cs.brown.edu/people/eli/papers/focs00.ps.</a></span></nobr></DIV>
<DIV style="position:absolute;top:854;left:475"><nobr><span class="ft3">[30] J. Rennie and A. McCallum. Using reinforcement learning to</span></nobr></DIV>
<DIV style="position:absolute;top:866;left:501"><nobr><span class="ft14">spider the web efficiently. In ICML, 1999. Online at <A href="http://www.cs.cmu.edu/~mccallum/papers/rlspider-icml99s.ps.gz">http://<br>www.cs.cmu.edu/~mccallum/papers/rlspider-icml99s.ps.gz</a>.</span></nobr></DIV>
<DIV style="position:absolute;top:892;left:475"><nobr><span class="ft3">[31] G.</span></nobr></DIV>
<DIV style="position:absolute;top:892;left:523"><nobr><span class="ft3">Salton</span></nobr></DIV>
<DIV style="position:absolute;top:892;left:566"><nobr><span class="ft3">and</span></nobr></DIV>
<DIV style="position:absolute;top:892;left:595"><nobr><span class="ft3">M.</span></nobr></DIV>
<DIV style="position:absolute;top:892;left:618"><nobr><span class="ft3">J.</span></nobr></DIV>
<DIV style="position:absolute;top:892;left:637"><nobr><span class="ft3">McGill.</span></nobr></DIV>
<DIV style="position:absolute;top:892;left:697"><nobr><span class="ft3">Introduction</span></nobr></DIV>
<DIV style="position:absolute;top:892;left:773"><nobr><span class="ft3">to</span></nobr></DIV>
<DIV style="position:absolute;top:892;left:793"><nobr><span class="ft3">Modern</span></nobr></DIV>
<DIV style="position:absolute;top:904;left:501"><nobr><span class="ft3">Information Retrieval. McGraw-Hill, 1983.</span></nobr></DIV>
<DIV style="position:absolute;top:918;left:475"><nobr><span class="ft3">[32] M. Subramanyam, G. V. R. Phanindra, M. Tiwari, and M. Jain.</span></nobr></DIV>
<DIV style="position:absolute;top:930;left:501"><nobr><span class="ft3">Focused crawling using TFIDF centroid.</span></nobr></DIV>
<DIV style="position:absolute;top:930;left:728"><nobr><span class="ft3">Hypertext Retrieval</span></nobr></DIV>
<DIV style="position:absolute;top:942;left:501"><nobr><span class="ft13">and Mining (CS610) class project, Apr. 2001. Details available<br>from manyam@cs.utexas.edu.</span></nobr></DIV>
<DIV style="position:absolute;top:968;left:475"><nobr><span class="ft3">[33] L. Torgo and J. Gama. Regression by classification. In D. Borges</span></nobr></DIV>
<DIV style="position:absolute;top:980;left:501"><nobr><span class="ft14">and C. Kaestner, editors, Brasilian AI Symposium, volume 1159<br>of Lecture Notes in Artificial Intelligence, Curitiba, Brazil,<br>1996. Springer-Verlag. Online at <A href="http://www.ncc.up.pt/~ltorgo/Papers/list_pub.html">http://www.ncc.up.pt/~ltorgo/<br>Papers/list_pub.html.</a></span></nobr></DIV>
<DIV style="position:absolute;top:1121;left:447"><nobr><span class="ft11">159</span></nobr></DIV>
</DIV>
</BODY>
</HTML>
